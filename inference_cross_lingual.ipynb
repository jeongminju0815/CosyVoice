{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff104921-de2f-4f2c-a6cd-36f277f5be20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 15:01:57,695 - modelscope - INFO - PyTorch version 2.0.0 Found.\n",
      "2025-03-21 15:01:57,697 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
      "2025-03-21 15:01:57,856 - modelscope - INFO - Loading done! Current index file version is 1.15.0, with md5 13b7082244438de82b16012a4fd7baad and a total number of 980 components indexed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to import ttsfrd, use WeTextProcessing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
      "  deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n",
      "2025-03-21 15:02:05,735 INFO input frame rate=25\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:115: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n",
      "2025-03-21 15:02:10,375 WETEXT INFO building fst for zh_normalizer ...\n",
      "2025-03-21 15:02:10,375 INFO building fst for zh_normalizer ...\n",
      "2025-03-21 15:02:52,831 WETEXT INFO done\n",
      "2025-03-21 15:02:52,831 INFO done\n",
      "2025-03-21 15:02:52,833 WETEXT INFO fst path: /data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/tn/zh_tn_tagger.fst\n",
      "2025-03-21 15:02:52,833 INFO fst path: /data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/tn/zh_tn_tagger.fst\n",
      "2025-03-21 15:02:52,834 WETEXT INFO           /data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/tn/zh_tn_verbalizer.fst\n",
      "2025-03-21 15:02:52,834 INFO           /data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/tn/zh_tn_verbalizer.fst\n",
      "2025-03-21 15:02:52,841 WETEXT INFO found existing fst: /data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/tn/en_tn_tagger.fst\n",
      "2025-03-21 15:02:52,841 INFO found existing fst: /data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/tn/en_tn_tagger.fst\n",
      "2025-03-21 15:02:52,842 WETEXT INFO                     /data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/tn/en_tn_verbalizer.fst\n",
      "2025-03-21 15:02:52,842 INFO                     /data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/tn/en_tn_verbalizer.fst\n",
      "2025-03-21 15:02:52,844 WETEXT INFO skip building fst for en_normalizer ...\n",
      "2025-03-21 15:02:52,844 INFO skip building fst for en_normalizer ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/21/2025-15:03:10] [TRT] [I] Loaded engine size: 290 MiB\n",
      "[03/21/2025-15:03:11] [TRT] [E] 1: [defaultAllocator.cpp::allocate::19] Error Code 1: Cuda Runtime (out of memory)\n",
      "[03/21/2025-15:03:11] [TRT] [W] Requested amount of GPU memory (9170563584 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.\n",
      "[03/21/2025-15:03:11] [TRT] [E] 2: [executionContext.cpp::ExecutionContext::552] Error Code 2: OutOfMemory (no further information)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('third_party/Matcha-TTS')\n",
    "from cosyvoice.cli.cosyvoice import CosyVoice, CosyVoice2\n",
    "from cosyvoice.utils.file_utils import load_wav\n",
    "import torchaudio\n",
    "from IPython.display import Audio\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# cosyvoice = CosyVoice2('pretrained_models/CosyVoice2-0.5B', load_jit=False, load_trt=False, fp16=False)\n",
    "cosyvoice = CosyVoice2('/data/minju/TTS/CosyVoice/pretrained_models/CosyVoice2-0.5B', load_jit=True, load_trt=True, fp16=False)\n",
    "#cosyvoice = CosyVoice('./pretrained_models/CosyVoice-300M',load_jit=False, load_trt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fee5072-7c4f-418c-a887-f05901c6d8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tony_default_0420_base_00019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update! <|en|> There is a hypothesis that the hippocampus, a brain region that plays a key role in memory formation, is not fully developed in infants.\n",
      "33\n",
      "update! \n",
      "0\n",
      "max value is  tensor(1.0034)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 15:03:22,677 INFO synthesis text <|en|> There is a hypothesis that the hippocampus, a brain region that plays a key role in memory formation, is not fully developed in infants.\n",
      "  0%|          | 0/1 [00:25<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'set_input_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m total_tensor \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     21\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cosyvoice\u001b[38;5;241m.\u001b[39minference_cross_lingual(tts_text, prompt_speech_16k, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)):\n\u001b[1;32m     23\u001b[0m     total_tensor\u001b[38;5;241m.\u001b[39mappend(j[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtts_speech\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m#torchaudio.save(f'{save_path}/{refer_name}_{i}_{tts_text[:3]}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\u001b[39;00m\n",
      "File \u001b[0;32m/data/minju/TTS/CosyVoice_origin/cosyvoice/cli/cosyvoice.py:97\u001b[0m, in \u001b[0;36mCosyVoice.inference_cross_lingual\u001b[0;34m(self, tts_text, prompt_speech_16k, stream, speed, text_frontend)\u001b[0m\n\u001b[1;32m     95\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     96\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msynthesis text \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i))\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtts(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_input, stream\u001b[38;5;241m=\u001b[39mstream, speed\u001b[38;5;241m=\u001b[39mspeed):\n\u001b[1;32m     98\u001b[0m     speech_len \u001b[38;5;241m=\u001b[39m model_output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtts_speech\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_rate\n\u001b[1;32m     99\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myield speech len \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, rtf \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(speech_len, (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m/\u001b[39m speech_len))\n",
      "File \u001b[0;32m/data/minju/TTS/CosyVoice_origin/cosyvoice/cli/model.py:383\u001b[0m, in \u001b[0;36mCosyVoice2Model.tts\u001b[0;34m(self, text, flow_embedding, llm_embedding, prompt_text, llm_prompt_speech_token, flow_prompt_speech_token, prompt_speech_feat, stream, speed, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m     p\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m    382\u001b[0m     this_tts_speech_token \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_speech_token_dict[this_uuid])\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 383\u001b[0m     this_tts_speech \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken2wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthis_tts_speech_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mprompt_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow_prompt_speech_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mprompt_feat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_speech_feat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43muuid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthis_uuid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mtoken_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mspeed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtts_speech\u001b[39m\u001b[38;5;124m'\u001b[39m: this_tts_speech\u001b[38;5;241m.\u001b[39mcpu()}\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlock:\n",
      "File \u001b[0;32m/data/minju/TTS/CosyVoice_origin/cosyvoice/cli/model.py:306\u001b[0m, in \u001b[0;36mCosyVoice2Model.token2wav\u001b[0;34m(self, token, prompt_token, prompt_feat, embedding, uuid, token_offset, finalize, speed)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtoken2wav\u001b[39m(\u001b[38;5;28mself\u001b[39m, token, prompt_token, prompt_feat, embedding, uuid, token_offset, finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, speed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n\u001b[0;32m--> 306\u001b[0m     tts_mel, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mtoken_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mprompt_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_token\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mprompt_token_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt_token\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mprompt_feat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_feat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mprompt_feat_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt_feat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinalize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     tts_mel \u001b[38;5;241m=\u001b[39m tts_mel[:, :, token_offset \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow\u001b[38;5;241m.\u001b[39mtoken_mel_ratio:]\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# append hift cache\u001b[39;00m\n",
      "File \u001b[0;32m/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/minju/TTS/CosyVoice_origin/cosyvoice/flow/flow.py:230\u001b[0m, in \u001b[0;36mCausalMaskedDiffWithXvec.inference\u001b[0;34m(self, token, token_len, prompt_token, prompt_token_len, prompt_feat, prompt_feat_len, embedding, finalize)\u001b[0m\n\u001b[1;32m    227\u001b[0m conds \u001b[38;5;241m=\u001b[39m conds\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    229\u001b[0m mask \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m~\u001b[39mmake_pad_mask(torch\u001b[38;5;241m.\u001b[39mtensor([mel_len1 \u001b[38;5;241m+\u001b[39m mel_len2])))\u001b[38;5;241m.\u001b[39mto(h)\n\u001b[0;32m--> 230\u001b[0m feat, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m    236\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m feat \u001b[38;5;241m=\u001b[39m feat[:, :, mel_len1:]\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m feat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m mel_len2\n",
      "File \u001b[0;32m/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/minju/TTS/CosyVoice_origin/cosyvoice/flow/flow_matching.py:214\u001b[0m, in \u001b[0;36mCausalConditionalCFM.forward\u001b[0;34m(self, mu, mask, n_timesteps, temperature, spks, cond)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_scheduler \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    213\u001b[0m     t_span \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mcos(t_span \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mpi)\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve_euler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_span\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_span\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data/minju/TTS/CosyVoice_origin/cosyvoice/flow/flow_matching.py:106\u001b[0m, in \u001b[0;36mConditionalCFM.solve_euler\u001b[0;34m(self, x, t_span, mu, mask, spks, cond)\u001b[0m\n\u001b[1;32m    104\u001b[0m spks_in[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m spks\n\u001b[1;32m    105\u001b[0m cond_in[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m cond\n\u001b[0;32m--> 106\u001b[0m dphi_dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_estimator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmu_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspks_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcond_in\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m dphi_dt, cfg_dphi_dt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(dphi_dt, [x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    113\u001b[0m dphi_dt \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_cfg_rate) \u001b[38;5;241m*\u001b[39m dphi_dt \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_cfg_rate \u001b[38;5;241m*\u001b[39m cfg_dphi_dt)\n",
      "File \u001b[0;32m/data/minju/TTS/CosyVoice_origin/cosyvoice/flow/flow_matching.py:126\u001b[0m, in \u001b[0;36mConditionalCFM.forward_estimator\u001b[0;34m(self, x, mask, mu, t, spks, cond)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mforward(x, mask, mu, t, spks, cond)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_input_shape\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m80\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mset_input_shape(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m, (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mset_input_shape(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmu\u001b[39m\u001b[38;5;124m'\u001b[39m, (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m80\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m)))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'set_input_shape'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "refer_audio = '/data/minju/TTS/CosyVoice/refer/men_love_refer.wav'\n",
    "refer_audio = '/data/minju/TTS/CosyVoice/refer/men_love_refer_02.wav'\n",
    "refer_audio = '/data/minju/TTS/CosyVoice/refer/tony_default_0420_base_00019.wav'\n",
    "refer_name = refer_audio.split(\"/\")[-1].replace(\".wav\", \"\")\n",
    "print(refer_name)\n",
    "prompt_speech_16k = load_wav(refer_audio, 16000)\n",
    "tts_text = \"오늘은 대기 정체와 국외 미세먼지까지 유입되면서 공기 질이 나쁘겠는데요.\"\n",
    "tts_text = \"선수 시절뿐 아니라 각종 선거에서 이변을 일으켜온 그답게 이번에도 그 진가를 보여줬다. 이번 체육회장 선거는 이기흥 현 회장 당선 가능성이 높다는 예상이 지배적이었다. 선거인단 구성 자체도 이 회장에게 유리하다는 지적이 있었다. 추첨으로 뽑히는 인원 외에 전국 이백이십팔개 시 군 구 체육회에서 추천한 인사가 선거인단에 포함되는 지정 선거인 제도가 도입됐는데 현직 회장으로 지역 체육회와 접촉이 많았던 이 회장을 위한 제도라는 비판이 있었다. 실제 이날 투표 현장에선 유 후보가 당선되자 환호성을 지르는 젊은 체육인들이 대거 눈에 띄었다. 대한체육회 전직 임원은 젊은 체육인들이 변화를 원했다. 체육인들을 만나보면 한국 체육계가 나이 드신 분들이 권위를 내세워 끌고 간다는 비판이 많았다. 젊은 사람이 와서 변화를 이끌어줬으면 하는 바람이 많았다고 전했다.\"\n",
    "tts_text = \"<|en|>I have never been in a relationship with my ideal type.\"\n",
    "tts_text = \"<|jp|>理想型に恋愛するただ一度もやったことはありません。\"\n",
    "tts_text = \"<|jp|>私は理想のタイプと付き合ったことがない。\"\n",
    "# tts_text = \"<|zh|>我从来没有经历过一段符合我理想类型的关系。\"\n",
    "tts_text = '<|en|>There is a hypothesis that the hippocampus, a brain region that plays a key role in memory formation, is not fully developed in infants.'\n",
    "# prompt_text = '손석희 전 앵커와 진행한 퇴임전 마지막 언론 대담 인터뷰 내일부터 이틀간 방송을 앞두고 있습니다.'\n",
    "# prompt_text = '이상형에 부합하는 연애 단 한번도 해본적 없습니다.'\n",
    "\n",
    "save_path = f'output-vc/250320-men-love'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "total_tensor = []\n",
    "start = time.time()\n",
    "for i, j in enumerate(cosyvoice.inference_cross_lingual(tts_text, prompt_speech_16k, stream=False)):\n",
    "    total_tensor.append(j['tts_speech'])\n",
    "    #torchaudio.save(f'{save_path}/{refer_name}_{i}_{tts_text[:3]}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "concatenated_tensor = torch.cat(total_tensor, dim=-1)\n",
    "torchaudio.save(f'{save_path}/{refer_name}_f_{tts_text[:3]}.wav', concatenated_tensor, cosyvoice.sample_rate)\n",
    "Audio(f'{save_path}/{refer_name}_f_{tts_text[:3]}.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b03fc-4e68-4486-91a6-99ac224111e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosyvoice",
   "language": "python",
   "name": "cosyvoice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
