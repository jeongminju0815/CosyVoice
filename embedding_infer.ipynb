{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de9b8192-95a9-4a63-b8e9-b5c57174de42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 05:03:33,046 - modelscope - INFO - PyTorch version 2.0.0 Found.\n",
      "2025-01-13 05:03:33,048 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
      "2025-01-13 05:03:33,084 - modelscope - INFO - Loading done! Current index file version is 1.15.0, with md5 13b7082244438de82b16012a4fd7baad and a total number of 980 components indexed\n",
      "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
      "  deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n",
      "2025-01-13 05:03:42,263 INFO input frame rate=50\n",
      "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:115: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-13 05:04:00,129] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 05:04:00,305 INFO gcc -pthread -B /data/minju/conda/envs/cosyvoice/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/minju/conda/envs/cosyvoice/include -fPIC -O2 -isystem /data/minju/conda/envs/cosyvoice/include -fPIC -c /tmp/tmpptz30zo0/test.c -o /tmp/tmpptz30zo0/test.o\n",
      "2025-01-13 05:04:00,553 INFO gcc -pthread -B /data/minju/conda/envs/cosyvoice/compiler_compat /tmp/tmpptz30zo0/test.o -laio -o /tmp/tmpptz30zo0/a.out\n",
      "/data/minju/conda/envs/cosyvoice/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m NVIDIA Inference is only supported on Ampere and newer architectures\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible\n",
      "{'sample_rate': 22050, 'text_encoder_input_size': 512, 'llm_input_size': 1024, 'llm_output_size': 1024, 'spk_embed_dim': 192, 'llm': TransformerLM(\n",
      "  (text_embedding): Embedding(51866, 512)\n",
      "  (text_encoder): ConformerEncoder(\n",
      "    (embed): LinearNoSubsampling(\n",
      "      (out): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (pos_enc): EspnetRelPositionalEncoding(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (after_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (encoders): ModuleList(\n",
      "      (0-5): 6 x ConformerEncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (linear_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (linear_out): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear_pos): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (activation): SiLU()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (w_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "        (norm_ff): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (text_encoder_affine_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (llm_embedding): Embedding(2, 1024)\n",
      "  (llm): TransformerEncoder(\n",
      "    (embed): LegacyLinearNoSubsampling(\n",
      "      (out): Sequential(\n",
      "        (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (pos_enc): EspnetRelPositionalEncoding(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (after_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (encoders): ModuleList(\n",
      "      (0-13): 14 x TransformerEncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (linear_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (linear_out): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear_pos): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (activation): ReLU()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (w_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (llm_decoder): Linear(in_features=1024, out_features=4097, bias=True)\n",
      "  (criterion_ce): LabelSmoothingLoss(\n",
      "    (criterion): KLDivLoss()\n",
      "  )\n",
      "  (speech_embedding): Embedding(4096, 1024)\n",
      "  (spk_embed_affine_layer): Linear(in_features=192, out_features=1024, bias=True)\n",
      "), 'flow': None, 'hift': None, 'parquet_opener': <function parquet_opener at 0x7f26a4684c10>, 'get_tokenizer': functools.partial(<functools._lru_cache_wrapper object at 0x7f2713745010>, multilingual=True, num_languages=100, language='ko', task='transcribe'), 'allowed_special': 'all', 'tokenize': functools.partial(<function tokenize at 0x7f26a42c8a60>, get_tokenizer=functools.partial(<functools._lru_cache_wrapper object at 0x7f2713745010>, multilingual=True, num_languages=100, language='ko', task='transcribe'), allowed_special='all'), 'filter': functools.partial(<function filter at 0x7f26a4684ee0>, max_length=40960, min_length=0, token_max_length=200, token_min_length=1), 'resample': functools.partial(<function resample at 0x7f26a4684f70>, resample_rate=22050), 'feat_extractor': functools.partial(<function mel_spectrogram at 0x7f269d79b760>, n_fft=1024, num_mels=80, sampling_rate=22050, hop_size=256, win_size=1024, fmin=0, fmax=8000, center=False), 'compute_fbank': functools.partial(<function compute_fbank at 0x7f26a42c88b0>, feat_extractor=functools.partial(<function mel_spectrogram at 0x7f269d79b760>, n_fft=1024, num_mels=80, sampling_rate=22050, hop_size=256, win_size=1024, fmin=0, fmax=8000, center=False)), 'parse_embedding': functools.partial(<function parse_embedding at 0x7f26a42c89d0>, normalize=True), 'shuffle': functools.partial(<function shuffle at 0x7f26a42c8af0>, shuffle_size=1000), 'sort': functools.partial(<function sort at 0x7f26a42c8b80>, sort_size=500), 'batch': functools.partial(<function batch at 0x7f26a42c8d30>, batch_type='dynamic', max_frames_in_batch=2000), 'padding': <function padding at 0x7f26a42c8dc0>, 'data_pipeline': [<function parquet_opener at 0x7f26a4684c10>, functools.partial(<function tokenize at 0x7f26a42c8a60>, get_tokenizer=functools.partial(<functools._lru_cache_wrapper object at 0x7f2713745010>, multilingual=True, num_languages=100, language='ko', task='transcribe'), allowed_special='all'), functools.partial(<function filter at 0x7f26a4684ee0>, max_length=40960, min_length=0, token_max_length=200, token_min_length=1), functools.partial(<function resample at 0x7f26a4684f70>, resample_rate=22050), functools.partial(<function compute_fbank at 0x7f26a42c88b0>, feat_extractor=functools.partial(<function mel_spectrogram at 0x7f269d79b760>, n_fft=1024, num_mels=80, sampling_rate=22050, hop_size=256, win_size=1024, fmin=0, fmax=8000, center=False)), functools.partial(<function parse_embedding at 0x7f26a42c89d0>, normalize=True), functools.partial(<function shuffle at 0x7f26a42c8af0>, shuffle_size=1000), functools.partial(<function sort at 0x7f26a42c8b80>, sort_size=500), functools.partial(<function batch at 0x7f26a42c8d30>, batch_type='dynamic', max_frames_in_batch=2000), <function padding at 0x7f26a42c8dc0>], 'train_conf': {'optim': 'adam', 'optim_conf': {'lr': 0.001}, 'scheduler': 'warmuplr', 'scheduler_conf': {'warmup_steps': 2500}, 'max_epoch': 200, 'grad_clip': 5, 'accum_grad': 2, 'log_interval': 100, 'save_per_step': -1}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('third_party/Matcha-TTS')\n",
    "\n",
    "from cosyvoice.cli.cosyvoice import CosyVoice\n",
    "from cosyvoice.utils.file_utils import load_wav\n",
    "import torchaudio\n",
    "\n",
    "cosyvoice = CosyVoice('./pretrained_models/CosyVoice-300M',load_jit=False, load_trt=False)\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "from cosyvoice.utils.train_utils import (\n",
    "init_distributed,\n",
    "init_dataset_and_dataloader,\n",
    "init_optimizer_and_scheduler,\n",
    "init_summarywriter, save_model,\n",
    "wrap_cuda_model, check_modify_and_save_config)\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "\n",
    "config_file = \"./pretrained_models/CosyVoice-300M/cosyvoice.yaml\"\n",
    "\n",
    "override_dict = {k: None for k in ['llm', 'flow', 'hift'] if k != \"llm\"}\n",
    "\n",
    "with open(config_file, 'r') as f:\n",
    "    configs = load_hyperpyyaml(f, overrides=override_dict)\n",
    "\n",
    "#configs['train_conf'].update(vars(args))\n",
    "\n",
    "print(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "135791a8-45a0-41e2-ab57-886cae626c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tony', 'elley', 'roy', 'eden', 'rudy', 'noa', 'ruby', 'lye', 'jenny', 'secretary_ian', 'secretary_roun', 'secretary_joy', 'bitna_bright', 'bitna_default', 'hayun_bright_1.05', 'hayun_default_1.05', 'kyeon_bright', 'kyeon_default', 'sanggyun_default', 'sehyeok_bright', 'sehyeok_default', 'wansun_default_1.05', 'yongmin_default_1.05', 'yuna_bright', 'yuna_default_1.05', 'boram_bright', 'tony_default_1.05', 'boram_default', 'kyungil_default_1.05', 'slx_speakers_KAIST_males_2', 'slx_speakers_del_JIHYANG', 'slx_speakers_SEHA_fastpitch', 'donghee_default', 'donghee_bright', 'F-A3-D', 'F-H3-D', 'F-NY-D', 'F-S3-D', 'F-A3-A', 'F-H3-A', 'F-NY-A', 'F-S3-A', 'F-A2-A', 'F-H2-A', 'F-S2-A', 'F-A2-E', 'F-H2-E', 'F-NY-E', 'F-S2-E', 'F-A1-C', 'F-H1-C', 'F-NY-C', 'F-S1-C', 'F-NX-A', 'F-A3-B', 'F-H3-B', 'F-NY-B', 'F-S3-B', 'F-A1-Q', 'F-H1-Q', 'F-NX-Q', 'F-S1-Q', 'F-A2-Q', 'F-H2-Q', 'F-NY-Q', 'F-S2-Q', 'N-NX-D', 'D-A2-C', 'D-H2-C', 'D-NX-C', 'D-S2-C', 'D-A2-F', 'D-H2-F', 'D-NX-F', 'D-S2-F', 'D-A1-D', 'D-A2-D', 'D-A3-D', 'D-H1-D', 'D-H2-D', 'D-H3-D', 'D-NX-D', 'D-NY-D', 'D-S1-D', 'D-S2-D', 'D-S3-D', 'D-A3-A', 'D-H3-A', 'D-NX-A', 'D-S3-A', 'D-A3-F', 'D-H3-F', 'D-S3-F', 'D-A3-C', 'D-H3-C', 'D-S3-C', 'D-A2-A', 'D-H2-A', 'D-S2-A', 'D-NY-A', 'D-A3-E', 'D-H3-E', 'D-NX-E', 'D-S3-E', 'D-A3-B', 'D-H3-B', 'D-NX-B', 'D-S3-B', 'D-A1-B', 'D-H1-B', 'D-NY-B', 'D-S1-B', 'D-A1-A', 'D-H1-A', 'D-S1-A', 'M-A3-C', 'M-H3-C', 'M-NX-C', 'M-S3-C', 'M-A3-E', 'sweetcon', 'M-NX-E', 'M-S3-E', 'M-A1-D', 'M-A2-D', 'M-A3-D', 'M-H1-D', 'M-H2-D', 'M-H3-D', 'M-NX-D', 'M-NY-D', 'M-S1-D', 'M-S2-D', 'M-S3-D', 'M-A3-F', 'M-H3-F', 'M-NX-F', 'M-S3-F', 'M-A2-A', 'M-H2-A', 'M-NX-A', 'M-S2-A', 'M-A2-B', 'M-H2-B', 'M-NX-B', 'M-S2-B', 'M-A2-E', 'M-H2-E', 'M-NY-E', 'M-S2-E', 'M-A1-A', 'M-H1-A', 'M-NY-A', 'M-S1-A', 'M-A1-E', 'M-H1-E', 'M-S1-E', 'M-A2-F', 'M-H2-F', 'M-NY-F', 'M-S2-F', 'M-A3-A', 'M-H3-A', 'M-S3-A', 'M-NY-B', 'A-A2-D', 'A-H2-D', 'sunbeacon', 'A-S2-D', 'A-A1-A', 'A-H1-A', 'A-NX-A', 'A-S1-A', 'A-A1-F', 'A-H1-F', 'A-NX-F', 'A-S1-F', 'A-A2-A', 'A-H2-A', 'A-S2-A', 'A-NX-D', 'A-A1-B', 'A-H1-B', 'A-NX-B', 'A-S1-B', 'mzcon', 'A-A2-E', 'happycon', 'A-NX-E', 'A-S2-E', 'chimneycon', 'grumblingcon', 'A-H3-F', 'A-S3-F', 'A-A1-G', 'A-H1-G', 'A-NX-G', 'A-S1-G', 'A-A3-A', 'A-H3-A', 'A-S3-A', 'A-A3-D', 'A-H3-D', 'A-S3-D', 'A-A3-E', 'A-H3-E', 'A-S3-E', 'A-A3-B', 'A-H3-B', 'A-S3-B', 'A-A2-G', 'A-H2-G', 'A-S2-G', 'S-XX-D', 'S-XY-D', 'S-XZ-D', 'S-YX-D', 'S-YY-D', 'S-YZ-D', 'S-ZX-D', 'S-ZZ-D', 'S-XZ-F', 'S-YZ-F', 'S-ZZ-F', 'S-XZ-A', 'S-YZ-A', 'S-ZZ-A', 'S-XX-F', 'S-XY-F', 'S-YX-F', 'S-YY-F', 'S-ZX-F', 'S-XZ-B', 'S-YZ-B', 'S-ZZ-B', 'S-XX-A', 'S-YX-A', 'S-ZX-A', 'S-NX-A', 'S-XY-E', 'S-YY-E', 'S-ZX-E', 'S-XX-E', 'S-YX-E', 'S-XX-G', 'S-YX-G', 'S-ZX-G', 'S-NX-E', 'S-XZ-E', 'S-YZ-E', 'S-ZZ-E', 'S-NX-D', 'S-XY-A', 'S-YY-A', 'K-A3-C', 'K-H3-C', 'K-NX-C', 'K-S3-C', 'K-A3-F', 'K-H3-F', 'K-NY-F', 'K-S3-F', 'K-A3-A', 'K-H3-A', 'K-NX-A', 'K-S3-A', 'K-H2-A', 'K-H2-F', 'K-NX-F', 'madamcon', 'K-NY-A', 'K-A1-D', 'K-A3-D', 'K-H1-D', 'K-H2-D', 'K-H3-D', 'K-NY-D', 'K-S3-D', 'K-A3-B', 'K-H2-B', 'K-NX-B', 'K-S3-B', 'K-NX-D', 'K-A1-F', 'K-H1-F', 'K-S1-F', 'K-A1-B', 'K-H1-B', 'K-NZ-B', 'K-S1-B', 'K-A1-E', 'K-H2-E', 'K-NY-E', 'K-S1-E', 'K-NZ-E', 'K-NZ-F', 'K-A1-C', 'K-H1-C', 'K-NZ-C', 'K-S1-C', 'K-A1-A', 'K-H1-A', 'K-S1-A', 'K-A1-G', 'K-H1-G', 'K-NZ-G', 'K-S1-G', 'K-NY-C', 'K-H1-E']\n",
      "309\n",
      "['cardergarden']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "## 임베딩 파일 경로 변경\n",
    "print(cosyvoice.list_available_spks())\n",
    "print(len(cosyvoice.list_available_spks()))\n",
    "\n",
    "emb_path = \"/data/minju/TTS/CosyVoice/embedding_models/son-ploonet/spk2info.pt\"\n",
    "# emb_path = \"/data/minju/TTS/CosyVoice/embedding_models/slx/spk2info.pt\"\n",
    "# emb_path = \"/data/minju/TTS/CosyVoice/embedding_models/semi/spk2info.pt\"\n",
    "emb_path = \"/data/minju/TTS/CosyVoice/embedding_models/senti-slx/spk2info.pt\"\n",
    "emb_path = \"/data/minju/TTS/CosyVoice/embedding_models/cardergarden/spk2info.pt\"\n",
    "emb_type = emb_path.split(\"/\")[-2]\n",
    "spk2info = torch.load(emb_path, map_location = \"cuda\")\n",
    "cosyvoice.frontend.spk2info = spk2info\n",
    "\n",
    "print(cosyvoice.list_available_spks())\n",
    "print(len(cosyvoice.list_available_spks()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbb85a65-de14-428f-8622-0a7bc259db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import os\n",
    "\n",
    "# 모델 변경\n",
    "# sft usage\n",
    "# change stream=True for chunk stream inference\n",
    "epoch = 20\n",
    "flag = True\n",
    "\n",
    "if flag:\n",
    "    model = configs[\"llm\"]\n",
    "    model.load_state_dict(torch.load(f\"/data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250111-son-ploonet/llm/torch_ddp/epoch_{epoch}_whole.pt\", map_location='cuda'), strict=False)\n",
    "    cosyvoice.model.llm = model.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f8631a0-f3ec-4ded-b241-9512532c060d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 06:20:15,509 INFO synthesis text 오늘부터 사나흘에 걸쳐 충남과 호남 지역 제주도 등에 많은 눈이 내리겠습니다。이 시각 대설주의보가 내려진 전북 고창의 모습을 보면 거리에 눈이 쌓인 가운데 굵은 눈이 펑펑 쏟아지고 있습니다。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text dtype: torch.int32\n",
      "text_len dtype: torch.int32\n",
      "prompt_text dtype: torch.int32\n",
      "prompt_text_len dtype: torch.int32\n",
      "prompt_speech_token dtype: torch.int32\n",
      "prompt_speech_token_len dtype: torch.int32\n",
      "embedding dtype: torch.float32\n",
      "embedding dtype after normalize: torch.float32\n",
      "embedding dtype after affine layer: torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 06:20:39,423 INFO yield speech len 14.675011337868481, rtf 1.629567438850026\n",
      "2025-01-13 06:20:39,436 INFO synthesis text 서해안에서 강한 눈구름대가 유입되면서 서쪽 지역을 중심으로 눈이 내리고 있습니다。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text dtype: torch.int32\n",
      "text_len dtype: torch.int32\n",
      "prompt_text dtype: torch.int32\n",
      "prompt_text_len dtype: torch.int32\n",
      "prompt_speech_token dtype: torch.int32\n",
      "prompt_speech_token_len dtype: torch.int32\n",
      "embedding dtype: torch.float32\n",
      "embedding dtype after normalize: torch.float32\n",
      "embedding dtype after affine layer: torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 06:20:50,723 INFO yield speech len 6.048798185941043, rtf 1.8659880544790095\n",
      "100%|██████████| 2/2 [00:35<00:00, 17.61s/it]\n"
     ]
    }
   ],
   "source": [
    "speaker = \"cardergarden\"\n",
    "text = \"오늘부터 사나흘에 걸쳐 충남과 호남 지역 제주도 등에 많은 눈이 내리겠습니다. 이 시각 대설주의보가 내려진 전북 고창의 모습을 보면 거리에 눈이 쌓인 가운데 굵은 눈이 펑펑 쏟아지고 있습니다. 서해안에서 강한 눈구름대가 유입되면서 서쪽 지역을 중심으로 눈이 내리고 있습니다.\"\n",
    "# text = \"끊임없이 올라가기만 하고 재미없어요. 내려오기도 해야 재밌죠. 오르락 내리락이있으니까 재미라는게 생기는거죠.\"\n",
    "# text = \"그룹 블랙핑크 로제와 팝스타 브루노 마스가 함께 부른 아파트가 빌보드 차트에서 전주보다 이십 구 계단 상승하며 오위에 올랐습니다.\"\n",
    "output_path = \"output-emb/250113\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "save_path = f\"{output_path}/sft_{emb_type}_{speaker}_{flag}_{text[:3]}\"\n",
    "for i, j in enumerate(cosyvoice.inference_sft(text, speaker, stream=False)):\n",
    "    torchaudio.save(f\"{save_path}_{i}.wav\", j['tts_speech'], cosyvoice.sample_rate)\n",
    "    #Audio(f\"{save_path}_{i}.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fc701a-d82f-4aa9-ac5c-5321964dc99a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosyvoice",
   "language": "python",
   "name": "cosyvoice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
