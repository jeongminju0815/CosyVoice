Run train. We only support llm traning for now. If your want to train from scratch, please use conf/cosyvoice.fromscratch.yaml
llm_train.sh: 18: [: torch_ddp: unexpected operator
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2025-01-10 05:20:31,967] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-10 05:20:31,975] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-10 05:20:31,982] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m NVIDIA Inference is only supported on Ampere and newer architectures
[93m [WARNING] [0m NVIDIA Inference is only supported on Ampere and newer architectures
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m NVIDIA Inference is only supported on Ampere and newer architectures
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
2025-01-10 05:20:37,914 INFO training on multiple gpus, this gpu 1, rank 1, world_size 3
2025-01-10 05:20:37,985 INFO training on multiple gpus, this gpu 0, rank 0, world_size 3
2025-01-10 05:20:38,098 INFO training on multiple gpus, this gpu 2, rank 2, world_size 3
2025-01-10 05:20:38,100 INFO Added key: store_based_barrier_key:1 to store for rank: 2
2025-01-10 05:20:38,916 INFO Added key: store_based_barrier_key:1 to store for rank: 1
2025-01-10 05:20:38,926 INFO Added key: store_based_barrier_key:1 to store for rank: 0
2025-01-10 05:20:38,926 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
2025-01-10 05:20:38,926 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
2025-01-10 05:20:38,935 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
start step 0 start epoch -1
start step 0 start epoch -1
2025-01-10 05:20:42,748 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/init.pt
start step 0 start epoch -1
2025-01-10 05:20:42,781 INFO Added key: store_based_barrier_key:2 to store for rank: 0
2025-01-10 05:20:42,791 INFO Added key: store_based_barrier_key:2 to store for rank: 1
2025-01-10 05:20:42,791 INFO Added key: store_based_barrier_key:2 to store for rank: 2
2025-01-10 05:20:42,791 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 3 nodes.
2025-01-10 05:20:42,791 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 3 nodes.
2025-01-10 05:20:42,791 INFO Epoch 0 TRAIN info lr 4e-07 rank 1
2025-01-10 05:20:42,791 INFO Epoch 0 TRAIN info lr 4e-07 rank 0
2025-01-10 05:20:42,791 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 05:20:42,791 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 05:20:42,791 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:2 with 3 nodes.
2025-01-10 05:20:42,791 INFO Epoch 0 TRAIN info lr 4e-07 rank 2
2025-01-10 05:20:42,791 INFO using accumulate grad, new batch size is 2 times larger than before
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
2025-01-10 05:21:14,257 DEBUG TRAIN Batch 0/100 loss 1.217812 acc 0.344512 lr 0.00002040 grad_norm 0.681026 rank 1
2025-01-10 05:21:14,257 DEBUG TRAIN Batch 0/100 loss 1.256413 acc 0.338999 lr 0.00002040 grad_norm 0.681026 rank 0
2025-01-10 05:21:14,258 DEBUG TRAIN Batch 0/100 loss 1.245216 acc 0.319714 lr 0.00002040 grad_norm 0.681026 rank 2
2025-01-10 05:21:38,184 DEBUG TRAIN Batch 0/200 loss 1.176485 acc 0.378277 lr 0.00004040 grad_norm 0.774793 rank 1
2025-01-10 05:21:38,185 DEBUG TRAIN Batch 0/200 loss 1.122301 acc 0.383838 lr 0.00004040 grad_norm 0.774793 rank 2
2025-01-10 05:21:38,185 DEBUG TRAIN Batch 0/200 loss 1.292237 acc 0.283822 lr 0.00004040 grad_norm 0.774793 rank 0
2025-01-10 05:22:01,901 DEBUG TRAIN Batch 0/300 loss 1.296500 acc 0.317025 lr 0.00006040 grad_norm 0.673567 rank 0
2025-01-10 05:22:01,902 DEBUG TRAIN Batch 0/300 loss 1.155829 acc 0.345142 lr 0.00006040 grad_norm 0.673567 rank 2
2025-01-10 05:22:01,902 DEBUG TRAIN Batch 0/300 loss 1.237045 acc 0.346004 lr 0.00006040 grad_norm 0.673567 rank 1
2025-01-10 05:22:25,276 DEBUG TRAIN Batch 0/400 loss 1.202960 acc 0.332983 lr 0.00008040 grad_norm 0.676852 rank 1
2025-01-10 05:22:25,276 DEBUG TRAIN Batch 0/400 loss 1.108133 acc 0.380059 lr 0.00008040 grad_norm 0.676852 rank 0
2025-01-10 05:22:25,277 DEBUG TRAIN Batch 0/400 loss 1.191987 acc 0.331942 lr 0.00008040 grad_norm 0.676852 rank 2
2025-01-10 05:22:49,269 DEBUG TRAIN Batch 0/500 loss 1.140077 acc 0.358561 lr 0.00010040 grad_norm 0.644082 rank 0
2025-01-10 05:22:49,270 DEBUG TRAIN Batch 0/500 loss 1.277898 acc 0.303201 lr 0.00010040 grad_norm 0.644082 rank 2
2025-01-10 05:22:49,270 DEBUG TRAIN Batch 0/500 loss 1.466184 acc 0.261414 lr 0.00010040 grad_norm 0.644082 rank 1
2025-01-10 05:23:12,715 DEBUG TRAIN Batch 0/600 loss 1.479312 acc 0.254593 lr 0.00012040 grad_norm 0.657797 rank 1
2025-01-10 05:23:12,715 DEBUG TRAIN Batch 0/600 loss 1.094319 acc 0.361582 lr 0.00012040 grad_norm 0.657797 rank 2
2025-01-10 05:23:12,716 DEBUG TRAIN Batch 0/600 loss 1.149774 acc 0.361242 lr 0.00012040 grad_norm 0.657797 rank 0
2025-01-10 05:23:36,945 DEBUG TRAIN Batch 0/700 loss 1.103356 acc 0.378160 lr 0.00014040 grad_norm 0.648708 rank 2
2025-01-10 05:23:36,945 DEBUG TRAIN Batch 0/700 loss 1.157558 acc 0.407266 lr 0.00014040 grad_norm 0.648708 rank 1
2025-01-10 05:23:36,948 DEBUG TRAIN Batch 0/700 loss 1.168641 acc 0.353448 lr 0.00014040 grad_norm 0.648708 rank 0
2025-01-10 05:24:01,594 DEBUG TRAIN Batch 0/800 loss 1.081151 acc 0.419453 lr 0.00016040 grad_norm 0.681256 rank 1
2025-01-10 05:24:01,594 DEBUG TRAIN Batch 0/800 loss 1.069350 acc 0.352941 lr 0.00016040 grad_norm 0.681256 rank 2
2025-01-10 05:24:01,599 DEBUG TRAIN Batch 0/800 loss 1.222967 acc 0.314050 lr 0.00016040 grad_norm 0.681256 rank 0
2025-01-10 05:24:26,277 DEBUG TRAIN Batch 0/900 loss 0.986938 acc 0.463529 lr 0.00018040 grad_norm 0.590052 rank 1
2025-01-10 05:24:26,277 DEBUG TRAIN Batch 0/900 loss 1.092676 acc 0.396092 lr 0.00018040 grad_norm 0.590052 rank 2
2025-01-10 05:24:26,277 DEBUG TRAIN Batch 0/900 loss 1.149262 acc 0.343640 lr 0.00018040 grad_norm 0.590052 rank 0
2025-01-10 05:24:50,778 DEBUG TRAIN Batch 0/1000 loss 0.910893 acc 0.486256 lr 0.00020040 grad_norm 0.597636 rank 1
2025-01-10 05:24:50,778 DEBUG TRAIN Batch 0/1000 loss 1.203110 acc 0.343621 lr 0.00020040 grad_norm 0.597636 rank 0
2025-01-10 05:24:50,778 DEBUG TRAIN Batch 0/1000 loss 1.069019 acc 0.383054 lr 0.00020040 grad_norm 0.597636 rank 2
2025-01-10 05:25:15,850 DEBUG TRAIN Batch 0/1100 loss 0.986351 acc 0.469914 lr 0.00022040 grad_norm 0.553297 rank 1
2025-01-10 05:25:15,850 DEBUG TRAIN Batch 0/1100 loss 1.097000 acc 0.373201 lr 0.00022040 grad_norm 0.553297 rank 0
2025-01-10 05:25:15,851 DEBUG TRAIN Batch 0/1100 loss 1.079141 acc 0.371377 lr 0.00022040 grad_norm 0.553297 rank 2
2025-01-10 05:25:40,287 DEBUG TRAIN Batch 0/1200 loss 1.265233 acc 0.314368 lr 0.00024040 grad_norm 0.552176 rank 2
2025-01-10 05:25:40,287 DEBUG TRAIN Batch 0/1200 loss 1.009742 acc 0.465140 lr 0.00024040 grad_norm 0.552176 rank 1
2025-01-10 05:25:40,288 DEBUG TRAIN Batch 0/1200 loss 1.164715 acc 0.350296 lr 0.00024040 grad_norm 0.552176 rank 0
2025-01-10 05:26:03,896 DEBUG TRAIN Batch 0/1300 loss 1.187699 acc 0.326316 lr 0.00026040 grad_norm 0.595765 rank 2
2025-01-10 05:26:03,897 DEBUG TRAIN Batch 0/1300 loss 1.287933 acc 0.309874 lr 0.00026040 grad_norm 0.595765 rank 0
2025-01-10 05:26:03,897 DEBUG TRAIN Batch 0/1300 loss 0.831726 acc 0.520384 lr 0.00026040 grad_norm 0.595765 rank 1
2025-01-10 05:26:28,006 DEBUG TRAIN Batch 0/1400 loss 1.051126 acc 0.420192 lr 0.00028040 grad_norm 0.546109 rank 1
2025-01-10 05:26:28,006 DEBUG TRAIN Batch 0/1400 loss 1.159460 acc 0.348271 lr 0.00028040 grad_norm 0.546109 rank 2
2025-01-10 05:26:28,006 DEBUG TRAIN Batch 0/1400 loss 1.251071 acc 0.345701 lr 0.00028040 grad_norm 0.546109 rank 0
2025-01-10 05:26:52,286 DEBUG TRAIN Batch 0/1500 loss 1.041729 acc 0.463768 lr 0.00030040 grad_norm 0.506566 rank 1
2025-01-10 05:26:52,286 DEBUG TRAIN Batch 0/1500 loss 1.226572 acc 0.318924 lr 0.00030040 grad_norm 0.506566 rank 0
2025-01-10 05:26:52,287 DEBUG TRAIN Batch 0/1500 loss 1.122548 acc 0.364121 lr 0.00030040 grad_norm 0.506566 rank 2
2025-01-10 05:27:16,162 DEBUG TRAIN Batch 0/1600 loss 1.276927 acc 0.322198 lr 0.00032040 grad_norm 0.511772 rank 0
2025-01-10 05:27:16,162 DEBUG TRAIN Batch 0/1600 loss 1.150714 acc 0.333961 lr 0.00032040 grad_norm 0.511772 rank 2
2025-01-10 05:27:16,163 DEBUG TRAIN Batch 0/1600 loss 1.289087 acc 0.319778 lr 0.00032040 grad_norm 0.511772 rank 1
2025-01-10 05:27:40,088 DEBUG TRAIN Batch 0/1700 loss 1.174751 acc 0.326707 lr 0.00034040 grad_norm 0.502216 rank 0
2025-01-10 05:27:40,088 DEBUG TRAIN Batch 0/1700 loss 1.019046 acc 0.426829 lr 0.00034040 grad_norm 0.502216 rank 2
2025-01-10 05:27:40,088 DEBUG TRAIN Batch 0/1700 loss 1.192847 acc 0.364341 lr 0.00034040 grad_norm 0.502216 rank 1
2025-01-10 05:28:03,958 DEBUG TRAIN Batch 0/1800 loss 1.013531 acc 0.443077 lr 0.00036040 grad_norm 0.446031 rank 2
2025-01-10 05:28:03,958 DEBUG TRAIN Batch 0/1800 loss 1.159523 acc 0.359530 lr 0.00036040 grad_norm 0.446031 rank 0
2025-01-10 05:28:03,958 DEBUG TRAIN Batch 0/1800 loss 1.192598 acc 0.357214 lr 0.00036040 grad_norm 0.446031 rank 1
2025-01-10 05:28:28,541 DEBUG TRAIN Batch 0/1900 loss 1.132792 acc 0.380500 lr 0.00038040 grad_norm 0.441263 rank 0
2025-01-10 05:28:28,541 DEBUG TRAIN Batch 0/1900 loss 1.122965 acc 0.425876 lr 0.00038040 grad_norm 0.441263 rank 1
2025-01-10 05:28:28,542 DEBUG TRAIN Batch 0/1900 loss 1.103351 acc 0.380269 lr 0.00038040 grad_norm 0.441263 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 05:29:50,995 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 05:29:51,007 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 05:29:51,366 INFO Epoch 0 Step 997 on_batch_end True CV rank 2
2025-01-10 05:29:51,366 INFO Epoch 0 Step 997 on_batch_end True CV rank 0
2025-01-10 05:29:51,367 INFO Epoch 0 Step 997 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 05:30:01,549 DEBUG CV Batch 0/100 loss 2.187784 acc 0.415831  rank 0
2025-01-10 05:30:01,565 DEBUG CV Batch 0/100 loss 2.187784 acc 0.415831  rank 2
2025-01-10 05:30:01,638 DEBUG CV Batch 0/100 loss 2.187784 acc 0.415831  rank 1
2025-01-10 05:30:02,129 INFO Epoch 0 Step 997 CV info lr 0.00039880000000000004 2 rank loss_2.3684653796647726 acc_0.3552266603106992
2025-01-10 05:30:02,136 INFO Epoch 0 Step 997 CV info lr 0.00039880000000000004 0 rank loss_2.3684653796647726 acc_0.3552266603106992
2025-01-10 05:30:02,215 INFO Epoch 0 Step 997 CV info lr 0.00039880000000000004 1 rank loss_2.3684653796647726 acc_0.3552266603106992
2025-01-10 05:30:03,422 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_0_whole.pt
2025-01-10 05:30:03,443 INFO Added key: store_based_barrier_key:3 to store for rank: 0
2025-01-10 05:30:03,443 INFO Added key: store_based_barrier_key:3 to store for rank: 1
2025-01-10 05:30:03,443 INFO Added key: store_based_barrier_key:3 to store for rank: 2
2025-01-10 05:30:03,443 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:3 with 3 nodes.
2025-01-10 05:30:03,444 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:3 with 3 nodes.
2025-01-10 05:30:03,450 INFO Epoch 1 TRAIN info lr 0.00039880000000000004 rank 1
2025-01-10 05:30:03,450 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 05:30:03,451 INFO Epoch 1 TRAIN info lr 0.00039880000000000004 rank 2
2025-01-10 05:30:03,451 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 05:30:03,453 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 3 nodes.
2025-01-10 05:30:03,454 INFO Epoch 1 TRAIN info lr 0.00039880000000000004 rank 0
2025-01-10 05:30:03,454 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 05:30:37,574 DEBUG TRAIN Batch 1/100 loss 1.202134 acc 0.360489 lr 0.00041880 grad_norm 0.576147 rank 0
2025-01-10 05:30:37,574 DEBUG TRAIN Batch 1/100 loss 1.163188 acc 0.339248 lr 0.00041880 grad_norm 0.576147 rank 2
2025-01-10 05:30:37,574 DEBUG TRAIN Batch 1/100 loss 1.100255 acc 0.367370 lr 0.00041880 grad_norm 0.576147 rank 1
2025-01-10 05:31:02,044 DEBUG TRAIN Batch 1/200 loss 1.097744 acc 0.367089 lr 0.00043880 grad_norm 0.571130 rank 2
2025-01-10 05:31:02,044 DEBUG TRAIN Batch 1/200 loss 1.044002 acc 0.375895 lr 0.00043880 grad_norm 0.571130 rank 1
2025-01-10 05:31:02,045 DEBUG TRAIN Batch 1/200 loss 1.152253 acc 0.370766 lr 0.00043880 grad_norm 0.571130 rank 0
2025-01-10 05:31:27,311 DEBUG TRAIN Batch 1/300 loss 1.070221 acc 0.382752 lr 0.00045880 grad_norm 0.502959 rank 2
2025-01-10 05:31:27,311 DEBUG TRAIN Batch 1/300 loss 1.223054 acc 0.341533 lr 0.00045880 grad_norm 0.502959 rank 0
2025-01-10 05:31:27,311 DEBUG TRAIN Batch 1/300 loss 1.076056 acc 0.384735 lr 0.00045880 grad_norm 0.502959 rank 1
2025-01-10 05:31:52,400 DEBUG TRAIN Batch 1/400 loss 1.094395 acc 0.368700 lr 0.00047880 grad_norm 0.453867 rank 1
2025-01-10 05:31:52,401 DEBUG TRAIN Batch 1/400 loss 1.114035 acc 0.368697 lr 0.00047880 grad_norm 0.453867 rank 2
2025-01-10 05:31:52,401 DEBUG TRAIN Batch 1/400 loss 1.175016 acc 0.366412 lr 0.00047880 grad_norm 0.453867 rank 0
2025-01-10 05:32:16,536 DEBUG TRAIN Batch 1/500 loss 1.115344 acc 0.337742 lr 0.00049880 grad_norm 0.448800 rank 2
2025-01-10 05:32:16,536 DEBUG TRAIN Batch 1/500 loss 1.232503 acc 0.325147 lr 0.00049880 grad_norm 0.448800 rank 0
2025-01-10 05:32:16,536 DEBUG TRAIN Batch 1/500 loss 1.117634 acc 0.369911 lr 0.00049880 grad_norm 0.448800 rank 1
2025-01-10 05:32:40,518 DEBUG TRAIN Batch 1/600 loss 1.054216 acc 0.383799 lr 0.00051880 grad_norm 0.457362 rank 1
2025-01-10 05:32:40,518 DEBUG TRAIN Batch 1/600 loss 1.150530 acc 0.364583 lr 0.00051880 grad_norm 0.457362 rank 0
2025-01-10 05:32:40,519 DEBUG TRAIN Batch 1/600 loss 1.148564 acc 0.352835 lr 0.00051880 grad_norm 0.457362 rank 2
2025-01-10 05:33:05,119 DEBUG TRAIN Batch 1/700 loss 1.153276 acc 0.397820 lr 0.00053880 grad_norm 0.453584 rank 0
2025-01-10 05:33:05,120 DEBUG TRAIN Batch 1/700 loss 1.219014 acc 0.327853 lr 0.00053880 grad_norm 0.453584 rank 2
2025-01-10 05:33:05,120 DEBUG TRAIN Batch 1/700 loss 1.036485 acc 0.385656 lr 0.00053880 grad_norm 0.453584 rank 1
2025-01-10 05:33:29,861 DEBUG TRAIN Batch 1/800 loss 1.187901 acc 0.351476 lr 0.00055880 grad_norm 0.515043 rank 1
2025-01-10 05:33:29,861 DEBUG TRAIN Batch 1/800 loss 1.166079 acc 0.343137 lr 0.00055880 grad_norm 0.515043 rank 0
2025-01-10 05:33:29,861 DEBUG TRAIN Batch 1/800 loss 1.140725 acc 0.363921 lr 0.00055880 grad_norm 0.515043 rank 2
2025-01-10 05:33:53,865 DEBUG TRAIN Batch 1/900 loss 1.166710 acc 0.343426 lr 0.00057880 grad_norm 0.414629 rank 0
2025-01-10 05:33:53,866 DEBUG TRAIN Batch 1/900 loss 1.098882 acc 0.394279 lr 0.00057880 grad_norm 0.414629 rank 2
2025-01-10 05:33:53,867 DEBUG TRAIN Batch 1/900 loss 1.237405 acc 0.320368 lr 0.00057880 grad_norm 0.414629 rank 1
2025-01-10 05:34:17,943 DEBUG TRAIN Batch 1/1000 loss 1.156008 acc 0.355876 lr 0.00059880 grad_norm 0.420860 rank 0
2025-01-10 05:34:17,944 DEBUG TRAIN Batch 1/1000 loss 1.139307 acc 0.368209 lr 0.00059880 grad_norm 0.420860 rank 2
2025-01-10 05:34:17,944 DEBUG TRAIN Batch 1/1000 loss 1.203678 acc 0.356164 lr 0.00059880 grad_norm 0.420860 rank 1
2025-01-10 05:34:42,252 DEBUG TRAIN Batch 1/1100 loss 1.170194 acc 0.364355 lr 0.00061880 grad_norm 0.389713 rank 2
2025-01-10 05:34:42,252 DEBUG TRAIN Batch 1/1100 loss 1.257536 acc 0.338249 lr 0.00061880 grad_norm 0.389713 rank 1
2025-01-10 05:34:42,255 DEBUG TRAIN Batch 1/1100 loss 1.108557 acc 0.388119 lr 0.00061880 grad_norm 0.389713 rank 0
2025-01-10 05:35:06,517 DEBUG TRAIN Batch 1/1200 loss 1.052611 acc 0.410208 lr 0.00063880 grad_norm 0.435303 rank 1
2025-01-10 05:35:06,517 DEBUG TRAIN Batch 1/1200 loss 1.109654 acc 0.388350 lr 0.00063880 grad_norm 0.435303 rank 0
2025-01-10 05:35:06,517 DEBUG TRAIN Batch 1/1200 loss 1.169380 acc 0.341014 lr 0.00063880 grad_norm 0.435303 rank 2
2025-01-10 05:35:30,208 DEBUG TRAIN Batch 1/1300 loss 1.125179 acc 0.355914 lr 0.00065880 grad_norm 0.391104 rank 0
2025-01-10 05:35:30,209 DEBUG TRAIN Batch 1/1300 loss 1.212073 acc 0.342806 lr 0.00065880 grad_norm 0.391104 rank 2
2025-01-10 05:35:30,209 DEBUG TRAIN Batch 1/1300 loss 1.209036 acc 0.342132 lr 0.00065880 grad_norm 0.391104 rank 1
2025-01-10 05:35:53,592 DEBUG TRAIN Batch 1/1400 loss 1.296687 acc 0.314848 lr 0.00067880 grad_norm 0.385135 rank 1
2025-01-10 05:35:53,593 DEBUG TRAIN Batch 1/1400 loss 1.101469 acc 0.392593 lr 0.00067880 grad_norm 0.385135 rank 0
2025-01-10 05:35:53,593 DEBUG TRAIN Batch 1/1400 loss 1.154240 acc 0.335508 lr 0.00067880 grad_norm 0.385135 rank 2
2025-01-10 05:36:17,548 DEBUG TRAIN Batch 1/1500 loss 1.146524 acc 0.355455 lr 0.00069880 grad_norm 0.412200 rank 0
2025-01-10 05:36:17,548 DEBUG TRAIN Batch 1/1500 loss 1.094112 acc 0.378855 lr 0.00069880 grad_norm 0.412200 rank 1
2025-01-10 05:36:17,549 DEBUG TRAIN Batch 1/1500 loss 1.217345 acc 0.318632 lr 0.00069880 grad_norm 0.412200 rank 2
2025-01-10 05:36:41,181 DEBUG TRAIN Batch 1/1600 loss 1.098211 acc 0.383534 lr 0.00071880 grad_norm 0.384052 rank 0
2025-01-10 05:36:41,181 DEBUG TRAIN Batch 1/1600 loss 1.079883 acc 0.387522 lr 0.00071880 grad_norm 0.384052 rank 1
2025-01-10 05:36:41,182 DEBUG TRAIN Batch 1/1600 loss 1.171918 acc 0.359070 lr 0.00071880 grad_norm 0.384052 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 05:38:01,573 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 05:38:01,581 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 05:38:02,059 INFO Epoch 1 Step 1840 on_batch_end True CV rank 1
2025-01-10 05:38:02,059 INFO Epoch 1 Step 1840 on_batch_end True CV rank 0
2025-01-10 05:38:02,059 INFO Epoch 1 Step 1840 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 05:38:11,681 DEBUG CV Batch 1/100 loss 2.185906 acc 0.410256  rank 2
2025-01-10 05:38:11,728 DEBUG CV Batch 1/100 loss 2.185906 acc 0.410256  rank 0
2025-01-10 05:38:12,140 DEBUG CV Batch 1/100 loss 2.185906 acc 0.410256  rank 1
2025-01-10 05:38:12,210 INFO Epoch 1 Step 1840 CV info lr 0.000736 0 rank loss_2.3369968078638377 acc_0.362186207779144
2025-01-10 05:38:12,229 INFO Epoch 1 Step 1840 CV info lr 0.000736 2 rank loss_2.3369968078638377 acc_0.362186207779144
2025-01-10 05:38:12,678 INFO Epoch 1 Step 1840 CV info lr 0.000736 1 rank loss_2.3369968078638377 acc_0.362186207779144
2025-01-10 05:38:13,490 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_1_whole.pt
2025-01-10 05:38:13,502 INFO Added key: store_based_barrier_key:4 to store for rank: 0
2025-01-10 05:38:13,512 INFO Added key: store_based_barrier_key:4 to store for rank: 1
2025-01-10 05:38:13,512 INFO Added key: store_based_barrier_key:4 to store for rank: 2
2025-01-10 05:38:13,512 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:4 with 3 nodes.
2025-01-10 05:38:13,512 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:4 with 3 nodes.
2025-01-10 05:38:13,512 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:4 with 3 nodes.
2025-01-10 05:38:13,513 INFO Epoch 2 TRAIN info lr 0.000736 rank 1
2025-01-10 05:38:13,513 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 05:38:13,517 INFO Epoch 2 TRAIN info lr 0.000736 rank 0
2025-01-10 05:38:13,517 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 05:38:13,521 INFO Epoch 2 TRAIN info lr 0.000736 rank 2
2025-01-10 05:38:13,521 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 05:38:45,132 DEBUG TRAIN Batch 2/100 loss 1.111192 acc 0.369453 lr 0.00075600 grad_norm 0.418737 rank 1
2025-01-10 05:38:45,132 DEBUG TRAIN Batch 2/100 loss 1.199045 acc 0.348999 lr 0.00075600 grad_norm 0.418737 rank 2
2025-01-10 05:38:45,133 DEBUG TRAIN Batch 2/100 loss 0.994080 acc 0.426630 lr 0.00075600 grad_norm 0.418737 rank 0
2025-01-10 05:39:08,938 DEBUG TRAIN Batch 2/200 loss 1.014328 acc 0.432373 lr 0.00077600 grad_norm 0.459418 rank 0
2025-01-10 05:39:08,939 DEBUG TRAIN Batch 2/200 loss 1.130510 acc 0.353191 lr 0.00077600 grad_norm 0.459418 rank 2
2025-01-10 05:39:08,939 DEBUG TRAIN Batch 2/200 loss 1.116937 acc 0.376590 lr 0.00077600 grad_norm 0.459418 rank 1
2025-01-10 05:39:35,176 DEBUG TRAIN Batch 2/300 loss 0.993420 acc 0.408592 lr 0.00079600 grad_norm 0.396659 rank 0
2025-01-10 05:39:35,176 DEBUG TRAIN Batch 2/300 loss 1.114340 acc 0.357430 lr 0.00079600 grad_norm 0.396659 rank 1
2025-01-10 05:39:35,201 DEBUG TRAIN Batch 2/300 loss 1.157447 acc 0.339888 lr 0.00079600 grad_norm 0.396659 rank 2
2025-01-10 05:40:00,721 DEBUG TRAIN Batch 2/400 loss 1.098288 acc 0.367197 lr 0.00081600 grad_norm 0.413321 rank 0
2025-01-10 05:40:00,721 DEBUG TRAIN Batch 2/400 loss 1.115904 acc 0.343252 lr 0.00081600 grad_norm 0.413321 rank 2
2025-01-10 05:40:00,721 DEBUG TRAIN Batch 2/400 loss 1.121221 acc 0.373673 lr 0.00081600 grad_norm 0.413321 rank 1
2025-01-10 05:40:25,536 DEBUG TRAIN Batch 2/500 loss 1.235157 acc 0.332397 lr 0.00083600 grad_norm 0.385041 rank 1
2025-01-10 05:40:25,536 DEBUG TRAIN Batch 2/500 loss 1.173214 acc 0.369082 lr 0.00083600 grad_norm 0.385041 rank 0
2025-01-10 05:40:25,536 DEBUG TRAIN Batch 2/500 loss 1.130782 acc 0.364996 lr 0.00083600 grad_norm 0.385041 rank 2
2025-01-10 05:40:49,831 DEBUG TRAIN Batch 2/600 loss 1.082457 acc 0.378407 lr 0.00085600 grad_norm 0.385741 rank 1
2025-01-10 05:40:49,832 DEBUG TRAIN Batch 2/600 loss 1.205582 acc 0.351254 lr 0.00085600 grad_norm 0.385741 rank 0
2025-01-10 05:40:49,835 DEBUG TRAIN Batch 2/600 loss 1.201947 acc 0.345837 lr 0.00085600 grad_norm 0.385741 rank 2
2025-01-10 05:41:13,320 DEBUG TRAIN Batch 2/700 loss 1.182226 acc 0.361403 lr 0.00087600 grad_norm 0.387387 rank 0
2025-01-10 05:41:13,320 DEBUG TRAIN Batch 2/700 loss 1.115716 acc 0.372587 lr 0.00087600 grad_norm 0.387387 rank 1
2025-01-10 05:41:13,320 DEBUG TRAIN Batch 2/700 loss 1.163720 acc 0.359434 lr 0.00087600 grad_norm 0.387387 rank 2
2025-01-10 05:41:37,224 DEBUG TRAIN Batch 2/800 loss 1.158855 acc 0.360568 lr 0.00089600 grad_norm 0.349429 rank 0
2025-01-10 05:41:37,224 DEBUG TRAIN Batch 2/800 loss 0.981842 acc 0.459888 lr 0.00089600 grad_norm 0.349429 rank 2
2025-01-10 05:41:37,225 DEBUG TRAIN Batch 2/800 loss 1.198096 acc 0.340619 lr 0.00089600 grad_norm 0.349429 rank 1
2025-01-10 05:42:01,061 DEBUG TRAIN Batch 2/900 loss 1.116629 acc 0.372917 lr 0.00091600 grad_norm 0.365319 rank 0
2025-01-10 05:42:01,062 DEBUG TRAIN Batch 2/900 loss 1.033920 acc 0.447880 lr 0.00091600 grad_norm 0.365319 rank 2
2025-01-10 05:42:01,063 DEBUG TRAIN Batch 2/900 loss 1.161211 acc 0.353943 lr 0.00091600 grad_norm 0.365319 rank 1
2025-01-10 05:42:24,814 DEBUG TRAIN Batch 2/1000 loss 1.093668 acc 0.373807 lr 0.00093600 grad_norm 0.370737 rank 0
2025-01-10 05:42:24,814 DEBUG TRAIN Batch 2/1000 loss 1.132585 acc 0.377880 lr 0.00093600 grad_norm 0.370737 rank 1
2025-01-10 05:42:24,814 DEBUG TRAIN Batch 2/1000 loss 1.205501 acc 0.383117 lr 0.00093600 grad_norm 0.370737 rank 2
2025-01-10 05:42:49,575 DEBUG TRAIN Batch 2/1100 loss 1.325435 acc 0.294824 lr 0.00095600 grad_norm 0.423057 rank 1
2025-01-10 05:42:49,576 DEBUG TRAIN Batch 2/1100 loss 0.930813 acc 0.515599 lr 0.00095600 grad_norm 0.423057 rank 2
2025-01-10 05:42:49,576 DEBUG TRAIN Batch 2/1100 loss 1.115771 acc 0.354767 lr 0.00095600 grad_norm 0.423057 rank 0
2025-01-10 05:43:13,631 DEBUG TRAIN Batch 2/1200 loss 1.279993 acc 0.353616 lr 0.00097600 grad_norm 0.373540 rank 0
2025-01-10 05:43:13,631 DEBUG TRAIN Batch 2/1200 loss 0.945355 acc 0.478702 lr 0.00097600 grad_norm 0.373540 rank 2
2025-01-10 05:43:13,632 DEBUG TRAIN Batch 2/1200 loss 1.337437 acc 0.298387 lr 0.00097600 grad_norm 0.373540 rank 1
2025-01-10 05:43:37,751 DEBUG TRAIN Batch 2/1300 loss 1.320347 acc 0.307474 lr 0.00099600 grad_norm 0.382819 rank 1
2025-01-10 05:43:37,752 DEBUG TRAIN Batch 2/1300 loss 1.285098 acc 0.319688 lr 0.00099600 grad_norm 0.382819 rank 0
2025-01-10 05:43:37,752 DEBUG TRAIN Batch 2/1300 loss 0.914379 acc 0.507791 lr 0.00099600 grad_norm 0.382819 rank 2
2025-01-10 05:44:01,596 DEBUG TRAIN Batch 2/1400 loss 1.232163 acc 0.305962 lr 0.00099209 grad_norm 0.368943 rank 1
2025-01-10 05:44:01,597 DEBUG TRAIN Batch 2/1400 loss 1.215067 acc 0.330601 lr 0.00099209 grad_norm 0.368943 rank 0
2025-01-10 05:44:01,597 DEBUG TRAIN Batch 2/1400 loss 1.128822 acc 0.368778 lr 0.00099209 grad_norm 0.368943 rank 2
2025-01-10 05:44:26,653 DEBUG TRAIN Batch 2/1500 loss 1.273014 acc 0.336505 lr 0.00098247 grad_norm 0.359163 rank 0
2025-01-10 05:44:26,653 DEBUG TRAIN Batch 2/1500 loss 1.238163 acc 0.338624 lr 0.00098247 grad_norm 0.359163 rank 1
2025-01-10 05:44:26,653 DEBUG TRAIN Batch 2/1500 loss 1.143937 acc 0.386364 lr 0.00098247 grad_norm 0.359163 rank 2
2025-01-10 05:44:50,556 DEBUG TRAIN Batch 2/1600 loss 1.334378 acc 0.285038 lr 0.00097312 grad_norm 0.332076 rank 1
2025-01-10 05:44:50,557 DEBUG TRAIN Batch 2/1600 loss 1.261351 acc 0.335814 lr 0.00097312 grad_norm 0.332076 rank 0
2025-01-10 05:44:50,557 DEBUG TRAIN Batch 2/1600 loss 1.264835 acc 0.333011 lr 0.00097312 grad_norm 0.332076 rank 2
2025-01-10 05:45:15,193 DEBUG TRAIN Batch 2/1700 loss 1.228774 acc 0.316274 lr 0.00096404 grad_norm 0.348149 rank 0
2025-01-10 05:45:15,193 DEBUG TRAIN Batch 2/1700 loss 1.213474 acc 0.337790 lr 0.00096404 grad_norm 0.348149 rank 1
2025-01-10 05:45:15,193 DEBUG TRAIN Batch 2/1700 loss 1.164649 acc 0.372480 lr 0.00096404 grad_norm 0.348149 rank 2
2025-01-10 05:45:39,053 DEBUG TRAIN Batch 2/1800 loss 1.118586 acc 0.388641 lr 0.00095520 grad_norm 0.358359 rank 1
2025-01-10 05:45:39,053 DEBUG TRAIN Batch 2/1800 loss 1.144523 acc 0.365175 lr 0.00095520 grad_norm 0.358359 rank 0
2025-01-10 05:45:39,054 DEBUG TRAIN Batch 2/1800 loss 1.293907 acc 0.345842 lr 0.00095520 grad_norm 0.358359 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 05:46:59,018 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 05:46:59,023 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 05:46:59,547 INFO Epoch 2 Step 2780 on_batch_end True CV rank 0
2025-01-10 05:46:59,547 INFO Epoch 2 Step 2780 on_batch_end True CV rank 1
2025-01-10 05:46:59,547 INFO Epoch 2 Step 2780 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 05:47:08,532 DEBUG CV Batch 2/100 loss 2.007755 acc 0.438127  rank 0
2025-01-10 05:47:08,728 DEBUG CV Batch 2/100 loss 2.007755 acc 0.438127  rank 2
2025-01-10 05:47:09,047 INFO Epoch 2 Step 2780 CV info lr 0.0009483040522636019 0 rank loss_2.369962496192832 acc_0.3566292147233821
2025-01-10 05:47:09,137 DEBUG CV Batch 2/100 loss 2.007755 acc 0.438127  rank 1
2025-01-10 05:47:09,263 INFO Epoch 2 Step 2780 CV info lr 0.0009483040522636019 2 rank loss_2.369962496192832 acc_0.3566292147233821
2025-01-10 05:47:09,675 INFO Epoch 2 Step 2780 CV info lr 0.0009483040522636019 1 rank loss_2.369962496192832 acc_0.3566292147233821
2025-01-10 05:47:10,316 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_2_whole.pt
2025-01-10 05:47:10,338 INFO Added key: store_based_barrier_key:5 to store for rank: 0
2025-01-10 05:47:10,348 INFO Added key: store_based_barrier_key:5 to store for rank: 2
2025-01-10 05:47:10,348 INFO Added key: store_based_barrier_key:5 to store for rank: 1
2025-01-10 05:47:10,349 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:5 with 3 nodes.
2025-01-10 05:47:10,356 INFO Epoch 3 TRAIN info lr 0.0009483040522636019 rank 1
2025-01-10 05:47:10,356 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 05:47:10,358 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:5 with 3 nodes.
2025-01-10 05:47:10,358 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:5 with 3 nodes.
2025-01-10 05:47:10,360 INFO Epoch 3 TRAIN info lr 0.0009483040522636019 rank 0
2025-01-10 05:47:10,360 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 05:47:10,365 INFO Epoch 3 TRAIN info lr 0.0009483040522636019 rank 2
2025-01-10 05:47:10,365 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 05:47:46,779 DEBUG TRAIN Batch 3/100 loss 1.166663 acc 0.349272 lr 0.00093989 grad_norm 0.350221 rank 2
2025-01-10 05:47:46,779 DEBUG TRAIN Batch 3/100 loss 1.150751 acc 0.373333 lr 0.00093989 grad_norm 0.350221 rank 0
2025-01-10 05:47:46,780 DEBUG TRAIN Batch 3/100 loss 0.953699 acc 0.479503 lr 0.00093989 grad_norm 0.350221 rank 1
2025-01-10 05:48:10,670 DEBUG TRAIN Batch 3/200 loss 1.158262 acc 0.376738 lr 0.00093169 grad_norm 0.350245 rank 2
2025-01-10 05:48:10,671 DEBUG TRAIN Batch 3/200 loss 1.162264 acc 0.361607 lr 0.00093169 grad_norm 0.350245 rank 0
2025-01-10 05:48:10,671 DEBUG TRAIN Batch 3/200 loss 0.990591 acc 0.455166 lr 0.00093169 grad_norm 0.350245 rank 1
2025-01-10 05:48:35,063 DEBUG TRAIN Batch 3/300 loss 1.094597 acc 0.394380 lr 0.00092371 grad_norm 0.341734 rank 2
2025-01-10 05:48:35,063 DEBUG TRAIN Batch 3/300 loss 1.113469 acc 0.346341 lr 0.00092371 grad_norm 0.341734 rank 1
2025-01-10 05:48:35,063 DEBUG TRAIN Batch 3/300 loss 1.168896 acc 0.346939 lr 0.00092371 grad_norm 0.341734 rank 0
2025-01-10 05:48:58,657 DEBUG TRAIN Batch 3/400 loss 1.075796 acc 0.402490 lr 0.00091593 grad_norm 0.359379 rank 2
2025-01-10 05:48:58,657 DEBUG TRAIN Batch 3/400 loss 0.953137 acc 0.466284 lr 0.00091593 grad_norm 0.359379 rank 1
2025-01-10 05:48:58,658 DEBUG TRAIN Batch 3/400 loss 1.198708 acc 0.370681 lr 0.00091593 grad_norm 0.359379 rank 0
2025-01-10 05:49:23,500 DEBUG TRAIN Batch 3/500 loss 1.081093 acc 0.381993 lr 0.00090834 grad_norm 0.328512 rank 2
2025-01-10 05:49:23,501 DEBUG TRAIN Batch 3/500 loss 0.933944 acc 0.506524 lr 0.00090834 grad_norm 0.328512 rank 1
2025-01-10 05:49:23,501 DEBUG TRAIN Batch 3/500 loss 1.432954 acc 0.261665 lr 0.00090834 grad_norm 0.328512 rank 0
2025-01-10 05:49:48,278 DEBUG TRAIN Batch 3/600 loss 1.091601 acc 0.364956 lr 0.00090094 grad_norm 0.347390 rank 2
2025-01-10 05:49:48,279 DEBUG TRAIN Batch 3/600 loss 1.522566 acc 0.245245 lr 0.00090094 grad_norm 0.347390 rank 0
2025-01-10 05:49:48,280 DEBUG TRAIN Batch 3/600 loss 0.873550 acc 0.518313 lr 0.00090094 grad_norm 0.347390 rank 1
2025-01-10 05:50:12,385 DEBUG TRAIN Batch 3/700 loss 1.071148 acc 0.418889 lr 0.00089371 grad_norm 0.344796 rank 1
2025-01-10 05:50:12,385 DEBUG TRAIN Batch 3/700 loss 1.202833 acc 0.341000 lr 0.00089371 grad_norm 0.344796 rank 0
2025-01-10 05:50:12,386 DEBUG TRAIN Batch 3/700 loss 1.093900 acc 0.368829 lr 0.00089371 grad_norm 0.344796 rank 2
2025-01-10 05:50:37,183 DEBUG TRAIN Batch 3/800 loss 0.880611 acc 0.504348 lr 0.00088666 grad_norm 0.314474 rank 1
2025-01-10 05:50:37,184 DEBUG TRAIN Batch 3/800 loss 1.123411 acc 0.365179 lr 0.00088666 grad_norm 0.314474 rank 0
2025-01-10 05:50:37,184 DEBUG TRAIN Batch 3/800 loss 1.015954 acc 0.406863 lr 0.00088666 grad_norm 0.314474 rank 2
2025-01-10 05:51:01,205 DEBUG TRAIN Batch 3/900 loss 0.899791 acc 0.517611 lr 0.00087977 grad_norm 0.346706 rank 1
2025-01-10 05:51:01,206 DEBUG TRAIN Batch 3/900 loss 1.152386 acc 0.350436 lr 0.00087977 grad_norm 0.346706 rank 0
2025-01-10 05:51:01,206 DEBUG TRAIN Batch 3/900 loss 1.063946 acc 0.388889 lr 0.00087977 grad_norm 0.346706 rank 2
2025-01-10 05:51:25,795 DEBUG TRAIN Batch 3/1000 loss 0.984821 acc 0.450742 lr 0.00087304 grad_norm 0.355372 rank 1
2025-01-10 05:51:25,795 DEBUG TRAIN Batch 3/1000 loss 1.159919 acc 0.356445 lr 0.00087304 grad_norm 0.355372 rank 0
2025-01-10 05:51:25,795 DEBUG TRAIN Batch 3/1000 loss 1.003527 acc 0.445697 lr 0.00087304 grad_norm 0.355372 rank 2
2025-01-10 05:51:51,564 DEBUG TRAIN Batch 3/1100 loss 0.945712 acc 0.476337 lr 0.00086646 grad_norm 0.303014 rank 1
2025-01-10 05:51:51,566 DEBUG TRAIN Batch 3/1100 loss 1.046303 acc 0.410431 lr 0.00086646 grad_norm 0.303014 rank 2
2025-01-10 05:51:51,566 DEBUG TRAIN Batch 3/1100 loss 1.113404 acc 0.371945 lr 0.00086646 grad_norm 0.303014 rank 0
2025-01-10 05:52:15,536 DEBUG TRAIN Batch 3/1200 loss 1.164389 acc 0.359964 lr 0.00086003 grad_norm 0.314561 rank 0
2025-01-10 05:52:15,536 DEBUG TRAIN Batch 3/1200 loss 1.092328 acc 0.385214 lr 0.00086003 grad_norm 0.314561 rank 1
2025-01-10 05:52:15,537 DEBUG TRAIN Batch 3/1200 loss 1.170293 acc 0.378650 lr 0.00086003 grad_norm 0.314561 rank 2
2025-01-10 05:52:41,516 DEBUG TRAIN Batch 3/1300 loss 1.139323 acc 0.389815 lr 0.00085373 grad_norm 0.319444 rank 2
2025-01-10 05:52:41,517 DEBUG TRAIN Batch 3/1300 loss 1.082986 acc 0.370036 lr 0.00085373 grad_norm 0.319444 rank 1
2025-01-10 05:52:41,517 DEBUG TRAIN Batch 3/1300 loss 1.203303 acc 0.349425 lr 0.00085373 grad_norm 0.319444 rank 0
2025-01-10 05:53:07,123 DEBUG TRAIN Batch 3/1400 loss 1.062782 acc 0.376596 lr 0.00084758 grad_norm 0.312853 rank 1
2025-01-10 05:53:07,123 DEBUG TRAIN Batch 3/1400 loss 1.227685 acc 0.348511 lr 0.00084758 grad_norm 0.312853 rank 2
2025-01-10 05:53:07,123 DEBUG TRAIN Batch 3/1400 loss 1.201906 acc 0.354754 lr 0.00084758 grad_norm 0.312853 rank 0
2025-01-10 05:53:32,896 DEBUG TRAIN Batch 3/1500 loss 1.168109 acc 0.357798 lr 0.00084156 grad_norm 0.306995 rank 1
2025-01-10 05:53:32,896 DEBUG TRAIN Batch 3/1500 loss 1.457251 acc 0.258230 lr 0.00084156 grad_norm 0.306995 rank 2
2025-01-10 05:53:32,900 DEBUG TRAIN Batch 3/1500 loss 1.174416 acc 0.348133 lr 0.00084156 grad_norm 0.306995 rank 0
2025-01-10 05:53:58,076 DEBUG TRAIN Batch 3/1600 loss 1.136669 acc 0.362550 lr 0.00083566 grad_norm 0.306878 rank 2
2025-01-10 05:53:58,076 DEBUG TRAIN Batch 3/1600 loss 1.104947 acc 0.400458 lr 0.00083566 grad_norm 0.306878 rank 0
2025-01-10 05:53:58,077 DEBUG TRAIN Batch 3/1600 loss 1.227052 acc 0.330786 lr 0.00083566 grad_norm 0.306878 rank 1
2025-01-10 05:54:24,392 DEBUG TRAIN Batch 3/1700 loss 1.198776 acc 0.353753 lr 0.00082988 grad_norm 0.332264 rank 1
2025-01-10 05:54:24,392 DEBUG TRAIN Batch 3/1700 loss 1.119925 acc 0.359390 lr 0.00082988 grad_norm 0.332264 rank 2
2025-01-10 05:54:24,392 DEBUG TRAIN Batch 3/1700 loss 1.147145 acc 0.383142 lr 0.00082988 grad_norm 0.332264 rank 0
2025-01-10 05:54:50,298 DEBUG TRAIN Batch 3/1800 loss 1.206621 acc 0.341760 lr 0.00082423 grad_norm 0.317262 rank 1
2025-01-10 05:54:50,298 DEBUG TRAIN Batch 3/1800 loss 1.024920 acc 0.413948 lr 0.00082423 grad_norm 0.317262 rank 2
2025-01-10 05:54:50,302 DEBUG TRAIN Batch 3/1800 loss 1.112374 acc 0.379845 lr 0.00082423 grad_norm 0.317262 rank 0
2025-01-10 05:55:15,969 DEBUG TRAIN Batch 3/1900 loss 1.189119 acc 0.343173 lr 0.00081868 grad_norm 0.302040 rank 1
2025-01-10 05:55:15,969 DEBUG TRAIN Batch 3/1900 loss 1.044241 acc 0.386538 lr 0.00081868 grad_norm 0.302040 rank 2
2025-01-10 05:55:15,972 DEBUG TRAIN Batch 3/1900 loss 1.119643 acc 0.351299 lr 0.00081868 grad_norm 0.302040 rank 0
2025-01-10 05:55:41,495 DEBUG TRAIN Batch 3/2000 loss 1.107268 acc 0.378631 lr 0.00081325 grad_norm 0.301471 rank 0
2025-01-10 05:55:41,496 DEBUG TRAIN Batch 3/2000 loss 1.066239 acc 0.408946 lr 0.00081325 grad_norm 0.301471 rank 2
2025-01-10 05:55:41,496 DEBUG TRAIN Batch 3/2000 loss 1.148982 acc 0.369467 lr 0.00081325 grad_norm 0.301471 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 05:56:59,503 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 05:56:59,508 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 05:56:59,924 INFO Epoch 3 Step 3814 on_batch_end True CV rank 0
2025-01-10 05:56:59,924 INFO Epoch 3 Step 3814 on_batch_end True CV rank 2
2025-01-10 05:56:59,924 INFO Epoch 3 Step 3814 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 05:57:10,027 DEBUG CV Batch 3/100 loss 1.962326 acc 0.459309  rank 0
2025-01-10 05:57:10,165 DEBUG CV Batch 3/100 loss 1.962326 acc 0.459309  rank 2
2025-01-10 05:57:10,533 INFO Epoch 3 Step 3814 CV info lr 0.0008096170769084694 0 rank loss_2.2398931279517056 acc_0.3803673746031627
2025-01-10 05:57:10,564 DEBUG CV Batch 3/100 loss 1.962326 acc 0.459309  rank 1
2025-01-10 05:57:10,681 INFO Epoch 3 Step 3814 CV info lr 0.0008096170769084694 2 rank loss_2.2398931279517056 acc_0.3803673746031627
2025-01-10 05:57:11,101 INFO Epoch 3 Step 3814 CV info lr 0.0008096170769084694 1 rank loss_2.2398931279517056 acc_0.3803673746031627
2025-01-10 05:57:12,228 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_3_whole.pt
2025-01-10 05:57:12,240 INFO Added key: store_based_barrier_key:6 to store for rank: 0
2025-01-10 05:57:12,250 INFO Added key: store_based_barrier_key:6 to store for rank: 2
2025-01-10 05:57:12,251 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:6 with 3 nodes.
2025-01-10 05:57:12,251 INFO Added key: store_based_barrier_key:6 to store for rank: 1
2025-01-10 05:57:12,251 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:6 with 3 nodes.
2025-01-10 05:57:12,251 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:6 with 3 nodes.
2025-01-10 05:57:12,253 INFO Epoch 4 TRAIN info lr 0.0008096170769084694 rank 2
2025-01-10 05:57:12,253 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 05:57:12,260 INFO Epoch 4 TRAIN info lr 0.0008096170769084694 rank 0
2025-01-10 05:57:12,260 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 05:57:12,260 INFO Epoch 4 TRAIN info lr 0.0008096170769084694 rank 1
2025-01-10 05:57:12,260 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 05:57:47,878 DEBUG TRAIN Batch 4/100 loss 1.013105 acc 0.425656 lr 0.00080436 grad_norm 0.317620 rank 2
2025-01-10 05:57:47,878 DEBUG TRAIN Batch 4/100 loss 0.965138 acc 0.452007 lr 0.00080436 grad_norm 0.317620 rank 1
2025-01-10 05:57:47,878 DEBUG TRAIN Batch 4/100 loss 1.093889 acc 0.376852 lr 0.00080436 grad_norm 0.317620 rank 0
2025-01-10 05:58:13,455 DEBUG TRAIN Batch 4/200 loss 1.012555 acc 0.424486 lr 0.00079921 grad_norm 0.367972 rank 2
2025-01-10 05:58:13,455 DEBUG TRAIN Batch 4/200 loss 0.950635 acc 0.413939 lr 0.00079921 grad_norm 0.367972 rank 1
2025-01-10 05:58:13,460 DEBUG TRAIN Batch 4/200 loss 1.140831 acc 0.364943 lr 0.00079921 grad_norm 0.367972 rank 0
2025-01-10 05:58:45,917 DEBUG TRAIN Batch 4/300 loss 1.034013 acc 0.411765 lr 0.00079415 grad_norm 0.320598 rank 0
2025-01-10 05:58:45,918 DEBUG TRAIN Batch 4/300 loss 1.041015 acc 0.401254 lr 0.00079415 grad_norm 0.320598 rank 2
2025-01-10 05:58:45,918 DEBUG TRAIN Batch 4/300 loss 1.061055 acc 0.399052 lr 0.00079415 grad_norm 0.320598 rank 1
2025-01-10 05:59:09,974 DEBUG TRAIN Batch 4/400 loss 1.009694 acc 0.425197 lr 0.00078919 grad_norm 0.346073 rank 2
2025-01-10 05:59:09,974 DEBUG TRAIN Batch 4/400 loss 0.950266 acc 0.431310 lr 0.00078919 grad_norm 0.346073 rank 1
2025-01-10 05:59:09,975 DEBUG TRAIN Batch 4/400 loss 0.838558 acc 0.530049 lr 0.00078919 grad_norm 0.346073 rank 0
2025-01-10 05:59:34,886 DEBUG TRAIN Batch 4/500 loss 0.931539 acc 0.459399 lr 0.00078432 grad_norm 0.311707 rank 2
2025-01-10 05:59:34,888 DEBUG TRAIN Batch 4/500 loss 1.037661 acc 0.399290 lr 0.00078432 grad_norm 0.311707 rank 1
2025-01-10 05:59:34,889 DEBUG TRAIN Batch 4/500 loss 0.835964 acc 0.538178 lr 0.00078432 grad_norm 0.311707 rank 0
2025-01-10 06:00:00,526 DEBUG TRAIN Batch 4/600 loss 1.030333 acc 0.379548 lr 0.00077954 grad_norm 0.314468 rank 2
2025-01-10 06:00:00,526 DEBUG TRAIN Batch 4/600 loss 1.075083 acc 0.384834 lr 0.00077954 grad_norm 0.314468 rank 1
2025-01-10 06:00:00,530 DEBUG TRAIN Batch 4/600 loss 0.930116 acc 0.502738 lr 0.00077954 grad_norm 0.314468 rank 0
2025-01-10 06:00:26,706 DEBUG TRAIN Batch 4/700 loss 1.001098 acc 0.436218 lr 0.00077484 grad_norm 0.328198 rank 1
2025-01-10 06:00:26,706 DEBUG TRAIN Batch 4/700 loss 0.987750 acc 0.406546 lr 0.00077484 grad_norm 0.328198 rank 2
2025-01-10 06:00:26,707 DEBUG TRAIN Batch 4/700 loss 0.752408 acc 0.552459 lr 0.00077484 grad_norm 0.328198 rank 0
2025-01-10 06:00:51,874 DEBUG TRAIN Batch 4/800 loss 0.957034 acc 0.450561 lr 0.00077023 grad_norm 0.321281 rank 0
2025-01-10 06:00:51,874 DEBUG TRAIN Batch 4/800 loss 1.046136 acc 0.406615 lr 0.00077023 grad_norm 0.321281 rank 2
2025-01-10 06:00:51,875 DEBUG TRAIN Batch 4/800 loss 1.118927 acc 0.386005 lr 0.00077023 grad_norm 0.321281 rank 1
2025-01-10 06:01:16,896 DEBUG TRAIN Batch 4/900 loss 1.094643 acc 0.381526 lr 0.00076570 grad_norm 0.318613 rank 2
2025-01-10 06:01:16,898 DEBUG TRAIN Batch 4/900 loss 0.879646 acc 0.508582 lr 0.00076570 grad_norm 0.318613 rank 0
2025-01-10 06:01:16,899 DEBUG TRAIN Batch 4/900 loss 1.009910 acc 0.411240 lr 0.00076570 grad_norm 0.318613 rank 1
2025-01-10 06:01:42,335 DEBUG TRAIN Batch 4/1000 loss 1.024467 acc 0.418812 lr 0.00076125 grad_norm 0.325108 rank 1
2025-01-10 06:01:42,335 DEBUG TRAIN Batch 4/1000 loss 1.114813 acc 0.366667 lr 0.00076125 grad_norm 0.325108 rank 2
2025-01-10 06:01:42,338 DEBUG TRAIN Batch 4/1000 loss 0.882355 acc 0.483333 lr 0.00076125 grad_norm 0.325108 rank 0
2025-01-10 06:02:08,741 DEBUG TRAIN Batch 4/1100 loss 1.072460 acc 0.384473 lr 0.00075688 grad_norm 0.321809 rank 2
2025-01-10 06:02:08,741 DEBUG TRAIN Batch 4/1100 loss 0.988106 acc 0.474667 lr 0.00075688 grad_norm 0.321809 rank 1
2025-01-10 06:02:08,744 DEBUG TRAIN Batch 4/1100 loss 0.906559 acc 0.506608 lr 0.00075688 grad_norm 0.321809 rank 0
2025-01-10 06:02:34,470 DEBUG TRAIN Batch 4/1200 loss 1.101100 acc 0.382851 lr 0.00075258 grad_norm 0.303662 rank 2
2025-01-10 06:02:34,470 DEBUG TRAIN Batch 4/1200 loss 1.176679 acc 0.375124 lr 0.00075258 grad_norm 0.303662 rank 0
2025-01-10 06:02:34,470 DEBUG TRAIN Batch 4/1200 loss 0.868400 acc 0.527316 lr 0.00075258 grad_norm 0.303662 rank 1
2025-01-10 06:03:00,214 DEBUG TRAIN Batch 4/1300 loss 1.206921 acc 0.339399 lr 0.00074836 grad_norm 0.307173 rank 2
2025-01-10 06:03:00,215 DEBUG TRAIN Batch 4/1300 loss 0.907066 acc 0.472477 lr 0.00074836 grad_norm 0.307173 rank 1
2025-01-10 06:03:00,217 DEBUG TRAIN Batch 4/1300 loss 1.173149 acc 0.360116 lr 0.00074836 grad_norm 0.307173 rank 0
2025-01-10 06:03:25,813 DEBUG TRAIN Batch 4/1400 loss 0.814104 acc 0.549383 lr 0.00074420 grad_norm 0.302564 rank 1
2025-01-10 06:03:25,814 DEBUG TRAIN Batch 4/1400 loss 1.208508 acc 0.325313 lr 0.00074420 grad_norm 0.302564 rank 0
2025-01-10 06:03:25,817 DEBUG TRAIN Batch 4/1400 loss 1.137867 acc 0.352632 lr 0.00074420 grad_norm 0.302564 rank 2
2025-01-10 06:03:51,594 DEBUG TRAIN Batch 4/1500 loss 1.179217 acc 0.345420 lr 0.00074011 grad_norm 0.311640 rank 2
2025-01-10 06:03:51,594 DEBUG TRAIN Batch 4/1500 loss 0.813454 acc 0.556000 lr 0.00074011 grad_norm 0.311640 rank 1
2025-01-10 06:03:51,598 DEBUG TRAIN Batch 4/1500 loss 1.183538 acc 0.343455 lr 0.00074011 grad_norm 0.311640 rank 0
2025-01-10 06:04:18,478 DEBUG TRAIN Batch 4/1600 loss 1.234713 acc 0.325812 lr 0.00073609 grad_norm 0.282117 rank 0
2025-01-10 06:04:18,479 DEBUG TRAIN Batch 4/1600 loss 0.710445 acc 0.599805 lr 0.00073609 grad_norm 0.282117 rank 1
2025-01-10 06:04:18,480 DEBUG TRAIN Batch 4/1600 loss 1.118590 acc 0.364646 lr 0.00073609 grad_norm 0.282117 rank 2
2025-01-10 06:04:43,508 DEBUG TRAIN Batch 4/1700 loss 1.124870 acc 0.377563 lr 0.00073213 grad_norm 0.300833 rank 2
2025-01-10 06:04:43,510 DEBUG TRAIN Batch 4/1700 loss 0.825173 acc 0.532258 lr 0.00073213 grad_norm 0.300833 rank 1
2025-01-10 06:04:43,511 DEBUG TRAIN Batch 4/1700 loss 1.071917 acc 0.369335 lr 0.00073213 grad_norm 0.300833 rank 0
2025-01-10 06:05:09,400 DEBUG TRAIN Batch 4/1800 loss 0.877586 acc 0.511628 lr 0.00072824 grad_norm 0.290046 rank 1
2025-01-10 06:05:09,400 DEBUG TRAIN Batch 4/1800 loss 1.130308 acc 0.352581 lr 0.00072824 grad_norm 0.290046 rank 2
2025-01-10 06:05:09,404 DEBUG TRAIN Batch 4/1800 loss 1.065336 acc 0.383383 lr 0.00072824 grad_norm 0.290046 rank 0
2025-01-10 06:05:34,877 DEBUG TRAIN Batch 4/1900 loss 1.174920 acc 0.369524 lr 0.00072441 grad_norm 0.320156 rank 2
2025-01-10 06:05:34,877 DEBUG TRAIN Batch 4/1900 loss 1.078122 acc 0.389105 lr 0.00072441 grad_norm 0.320156 rank 0
2025-01-10 06:05:34,877 DEBUG TRAIN Batch 4/1900 loss 0.919421 acc 0.479741 lr 0.00072441 grad_norm 0.320156 rank 1
2025-01-10 06:05:59,960 DEBUG TRAIN Batch 4/2000 loss 1.075541 acc 0.391710 lr 0.00072064 grad_norm 0.307489 rank 2
2025-01-10 06:05:59,960 DEBUG TRAIN Batch 4/2000 loss 1.088305 acc 0.389292 lr 0.00072064 grad_norm 0.307489 rank 0
2025-01-10 06:05:59,960 DEBUG TRAIN Batch 4/2000 loss 0.832612 acc 0.514936 lr 0.00072064 grad_norm 0.307489 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 06:07:17,884 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59927ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 06:07:17,965 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 06:07:18,395 INFO Epoch 4 Step 4848 on_batch_end True CV rank 1
2025-01-10 06:07:18,395 INFO Epoch 4 Step 4848 on_batch_end True CV rank 0
2025-01-10 06:07:18,395 INFO Epoch 4 Step 4848 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 06:07:27,520 DEBUG CV Batch 4/100 loss 1.981496 acc 0.439242  rank 0
2025-01-10 06:07:27,873 DEBUG CV Batch 4/100 loss 1.981496 acc 0.439242  rank 2
2025-01-10 06:07:28,042 DEBUG CV Batch 4/100 loss 1.981496 acc 0.439242  rank 1
2025-01-10 06:07:28,054 INFO Epoch 4 Step 4848 CV info lr 0.0007181062370267827 0 rank loss_2.140781350825962 acc_0.3986705433773367
2025-01-10 06:07:28,401 INFO Epoch 4 Step 4848 CV info lr 0.0007181062370267827 2 rank loss_2.140781350825962 acc_0.3986705433773367
2025-01-10 06:07:28,585 INFO Epoch 4 Step 4848 CV info lr 0.0007181062370267827 1 rank loss_2.140781350825962 acc_0.3986705433773367
2025-01-10 06:07:29,348 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_4_whole.pt
2025-01-10 06:07:29,370 INFO Added key: store_based_barrier_key:7 to store for rank: 0
2025-01-10 06:07:29,370 INFO Added key: store_based_barrier_key:7 to store for rank: 1
2025-01-10 06:07:29,370 INFO Added key: store_based_barrier_key:7 to store for rank: 2
2025-01-10 06:07:29,370 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:7 with 3 nodes.
2025-01-10 06:07:29,370 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:7 with 3 nodes.
2025-01-10 06:07:29,371 INFO Epoch 5 TRAIN info lr 0.0007181062370267827 rank 1
2025-01-10 06:07:29,371 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 06:07:29,373 INFO Epoch 5 TRAIN info lr 0.0007181062370267827 rank 2
2025-01-10 06:07:29,373 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 06:07:29,380 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:7 with 3 nodes.
2025-01-10 06:07:29,390 INFO Epoch 5 TRAIN info lr 0.0007181062370267827 rank 0
2025-01-10 06:07:29,390 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 06:07:59,924 DEBUG TRAIN Batch 5/100 loss 1.034247 acc 0.408077 lr 0.00071443 grad_norm 0.325909 rank 0
2025-01-10 06:07:59,924 DEBUG TRAIN Batch 5/100 loss 1.070598 acc 0.413687 lr 0.00071443 grad_norm 0.325909 rank 1
2025-01-10 06:07:59,924 DEBUG TRAIN Batch 5/100 loss 0.966632 acc 0.445248 lr 0.00071443 grad_norm 0.325909 rank 2
2025-01-10 06:08:23,489 DEBUG TRAIN Batch 5/200 loss 1.087410 acc 0.380832 lr 0.00071081 grad_norm 0.355431 rank 0
2025-01-10 06:08:23,489 DEBUG TRAIN Batch 5/200 loss 1.108463 acc 0.392210 lr 0.00071081 grad_norm 0.355431 rank 1
2025-01-10 06:08:23,489 DEBUG TRAIN Batch 5/200 loss 1.059942 acc 0.398964 lr 0.00071081 grad_norm 0.355431 rank 2
2025-01-10 06:08:46,870 DEBUG TRAIN Batch 5/300 loss 1.063271 acc 0.377902 lr 0.00070725 grad_norm 0.339542 rank 0
2025-01-10 06:08:46,870 DEBUG TRAIN Batch 5/300 loss 1.149032 acc 0.352262 lr 0.00070725 grad_norm 0.339542 rank 1
2025-01-10 06:08:46,871 DEBUG TRAIN Batch 5/300 loss 1.088728 acc 0.396750 lr 0.00070725 grad_norm 0.339542 rank 2
2025-01-10 06:09:10,730 DEBUG TRAIN Batch 5/400 loss 1.002550 acc 0.434641 lr 0.00070374 grad_norm 0.341454 rank 2
2025-01-10 06:09:10,730 DEBUG TRAIN Batch 5/400 loss 1.056139 acc 0.421699 lr 0.00070374 grad_norm 0.341454 rank 0
2025-01-10 06:09:10,730 DEBUG TRAIN Batch 5/400 loss 1.068692 acc 0.381166 lr 0.00070374 grad_norm 0.341454 rank 1
2025-01-10 06:09:34,406 DEBUG TRAIN Batch 5/500 loss 1.093415 acc 0.368821 lr 0.00070028 grad_norm 0.329168 rank 1
2025-01-10 06:09:34,406 DEBUG TRAIN Batch 5/500 loss 1.049135 acc 0.402351 lr 0.00070028 grad_norm 0.329168 rank 0
2025-01-10 06:09:34,407 DEBUG TRAIN Batch 5/500 loss 1.069013 acc 0.378641 lr 0.00070028 grad_norm 0.329168 rank 2
2025-01-10 06:09:57,904 DEBUG TRAIN Batch 5/600 loss 0.969088 acc 0.427262 lr 0.00069687 grad_norm 0.352225 rank 0
2025-01-10 06:09:57,904 DEBUG TRAIN Batch 5/600 loss 1.108004 acc 0.378238 lr 0.00069687 grad_norm 0.352225 rank 1
2025-01-10 06:09:57,904 DEBUG TRAIN Batch 5/600 loss 1.057506 acc 0.401685 lr 0.00069687 grad_norm 0.352225 rank 2
2025-01-10 06:10:21,709 DEBUG TRAIN Batch 5/700 loss 0.936038 acc 0.469428 lr 0.00069351 grad_norm 0.352924 rank 1
2025-01-10 06:10:21,709 DEBUG TRAIN Batch 5/700 loss 0.896294 acc 0.435946 lr 0.00069351 grad_norm 0.352924 rank 2
2025-01-10 06:10:21,709 DEBUG TRAIN Batch 5/700 loss 1.073892 acc 0.392439 lr 0.00069351 grad_norm 0.352924 rank 0
2025-01-10 06:10:45,061 DEBUG TRAIN Batch 5/800 loss 1.082031 acc 0.382171 lr 0.00069020 grad_norm 0.316594 rank 1
2025-01-10 06:10:45,061 DEBUG TRAIN Batch 5/800 loss 1.019217 acc 0.404700 lr 0.00069020 grad_norm 0.316594 rank 2
2025-01-10 06:10:45,061 DEBUG TRAIN Batch 5/800 loss 1.007228 acc 0.411662 lr 0.00069020 grad_norm 0.316594 rank 0
2025-01-10 06:11:08,772 DEBUG TRAIN Batch 5/900 loss 0.946712 acc 0.456835 lr 0.00068693 grad_norm 0.318921 rank 1
2025-01-10 06:11:08,772 DEBUG TRAIN Batch 5/900 loss 1.025827 acc 0.379436 lr 0.00068693 grad_norm 0.318921 rank 2
2025-01-10 06:11:08,772 DEBUG TRAIN Batch 5/900 loss 0.898353 acc 0.488064 lr 0.00068693 grad_norm 0.318921 rank 0
2025-01-10 06:11:33,065 DEBUG TRAIN Batch 5/1000 loss 1.055651 acc 0.399127 lr 0.00068371 grad_norm 0.321702 rank 2
2025-01-10 06:11:33,065 DEBUG TRAIN Batch 5/1000 loss 1.179834 acc 0.352511 lr 0.00068371 grad_norm 0.321702 rank 1
2025-01-10 06:11:33,066 DEBUG TRAIN Batch 5/1000 loss 0.908490 acc 0.478936 lr 0.00068371 grad_norm 0.321702 rank 0
2025-01-10 06:11:58,509 DEBUG TRAIN Batch 5/1100 loss 0.910680 acc 0.489619 lr 0.00068054 grad_norm 0.290801 rank 0
2025-01-10 06:11:58,509 DEBUG TRAIN Batch 5/1100 loss 1.044955 acc 0.426829 lr 0.00068054 grad_norm 0.290801 rank 2
2025-01-10 06:11:58,509 DEBUG TRAIN Batch 5/1100 loss 1.078969 acc 0.380346 lr 0.00068054 grad_norm 0.290801 rank 1
2025-01-10 06:12:22,014 DEBUG TRAIN Batch 5/1200 loss 1.074492 acc 0.390244 lr 0.00067741 grad_norm 0.303215 rank 1
2025-01-10 06:12:22,015 DEBUG TRAIN Batch 5/1200 loss 1.093796 acc 0.394071 lr 0.00067741 grad_norm 0.303215 rank 2
2025-01-10 06:12:22,015 DEBUG TRAIN Batch 5/1200 loss 0.882383 acc 0.502276 lr 0.00067741 grad_norm 0.303215 rank 0
2025-01-10 06:12:46,094 DEBUG TRAIN Batch 5/1300 loss 1.117551 acc 0.381760 lr 0.00067432 grad_norm 0.328283 rank 1
2025-01-10 06:12:46,094 DEBUG TRAIN Batch 5/1300 loss 1.033166 acc 0.399781 lr 0.00067432 grad_norm 0.328283 rank 2
2025-01-10 06:12:46,094 DEBUG TRAIN Batch 5/1300 loss 0.853158 acc 0.505391 lr 0.00067432 grad_norm 0.328283 rank 0
2025-01-10 06:13:12,171 DEBUG TRAIN Batch 5/1400 loss 0.832330 acc 0.520179 lr 0.00067128 grad_norm 0.340429 rank 0
2025-01-10 06:13:12,172 DEBUG TRAIN Batch 5/1400 loss 1.253268 acc 0.338066 lr 0.00067128 grad_norm 0.340429 rank 2
2025-01-10 06:13:12,172 DEBUG TRAIN Batch 5/1400 loss 1.139627 acc 0.365421 lr 0.00067128 grad_norm 0.340429 rank 1
2025-01-10 06:13:36,333 DEBUG TRAIN Batch 5/1500 loss 1.084566 acc 0.381115 lr 0.00066827 grad_norm 0.322708 rank 1
2025-01-10 06:13:36,333 DEBUG TRAIN Batch 5/1500 loss 0.804442 acc 0.535514 lr 0.00066827 grad_norm 0.322708 rank 0
2025-01-10 06:13:36,333 DEBUG TRAIN Batch 5/1500 loss 1.035791 acc 0.395085 lr 0.00066827 grad_norm 0.322708 rank 2
2025-01-10 06:14:00,262 DEBUG TRAIN Batch 5/1600 loss 0.861807 acc 0.511317 lr 0.00066531 grad_norm 0.316385 rank 0
2025-01-10 06:14:00,262 DEBUG TRAIN Batch 5/1600 loss 1.086952 acc 0.385915 lr 0.00066531 grad_norm 0.316385 rank 1
2025-01-10 06:14:00,262 DEBUG TRAIN Batch 5/1600 loss 1.068595 acc 0.378817 lr 0.00066531 grad_norm 0.316385 rank 2
2025-01-10 06:14:25,507 DEBUG TRAIN Batch 5/1700 loss 1.134061 acc 0.361914 lr 0.00066238 grad_norm 0.329138 rank 1
2025-01-10 06:14:25,507 DEBUG TRAIN Batch 5/1700 loss 0.902515 acc 0.490818 lr 0.00066238 grad_norm 0.329138 rank 0
2025-01-10 06:14:25,507 DEBUG TRAIN Batch 5/1700 loss 0.919865 acc 0.451912 lr 0.00066238 grad_norm 0.329138 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 06:15:31,584 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 06:15:31,589 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 06:15:32,040 INFO Epoch 5 Step 5711 on_batch_end True CV rank 0
2025-01-10 06:15:32,040 INFO Epoch 5 Step 5711 on_batch_end True CV rank 2
2025-01-10 06:15:32,040 INFO Epoch 5 Step 5711 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 06:15:40,951 DEBUG CV Batch 5/100 loss 1.708770 acc 0.503902  rank 0
2025-01-10 06:15:41,366 DEBUG CV Batch 5/100 loss 1.708770 acc 0.503902  rank 2
2025-01-10 06:15:41,423 INFO Epoch 5 Step 5711 CV info lr 0.0006616280731889014 0 rank loss_2.1122207393248877 acc_0.4041835457870835
2025-01-10 06:15:41,665 DEBUG CV Batch 5/100 loss 1.708770 acc 0.503902  rank 1
2025-01-10 06:15:41,899 INFO Epoch 5 Step 5711 CV info lr 0.0006616280731889014 2 rank loss_2.1122207393248877 acc_0.4041835457870835
2025-01-10 06:15:42,203 INFO Epoch 5 Step 5711 CV info lr 0.0006616280731889014 1 rank loss_2.1122207393248877 acc_0.4041835457870835
2025-01-10 06:15:42,706 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_5_whole.pt
2025-01-10 06:15:42,727 INFO Added key: store_based_barrier_key:8 to store for rank: 0
2025-01-10 06:15:42,738 INFO Added key: store_based_barrier_key:8 to store for rank: 2
2025-01-10 06:15:42,738 INFO Added key: store_based_barrier_key:8 to store for rank: 1
2025-01-10 06:15:42,738 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:8 with 3 nodes.
2025-01-10 06:15:42,738 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:8 with 3 nodes.
2025-01-10 06:15:42,744 INFO Epoch 6 TRAIN info lr 0.0006616280731889014 rank 1
2025-01-10 06:15:42,744 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 06:15:42,748 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:8 with 3 nodes.
2025-01-10 06:15:42,748 INFO Epoch 6 TRAIN info lr 0.0006616280731889014 rank 2
2025-01-10 06:15:42,748 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 06:15:42,749 INFO Epoch 6 TRAIN info lr 0.0006616280731889014 rank 0
2025-01-10 06:15:42,749 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 06:16:18,413 DEBUG TRAIN Batch 6/100 loss 0.996709 acc 0.439425 lr 0.00065875 grad_norm 0.339849 rank 1
2025-01-10 06:16:18,414 DEBUG TRAIN Batch 6/100 loss 0.718997 acc 0.570886 lr 0.00065875 grad_norm 0.339849 rank 0
2025-01-10 06:16:18,414 DEBUG TRAIN Batch 6/100 loss 1.021447 acc 0.386625 lr 0.00065875 grad_norm 0.339849 rank 2
2025-01-10 06:16:42,030 DEBUG TRAIN Batch 6/200 loss 0.837974 acc 0.519645 lr 0.00065591 grad_norm 0.363496 rank 1
2025-01-10 06:16:42,030 DEBUG TRAIN Batch 6/200 loss 0.808276 acc 0.524952 lr 0.00065591 grad_norm 0.363496 rank 0
2025-01-10 06:16:42,031 DEBUG TRAIN Batch 6/200 loss 1.042078 acc 0.374552 lr 0.00065591 grad_norm 0.363496 rank 2
2025-01-10 06:17:05,815 DEBUG TRAIN Batch 6/300 loss 0.892160 acc 0.450835 lr 0.00065311 grad_norm 0.381764 rank 2
2025-01-10 06:17:05,815 DEBUG TRAIN Batch 6/300 loss 0.982905 acc 0.445783 lr 0.00065311 grad_norm 0.381764 rank 1
2025-01-10 06:17:05,816 DEBUG TRAIN Batch 6/300 loss 0.874705 acc 0.529032 lr 0.00065311 grad_norm 0.381764 rank 0
2025-01-10 06:17:29,328 DEBUG TRAIN Batch 6/400 loss 1.093343 acc 0.385802 lr 0.00065034 grad_norm 0.344145 rank 1
2025-01-10 06:17:29,328 DEBUG TRAIN Batch 6/400 loss 0.786381 acc 0.544808 lr 0.00065034 grad_norm 0.344145 rank 0
2025-01-10 06:17:29,328 DEBUG TRAIN Batch 6/400 loss 0.980458 acc 0.437780 lr 0.00065034 grad_norm 0.344145 rank 2
2025-01-10 06:17:53,645 DEBUG TRAIN Batch 6/500 loss 0.939910 acc 0.442189 lr 0.00064761 grad_norm 0.349900 rank 2
2025-01-10 06:17:53,645 DEBUG TRAIN Batch 6/500 loss 0.931511 acc 0.493827 lr 0.00064761 grad_norm 0.349900 rank 0
2025-01-10 06:17:53,646 DEBUG TRAIN Batch 6/500 loss 0.988005 acc 0.430973 lr 0.00064761 grad_norm 0.349900 rank 1
2025-01-10 06:18:18,594 DEBUG TRAIN Batch 6/600 loss 1.052413 acc 0.431752 lr 0.00064491 grad_norm 0.322238 rank 2
2025-01-10 06:18:18,594 DEBUG TRAIN Batch 6/600 loss 0.810177 acc 0.534221 lr 0.00064491 grad_norm 0.322238 rank 0
2025-01-10 06:18:18,595 DEBUG TRAIN Batch 6/600 loss 1.046365 acc 0.362550 lr 0.00064491 grad_norm 0.322238 rank 1
2025-01-10 06:18:42,396 DEBUG TRAIN Batch 6/700 loss 1.028172 acc 0.419355 lr 0.00064224 grad_norm 0.353614 rank 2
2025-01-10 06:18:42,396 DEBUG TRAIN Batch 6/700 loss 0.839700 acc 0.536199 lr 0.00064224 grad_norm 0.353614 rank 0
2025-01-10 06:18:42,397 DEBUG TRAIN Batch 6/700 loss 0.955817 acc 0.444444 lr 0.00064224 grad_norm 0.353614 rank 1
2025-01-10 06:19:07,371 DEBUG TRAIN Batch 6/800 loss 1.101107 acc 0.389445 lr 0.00063961 grad_norm 0.350173 rank 2
2025-01-10 06:19:07,372 DEBUG TRAIN Batch 6/800 loss 0.842142 acc 0.504036 lr 0.00063961 grad_norm 0.350173 rank 0
2025-01-10 06:19:07,372 DEBUG TRAIN Batch 6/800 loss 0.964090 acc 0.426455 lr 0.00063961 grad_norm 0.350173 rank 1
2025-01-10 06:19:32,695 DEBUG TRAIN Batch 6/900 loss 1.027756 acc 0.415398 lr 0.00063701 grad_norm 0.332024 rank 1
2025-01-10 06:19:32,695 DEBUG TRAIN Batch 6/900 loss 1.077597 acc 0.402659 lr 0.00063701 grad_norm 0.332024 rank 2
2025-01-10 06:19:32,699 DEBUG TRAIN Batch 6/900 loss 0.751268 acc 0.555906 lr 0.00063701 grad_norm 0.332024 rank 0
2025-01-10 06:19:58,278 DEBUG TRAIN Batch 6/1000 loss 1.094811 acc 0.387033 lr 0.00063444 grad_norm 0.339721 rank 1
2025-01-10 06:19:58,279 DEBUG TRAIN Batch 6/1000 loss 1.038293 acc 0.382746 lr 0.00063444 grad_norm 0.339721 rank 2
2025-01-10 06:19:58,282 DEBUG TRAIN Batch 6/1000 loss 0.764084 acc 0.562500 lr 0.00063444 grad_norm 0.339721 rank 0
2025-01-10 06:20:24,749 DEBUG TRAIN Batch 6/1100 loss 0.757410 acc 0.560194 lr 0.00063190 grad_norm 0.315941 rank 0
2025-01-10 06:20:24,749 DEBUG TRAIN Batch 6/1100 loss 0.978527 acc 0.433145 lr 0.00063190 grad_norm 0.315941 rank 2
2025-01-10 06:20:24,752 DEBUG TRAIN Batch 6/1100 loss 1.116667 acc 0.377589 lr 0.00063190 grad_norm 0.315941 rank 1
2025-01-10 06:20:49,797 DEBUG TRAIN Batch 6/1200 loss 1.047148 acc 0.406829 lr 0.00062939 grad_norm 0.322948 rank 1
2025-01-10 06:20:49,799 DEBUG TRAIN Batch 6/1200 loss 1.000482 acc 0.415016 lr 0.00062939 grad_norm 0.322948 rank 0
2025-01-10 06:20:49,801 DEBUG TRAIN Batch 6/1200 loss 1.025087 acc 0.427245 lr 0.00062939 grad_norm 0.322948 rank 2
2025-01-10 06:21:15,231 DEBUG TRAIN Batch 6/1300 loss 1.027848 acc 0.414230 lr 0.00062691 grad_norm 0.304440 rank 2
2025-01-10 06:21:15,231 DEBUG TRAIN Batch 6/1300 loss 0.978384 acc 0.409765 lr 0.00062691 grad_norm 0.304440 rank 0
2025-01-10 06:21:15,235 DEBUG TRAIN Batch 6/1300 loss 1.000674 acc 0.411640 lr 0.00062691 grad_norm 0.304440 rank 1
2025-01-10 06:21:41,136 DEBUG TRAIN Batch 6/1400 loss 1.052272 acc 0.397666 lr 0.00062446 grad_norm 0.317727 rank 1
2025-01-10 06:21:41,136 DEBUG TRAIN Batch 6/1400 loss 1.055848 acc 0.408273 lr 0.00062446 grad_norm 0.317727 rank 2
2025-01-10 06:21:41,137 DEBUG TRAIN Batch 6/1400 loss 1.022424 acc 0.402944 lr 0.00062446 grad_norm 0.317727 rank 0
2025-01-10 06:22:06,352 DEBUG TRAIN Batch 6/1500 loss 0.971377 acc 0.466997 lr 0.00062204 grad_norm 0.336435 rank 2
2025-01-10 06:22:06,352 DEBUG TRAIN Batch 6/1500 loss 1.019222 acc 0.396648 lr 0.00062204 grad_norm 0.336435 rank 1
2025-01-10 06:22:06,354 DEBUG TRAIN Batch 6/1500 loss 0.989512 acc 0.412000 lr 0.00062204 grad_norm 0.336435 rank 0
2025-01-10 06:22:31,651 DEBUG TRAIN Batch 6/1600 loss 0.950502 acc 0.453211 lr 0.00061965 grad_norm 0.331213 rank 1
2025-01-10 06:22:31,652 DEBUG TRAIN Batch 6/1600 loss 0.961597 acc 0.416488 lr 0.00061965 grad_norm 0.331213 rank 2
2025-01-10 06:22:31,652 DEBUG TRAIN Batch 6/1600 loss 0.997471 acc 0.418198 lr 0.00061965 grad_norm 0.331213 rank 0
2025-01-10 06:22:56,812 DEBUG TRAIN Batch 6/1700 loss 0.914025 acc 0.441176 lr 0.00061728 grad_norm 0.322244 rank 1
2025-01-10 06:22:56,813 DEBUG TRAIN Batch 6/1700 loss 0.977490 acc 0.425551 lr 0.00061728 grad_norm 0.322244 rank 0
2025-01-10 06:22:56,813 DEBUG TRAIN Batch 6/1700 loss 1.086362 acc 0.386847 lr 0.00061728 grad_norm 0.322244 rank 2
2025-01-10 06:23:22,567 DEBUG TRAIN Batch 6/1800 loss 0.885037 acc 0.457469 lr 0.00061495 grad_norm 0.319427 rank 2
2025-01-10 06:23:22,567 DEBUG TRAIN Batch 6/1800 loss 0.884135 acc 0.463072 lr 0.00061495 grad_norm 0.319427 rank 1
2025-01-10 06:23:22,567 DEBUG TRAIN Batch 6/1800 loss 0.944610 acc 0.457658 lr 0.00061495 grad_norm 0.319427 rank 0
2025-01-10 06:23:48,098 DEBUG TRAIN Batch 6/1900 loss 0.987605 acc 0.440514 lr 0.00061263 grad_norm 0.354946 rank 2
2025-01-10 06:23:48,100 DEBUG TRAIN Batch 6/1900 loss 0.857323 acc 0.482866 lr 0.00061263 grad_norm 0.354946 rank 1
2025-01-10 06:23:48,101 DEBUG TRAIN Batch 6/1900 loss 1.023084 acc 0.422414 lr 0.00061263 grad_norm 0.354946 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 06:24:53,813 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 06:24:53,814 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 06:24:54,246 INFO Epoch 6 Step 6672 on_batch_end True CV rank 0
2025-01-10 06:24:54,246 INFO Epoch 6 Step 6672 on_batch_end True CV rank 1
2025-01-10 06:24:54,246 INFO Epoch 6 Step 6672 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 06:25:04,532 DEBUG CV Batch 6/100 loss 1.640945 acc 0.501672  rank 0
2025-01-10 06:25:04,743 DEBUG CV Batch 6/100 loss 1.640945 acc 0.501672  rank 2
2025-01-10 06:25:05,081 INFO Epoch 6 Step 6672 CV info lr 0.0006121276335929898 0 rank loss_1.973433065571283 acc_0.43770158186293484
2025-01-10 06:25:05,230 DEBUG CV Batch 6/100 loss 1.640945 acc 0.501672  rank 1
2025-01-10 06:25:05,293 INFO Epoch 6 Step 6672 CV info lr 0.0006121276335929898 2 rank loss_1.973433065571283 acc_0.43770158186293484
2025-01-10 06:25:05,813 INFO Epoch 6 Step 6672 CV info lr 0.0006121276335929898 1 rank loss_1.973433065571283 acc_0.43770158186293484
2025-01-10 06:25:06,628 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_6_whole.pt
2025-01-10 06:25:06,640 INFO Added key: store_based_barrier_key:9 to store for rank: 0
2025-01-10 06:25:06,650 INFO Added key: store_based_barrier_key:9 to store for rank: 1
2025-01-10 06:25:06,650 INFO Added key: store_based_barrier_key:9 to store for rank: 2
2025-01-10 06:25:06,651 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:9 with 3 nodes.
2025-01-10 06:25:06,651 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:9 with 3 nodes.
2025-01-10 06:25:06,651 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:9 with 3 nodes.
2025-01-10 06:25:06,656 INFO Epoch 7 TRAIN info lr 0.0006121276335929898 rank 2
2025-01-10 06:25:06,656 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 06:25:06,657 INFO Epoch 7 TRAIN info lr 0.0006121276335929898 rank 0
2025-01-10 06:25:06,657 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 06:25:06,658 INFO Epoch 7 TRAIN info lr 0.0006121276335929898 rank 1
2025-01-10 06:25:06,658 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 06:25:45,906 DEBUG TRAIN Batch 7/100 loss 0.973646 acc 0.441760 lr 0.00060985 grad_norm 0.363402 rank 1
2025-01-10 06:25:45,907 DEBUG TRAIN Batch 7/100 loss 0.979335 acc 0.405128 lr 0.00060985 grad_norm 0.363402 rank 2
2025-01-10 06:25:45,907 DEBUG TRAIN Batch 7/100 loss 0.813898 acc 0.499499 lr 0.00060985 grad_norm 0.363402 rank 0
2025-01-10 06:26:10,059 DEBUG TRAIN Batch 7/200 loss 0.809225 acc 0.523977 lr 0.00060759 grad_norm 0.383531 rank 1
2025-01-10 06:26:10,059 DEBUG TRAIN Batch 7/200 loss 0.952722 acc 0.444053 lr 0.00060759 grad_norm 0.383531 rank 0
2025-01-10 06:26:10,060 DEBUG TRAIN Batch 7/200 loss 0.888515 acc 0.490123 lr 0.00060759 grad_norm 0.383531 rank 2
2025-01-10 06:26:34,606 DEBUG TRAIN Batch 7/300 loss 0.909241 acc 0.455513 lr 0.00060536 grad_norm 0.340417 rank 1
2025-01-10 06:26:34,607 DEBUG TRAIN Batch 7/300 loss 0.864253 acc 0.490272 lr 0.00060536 grad_norm 0.340417 rank 2
2025-01-10 06:26:34,607 DEBUG TRAIN Batch 7/300 loss 0.911729 acc 0.462598 lr 0.00060536 grad_norm 0.340417 rank 0
2025-01-10 06:26:58,832 DEBUG TRAIN Batch 7/400 loss 0.874056 acc 0.487236 lr 0.00060315 grad_norm 0.373181 rank 0
2025-01-10 06:26:58,832 DEBUG TRAIN Batch 7/400 loss 0.933998 acc 0.469565 lr 0.00060315 grad_norm 0.373181 rank 1
2025-01-10 06:26:58,832 DEBUG TRAIN Batch 7/400 loss 0.887151 acc 0.447872 lr 0.00060315 grad_norm 0.373181 rank 2
2025-01-10 06:27:22,918 DEBUG TRAIN Batch 7/500 loss 0.850647 acc 0.491819 lr 0.00060097 grad_norm 0.362705 rank 2
2025-01-10 06:27:22,918 DEBUG TRAIN Batch 7/500 loss 0.783951 acc 0.513514 lr 0.00060097 grad_norm 0.362705 rank 0
2025-01-10 06:27:22,919 DEBUG TRAIN Batch 7/500 loss 0.929288 acc 0.498584 lr 0.00060097 grad_norm 0.362705 rank 1
2025-01-10 06:27:46,474 DEBUG TRAIN Batch 7/600 loss 0.825880 acc 0.507821 lr 0.00059881 grad_norm 0.357962 rank 2
2025-01-10 06:27:46,474 DEBUG TRAIN Batch 7/600 loss 0.888120 acc 0.479716 lr 0.00059881 grad_norm 0.357962 rank 1
2025-01-10 06:27:46,474 DEBUG TRAIN Batch 7/600 loss 0.927436 acc 0.449331 lr 0.00059881 grad_norm 0.357962 rank 0
2025-01-10 06:28:11,424 DEBUG TRAIN Batch 7/700 loss 0.963041 acc 0.415761 lr 0.00059668 grad_norm 0.323563 rank 0
2025-01-10 06:28:11,425 DEBUG TRAIN Batch 7/700 loss 0.928247 acc 0.481244 lr 0.00059668 grad_norm 0.323563 rank 1
2025-01-10 06:28:11,425 DEBUG TRAIN Batch 7/700 loss 0.852001 acc 0.480923 lr 0.00059668 grad_norm 0.323563 rank 2
2025-01-10 06:28:35,540 DEBUG TRAIN Batch 7/800 loss 0.856165 acc 0.485567 lr 0.00059456 grad_norm 0.350426 rank 2
2025-01-10 06:28:35,540 DEBUG TRAIN Batch 7/800 loss 0.920756 acc 0.459911 lr 0.00059456 grad_norm 0.350426 rank 1
2025-01-10 06:28:35,540 DEBUG TRAIN Batch 7/800 loss 0.985946 acc 0.411867 lr 0.00059456 grad_norm 0.350426 rank 0
2025-01-10 06:28:59,418 DEBUG TRAIN Batch 7/900 loss 0.964867 acc 0.416594 lr 0.00059247 grad_norm 0.321799 rank 0
2025-01-10 06:28:59,419 DEBUG TRAIN Batch 7/900 loss 0.985929 acc 0.419162 lr 0.00059247 grad_norm 0.321799 rank 1
2025-01-10 06:28:59,419 DEBUG TRAIN Batch 7/900 loss 0.749479 acc 0.558935 lr 0.00059247 grad_norm 0.321799 rank 2
2025-01-10 06:29:22,800 DEBUG TRAIN Batch 7/1000 loss 0.978481 acc 0.435614 lr 0.00059040 grad_norm 0.341871 rank 1
2025-01-10 06:29:22,800 DEBUG TRAIN Batch 7/1000 loss 0.883659 acc 0.460674 lr 0.00059040 grad_norm 0.341871 rank 0
2025-01-10 06:29:22,801 DEBUG TRAIN Batch 7/1000 loss 0.796806 acc 0.517241 lr 0.00059040 grad_norm 0.341871 rank 2
2025-01-10 06:29:46,996 DEBUG TRAIN Batch 7/1100 loss 0.956114 acc 0.447222 lr 0.00058836 grad_norm 0.343999 rank 0
2025-01-10 06:29:46,996 DEBUG TRAIN Batch 7/1100 loss 0.822620 acc 0.486486 lr 0.00058836 grad_norm 0.343999 rank 1
2025-01-10 06:29:46,996 DEBUG TRAIN Batch 7/1100 loss 0.880542 acc 0.478469 lr 0.00058836 grad_norm 0.343999 rank 2
2025-01-10 06:30:11,687 DEBUG TRAIN Batch 7/1200 loss 0.843342 acc 0.474090 lr 0.00058633 grad_norm 0.371187 rank 0
2025-01-10 06:30:11,687 DEBUG TRAIN Batch 7/1200 loss 0.984755 acc 0.443074 lr 0.00058633 grad_norm 0.371187 rank 1
2025-01-10 06:30:11,687 DEBUG TRAIN Batch 7/1200 loss 0.745042 acc 0.569823 lr 0.00058633 grad_norm 0.371187 rank 2
2025-01-10 06:30:35,542 DEBUG TRAIN Batch 7/1300 loss 0.960586 acc 0.427746 lr 0.00058433 grad_norm 0.354853 rank 0
2025-01-10 06:30:35,542 DEBUG TRAIN Batch 7/1300 loss 0.945082 acc 0.445298 lr 0.00058433 grad_norm 0.354853 rank 1
2025-01-10 06:30:35,542 DEBUG TRAIN Batch 7/1300 loss 0.827530 acc 0.560113 lr 0.00058433 grad_norm 0.354853 rank 2
2025-01-10 06:31:00,837 DEBUG TRAIN Batch 7/1400 loss 0.879900 acc 0.478316 lr 0.00058234 grad_norm 0.408941 rank 0
2025-01-10 06:31:00,837 DEBUG TRAIN Batch 7/1400 loss 0.845346 acc 0.470209 lr 0.00058234 grad_norm 0.408941 rank 1
2025-01-10 06:31:00,837 DEBUG TRAIN Batch 7/1400 loss 0.824470 acc 0.546682 lr 0.00058234 grad_norm 0.408941 rank 2
2025-01-10 06:31:26,076 DEBUG TRAIN Batch 7/1500 loss 1.095030 acc 0.379447 lr 0.00058038 grad_norm 0.314607 rank 1
2025-01-10 06:31:26,076 DEBUG TRAIN Batch 7/1500 loss 0.911618 acc 0.450000 lr 0.00058038 grad_norm 0.314607 rank 0
2025-01-10 06:31:26,076 DEBUG TRAIN Batch 7/1500 loss 0.817038 acc 0.527103 lr 0.00058038 grad_norm 0.314607 rank 2
2025-01-10 06:31:50,057 DEBUG TRAIN Batch 7/1600 loss 1.103752 acc 0.357838 lr 0.00057843 grad_norm 0.334033 rank 1
2025-01-10 06:31:50,058 DEBUG TRAIN Batch 7/1600 loss 0.906376 acc 0.469347 lr 0.00057843 grad_norm 0.334033 rank 2
2025-01-10 06:31:50,058 DEBUG TRAIN Batch 7/1600 loss 0.977126 acc 0.426840 lr 0.00057843 grad_norm 0.334033 rank 0
2025-01-10 06:32:15,091 DEBUG TRAIN Batch 7/1700 loss 1.016899 acc 0.423488 lr 0.00057651 grad_norm 0.351068 rank 0
2025-01-10 06:32:15,091 DEBUG TRAIN Batch 7/1700 loss 0.673228 acc 0.593023 lr 0.00057651 grad_norm 0.351068 rank 2
2025-01-10 06:32:15,091 DEBUG TRAIN Batch 7/1700 loss 1.122245 acc 0.375242 lr 0.00057651 grad_norm 0.351068 rank 1
2025-01-10 06:32:39,230 DEBUG TRAIN Batch 7/1800 loss 0.997631 acc 0.419453 lr 0.00057460 grad_norm 0.399516 rank 0
2025-01-10 06:32:39,230 DEBUG TRAIN Batch 7/1800 loss 0.928063 acc 0.446667 lr 0.00057460 grad_norm 0.399516 rank 1
2025-01-10 06:32:39,231 DEBUG TRAIN Batch 7/1800 loss 0.885845 acc 0.482143 lr 0.00057460 grad_norm 0.399516 rank 2
2025-01-10 06:33:03,927 DEBUG TRAIN Batch 7/1900 loss 0.898576 acc 0.454545 lr 0.00057271 grad_norm 0.361133 rank 1
2025-01-10 06:33:03,927 DEBUG TRAIN Batch 7/1900 loss 1.043727 acc 0.393116 lr 0.00057271 grad_norm 0.361133 rank 0
2025-01-10 06:33:03,927 DEBUG TRAIN Batch 7/1900 loss 0.759594 acc 0.570142 lr 0.00057271 grad_norm 0.361133 rank 2
2025-01-10 06:33:29,182 DEBUG TRAIN Batch 7/2000 loss 0.860475 acc 0.454194 lr 0.00057084 grad_norm 0.338996 rank 1
2025-01-10 06:33:29,183 DEBUG TRAIN Batch 7/2000 loss 0.981842 acc 0.438214 lr 0.00057084 grad_norm 0.338996 rank 0
2025-01-10 06:33:29,183 DEBUG TRAIN Batch 7/2000 loss 1.047173 acc 0.412944 lr 0.00057084 grad_norm 0.338996 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 06:34:31,178 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 06:34:31,178 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 06:34:31,626 INFO Epoch 7 Step 7676 on_batch_end True CV rank 0
2025-01-10 06:34:31,626 INFO Epoch 7 Step 7676 on_batch_end True CV rank 2
2025-01-10 06:34:31,626 INFO Epoch 7 Step 7676 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 06:34:40,816 DEBUG CV Batch 7/100 loss 1.524036 acc 0.545151  rank 2
2025-01-10 06:34:40,947 DEBUG CV Batch 7/100 loss 1.524036 acc 0.545151  rank 0
2025-01-10 06:34:41,307 INFO Epoch 7 Step 7676 CV info lr 0.000570692968051316 2 rank loss_1.9015625908709408 acc_0.45676033290331824
2025-01-10 06:34:41,482 INFO Epoch 7 Step 7676 CV info lr 0.000570692968051316 0 rank loss_1.9015625908709408 acc_0.45676033290331824
2025-01-10 06:34:41,485 DEBUG CV Batch 7/100 loss 1.524036 acc 0.545151  rank 1
2025-01-10 06:34:42,031 INFO Epoch 7 Step 7676 CV info lr 0.000570692968051316 1 rank loss_1.9015625908709408 acc_0.45676033290331824
2025-01-10 06:34:42,748 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_7_whole.pt
2025-01-10 06:34:42,759 INFO Added key: store_based_barrier_key:10 to store for rank: 0
2025-01-10 06:34:42,770 INFO Added key: store_based_barrier_key:10 to store for rank: 2
2025-01-10 06:34:42,770 INFO Added key: store_based_barrier_key:10 to store for rank: 1
2025-01-10 06:34:42,770 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:10 with 3 nodes.
2025-01-10 06:34:42,777 INFO Epoch 8 TRAIN info lr 0.000570692968051316 rank 1
2025-01-10 06:34:42,777 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 06:34:42,780 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:10 with 3 nodes.
2025-01-10 06:34:42,780 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:10 with 3 nodes.
2025-01-10 06:34:42,782 INFO Epoch 8 TRAIN info lr 0.000570692968051316 rank 2
2025-01-10 06:34:42,782 INFO Epoch 8 TRAIN info lr 0.000570692968051316 rank 0
2025-01-10 06:34:42,782 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 06:34:42,782 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 06:35:14,561 DEBUG TRAIN Batch 8/100 loss 0.861653 acc 0.478147 lr 0.00056884 grad_norm 0.388346 rank 1
2025-01-10 06:35:14,562 DEBUG TRAIN Batch 8/100 loss 0.750300 acc 0.544524 lr 0.00056884 grad_norm 0.388346 rank 0
2025-01-10 06:35:14,562 DEBUG TRAIN Batch 8/100 loss 0.829286 acc 0.490340 lr 0.00056884 grad_norm 0.388346 rank 2
2025-01-10 06:35:38,554 DEBUG TRAIN Batch 8/200 loss 0.971034 acc 0.439462 lr 0.00056701 grad_norm 0.390175 rank 0
2025-01-10 06:35:38,555 DEBUG TRAIN Batch 8/200 loss 0.876181 acc 0.465291 lr 0.00056701 grad_norm 0.390175 rank 2
2025-01-10 06:35:38,554 DEBUG TRAIN Batch 8/200 loss 0.889503 acc 0.482854 lr 0.00056701 grad_norm 0.390175 rank 1
2025-01-10 06:36:03,222 DEBUG TRAIN Batch 8/300 loss 1.088538 acc 0.369176 lr 0.00056520 grad_norm 0.368724 rank 1
2025-01-10 06:36:03,223 DEBUG TRAIN Batch 8/300 loss 0.938136 acc 0.464387 lr 0.00056520 grad_norm 0.368724 rank 2
2025-01-10 06:36:03,223 DEBUG TRAIN Batch 8/300 loss 0.902007 acc 0.461462 lr 0.00056520 grad_norm 0.368724 rank 0
2025-01-10 06:36:26,907 DEBUG TRAIN Batch 8/400 loss 0.878068 acc 0.483903 lr 0.00056340 grad_norm 0.401340 rank 2
2025-01-10 06:36:26,908 DEBUG TRAIN Batch 8/400 loss 0.936473 acc 0.449275 lr 0.00056340 grad_norm 0.401340 rank 0
2025-01-10 06:36:26,908 DEBUG TRAIN Batch 8/400 loss 1.016065 acc 0.383634 lr 0.00056340 grad_norm 0.401340 rank 1
2025-01-10 06:36:51,497 DEBUG TRAIN Batch 8/500 loss 0.826115 acc 0.513208 lr 0.00056162 grad_norm 0.358754 rank 2
2025-01-10 06:36:51,497 DEBUG TRAIN Batch 8/500 loss 0.919845 acc 0.466549 lr 0.00056162 grad_norm 0.358754 rank 0
2025-01-10 06:36:51,498 DEBUG TRAIN Batch 8/500 loss 1.017716 acc 0.417881 lr 0.00056162 grad_norm 0.358754 rank 1
2025-01-10 06:37:15,424 DEBUG TRAIN Batch 8/600 loss 1.073054 acc 0.362524 lr 0.00055986 grad_norm 0.372760 rank 1
2025-01-10 06:37:15,425 DEBUG TRAIN Batch 8/600 loss 0.966248 acc 0.428571 lr 0.00055986 grad_norm 0.372760 rank 2
2025-01-10 06:37:15,427 DEBUG TRAIN Batch 8/600 loss 0.862064 acc 0.461751 lr 0.00055986 grad_norm 0.372760 rank 0
2025-01-10 06:37:39,517 DEBUG TRAIN Batch 8/700 loss 0.918719 acc 0.453654 lr 0.00055811 grad_norm 0.420323 rank 1
2025-01-10 06:37:39,518 DEBUG TRAIN Batch 8/700 loss 0.864235 acc 0.471390 lr 0.00055811 grad_norm 0.420323 rank 0
2025-01-10 06:37:39,518 DEBUG TRAIN Batch 8/700 loss 0.943830 acc 0.438429 lr 0.00055811 grad_norm 0.420323 rank 2
2025-01-10 06:38:03,474 DEBUG TRAIN Batch 8/800 loss 0.824014 acc 0.502402 lr 0.00055638 grad_norm 0.365467 rank 1
2025-01-10 06:38:03,474 DEBUG TRAIN Batch 8/800 loss 0.822732 acc 0.478692 lr 0.00055638 grad_norm 0.365467 rank 0
2025-01-10 06:38:03,474 DEBUG TRAIN Batch 8/800 loss 0.912289 acc 0.466270 lr 0.00055638 grad_norm 0.365467 rank 2
2025-01-10 06:38:29,656 DEBUG TRAIN Batch 8/900 loss 0.751636 acc 0.533909 lr 0.00055467 grad_norm 0.381750 rank 1
2025-01-10 06:38:29,656 DEBUG TRAIN Batch 8/900 loss 0.890316 acc 0.465374 lr 0.00055467 grad_norm 0.381750 rank 2
2025-01-10 06:38:29,675 DEBUG TRAIN Batch 8/900 loss 0.884286 acc 0.478222 lr 0.00055467 grad_norm 0.381750 rank 0
2025-01-10 06:38:54,273 DEBUG TRAIN Batch 8/1000 loss 0.728375 acc 0.549488 lr 0.00055297 grad_norm 0.410947 rank 2
2025-01-10 06:38:54,273 DEBUG TRAIN Batch 8/1000 loss 0.867827 acc 0.483178 lr 0.00055297 grad_norm 0.410947 rank 1
2025-01-10 06:38:54,274 DEBUG TRAIN Batch 8/1000 loss 0.842805 acc 0.475546 lr 0.00055297 grad_norm 0.410947 rank 0
2025-01-10 06:39:20,212 DEBUG TRAIN Batch 8/1100 loss 0.918503 acc 0.451309 lr 0.00055128 grad_norm 0.369057 rank 2
2025-01-10 06:39:20,212 DEBUG TRAIN Batch 8/1100 loss 0.850003 acc 0.493789 lr 0.00055128 grad_norm 0.369057 rank 1
2025-01-10 06:39:20,229 DEBUG TRAIN Batch 8/1100 loss 0.809481 acc 0.512346 lr 0.00055128 grad_norm 0.369057 rank 0
2025-01-10 06:39:45,855 DEBUG TRAIN Batch 8/1200 loss 0.709576 acc 0.579802 lr 0.00054962 grad_norm 0.361166 rank 1
2025-01-10 06:39:45,855 DEBUG TRAIN Batch 8/1200 loss 0.815061 acc 0.525696 lr 0.00054962 grad_norm 0.361166 rank 0
2025-01-10 06:39:45,856 DEBUG TRAIN Batch 8/1200 loss 0.873910 acc 0.477650 lr 0.00054962 grad_norm 0.361166 rank 2
2025-01-10 06:40:09,443 DEBUG TRAIN Batch 8/1300 loss 0.664089 acc 0.600000 lr 0.00054796 grad_norm 0.352633 rank 1
2025-01-10 06:40:09,443 DEBUG TRAIN Batch 8/1300 loss 0.909270 acc 0.458111 lr 0.00054796 grad_norm 0.352633 rank 0
2025-01-10 06:40:09,444 DEBUG TRAIN Batch 8/1300 loss 0.962745 acc 0.439453 lr 0.00054796 grad_norm 0.352633 rank 2
2025-01-10 06:40:33,859 DEBUG TRAIN Batch 8/1400 loss 0.766945 acc 0.539757 lr 0.00054633 grad_norm 0.367393 rank 1
2025-01-10 06:40:33,859 DEBUG TRAIN Batch 8/1400 loss 0.973204 acc 0.427359 lr 0.00054633 grad_norm 0.367393 rank 2
2025-01-10 06:40:33,860 DEBUG TRAIN Batch 8/1400 loss 0.946168 acc 0.437381 lr 0.00054633 grad_norm 0.367393 rank 0
2025-01-10 06:40:59,241 DEBUG TRAIN Batch 8/1500 loss 0.643835 acc 0.598400 lr 0.00054470 grad_norm 0.358757 rank 1
2025-01-10 06:40:59,242 DEBUG TRAIN Batch 8/1500 loss 1.045201 acc 0.409091 lr 0.00054470 grad_norm 0.358757 rank 2
2025-01-10 06:40:59,254 DEBUG TRAIN Batch 8/1500 loss 0.952688 acc 0.420671 lr 0.00054470 grad_norm 0.358757 rank 0
2025-01-10 06:41:27,061 DEBUG TRAIN Batch 8/1600 loss 0.682553 acc 0.598846 lr 0.00054309 grad_norm 0.382059 rank 1
2025-01-10 06:41:27,062 DEBUG TRAIN Batch 8/1600 loss 1.030999 acc 0.410796 lr 0.00054309 grad_norm 0.382059 rank 2
2025-01-10 06:41:27,062 DEBUG TRAIN Batch 8/1600 loss 0.958603 acc 0.456984 lr 0.00054309 grad_norm 0.382059 rank 0
2025-01-10 06:41:52,226 DEBUG TRAIN Batch 8/1700 loss 0.651014 acc 0.617359 lr 0.00054150 grad_norm 0.370557 rank 1
2025-01-10 06:41:52,227 DEBUG TRAIN Batch 8/1700 loss 1.049498 acc 0.388313 lr 0.00054150 grad_norm 0.370557 rank 2
2025-01-10 06:41:52,227 DEBUG TRAIN Batch 8/1700 loss 0.862196 acc 0.491285 lr 0.00054150 grad_norm 0.370557 rank 0
2025-01-10 06:42:18,079 DEBUG TRAIN Batch 8/1800 loss 1.044476 acc 0.406526 lr 0.00053992 grad_norm 0.323225 rank 2
2025-01-10 06:42:18,080 DEBUG TRAIN Batch 8/1800 loss 0.858752 acc 0.527473 lr 0.00053992 grad_norm 0.323225 rank 0
2025-01-10 06:42:18,080 DEBUG TRAIN Batch 8/1800 loss 0.808375 acc 0.523864 lr 0.00053992 grad_norm 0.323225 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 06:43:40,815 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 06:43:40,816 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 06:43:41,254 INFO Epoch 8 Step 8622 on_batch_end True CV rank 0
2025-01-10 06:43:41,254 INFO Epoch 8 Step 8622 on_batch_end True CV rank 1
2025-01-10 06:43:41,254 INFO Epoch 8 Step 8622 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 06:43:50,430 DEBUG CV Batch 8/100 loss 1.362685 acc 0.581940  rank 0
2025-01-10 06:43:50,546 DEBUG CV Batch 8/100 loss 1.362685 acc 0.581940  rank 2
2025-01-10 06:43:50,789 DEBUG CV Batch 8/100 loss 1.362685 acc 0.581940  rank 1
2025-01-10 06:43:50,946 INFO Epoch 8 Step 8622 CV info lr 0.0005384755581260321 0 rank loss_1.853342144374262 acc_0.4666502921466242
2025-01-10 06:43:51,068 INFO Epoch 8 Step 8622 CV info lr 0.0005384755581260321 2 rank loss_1.853342144374262 acc_0.4666502921466242
2025-01-10 06:43:51,290 INFO Epoch 8 Step 8622 CV info lr 0.0005384755581260321 1 rank loss_1.853342144374262 acc_0.4666502921466242
2025-01-10 06:43:52,252 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_8_whole.pt
2025-01-10 06:43:52,274 INFO Added key: store_based_barrier_key:11 to store for rank: 0
2025-01-10 06:43:52,285 INFO Added key: store_based_barrier_key:11 to store for rank: 2
2025-01-10 06:43:52,285 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:11 with 3 nodes.
2025-01-10 06:43:52,285 INFO Added key: store_based_barrier_key:11 to store for rank: 1
2025-01-10 06:43:52,285 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:11 with 3 nodes.
2025-01-10 06:43:52,287 INFO Epoch 9 TRAIN info lr 0.0005384755581260321 rank 1
2025-01-10 06:43:52,287 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 06:43:52,293 INFO Epoch 9 TRAIN info lr 0.0005384755581260321 rank 2
2025-01-10 06:43:52,293 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 06:43:52,295 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:11 with 3 nodes.
2025-01-10 06:43:52,305 INFO Epoch 9 TRAIN info lr 0.0005384755581260321 rank 0
2025-01-10 06:43:52,305 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 06:44:28,883 DEBUG TRAIN Batch 9/100 loss 0.784581 acc 0.534972 lr 0.00053692 grad_norm 0.398532 rank 2
2025-01-10 06:44:28,883 DEBUG TRAIN Batch 9/100 loss 0.901752 acc 0.466725 lr 0.00053692 grad_norm 0.398532 rank 0
2025-01-10 06:44:28,884 DEBUG TRAIN Batch 9/100 loss 0.908913 acc 0.477153 lr 0.00053692 grad_norm 0.398532 rank 1
2025-01-10 06:44:52,887 DEBUG TRAIN Batch 9/200 loss 0.760278 acc 0.537465 lr 0.00053538 grad_norm 0.435379 rank 1
2025-01-10 06:44:52,887 DEBUG TRAIN Batch 9/200 loss 0.799391 acc 0.506024 lr 0.00053538 grad_norm 0.435379 rank 0
2025-01-10 06:44:52,888 DEBUG TRAIN Batch 9/200 loss 0.868980 acc 0.486867 lr 0.00053538 grad_norm 0.435379 rank 2
2025-01-10 06:45:18,263 DEBUG TRAIN Batch 9/300 loss 0.961483 acc 0.436346 lr 0.00053385 grad_norm 0.443068 rank 0
2025-01-10 06:45:18,263 DEBUG TRAIN Batch 9/300 loss 0.778875 acc 0.528934 lr 0.00053385 grad_norm 0.443068 rank 1
2025-01-10 06:45:18,263 DEBUG TRAIN Batch 9/300 loss 0.822294 acc 0.481223 lr 0.00053385 grad_norm 0.443068 rank 2
2025-01-10 06:45:44,658 DEBUG TRAIN Batch 9/400 loss 0.645147 acc 0.588378 lr 0.00053234 grad_norm 0.423162 rank 1
2025-01-10 06:45:44,658 DEBUG TRAIN Batch 9/400 loss 0.811923 acc 0.497148 lr 0.00053234 grad_norm 0.423162 rank 2
2025-01-10 06:45:44,676 DEBUG TRAIN Batch 9/400 loss 0.845818 acc 0.493518 lr 0.00053234 grad_norm 0.423162 rank 0
2025-01-10 06:46:10,857 DEBUG TRAIN Batch 9/500 loss 0.839730 acc 0.500969 lr 0.00053083 grad_norm 0.382327 rank 2
2025-01-10 06:46:10,857 DEBUG TRAIN Batch 9/500 loss 0.813771 acc 0.513913 lr 0.00053083 grad_norm 0.382327 rank 1
2025-01-10 06:46:10,858 DEBUG TRAIN Batch 9/500 loss 0.872354 acc 0.454910 lr 0.00053083 grad_norm 0.382327 rank 0
2025-01-10 06:46:36,672 DEBUG TRAIN Batch 9/600 loss 0.871756 acc 0.477167 lr 0.00052935 grad_norm 0.405157 rank 0
2025-01-10 06:46:36,672 DEBUG TRAIN Batch 9/600 loss 0.745923 acc 0.533149 lr 0.00052935 grad_norm 0.405157 rank 1
2025-01-10 06:46:36,672 DEBUG TRAIN Batch 9/600 loss 0.708925 acc 0.559633 lr 0.00052935 grad_norm 0.405157 rank 2
2025-01-10 06:47:00,732 DEBUG TRAIN Batch 9/700 loss 1.045148 acc 0.407993 lr 0.00052787 grad_norm 0.412413 rank 2
2025-01-10 06:47:00,732 DEBUG TRAIN Batch 9/700 loss 0.716063 acc 0.557930 lr 0.00052787 grad_norm 0.412413 rank 0
2025-01-10 06:47:00,733 DEBUG TRAIN Batch 9/700 loss 0.987737 acc 0.425023 lr 0.00052787 grad_norm 0.412413 rank 1
2025-01-10 06:47:25,539 DEBUG TRAIN Batch 9/800 loss 0.956556 acc 0.435130 lr 0.00052640 grad_norm 0.357821 rank 1
2025-01-10 06:47:25,539 DEBUG TRAIN Batch 9/800 loss 1.085426 acc 0.394623 lr 0.00052640 grad_norm 0.357821 rank 2
2025-01-10 06:47:25,539 DEBUG TRAIN Batch 9/800 loss 0.865196 acc 0.474716 lr 0.00052640 grad_norm 0.357821 rank 0
2025-01-10 06:47:49,404 DEBUG TRAIN Batch 9/900 loss 0.909959 acc 0.455399 lr 0.00052495 grad_norm 0.390802 rank 1
2025-01-10 06:47:49,405 DEBUG TRAIN Batch 9/900 loss 0.916797 acc 0.459946 lr 0.00052495 grad_norm 0.390802 rank 0
2025-01-10 06:47:49,407 DEBUG TRAIN Batch 9/900 loss 0.895136 acc 0.472008 lr 0.00052495 grad_norm 0.390802 rank 2
2025-01-10 06:48:13,411 DEBUG TRAIN Batch 9/1000 loss 0.943690 acc 0.447534 lr 0.00052351 grad_norm 0.363123 rank 2
2025-01-10 06:48:13,411 DEBUG TRAIN Batch 9/1000 loss 0.848590 acc 0.466946 lr 0.00052351 grad_norm 0.363123 rank 0
2025-01-10 06:48:13,412 DEBUG TRAIN Batch 9/1000 loss 0.990587 acc 0.417937 lr 0.00052351 grad_norm 0.363123 rank 1
2025-01-10 06:48:39,177 DEBUG TRAIN Batch 9/1100 loss 0.947037 acc 0.453757 lr 0.00052208 grad_norm 0.360311 rank 2
2025-01-10 06:48:39,177 DEBUG TRAIN Batch 9/1100 loss 0.742271 acc 0.554787 lr 0.00052208 grad_norm 0.360311 rank 0
2025-01-10 06:48:39,177 DEBUG TRAIN Batch 9/1100 loss 0.889798 acc 0.494884 lr 0.00052208 grad_norm 0.360311 rank 1
2025-01-10 06:49:03,145 DEBUG TRAIN Batch 9/1200 loss 0.888959 acc 0.463063 lr 0.00052066 grad_norm 0.373383 rank 0
2025-01-10 06:49:03,145 DEBUG TRAIN Batch 9/1200 loss 0.872291 acc 0.455809 lr 0.00052066 grad_norm 0.373383 rank 2
2025-01-10 06:49:03,145 DEBUG TRAIN Batch 9/1200 loss 0.917282 acc 0.457426 lr 0.00052066 grad_norm 0.373383 rank 1
2025-01-10 06:49:28,205 DEBUG TRAIN Batch 9/1300 loss 0.801777 acc 0.539559 lr 0.00051926 grad_norm 0.375596 rank 1
2025-01-10 06:49:28,206 DEBUG TRAIN Batch 9/1300 loss 0.756970 acc 0.525935 lr 0.00051926 grad_norm 0.375596 rank 2
2025-01-10 06:49:28,223 DEBUG TRAIN Batch 9/1300 loss 0.845499 acc 0.490451 lr 0.00051926 grad_norm 0.375596 rank 0
2025-01-10 06:49:54,033 DEBUG TRAIN Batch 9/1400 loss 0.845121 acc 0.478134 lr 0.00051786 grad_norm 0.405518 rank 2
2025-01-10 06:49:54,034 DEBUG TRAIN Batch 9/1400 loss 0.797388 acc 0.527919 lr 0.00051786 grad_norm 0.405518 rank 0
2025-01-10 06:49:54,034 DEBUG TRAIN Batch 9/1400 loss 0.917331 acc 0.469018 lr 0.00051786 grad_norm 0.405518 rank 1
2025-01-10 06:50:21,493 DEBUG TRAIN Batch 9/1500 loss 0.829792 acc 0.520958 lr 0.00051648 grad_norm 0.421902 rank 2
2025-01-10 06:50:21,494 DEBUG TRAIN Batch 9/1500 loss 0.965103 acc 0.446199 lr 0.00051648 grad_norm 0.421902 rank 0
2025-01-10 06:50:21,494 DEBUG TRAIN Batch 9/1500 loss 0.972761 acc 0.443844 lr 0.00051648 grad_norm 0.421902 rank 1
2025-01-10 06:50:45,613 DEBUG TRAIN Batch 9/1600 loss 0.868661 acc 0.485973 lr 0.00051511 grad_norm 0.383636 rank 0
2025-01-10 06:50:45,613 DEBUG TRAIN Batch 9/1600 loss 1.003702 acc 0.419472 lr 0.00051511 grad_norm 0.383636 rank 1
2025-01-10 06:50:45,613 DEBUG TRAIN Batch 9/1600 loss 0.870272 acc 0.474385 lr 0.00051511 grad_norm 0.383636 rank 2
2025-01-10 06:51:08,837 DEBUG TRAIN Batch 9/1700 loss 0.895236 acc 0.480569 lr 0.00051375 grad_norm 0.383296 rank 0
2025-01-10 06:51:08,837 DEBUG TRAIN Batch 9/1700 loss 1.007576 acc 0.418627 lr 0.00051375 grad_norm 0.383296 rank 1
2025-01-10 06:51:08,838 DEBUG TRAIN Batch 9/1700 loss 0.779849 acc 0.521452 lr 0.00051375 grad_norm 0.383296 rank 2
2025-01-10 06:51:35,534 DEBUG TRAIN Batch 9/1800 loss 0.848471 acc 0.496063 lr 0.00051240 grad_norm 0.401675 rank 0
2025-01-10 06:51:35,534 DEBUG TRAIN Batch 9/1800 loss 0.770542 acc 0.546763 lr 0.00051240 grad_norm 0.401675 rank 2
2025-01-10 06:51:35,534 DEBUG TRAIN Batch 9/1800 loss 0.922650 acc 0.459930 lr 0.00051240 grad_norm 0.401675 rank 1
2025-01-10 06:52:00,360 DEBUG TRAIN Batch 9/1900 loss 0.875083 acc 0.488352 lr 0.00051106 grad_norm 0.362235 rank 2
2025-01-10 06:52:00,360 DEBUG TRAIN Batch 9/1900 loss 0.938791 acc 0.443119 lr 0.00051106 grad_norm 0.362235 rank 1
2025-01-10 06:52:00,374 DEBUG TRAIN Batch 9/1900 loss 0.845175 acc 0.500000 lr 0.00051106 grad_norm 0.362235 rank 0
2025-01-10 06:52:26,265 DEBUG TRAIN Batch 9/2000 loss 0.929504 acc 0.430324 lr 0.00050973 grad_norm 0.370179 rank 2
2025-01-10 06:52:26,265 DEBUG TRAIN Batch 9/2000 loss 0.866270 acc 0.507415 lr 0.00050973 grad_norm 0.370179 rank 0
2025-01-10 06:52:26,266 DEBUG TRAIN Batch 9/2000 loss 1.065299 acc 0.402830 lr 0.00050973 grad_norm 0.370179 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 06:53:45,407 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59983ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 06:53:45,422 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 06:53:45,769 INFO Epoch 9 Step 9662 on_batch_end True CV rank 1
2025-01-10 06:53:45,769 INFO Epoch 9 Step 9662 on_batch_end True CV rank 0
2025-01-10 06:53:45,769 INFO Epoch 9 Step 9662 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 06:53:54,859 DEBUG CV Batch 9/100 loss 1.440315 acc 0.560758  rank 0
2025-01-10 06:53:54,979 DEBUG CV Batch 9/100 loss 1.440315 acc 0.560758  rank 2
2025-01-10 06:53:55,363 INFO Epoch 9 Step 9662 CV info lr 0.0005086704250541577 0 rank loss_1.7594481591592754 acc_0.4967577763293919
2025-01-10 06:53:55,407 DEBUG CV Batch 9/100 loss 1.440315 acc 0.560758  rank 1
2025-01-10 06:53:55,515 INFO Epoch 9 Step 9662 CV info lr 0.0005086704250541577 2 rank loss_1.7594481591592754 acc_0.4967577763293919
2025-01-10 06:53:55,967 INFO Epoch 9 Step 9662 CV info lr 0.0005086704250541577 1 rank loss_1.7594481591592754 acc_0.4967577763293919
2025-01-10 06:53:56,658 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_9_whole.pt
2025-01-10 06:53:56,670 INFO Added key: store_based_barrier_key:12 to store for rank: 0
2025-01-10 06:53:56,680 INFO Added key: store_based_barrier_key:12 to store for rank: 1
2025-01-10 06:53:56,680 INFO Added key: store_based_barrier_key:12 to store for rank: 2
2025-01-10 06:53:56,680 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:12 with 3 nodes.
2025-01-10 06:53:56,680 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:12 with 3 nodes.
2025-01-10 06:53:56,688 INFO Epoch 10 TRAIN info lr 0.0005086704250541577 rank 2
2025-01-10 06:53:56,689 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 06:53:56,689 INFO Epoch 10 TRAIN info lr 0.0005086704250541577 rank 0
2025-01-10 06:53:56,689 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 06:53:56,690 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:12 with 3 nodes.
2025-01-10 06:53:56,690 INFO Epoch 10 TRAIN info lr 0.0005086704250541577 rank 1
2025-01-10 06:53:56,690 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 06:54:27,452 DEBUG TRAIN Batch 10/100 loss 0.765775 acc 0.545548 lr 0.00050736 grad_norm 0.442152 rank 1
2025-01-10 06:54:27,452 DEBUG TRAIN Batch 10/100 loss 0.761688 acc 0.528080 lr 0.00050736 grad_norm 0.442152 rank 0
2025-01-10 06:54:27,452 DEBUG TRAIN Batch 10/100 loss 0.698784 acc 0.573045 lr 0.00050736 grad_norm 0.442152 rank 2
2025-01-10 06:54:50,800 DEBUG TRAIN Batch 10/200 loss 0.793622 acc 0.516551 lr 0.00050606 grad_norm 0.438890 rank 2
2025-01-10 06:54:50,801 DEBUG TRAIN Batch 10/200 loss 0.667494 acc 0.577150 lr 0.00050606 grad_norm 0.438890 rank 0
2025-01-10 06:54:50,801 DEBUG TRAIN Batch 10/200 loss 0.810654 acc 0.505405 lr 0.00050606 grad_norm 0.438890 rank 1
2025-01-10 06:55:14,124 DEBUG TRAIN Batch 10/300 loss 0.759780 acc 0.516667 lr 0.00050477 grad_norm 0.396446 rank 1
2025-01-10 06:55:14,125 DEBUG TRAIN Batch 10/300 loss 0.782329 acc 0.520073 lr 0.00050477 grad_norm 0.396446 rank 0
2025-01-10 06:55:14,125 DEBUG TRAIN Batch 10/300 loss 0.809999 acc 0.512476 lr 0.00050477 grad_norm 0.396446 rank 2
2025-01-10 06:55:37,710 DEBUG TRAIN Batch 10/400 loss 0.693035 acc 0.551163 lr 0.00050349 grad_norm 0.435358 rank 1
2025-01-10 06:55:37,712 DEBUG TRAIN Batch 10/400 loss 0.639109 acc 0.600251 lr 0.00050349 grad_norm 0.435358 rank 0
2025-01-10 06:55:37,712 DEBUG TRAIN Batch 10/400 loss 0.755372 acc 0.536773 lr 0.00050349 grad_norm 0.435358 rank 2
2025-01-10 06:56:02,378 DEBUG TRAIN Batch 10/500 loss 0.715897 acc 0.559855 lr 0.00050221 grad_norm 0.474177 rank 0
2025-01-10 06:56:02,379 DEBUG TRAIN Batch 10/500 loss 0.838411 acc 0.500458 lr 0.00050221 grad_norm 0.474177 rank 2
2025-01-10 06:56:02,379 DEBUG TRAIN Batch 10/500 loss 0.744030 acc 0.544582 lr 0.00050221 grad_norm 0.474177 rank 1
2025-01-10 06:56:27,188 DEBUG TRAIN Batch 10/600 loss 0.798738 acc 0.500525 lr 0.00050095 grad_norm 0.393680 rank 1
2025-01-10 06:56:27,188 DEBUG TRAIN Batch 10/600 loss 0.723721 acc 0.549909 lr 0.00050095 grad_norm 0.393680 rank 2
2025-01-10 06:56:27,188 DEBUG TRAIN Batch 10/600 loss 0.864158 acc 0.472404 lr 0.00050095 grad_norm 0.393680 rank 0
2025-01-10 06:56:51,845 DEBUG TRAIN Batch 10/700 loss 0.771582 acc 0.498551 lr 0.00049970 grad_norm 0.469490 rank 2
2025-01-10 06:56:51,845 DEBUG TRAIN Batch 10/700 loss 0.729172 acc 0.511194 lr 0.00049970 grad_norm 0.469490 rank 1
2025-01-10 06:56:51,845 DEBUG TRAIN Batch 10/700 loss 0.857277 acc 0.479561 lr 0.00049970 grad_norm 0.469490 rank 0
2025-01-10 06:57:16,197 DEBUG TRAIN Batch 10/800 loss 0.741070 acc 0.547379 lr 0.00049846 grad_norm 0.411132 rank 2
2025-01-10 06:57:16,197 DEBUG TRAIN Batch 10/800 loss 0.847829 acc 0.482578 lr 0.00049846 grad_norm 0.411132 rank 0
2025-01-10 06:57:16,198 DEBUG TRAIN Batch 10/800 loss 1.076297 acc 0.394640 lr 0.00049846 grad_norm 0.411132 rank 1
2025-01-10 06:57:40,357 DEBUG TRAIN Batch 10/900 loss 0.616276 acc 0.590909 lr 0.00049722 grad_norm 0.442316 rank 2
2025-01-10 06:57:40,358 DEBUG TRAIN Batch 10/900 loss 1.043527 acc 0.402477 lr 0.00049722 grad_norm 0.442316 rank 1
2025-01-10 06:57:40,358 DEBUG TRAIN Batch 10/900 loss 0.854766 acc 0.475349 lr 0.00049722 grad_norm 0.442316 rank 0
2025-01-10 06:58:04,741 DEBUG TRAIN Batch 10/1000 loss 0.804901 acc 0.513542 lr 0.00049600 grad_norm 0.443447 rank 0
2025-01-10 06:58:04,741 DEBUG TRAIN Batch 10/1000 loss 0.892266 acc 0.451087 lr 0.00049600 grad_norm 0.443447 rank 1
2025-01-10 06:58:04,742 DEBUG TRAIN Batch 10/1000 loss 0.760487 acc 0.547667 lr 0.00049600 grad_norm 0.443447 rank 2
2025-01-10 06:58:29,855 DEBUG TRAIN Batch 10/1100 loss 0.747734 acc 0.542857 lr 0.00049478 grad_norm 0.423235 rank 0
2025-01-10 06:58:29,855 DEBUG TRAIN Batch 10/1100 loss 0.881808 acc 0.478958 lr 0.00049478 grad_norm 0.423235 rank 2
2025-01-10 06:58:29,856 DEBUG TRAIN Batch 10/1100 loss 0.754601 acc 0.549598 lr 0.00049478 grad_norm 0.423235 rank 1
2025-01-10 06:58:54,111 DEBUG TRAIN Batch 10/1200 loss 0.796576 acc 0.500457 lr 0.00049358 grad_norm 0.398863 rank 2
2025-01-10 06:58:54,111 DEBUG TRAIN Batch 10/1200 loss 0.679034 acc 0.595381 lr 0.00049358 grad_norm 0.398863 rank 0
2025-01-10 06:58:54,114 DEBUG TRAIN Batch 10/1200 loss 0.785617 acc 0.540330 lr 0.00049358 grad_norm 0.398863 rank 1
2025-01-10 06:59:19,175 DEBUG TRAIN Batch 10/1300 loss 0.730056 acc 0.548851 lr 0.00049238 grad_norm 0.442630 rank 2
2025-01-10 06:59:19,175 DEBUG TRAIN Batch 10/1300 loss 0.891890 acc 0.485130 lr 0.00049238 grad_norm 0.442630 rank 0
2025-01-10 06:59:19,176 DEBUG TRAIN Batch 10/1300 loss 0.537426 acc 0.656667 lr 0.00049238 grad_norm 0.442630 rank 1
2025-01-10 06:59:43,397 DEBUG TRAIN Batch 10/1400 loss 0.742759 acc 0.565336 lr 0.00049119 grad_norm 0.453082 rank 2
2025-01-10 06:59:43,397 DEBUG TRAIN Batch 10/1400 loss 0.774036 acc 0.547303 lr 0.00049119 grad_norm 0.453082 rank 0
2025-01-10 06:59:43,397 DEBUG TRAIN Batch 10/1400 loss 0.597496 acc 0.640000 lr 0.00049119 grad_norm 0.453082 rank 1
2025-01-10 07:00:08,127 DEBUG TRAIN Batch 10/1500 loss 0.742903 acc 0.545226 lr 0.00049001 grad_norm 0.447129 rank 0
2025-01-10 07:00:08,128 DEBUG TRAIN Batch 10/1500 loss 0.729612 acc 0.551402 lr 0.00049001 grad_norm 0.447129 rank 2
2025-01-10 07:00:08,128 DEBUG TRAIN Batch 10/1500 loss 0.679647 acc 0.590000 lr 0.00049001 grad_norm 0.447129 rank 1
2025-01-10 07:00:33,488 DEBUG TRAIN Batch 10/1600 loss 0.808971 acc 0.504036 lr 0.00048884 grad_norm 0.424602 rank 2
2025-01-10 07:00:33,488 DEBUG TRAIN Batch 10/1600 loss 0.751505 acc 0.538601 lr 0.00048884 grad_norm 0.424602 rank 1
2025-01-10 07:00:33,489 DEBUG TRAIN Batch 10/1600 loss 0.667012 acc 0.585000 lr 0.00048884 grad_norm 0.424602 rank 0
2025-01-10 07:00:57,209 DEBUG TRAIN Batch 10/1700 loss 0.735072 acc 0.500949 lr 0.00048767 grad_norm 0.433255 rank 0
2025-01-10 07:00:57,209 DEBUG TRAIN Batch 10/1700 loss 0.685498 acc 0.563564 lr 0.00048767 grad_norm 0.433255 rank 2
2025-01-10 07:00:57,209 DEBUG TRAIN Batch 10/1700 loss 0.592295 acc 0.647194 lr 0.00048767 grad_norm 0.433255 rank 1
2025-01-10 07:01:22,019 DEBUG TRAIN Batch 10/1800 loss 0.646118 acc 0.630973 lr 0.00048652 grad_norm 0.392477 rank 1
2025-01-10 07:01:22,020 DEBUG TRAIN Batch 10/1800 loss 0.831072 acc 0.491984 lr 0.00048652 grad_norm 0.392477 rank 2
2025-01-10 07:01:22,020 DEBUG TRAIN Batch 10/1800 loss 0.711493 acc 0.567031 lr 0.00048652 grad_norm 0.392477 rank 0
2025-01-10 07:01:46,039 DEBUG TRAIN Batch 10/1900 loss 0.738203 acc 0.558736 lr 0.00048537 grad_norm 0.412243 rank 0
2025-01-10 07:01:46,039 DEBUG TRAIN Batch 10/1900 loss 0.895477 acc 0.474114 lr 0.00048537 grad_norm 0.412243 rank 2
2025-01-10 07:01:46,039 DEBUG TRAIN Batch 10/1900 loss 0.473661 acc 0.692901 lr 0.00048537 grad_norm 0.412243 rank 1
2025-01-10 07:02:10,269 DEBUG TRAIN Batch 10/2000 loss 0.789440 acc 0.520913 lr 0.00048423 grad_norm 0.407576 rank 0
2025-01-10 07:02:10,269 DEBUG TRAIN Batch 10/2000 loss 0.954865 acc 0.433684 lr 0.00048423 grad_norm 0.407576 rank 2
2025-01-10 07:02:10,269 DEBUG TRAIN Batch 10/2000 loss 0.561498 acc 0.652949 lr 0.00048423 grad_norm 0.407576 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 07:03:11,805 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 07:03:11,806 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 07:03:12,248 INFO Epoch 10 Step 10665 on_batch_end True CV rank 0
2025-01-10 07:03:12,248 INFO Epoch 10 Step 10665 on_batch_end True CV rank 1
2025-01-10 07:03:12,249 INFO Epoch 10 Step 10665 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 07:03:21,449 DEBUG CV Batch 10/100 loss 1.041949 acc 0.690078  rank 0
2025-01-10 07:03:21,687 DEBUG CV Batch 10/100 loss 1.041949 acc 0.690078  rank 2
2025-01-10 07:03:21,877 DEBUG CV Batch 10/100 loss 1.041949 acc 0.690078  rank 1
2025-01-10 07:03:21,970 INFO Epoch 10 Step 10665 CV info lr 0.00048416074481177234 0 rank loss_1.6772351045357554 acc_0.5243935847099412
2025-01-10 07:03:22,208 INFO Epoch 10 Step 10665 CV info lr 0.00048416074481177234 2 rank loss_1.6772351045357554 acc_0.5243935847099412
2025-01-10 07:03:22,413 INFO Epoch 10 Step 10665 CV info lr 0.00048416074481177234 1 rank loss_1.6772351045357554 acc_0.5243935847099412
2025-01-10 07:03:23,256 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_10_whole.pt
2025-01-10 07:03:23,278 INFO Added key: store_based_barrier_key:13 to store for rank: 0
2025-01-10 07:03:23,288 INFO Added key: store_based_barrier_key:13 to store for rank: 2
2025-01-10 07:03:23,288 INFO Added key: store_based_barrier_key:13 to store for rank: 1
2025-01-10 07:03:23,288 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:13 with 3 nodes.
2025-01-10 07:03:23,298 INFO Epoch 11 TRAIN info lr 0.00048416074481177234 rank 1
2025-01-10 07:03:23,298 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 07:03:23,298 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:13 with 3 nodes.
2025-01-10 07:03:23,298 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:13 with 3 nodes.
2025-01-10 07:03:23,304 INFO Epoch 11 TRAIN info lr 0.00048416074481177234 rank 2
2025-01-10 07:03:23,305 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 07:03:23,305 INFO Epoch 11 TRAIN info lr 0.00048416074481177234 rank 0
2025-01-10 07:03:23,305 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 07:03:54,289 DEBUG TRAIN Batch 11/100 loss 0.717567 acc 0.548781 lr 0.00048303 grad_norm 0.448279 rank 0
2025-01-10 07:03:54,290 DEBUG TRAIN Batch 11/100 loss 0.875008 acc 0.469157 lr 0.00048303 grad_norm 0.448279 rank 2
2025-01-10 07:03:54,290 DEBUG TRAIN Batch 11/100 loss 0.765141 acc 0.536765 lr 0.00048303 grad_norm 0.448279 rank 1
2025-01-10 07:04:18,139 DEBUG TRAIN Batch 11/200 loss 0.632507 acc 0.587264 lr 0.00048191 grad_norm 0.434767 rank 0
2025-01-10 07:04:18,139 DEBUG TRAIN Batch 11/200 loss 0.808685 acc 0.518095 lr 0.00048191 grad_norm 0.434767 rank 1
2025-01-10 07:04:18,139 DEBUG TRAIN Batch 11/200 loss 0.847717 acc 0.511770 lr 0.00048191 grad_norm 0.434767 rank 2
2025-01-10 07:04:41,544 DEBUG TRAIN Batch 11/300 loss 0.735159 acc 0.544700 lr 0.00048079 grad_norm 0.430693 rank 0
2025-01-10 07:04:41,544 DEBUG TRAIN Batch 11/300 loss 0.802587 acc 0.503046 lr 0.00048079 grad_norm 0.430693 rank 1
2025-01-10 07:04:41,544 DEBUG TRAIN Batch 11/300 loss 0.820816 acc 0.497704 lr 0.00048079 grad_norm 0.430693 rank 2
2025-01-10 07:05:05,033 DEBUG TRAIN Batch 11/400 loss 0.848007 acc 0.506442 lr 0.00047968 grad_norm 0.495512 rank 2
2025-01-10 07:05:05,033 DEBUG TRAIN Batch 11/400 loss 0.716786 acc 0.555658 lr 0.00047968 grad_norm 0.495512 rank 0
2025-01-10 07:05:05,033 DEBUG TRAIN Batch 11/400 loss 0.750621 acc 0.541916 lr 0.00047968 grad_norm 0.495512 rank 1
2025-01-10 07:05:29,050 DEBUG TRAIN Batch 11/500 loss 0.728339 acc 0.542100 lr 0.00047858 grad_norm 0.441635 rank 0
2025-01-10 07:05:29,050 DEBUG TRAIN Batch 11/500 loss 0.726238 acc 0.537500 lr 0.00047858 grad_norm 0.441635 rank 2
2025-01-10 07:05:29,051 DEBUG TRAIN Batch 11/500 loss 0.786275 acc 0.526660 lr 0.00047858 grad_norm 0.441635 rank 1
2025-01-10 07:05:52,538 DEBUG TRAIN Batch 11/600 loss 0.764519 acc 0.507605 lr 0.00047749 grad_norm 0.443642 rank 0
2025-01-10 07:05:52,538 DEBUG TRAIN Batch 11/600 loss 0.821528 acc 0.489871 lr 0.00047749 grad_norm 0.443642 rank 1
2025-01-10 07:05:52,539 DEBUG TRAIN Batch 11/600 loss 0.807272 acc 0.527223 lr 0.00047749 grad_norm 0.443642 rank 2
2025-01-10 07:06:16,438 DEBUG TRAIN Batch 11/700 loss 0.801365 acc 0.503084 lr 0.00047641 grad_norm 0.450594 rank 0
2025-01-10 07:06:16,438 DEBUG TRAIN Batch 11/700 loss 0.683574 acc 0.561404 lr 0.00047641 grad_norm 0.450594 rank 2
2025-01-10 07:06:16,438 DEBUG TRAIN Batch 11/700 loss 0.709424 acc 0.546392 lr 0.00047641 grad_norm 0.450594 rank 1
2025-01-10 07:06:41,163 DEBUG TRAIN Batch 11/800 loss 0.701710 acc 0.548872 lr 0.00047533 grad_norm 0.448845 rank 2
2025-01-10 07:06:41,163 DEBUG TRAIN Batch 11/800 loss 0.723735 acc 0.564626 lr 0.00047533 grad_norm 0.448845 rank 0
2025-01-10 07:06:41,164 DEBUG TRAIN Batch 11/800 loss 0.923931 acc 0.445545 lr 0.00047533 grad_norm 0.448845 rank 1
2025-01-10 07:07:05,209 DEBUG TRAIN Batch 11/900 loss 0.869622 acc 0.486702 lr 0.00047426 grad_norm 0.433129 rank 1
2025-01-10 07:07:05,210 DEBUG TRAIN Batch 11/900 loss 0.764796 acc 0.525836 lr 0.00047426 grad_norm 0.433129 rank 0
2025-01-10 07:07:05,210 DEBUG TRAIN Batch 11/900 loss 0.604495 acc 0.621311 lr 0.00047426 grad_norm 0.433129 rank 2
2025-01-10 07:07:29,031 DEBUG TRAIN Batch 11/1000 loss 0.696199 acc 0.551269 lr 0.00047320 grad_norm 0.448480 rank 2
2025-01-10 07:07:29,032 DEBUG TRAIN Batch 11/1000 loss 0.634213 acc 0.582888 lr 0.00047320 grad_norm 0.448480 rank 0
2025-01-10 07:07:29,032 DEBUG TRAIN Batch 11/1000 loss 0.852713 acc 0.483573 lr 0.00047320 grad_norm 0.448480 rank 1
2025-01-10 07:07:53,164 DEBUG TRAIN Batch 11/1100 loss 0.637848 acc 0.589382 lr 0.00047214 grad_norm 0.465874 rank 0
2025-01-10 07:07:53,164 DEBUG TRAIN Batch 11/1100 loss 0.900509 acc 0.451954 lr 0.00047214 grad_norm 0.465874 rank 1
2025-01-10 07:07:53,164 DEBUG TRAIN Batch 11/1100 loss 0.789173 acc 0.513612 lr 0.00047214 grad_norm 0.465874 rank 2
2025-01-10 07:08:18,177 DEBUG TRAIN Batch 11/1200 loss 0.614122 acc 0.612078 lr 0.00047109 grad_norm 0.513489 rank 2
2025-01-10 07:08:18,177 DEBUG TRAIN Batch 11/1200 loss 0.567484 acc 0.621662 lr 0.00047109 grad_norm 0.513489 rank 0
2025-01-10 07:08:18,177 DEBUG TRAIN Batch 11/1200 loss 0.827397 acc 0.489676 lr 0.00047109 grad_norm 0.513489 rank 1
2025-01-10 07:08:42,520 DEBUG TRAIN Batch 11/1300 loss 0.774592 acc 0.495845 lr 0.00047005 grad_norm 0.431787 rank 0
2025-01-10 07:08:42,520 DEBUG TRAIN Batch 11/1300 loss 0.728011 acc 0.549438 lr 0.00047005 grad_norm 0.431787 rank 1
2025-01-10 07:08:42,521 DEBUG TRAIN Batch 11/1300 loss 0.752184 acc 0.518966 lr 0.00047005 grad_norm 0.431787 rank 2
2025-01-10 07:09:06,126 DEBUG TRAIN Batch 11/1400 loss 0.810448 acc 0.508424 lr 0.00046901 grad_norm 0.429872 rank 1
2025-01-10 07:09:06,127 DEBUG TRAIN Batch 11/1400 loss 0.515975 acc 0.671302 lr 0.00046901 grad_norm 0.429872 rank 2
2025-01-10 07:09:06,127 DEBUG TRAIN Batch 11/1400 loss 0.739799 acc 0.535484 lr 0.00046901 grad_norm 0.429872 rank 0
2025-01-10 07:09:30,113 DEBUG TRAIN Batch 11/1500 loss 0.733553 acc 0.538700 lr 0.00046799 grad_norm 0.455534 rank 1
2025-01-10 07:09:30,114 DEBUG TRAIN Batch 11/1500 loss 0.737681 acc 0.546919 lr 0.00046799 grad_norm 0.455534 rank 2
2025-01-10 07:09:30,114 DEBUG TRAIN Batch 11/1500 loss 0.801483 acc 0.517000 lr 0.00046799 grad_norm 0.455534 rank 0
2025-01-10 07:09:53,824 DEBUG TRAIN Batch 11/1600 loss 0.558535 acc 0.616734 lr 0.00046696 grad_norm 0.454999 rank 0
2025-01-10 07:09:53,825 DEBUG TRAIN Batch 11/1600 loss 0.576093 acc 0.665988 lr 0.00046696 grad_norm 0.454999 rank 2
2025-01-10 07:09:53,825 DEBUG TRAIN Batch 11/1600 loss 0.791348 acc 0.519528 lr 0.00046696 grad_norm 0.454999 rank 1
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 07:11:09,340 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 07:11:09,340 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 07:11:09,756 INFO Epoch 11 Step 11497 on_batch_end True CV rank 0
2025-01-10 07:11:09,756 INFO Epoch 11 Step 11497 on_batch_end True CV rank 2
2025-01-10 07:11:09,756 INFO Epoch 11 Step 11497 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 07:11:19,021 DEBUG CV Batch 11/100 loss 0.967173 acc 0.704571  rank 0
2025-01-10 07:11:19,028 DEBUG CV Batch 11/100 loss 0.967173 acc 0.704571  rank 2
2025-01-10 07:11:19,470 DEBUG CV Batch 11/100 loss 0.967173 acc 0.704571  rank 1
2025-01-10 07:11:19,536 INFO Epoch 11 Step 11497 CV info lr 0.0004663132315524072 0 rank loss_1.7119109902465552 acc_0.516266116512972
2025-01-10 07:11:19,552 INFO Epoch 11 Step 11497 CV info lr 0.0004663132315524072 2 rank loss_1.7119109902465552 acc_0.516266116512972
2025-01-10 07:11:20,008 INFO Epoch 11 Step 11497 CV info lr 0.0004663132315524072 1 rank loss_1.7119109902465552 acc_0.516266116512972
2025-01-10 07:11:20,807 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_11_whole.pt
2025-01-10 07:11:20,828 INFO Added key: store_based_barrier_key:14 to store for rank: 0
2025-01-10 07:11:20,839 INFO Added key: store_based_barrier_key:14 to store for rank: 1
2025-01-10 07:11:20,839 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:14 with 3 nodes.
2025-01-10 07:11:20,839 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:14 with 3 nodes.
2025-01-10 07:11:20,839 INFO Added key: store_based_barrier_key:14 to store for rank: 2
2025-01-10 07:11:20,839 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:14 with 3 nodes.
2025-01-10 07:11:20,842 INFO Epoch 12 TRAIN info lr 0.0004663132315524072 rank 1
2025-01-10 07:11:20,842 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 07:11:20,843 INFO Epoch 12 TRAIN info lr 0.0004663132315524072 rank 2
2025-01-10 07:11:20,843 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 07:11:20,845 INFO Epoch 12 TRAIN info lr 0.0004663132315524072 rank 0
2025-01-10 07:11:20,845 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 07:11:53,883 DEBUG TRAIN Batch 12/100 loss 0.547769 acc 0.628319 lr 0.00046530 grad_norm 0.468867 rank 2
2025-01-10 07:11:53,883 DEBUG TRAIN Batch 12/100 loss 0.613090 acc 0.608421 lr 0.00046530 grad_norm 0.468867 rank 0
2025-01-10 07:11:53,884 DEBUG TRAIN Batch 12/100 loss 0.651147 acc 0.611062 lr 0.00046530 grad_norm 0.468867 rank 1
2025-01-10 07:12:17,974 DEBUG TRAIN Batch 12/200 loss 0.569508 acc 0.632629 lr 0.00046430 grad_norm 0.531514 rank 2
2025-01-10 07:12:17,974 DEBUG TRAIN Batch 12/200 loss 0.650104 acc 0.568345 lr 0.00046430 grad_norm 0.531514 rank 0
2025-01-10 07:12:17,975 DEBUG TRAIN Batch 12/200 loss 0.623621 acc 0.610154 lr 0.00046430 grad_norm 0.531514 rank 1
2025-01-10 07:12:42,119 DEBUG TRAIN Batch 12/300 loss 0.849299 acc 0.514210 lr 0.00046330 grad_norm 0.494692 rank 1
2025-01-10 07:12:42,120 DEBUG TRAIN Batch 12/300 loss 0.732459 acc 0.527778 lr 0.00046330 grad_norm 0.494692 rank 0
2025-01-10 07:12:42,120 DEBUG TRAIN Batch 12/300 loss 0.458901 acc 0.701278 lr 0.00046330 grad_norm 0.494692 rank 2
2025-01-10 07:13:06,619 DEBUG TRAIN Batch 12/400 loss 0.693504 acc 0.571271 lr 0.00046231 grad_norm 0.513087 rank 1
2025-01-10 07:13:06,619 DEBUG TRAIN Batch 12/400 loss 0.621891 acc 0.597889 lr 0.00046231 grad_norm 0.513087 rank 0
2025-01-10 07:13:06,619 DEBUG TRAIN Batch 12/400 loss 0.682661 acc 0.586242 lr 0.00046231 grad_norm 0.513087 rank 2
2025-01-10 07:13:30,711 DEBUG TRAIN Batch 12/500 loss 0.842149 acc 0.495645 lr 0.00046132 grad_norm 0.459327 rank 1
2025-01-10 07:13:30,712 DEBUG TRAIN Batch 12/500 loss 0.643174 acc 0.593171 lr 0.00046132 grad_norm 0.459327 rank 2
2025-01-10 07:13:30,712 DEBUG TRAIN Batch 12/500 loss 0.500485 acc 0.694503 lr 0.00046132 grad_norm 0.459327 rank 0
2025-01-10 07:13:54,922 DEBUG TRAIN Batch 12/600 loss 0.638041 acc 0.606426 lr 0.00046035 grad_norm 0.479233 rank 2
2025-01-10 07:13:54,922 DEBUG TRAIN Batch 12/600 loss 0.580848 acc 0.639738 lr 0.00046035 grad_norm 0.479233 rank 0
2025-01-10 07:13:54,922 DEBUG TRAIN Batch 12/600 loss 0.832383 acc 0.504554 lr 0.00046035 grad_norm 0.479233 rank 1
2025-01-10 07:14:20,014 DEBUG TRAIN Batch 12/700 loss 0.457508 acc 0.708564 lr 0.00045937 grad_norm 0.526172 rank 2
2025-01-10 07:14:20,014 DEBUG TRAIN Batch 12/700 loss 0.927428 acc 0.482448 lr 0.00045937 grad_norm 0.526172 rank 1
2025-01-10 07:14:20,014 DEBUG TRAIN Batch 12/700 loss 0.614671 acc 0.643103 lr 0.00045937 grad_norm 0.526172 rank 0
2025-01-10 07:14:43,767 DEBUG TRAIN Batch 12/800 loss 0.879296 acc 0.471715 lr 0.00045841 grad_norm 0.492613 rank 1
2025-01-10 07:14:43,768 DEBUG TRAIN Batch 12/800 loss 0.697322 acc 0.555454 lr 0.00045841 grad_norm 0.492613 rank 2
2025-01-10 07:14:43,768 DEBUG TRAIN Batch 12/800 loss 0.571299 acc 0.643505 lr 0.00045841 grad_norm 0.492613 rank 0
2025-01-10 07:15:07,614 DEBUG TRAIN Batch 12/900 loss 0.618837 acc 0.628947 lr 0.00045745 grad_norm 0.530275 rank 0
2025-01-10 07:15:07,614 DEBUG TRAIN Batch 12/900 loss 0.793314 acc 0.525151 lr 0.00045745 grad_norm 0.530275 rank 1
2025-01-10 07:15:07,614 DEBUG TRAIN Batch 12/900 loss 0.625837 acc 0.589008 lr 0.00045745 grad_norm 0.530275 rank 2
2025-01-10 07:15:33,088 DEBUG TRAIN Batch 12/1000 loss 0.694939 acc 0.558665 lr 0.00045649 grad_norm 0.445703 rank 1
2025-01-10 07:15:33,088 DEBUG TRAIN Batch 12/1000 loss 0.703689 acc 0.556773 lr 0.00045649 grad_norm 0.445703 rank 2
2025-01-10 07:15:33,088 DEBUG TRAIN Batch 12/1000 loss 0.551665 acc 0.646330 lr 0.00045649 grad_norm 0.445703 rank 0
2025-01-10 07:15:57,023 DEBUG TRAIN Batch 12/1100 loss 0.575790 acc 0.634940 lr 0.00045554 grad_norm 0.449739 rank 0
2025-01-10 07:15:57,023 DEBUG TRAIN Batch 12/1100 loss 0.734152 acc 0.530594 lr 0.00045554 grad_norm 0.449739 rank 1
2025-01-10 07:15:57,023 DEBUG TRAIN Batch 12/1100 loss 0.760535 acc 0.525585 lr 0.00045554 grad_norm 0.449739 rank 2
2025-01-10 07:16:21,599 DEBUG TRAIN Batch 12/1200 loss 0.629868 acc 0.615101 lr 0.00045460 grad_norm 0.440501 rank 0
2025-01-10 07:16:21,599 DEBUG TRAIN Batch 12/1200 loss 0.699291 acc 0.573832 lr 0.00045460 grad_norm 0.440501 rank 2
2025-01-10 07:16:21,599 DEBUG TRAIN Batch 12/1200 loss 0.681313 acc 0.563310 lr 0.00045460 grad_norm 0.440501 rank 1
2025-01-10 07:16:45,539 DEBUG TRAIN Batch 12/1300 loss 0.672157 acc 0.570968 lr 0.00045367 grad_norm 0.497711 rank 1
2025-01-10 07:16:45,539 DEBUG TRAIN Batch 12/1300 loss 0.628679 acc 0.618306 lr 0.00045367 grad_norm 0.497711 rank 2
2025-01-10 07:16:45,539 DEBUG TRAIN Batch 12/1300 loss 0.486611 acc 0.696203 lr 0.00045367 grad_norm 0.497711 rank 0
2025-01-10 07:17:09,878 DEBUG TRAIN Batch 12/1400 loss 0.586973 acc 0.632768 lr 0.00045273 grad_norm 0.482866 rank 0
2025-01-10 07:17:09,879 DEBUG TRAIN Batch 12/1400 loss 0.722049 acc 0.542754 lr 0.00045273 grad_norm 0.482866 rank 2
2025-01-10 07:17:09,879 DEBUG TRAIN Batch 12/1400 loss 0.794624 acc 0.511052 lr 0.00045273 grad_norm 0.482866 rank 1
2025-01-10 07:17:34,515 DEBUG TRAIN Batch 12/1500 loss 0.664469 acc 0.573230 lr 0.00045181 grad_norm 0.471962 rank 2
2025-01-10 07:17:34,515 DEBUG TRAIN Batch 12/1500 loss 0.814125 acc 0.491589 lr 0.00045181 grad_norm 0.471962 rank 1
2025-01-10 07:17:34,515 DEBUG TRAIN Batch 12/1500 loss 0.649908 acc 0.597590 lr 0.00045181 grad_norm 0.471962 rank 0
2025-01-10 07:18:00,333 DEBUG TRAIN Batch 12/1600 loss 0.784777 acc 0.508427 lr 0.00045089 grad_norm 0.488805 rank 1
2025-01-10 07:18:00,334 DEBUG TRAIN Batch 12/1600 loss 0.676922 acc 0.590689 lr 0.00045089 grad_norm 0.488805 rank 0
2025-01-10 07:18:00,334 DEBUG TRAIN Batch 12/1600 loss 0.743804 acc 0.539336 lr 0.00045089 grad_norm 0.488805 rank 2
2025-01-10 07:18:24,324 DEBUG TRAIN Batch 12/1700 loss 0.638145 acc 0.601151 lr 0.00044998 grad_norm 0.445467 rank 0
2025-01-10 07:18:24,324 DEBUG TRAIN Batch 12/1700 loss 0.722097 acc 0.542458 lr 0.00044998 grad_norm 0.445467 rank 2
2025-01-10 07:18:24,324 DEBUG TRAIN Batch 12/1700 loss 0.791284 acc 0.536388 lr 0.00044998 grad_norm 0.445467 rank 1
2025-01-10 07:18:48,091 DEBUG TRAIN Batch 12/1800 loss 0.679200 acc 0.583962 lr 0.00044907 grad_norm 0.455476 rank 2
2025-01-10 07:18:48,091 DEBUG TRAIN Batch 12/1800 loss 0.833153 acc 0.489637 lr 0.00044907 grad_norm 0.455476 rank 1
2025-01-10 07:18:48,109 DEBUG TRAIN Batch 12/1800 loss 0.793572 acc 0.511677 lr 0.00044907 grad_norm 0.455476 rank 0
2025-01-10 07:19:19,981 DEBUG TRAIN Batch 12/1900 loss 0.787094 acc 0.525188 lr 0.00044816 grad_norm 0.469713 rank 1
2025-01-10 07:19:19,982 DEBUG TRAIN Batch 12/1900 loss 0.718912 acc 0.567966 lr 0.00044816 grad_norm 0.469713 rank 2
2025-01-10 07:19:20,000 DEBUG TRAIN Batch 12/1900 loss 0.719438 acc 0.541667 lr 0.00044816 grad_norm 0.469713 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 07:20:29,077 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 07:20:29,079 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 07:20:29,506 INFO Epoch 12 Step 12462 on_batch_end True CV rank 2
2025-01-10 07:20:29,506 INFO Epoch 12 Step 12462 on_batch_end True CV rank 0
2025-01-10 07:20:29,506 INFO Epoch 12 Step 12462 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 07:20:38,572 DEBUG CV Batch 12/100 loss 0.719989 acc 0.793757  rank 0
2025-01-10 07:20:38,965 DEBUG CV Batch 12/100 loss 0.719989 acc 0.793757  rank 2
2025-01-10 07:20:39,080 INFO Epoch 12 Step 12462 CV info lr 0.00044789491396534785 0 rank loss_1.5759327057422252 acc_0.5653451303379577
2025-01-10 07:20:39,248 DEBUG CV Batch 12/100 loss 0.719989 acc 0.793757  rank 1
2025-01-10 07:20:39,494 INFO Epoch 12 Step 12462 CV info lr 0.00044789491396534785 2 rank loss_1.5759327057422252 acc_0.5653451303379577
2025-01-10 07:20:39,788 INFO Epoch 12 Step 12462 CV info lr 0.00044789491396534785 1 rank loss_1.5759327057422252 acc_0.5653451303379577
2025-01-10 07:20:40,372 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_12_whole.pt
2025-01-10 07:20:40,384 INFO Added key: store_based_barrier_key:15 to store for rank: 0
2025-01-10 07:20:40,394 INFO Added key: store_based_barrier_key:15 to store for rank: 2
2025-01-10 07:20:40,395 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:15 with 3 nodes.
2025-01-10 07:20:40,395 INFO Added key: store_based_barrier_key:15 to store for rank: 1
2025-01-10 07:20:40,395 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:15 with 3 nodes.
2025-01-10 07:20:40,398 INFO Epoch 13 TRAIN info lr 0.00044789491396534785 rank 1
2025-01-10 07:20:40,398 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 07:20:40,401 INFO Epoch 13 TRAIN info lr 0.00044789491396534785 rank 2
2025-01-10 07:20:40,401 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 07:20:40,405 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:15 with 3 nodes.
2025-01-10 07:20:40,405 INFO Epoch 13 TRAIN info lr 0.00044789491396534785 rank 0
2025-01-10 07:20:40,405 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 07:21:11,265 DEBUG TRAIN Batch 13/100 loss 0.585483 acc 0.618613 lr 0.00044700 grad_norm 0.500628 rank 2
2025-01-10 07:21:11,265 DEBUG TRAIN Batch 13/100 loss 0.558872 acc 0.626131 lr 0.00044700 grad_norm 0.500628 rank 0
2025-01-10 07:21:11,266 DEBUG TRAIN Batch 13/100 loss 0.705742 acc 0.550785 lr 0.00044700 grad_norm 0.500628 rank 1
2025-01-10 07:21:35,175 DEBUG TRAIN Batch 13/200 loss 0.678078 acc 0.572610 lr 0.00044611 grad_norm 0.497707 rank 2
2025-01-10 07:21:35,175 DEBUG TRAIN Batch 13/200 loss 0.602782 acc 0.609043 lr 0.00044611 grad_norm 0.497707 rank 0
2025-01-10 07:21:35,175 DEBUG TRAIN Batch 13/200 loss 0.551852 acc 0.649433 lr 0.00044611 grad_norm 0.497707 rank 1
2025-01-10 07:21:58,852 DEBUG TRAIN Batch 13/300 loss 0.621047 acc 0.610039 lr 0.00044522 grad_norm 0.505984 rank 2
2025-01-10 07:21:58,852 DEBUG TRAIN Batch 13/300 loss 0.666592 acc 0.594937 lr 0.00044522 grad_norm 0.505984 rank 0
2025-01-10 07:21:58,853 DEBUG TRAIN Batch 13/300 loss 0.753246 acc 0.536355 lr 0.00044522 grad_norm 0.505984 rank 1
2025-01-10 07:22:25,265 DEBUG TRAIN Batch 13/400 loss 0.535800 acc 0.655542 lr 0.00044434 grad_norm 0.531343 rank 2
2025-01-10 07:22:25,265 DEBUG TRAIN Batch 13/400 loss 0.715349 acc 0.551758 lr 0.00044434 grad_norm 0.531343 rank 1
2025-01-10 07:22:25,287 DEBUG TRAIN Batch 13/400 loss 0.596436 acc 0.596916 lr 0.00044434 grad_norm 0.531343 rank 0
2025-01-10 07:22:54,410 DEBUG TRAIN Batch 13/500 loss 0.672542 acc 0.578758 lr 0.00044347 grad_norm 0.500246 rank 2
2025-01-10 07:22:54,410 DEBUG TRAIN Batch 13/500 loss 0.763641 acc 0.535419 lr 0.00044347 grad_norm 0.500246 rank 1
2025-01-10 07:22:54,411 DEBUG TRAIN Batch 13/500 loss 0.320827 acc 0.795853 lr 0.00044347 grad_norm 0.500246 rank 0
2025-01-10 07:23:24,146 DEBUG TRAIN Batch 13/600 loss 0.611080 acc 0.594111 lr 0.00044260 grad_norm 0.491092 rank 2
2025-01-10 07:23:24,147 DEBUG TRAIN Batch 13/600 loss 0.685438 acc 0.557062 lr 0.00044260 grad_norm 0.491092 rank 1
2025-01-10 07:23:24,170 DEBUG TRAIN Batch 13/600 loss 0.769842 acc 0.522984 lr 0.00044260 grad_norm 0.491092 rank 0
2025-01-10 07:23:54,784 DEBUG TRAIN Batch 13/700 loss 0.694868 acc 0.572719 lr 0.00044173 grad_norm 0.494075 rank 1
2025-01-10 07:23:54,784 DEBUG TRAIN Batch 13/700 loss 0.737634 acc 0.544132 lr 0.00044173 grad_norm 0.494075 rank 2
2025-01-10 07:23:54,815 DEBUG TRAIN Batch 13/700 loss 0.559275 acc 0.640000 lr 0.00044173 grad_norm 0.494075 rank 0
2025-01-10 07:24:21,170 DEBUG TRAIN Batch 13/800 loss 0.719811 acc 0.564047 lr 0.00044088 grad_norm 0.499489 rank 1
2025-01-10 07:24:21,170 DEBUG TRAIN Batch 13/800 loss 0.726851 acc 0.550519 lr 0.00044088 grad_norm 0.499489 rank 2
2025-01-10 07:24:21,173 DEBUG TRAIN Batch 13/800 loss 0.780100 acc 0.507863 lr 0.00044088 grad_norm 0.499489 rank 0
2025-01-10 07:24:48,863 DEBUG TRAIN Batch 13/900 loss 0.724985 acc 0.568121 lr 0.00044002 grad_norm 0.533037 rank 1
2025-01-10 07:24:48,863 DEBUG TRAIN Batch 13/900 loss 0.762344 acc 0.534698 lr 0.00044002 grad_norm 0.533037 rank 0
2025-01-10 07:24:48,864 DEBUG TRAIN Batch 13/900 loss 0.343025 acc 0.797005 lr 0.00044002 grad_norm 0.533037 rank 2
2025-01-10 07:25:12,418 DEBUG TRAIN Batch 13/1000 loss 0.744070 acc 0.544405 lr 0.00043917 grad_norm 0.480836 rank 1
2025-01-10 07:25:12,419 DEBUG TRAIN Batch 13/1000 loss 0.692719 acc 0.554622 lr 0.00043917 grad_norm 0.480836 rank 2
2025-01-10 07:25:12,419 DEBUG TRAIN Batch 13/1000 loss 0.730520 acc 0.553892 lr 0.00043917 grad_norm 0.480836 rank 0
2025-01-10 07:25:36,245 DEBUG TRAIN Batch 13/1100 loss 0.575071 acc 0.633588 lr 0.00043833 grad_norm 0.499684 rank 2
2025-01-10 07:25:36,245 DEBUG TRAIN Batch 13/1100 loss 0.672820 acc 0.578719 lr 0.00043833 grad_norm 0.499684 rank 0
2025-01-10 07:25:36,245 DEBUG TRAIN Batch 13/1100 loss 0.680031 acc 0.566142 lr 0.00043833 grad_norm 0.499684 rank 1
2025-01-10 07:25:59,827 DEBUG TRAIN Batch 13/1200 loss 0.685491 acc 0.585302 lr 0.00043749 grad_norm 0.509786 rank 2
2025-01-10 07:25:59,827 DEBUG TRAIN Batch 13/1200 loss 0.765563 acc 0.521526 lr 0.00043749 grad_norm 0.509786 rank 0
2025-01-10 07:25:59,827 DEBUG TRAIN Batch 13/1200 loss 0.783652 acc 0.529592 lr 0.00043749 grad_norm 0.509786 rank 1
2025-01-10 07:26:23,424 DEBUG TRAIN Batch 13/1300 loss 0.707165 acc 0.562885 lr 0.00043665 grad_norm 0.462990 rank 2
2025-01-10 07:26:23,424 DEBUG TRAIN Batch 13/1300 loss 0.683891 acc 0.564744 lr 0.00043665 grad_norm 0.462990 rank 0
2025-01-10 07:26:23,424 DEBUG TRAIN Batch 13/1300 loss 0.447286 acc 0.730884 lr 0.00043665 grad_norm 0.462990 rank 1
2025-01-10 07:26:46,907 DEBUG TRAIN Batch 13/1400 loss 0.462657 acc 0.707921 lr 0.00043582 grad_norm 0.465906 rank 1
2025-01-10 07:26:46,907 DEBUG TRAIN Batch 13/1400 loss 0.551712 acc 0.658908 lr 0.00043582 grad_norm 0.465906 rank 0
2025-01-10 07:26:46,908 DEBUG TRAIN Batch 13/1400 loss 0.687789 acc 0.583567 lr 0.00043582 grad_norm 0.465906 rank 2
2025-01-10 07:27:11,176 DEBUG TRAIN Batch 13/1500 loss 0.687918 acc 0.581262 lr 0.00043500 grad_norm 0.480030 rank 1
2025-01-10 07:27:11,177 DEBUG TRAIN Batch 13/1500 loss 0.551228 acc 0.660542 lr 0.00043500 grad_norm 0.480030 rank 0
2025-01-10 07:27:11,177 DEBUG TRAIN Batch 13/1500 loss 0.681475 acc 0.593779 lr 0.00043500 grad_norm 0.480030 rank 2
2025-01-10 07:27:36,240 DEBUG TRAIN Batch 13/1600 loss 0.598775 acc 0.609218 lr 0.00043418 grad_norm 0.629948 rank 2
2025-01-10 07:27:36,240 DEBUG TRAIN Batch 13/1600 loss 0.492255 acc 0.686598 lr 0.00043418 grad_norm 0.629948 rank 0
2025-01-10 07:27:36,240 DEBUG TRAIN Batch 13/1600 loss 0.551650 acc 0.653160 lr 0.00043418 grad_norm 0.629948 rank 1
2025-01-10 07:28:01,395 DEBUG TRAIN Batch 13/1700 loss 0.440162 acc 0.711790 lr 0.00043336 grad_norm 0.552874 rank 1
2025-01-10 07:28:01,395 DEBUG TRAIN Batch 13/1700 loss 0.722219 acc 0.556903 lr 0.00043336 grad_norm 0.552874 rank 2
2025-01-10 07:28:01,395 DEBUG TRAIN Batch 13/1700 loss 0.376324 acc 0.735069 lr 0.00043336 grad_norm 0.552874 rank 0
2025-01-10 07:28:26,715 DEBUG TRAIN Batch 13/1800 loss 0.642471 acc 0.605405 lr 0.00043255 grad_norm 0.481225 rank 2
2025-01-10 07:28:26,715 DEBUG TRAIN Batch 13/1800 loss 0.579102 acc 0.638368 lr 0.00043255 grad_norm 0.481225 rank 0
2025-01-10 07:28:26,715 DEBUG TRAIN Batch 13/1800 loss 0.611983 acc 0.622086 lr 0.00043255 grad_norm 0.481225 rank 1
2025-01-10 07:28:52,188 DEBUG TRAIN Batch 13/1900 loss 0.398724 acc 0.734838 lr 0.00043174 grad_norm 0.521398 rank 2
2025-01-10 07:28:52,188 DEBUG TRAIN Batch 13/1900 loss 0.519938 acc 0.669118 lr 0.00043174 grad_norm 0.521398 rank 0
2025-01-10 07:28:52,189 DEBUG TRAIN Batch 13/1900 loss 0.701335 acc 0.570312 lr 0.00043174 grad_norm 0.521398 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 07:30:07,283 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59947ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 07:30:07,341 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 07:30:07,782 INFO Epoch 13 Step 13442 on_batch_end True CV rank 0
2025-01-10 07:30:07,782 INFO Epoch 13 Step 13442 on_batch_end True CV rank 1
2025-01-10 07:30:07,782 INFO Epoch 13 Step 13442 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 07:30:16,817 DEBUG CV Batch 13/100 loss 0.818361 acc 0.753623  rank 0
2025-01-10 07:30:17,303 DEBUG CV Batch 13/100 loss 0.818361 acc 0.753623  rank 2
2025-01-10 07:30:17,312 INFO Epoch 13 Step 13442 CV info lr 0.000431258888067736 0 rank loss_1.5792288714856433 acc_0.5718282543514904
2025-01-10 07:30:17,479 DEBUG CV Batch 13/100 loss 0.818361 acc 0.753623  rank 1
2025-01-10 07:30:17,847 INFO Epoch 13 Step 13442 CV info lr 0.000431258888067736 2 rank loss_1.5792288714856433 acc_0.5718282543514904
2025-01-10 07:30:18,002 INFO Epoch 13 Step 13442 CV info lr 0.000431258888067736 1 rank loss_1.5792288714856433 acc_0.5718282543514904
2025-01-10 07:30:18,609 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_13_whole.pt
2025-01-10 07:30:18,631 INFO Added key: store_based_barrier_key:16 to store for rank: 0
2025-01-10 07:30:18,631 INFO Added key: store_based_barrier_key:16 to store for rank: 1
2025-01-10 07:30:18,631 INFO Added key: store_based_barrier_key:16 to store for rank: 2
2025-01-10 07:30:18,632 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:16 with 3 nodes.
2025-01-10 07:30:18,635 INFO Epoch 14 TRAIN info lr 0.000431258888067736 rank 2
2025-01-10 07:30:18,635 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 07:30:18,641 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:16 with 3 nodes.
2025-01-10 07:30:18,642 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:16 with 3 nodes.
2025-01-10 07:30:18,644 INFO Epoch 14 TRAIN info lr 0.000431258888067736 rank 0
2025-01-10 07:30:18,644 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 07:30:18,651 INFO Epoch 14 TRAIN info lr 0.000431258888067736 rank 1
2025-01-10 07:30:18,651 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 07:30:55,763 DEBUG TRAIN Batch 14/100 loss 0.618007 acc 0.588068 lr 0.00043046 grad_norm 0.509280 rank 0
2025-01-10 07:30:55,763 DEBUG TRAIN Batch 14/100 loss 0.270536 acc 0.851852 lr 0.00043046 grad_norm 0.509280 rank 2
2025-01-10 07:30:55,763 DEBUG TRAIN Batch 14/100 loss 0.444623 acc 0.734796 lr 0.00043046 grad_norm 0.509280 rank 1
2025-01-10 07:31:20,266 DEBUG TRAIN Batch 14/200 loss 0.623970 acc 0.607656 lr 0.00042966 grad_norm 0.547946 rank 0
2025-01-10 07:31:20,266 DEBUG TRAIN Batch 14/200 loss 0.595749 acc 0.637965 lr 0.00042966 grad_norm 0.547946 rank 2
2025-01-10 07:31:20,267 DEBUG TRAIN Batch 14/200 loss 0.636822 acc 0.609005 lr 0.00042966 grad_norm 0.547946 rank 1
2025-01-10 07:31:45,708 DEBUG TRAIN Batch 14/300 loss 0.601698 acc 0.649038 lr 0.00042887 grad_norm 0.559936 rank 1
2025-01-10 07:31:45,708 DEBUG TRAIN Batch 14/300 loss 0.250232 acc 0.836868 lr 0.00042887 grad_norm 0.559936 rank 2
2025-01-10 07:31:45,708 DEBUG TRAIN Batch 14/300 loss 0.630393 acc 0.594424 lr 0.00042887 grad_norm 0.559936 rank 0
2025-01-10 07:32:13,906 DEBUG TRAIN Batch 14/400 loss 0.596132 acc 0.636183 lr 0.00042809 grad_norm 0.547998 rank 0
2025-01-10 07:32:13,906 DEBUG TRAIN Batch 14/400 loss 0.334956 acc 0.769006 lr 0.00042809 grad_norm 0.547998 rank 1
2025-01-10 07:32:13,906 DEBUG TRAIN Batch 14/400 loss 0.381573 acc 0.738331 lr 0.00042809 grad_norm 0.547998 rank 2
2025-01-10 07:32:38,564 DEBUG TRAIN Batch 14/500 loss 0.540726 acc 0.648376 lr 0.00042730 grad_norm 0.516655 rank 0
2025-01-10 07:32:38,564 DEBUG TRAIN Batch 14/500 loss 0.412521 acc 0.721007 lr 0.00042730 grad_norm 0.516655 rank 1
2025-01-10 07:32:38,565 DEBUG TRAIN Batch 14/500 loss 0.364633 acc 0.760391 lr 0.00042730 grad_norm 0.516655 rank 2
2025-01-10 07:33:07,429 DEBUG TRAIN Batch 14/600 loss 0.664218 acc 0.581871 lr 0.00042653 grad_norm 0.551983 rank 0
2025-01-10 07:33:07,429 DEBUG TRAIN Batch 14/600 loss 0.565839 acc 0.633851 lr 0.00042653 grad_norm 0.551983 rank 2
2025-01-10 07:33:07,429 DEBUG TRAIN Batch 14/600 loss 0.405377 acc 0.747549 lr 0.00042653 grad_norm 0.551983 rank 1
2025-01-10 07:33:32,996 DEBUG TRAIN Batch 14/700 loss 0.447384 acc 0.716854 lr 0.00042575 grad_norm 0.558678 rank 2
2025-01-10 07:33:32,997 DEBUG TRAIN Batch 14/700 loss 0.715912 acc 0.582266 lr 0.00042575 grad_norm 0.558678 rank 1
2025-01-10 07:33:33,013 DEBUG TRAIN Batch 14/700 loss 0.550495 acc 0.643216 lr 0.00042575 grad_norm 0.558678 rank 0
2025-01-10 07:34:00,977 DEBUG TRAIN Batch 14/800 loss 0.664617 acc 0.582897 lr 0.00042498 grad_norm 0.515481 rank 0
2025-01-10 07:34:00,978 DEBUG TRAIN Batch 14/800 loss 0.401936 acc 0.750725 lr 0.00042498 grad_norm 0.515481 rank 1
2025-01-10 07:34:00,978 DEBUG TRAIN Batch 14/800 loss 0.651309 acc 0.612457 lr 0.00042498 grad_norm 0.515481 rank 2
2025-01-10 07:34:24,811 DEBUG TRAIN Batch 14/900 loss 0.793075 acc 0.511628 lr 0.00042422 grad_norm 0.499872 rank 1
2025-01-10 07:34:24,812 DEBUG TRAIN Batch 14/900 loss 0.737468 acc 0.532174 lr 0.00042422 grad_norm 0.499872 rank 0
2025-01-10 07:34:24,812 DEBUG TRAIN Batch 14/900 loss 0.289017 acc 0.809816 lr 0.00042422 grad_norm 0.499872 rank 2
2025-01-10 07:34:51,659 DEBUG TRAIN Batch 14/1000 loss 0.736964 acc 0.556370 lr 0.00042346 grad_norm 0.483585 rank 1
2025-01-10 07:34:51,660 DEBUG TRAIN Batch 14/1000 loss 0.416939 acc 0.750685 lr 0.00042346 grad_norm 0.483585 rank 2
2025-01-10 07:34:51,677 DEBUG TRAIN Batch 14/1000 loss 0.749072 acc 0.531524 lr 0.00042346 grad_norm 0.483585 rank 0
2025-01-10 07:35:18,190 DEBUG TRAIN Batch 14/1100 loss 0.589520 acc 0.609484 lr 0.00042270 grad_norm 0.479331 rank 0
2025-01-10 07:35:18,190 DEBUG TRAIN Batch 14/1100 loss 0.604182 acc 0.628155 lr 0.00042270 grad_norm 0.479331 rank 2
2025-01-10 07:35:18,191 DEBUG TRAIN Batch 14/1100 loss 0.728611 acc 0.558308 lr 0.00042270 grad_norm 0.479331 rank 1
2025-01-10 07:35:46,068 DEBUG TRAIN Batch 14/1200 loss 0.606724 acc 0.615639 lr 0.00042194 grad_norm 0.481331 rank 1
2025-01-10 07:35:46,068 DEBUG TRAIN Batch 14/1200 loss 0.765340 acc 0.533802 lr 0.00042194 grad_norm 0.481331 rank 2
2025-01-10 07:35:46,069 DEBUG TRAIN Batch 14/1200 loss 0.758323 acc 0.540351 lr 0.00042194 grad_norm 0.481331 rank 0
2025-01-10 07:36:10,004 DEBUG TRAIN Batch 14/1300 loss 0.609889 acc 0.615799 lr 0.00042120 grad_norm 0.551763 rank 1
2025-01-10 07:36:10,004 DEBUG TRAIN Batch 14/1300 loss 0.661660 acc 0.571782 lr 0.00042120 grad_norm 0.551763 rank 0
2025-01-10 07:36:10,004 DEBUG TRAIN Batch 14/1300 loss 0.605728 acc 0.616898 lr 0.00042120 grad_norm 0.551763 rank 2
2025-01-10 07:36:35,360 DEBUG TRAIN Batch 14/1400 loss 0.584063 acc 0.633333 lr 0.00042045 grad_norm 0.523465 rank 1
2025-01-10 07:36:35,361 DEBUG TRAIN Batch 14/1400 loss 0.658383 acc 0.573359 lr 0.00042045 grad_norm 0.523465 rank 2
2025-01-10 07:36:35,378 DEBUG TRAIN Batch 14/1400 loss 0.585537 acc 0.613365 lr 0.00042045 grad_norm 0.523465 rank 0
2025-01-10 07:37:06,477 DEBUG TRAIN Batch 14/1500 loss 0.499303 acc 0.653575 lr 0.00041971 grad_norm 0.537526 rank 1
2025-01-10 07:37:06,478 DEBUG TRAIN Batch 14/1500 loss 0.665914 acc 0.586998 lr 0.00041971 grad_norm 0.537526 rank 2
2025-01-10 07:37:06,495 DEBUG TRAIN Batch 14/1500 loss 0.473513 acc 0.697674 lr 0.00041971 grad_norm 0.537526 rank 0
2025-01-10 07:37:31,146 DEBUG TRAIN Batch 14/1600 loss 0.616208 acc 0.617003 lr 0.00041897 grad_norm 0.497733 rank 1
2025-01-10 07:37:31,146 DEBUG TRAIN Batch 14/1600 loss 0.700251 acc 0.558294 lr 0.00041897 grad_norm 0.497733 rank 2
2025-01-10 07:37:31,146 DEBUG TRAIN Batch 14/1600 loss 0.596659 acc 0.631772 lr 0.00041897 grad_norm 0.497733 rank 0
2025-01-10 07:37:54,790 DEBUG TRAIN Batch 14/1700 loss 0.538748 acc 0.639423 lr 0.00041824 grad_norm 0.547705 rank 1
2025-01-10 07:37:54,791 DEBUG TRAIN Batch 14/1700 loss 0.732445 acc 0.552354 lr 0.00041824 grad_norm 0.547705 rank 2
2025-01-10 07:37:54,796 DEBUG TRAIN Batch 14/1700 loss 0.569813 acc 0.643221 lr 0.00041824 grad_norm 0.547705 rank 0
2025-01-10 07:38:24,436 DEBUG TRAIN Batch 14/1800 loss 0.556729 acc 0.642787 lr 0.00041751 grad_norm 0.548759 rank 1
2025-01-10 07:38:24,436 DEBUG TRAIN Batch 14/1800 loss 0.661636 acc 0.594891 lr 0.00041751 grad_norm 0.548759 rank 2
2025-01-10 07:38:24,468 DEBUG TRAIN Batch 14/1800 loss 0.460985 acc 0.715071 lr 0.00041751 grad_norm 0.548759 rank 0
2025-01-10 07:38:52,907 DEBUG TRAIN Batch 14/1900 loss 0.643981 acc 0.595049 lr 0.00041678 grad_norm 0.488398 rank 1
2025-01-10 07:38:52,908 DEBUG TRAIN Batch 14/1900 loss 0.640202 acc 0.592267 lr 0.00041678 grad_norm 0.488398 rank 0
2025-01-10 07:38:52,908 DEBUG TRAIN Batch 14/1900 loss 0.655321 acc 0.577009 lr 0.00041678 grad_norm 0.488398 rank 2
2025-01-10 07:39:16,674 DEBUG TRAIN Batch 14/2000 loss 0.775663 acc 0.539823 lr 0.00041606 grad_norm 0.514561 rank 1
2025-01-10 07:39:16,675 DEBUG TRAIN Batch 14/2000 loss 0.683429 acc 0.583333 lr 0.00041606 grad_norm 0.514561 rank 2
2025-01-10 07:39:16,692 DEBUG TRAIN Batch 14/2000 loss 0.658978 acc 0.585278 lr 0.00041606 grad_norm 0.514561 rank 0
2025-01-10 07:39:46,588 DEBUG TRAIN Batch 14/2100 loss 0.608486 acc 0.588900 lr 0.00041534 grad_norm 0.521883 rank 2
2025-01-10 07:39:46,588 DEBUG TRAIN Batch 14/2100 loss 0.771285 acc 0.539400 lr 0.00041534 grad_norm 0.521883 rank 1
2025-01-10 07:39:46,618 DEBUG TRAIN Batch 14/2100 loss 0.723894 acc 0.566184 lr 0.00041534 grad_norm 0.521883 rank 0
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 07:41:08,756 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 07:41:08,764 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 07:41:09,134 INFO Epoch 14 Step 14531 on_batch_end True CV rank 0
2025-01-10 07:41:09,134 INFO Epoch 14 Step 14531 on_batch_end True CV rank 2
2025-01-10 07:41:09,134 INFO Epoch 14 Step 14531 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 07:41:18,269 DEBUG CV Batch 14/100 loss 0.609164 acc 0.836120  rank 0
2025-01-10 07:41:18,583 DEBUG CV Batch 14/100 loss 0.609164 acc 0.836120  rank 2
2025-01-10 07:41:18,805 INFO Epoch 14 Step 14531 CV info lr 0.0004147842459440409 0 rank loss_1.487326132362349 acc_0.6104987007484102
2025-01-10 07:41:18,818 DEBUG CV Batch 14/100 loss 0.609164 acc 0.836120  rank 1
2025-01-10 07:41:19,115 INFO Epoch 14 Step 14531 CV info lr 0.0004147842459440409 2 rank loss_1.487326132362349 acc_0.6104987007484102
2025-01-10 07:41:19,356 INFO Epoch 14 Step 14531 CV info lr 0.0004147842459440409 1 rank loss_1.487326132362349 acc_0.6104987007484102
2025-01-10 07:41:20,096 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_14_whole.pt
2025-01-10 07:41:20,107 INFO Added key: store_based_barrier_key:17 to store for rank: 0
2025-01-10 07:41:20,118 INFO Added key: store_based_barrier_key:17 to store for rank: 2
2025-01-10 07:41:20,118 INFO Added key: store_based_barrier_key:17 to store for rank: 1
2025-01-10 07:41:20,118 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:17 with 3 nodes.
2025-01-10 07:41:20,119 INFO Epoch 15 TRAIN info lr 0.0004147842459440409 rank 1
2025-01-10 07:41:20,120 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 07:41:20,128 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:17 with 3 nodes.
2025-01-10 07:41:20,128 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:17 with 3 nodes.
2025-01-10 07:41:20,131 INFO Epoch 15 TRAIN info lr 0.0004147842459440409 rank 0
2025-01-10 07:41:20,131 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 07:41:20,131 INFO Epoch 15 TRAIN info lr 0.0004147842459440409 rank 2
2025-01-10 07:41:20,131 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 07:41:56,976 DEBUG TRAIN Batch 15/100 loss 0.473847 acc 0.677711 lr 0.00041407 grad_norm 0.543973 rank 0
2025-01-10 07:41:56,976 DEBUG TRAIN Batch 15/100 loss 0.420594 acc 0.735537 lr 0.00041407 grad_norm 0.543973 rank 1
2025-01-10 07:41:56,976 DEBUG TRAIN Batch 15/100 loss 0.558075 acc 0.652866 lr 0.00041407 grad_norm 0.543973 rank 2
2025-01-10 07:42:21,160 DEBUG TRAIN Batch 15/200 loss 0.418429 acc 0.733628 lr 0.00041336 grad_norm 0.536636 rank 1
2025-01-10 07:42:21,160 DEBUG TRAIN Batch 15/200 loss 0.565786 acc 0.632615 lr 0.00041336 grad_norm 0.536636 rank 0
2025-01-10 07:42:21,160 DEBUG TRAIN Batch 15/200 loss 0.500254 acc 0.680000 lr 0.00041336 grad_norm 0.536636 rank 2
2025-01-10 07:42:45,619 DEBUG TRAIN Batch 15/300 loss 0.521536 acc 0.655924 lr 0.00041266 grad_norm 0.533241 rank 1
2025-01-10 07:42:45,620 DEBUG TRAIN Batch 15/300 loss 0.594924 acc 0.611687 lr 0.00041266 grad_norm 0.533241 rank 2
2025-01-10 07:42:45,620 DEBUG TRAIN Batch 15/300 loss 0.552733 acc 0.637017 lr 0.00041266 grad_norm 0.533241 rank 0
2025-01-10 07:43:09,281 DEBUG TRAIN Batch 15/400 loss 0.394571 acc 0.737581 lr 0.00041196 grad_norm 0.562208 rank 1
2025-01-10 07:43:09,281 DEBUG TRAIN Batch 15/400 loss 0.542819 acc 0.648262 lr 0.00041196 grad_norm 0.562208 rank 2
2025-01-10 07:43:09,281 DEBUG TRAIN Batch 15/400 loss 0.630408 acc 0.616608 lr 0.00041196 grad_norm 0.562208 rank 0
2025-01-10 07:43:34,248 DEBUG TRAIN Batch 15/500 loss 0.530995 acc 0.655238 lr 0.00041126 grad_norm 0.547857 rank 1
2025-01-10 07:43:34,248 DEBUG TRAIN Batch 15/500 loss 0.583439 acc 0.628492 lr 0.00041126 grad_norm 0.547857 rank 0
2025-01-10 07:43:34,248 DEBUG TRAIN Batch 15/500 loss 0.650670 acc 0.597208 lr 0.00041126 grad_norm 0.547857 rank 2
2025-01-10 07:43:58,726 DEBUG TRAIN Batch 15/600 loss 0.556717 acc 0.633459 lr 0.00041057 grad_norm 0.530432 rank 0
2025-01-10 07:43:58,726 DEBUG TRAIN Batch 15/600 loss 0.637486 acc 0.614350 lr 0.00041057 grad_norm 0.530432 rank 2
2025-01-10 07:43:58,726 DEBUG TRAIN Batch 15/600 loss 0.501864 acc 0.693438 lr 0.00041057 grad_norm 0.530432 rank 1
2025-01-10 07:44:22,764 DEBUG TRAIN Batch 15/700 loss 0.549403 acc 0.642478 lr 0.00040988 grad_norm 0.532636 rank 1
2025-01-10 07:44:22,765 DEBUG TRAIN Batch 15/700 loss 0.680864 acc 0.573889 lr 0.00040988 grad_norm 0.532636 rank 2
2025-01-10 07:44:22,766 DEBUG TRAIN Batch 15/700 loss 0.560004 acc 0.646429 lr 0.00040988 grad_norm 0.532636 rank 0
2025-01-10 07:44:47,770 DEBUG TRAIN Batch 15/800 loss 0.472497 acc 0.691371 lr 0.00040919 grad_norm 0.561191 rank 0
2025-01-10 07:44:47,770 DEBUG TRAIN Batch 15/800 loss 0.602753 acc 0.612167 lr 0.00040919 grad_norm 0.561191 rank 2
2025-01-10 07:44:47,771 DEBUG TRAIN Batch 15/800 loss 0.545612 acc 0.658385 lr 0.00040919 grad_norm 0.561191 rank 1
2025-01-10 07:45:11,948 DEBUG TRAIN Batch 15/900 loss 0.716509 acc 0.581438 lr 0.00040851 grad_norm 0.548283 rank 2
2025-01-10 07:45:11,948 DEBUG TRAIN Batch 15/900 loss 0.498876 acc 0.669763 lr 0.00040851 grad_norm 0.548283 rank 0
2025-01-10 07:45:11,948 DEBUG TRAIN Batch 15/900 loss 0.557373 acc 0.648363 lr 0.00040851 grad_norm 0.548283 rank 1
2025-01-10 07:45:35,808 DEBUG TRAIN Batch 15/1000 loss 0.751432 acc 0.533467 lr 0.00040783 grad_norm 0.561219 rank 2
2025-01-10 07:45:35,808 DEBUG TRAIN Batch 15/1000 loss 0.533121 acc 0.639223 lr 0.00040783 grad_norm 0.561219 rank 0
2025-01-10 07:45:35,808 DEBUG TRAIN Batch 15/1000 loss 0.520547 acc 0.682051 lr 0.00040783 grad_norm 0.561219 rank 1
2025-01-10 07:46:01,323 DEBUG TRAIN Batch 15/1100 loss 0.697290 acc 0.578894 lr 0.00040715 grad_norm 0.529504 rank 0
2025-01-10 07:46:01,323 DEBUG TRAIN Batch 15/1100 loss 0.659545 acc 0.594077 lr 0.00040715 grad_norm 0.529504 rank 1
2025-01-10 07:46:01,323 DEBUG TRAIN Batch 15/1100 loss 0.697327 acc 0.552141 lr 0.00040715 grad_norm 0.529504 rank 2
2025-01-10 07:46:27,211 DEBUG TRAIN Batch 15/1200 loss 0.681571 acc 0.571554 lr 0.00040648 grad_norm 0.521821 rank 2
2025-01-10 07:46:27,210 DEBUG TRAIN Batch 15/1200 loss 0.584891 acc 0.615672 lr 0.00040648 grad_norm 0.521821 rank 1
2025-01-10 07:46:27,227 DEBUG TRAIN Batch 15/1200 loss 0.781544 acc 0.540967 lr 0.00040648 grad_norm 0.521821 rank 0
2025-01-10 07:46:59,199 DEBUG TRAIN Batch 15/1300 loss 0.812547 acc 0.504942 lr 0.00040581 grad_norm 0.545157 rank 2
2025-01-10 07:46:59,200 DEBUG TRAIN Batch 15/1300 loss 0.537735 acc 0.652505 lr 0.00040581 grad_norm 0.545157 rank 1
2025-01-10 07:46:59,216 DEBUG TRAIN Batch 15/1300 loss 0.396155 acc 0.750427 lr 0.00040581 grad_norm 0.545157 rank 0
2025-01-10 07:47:29,548 DEBUG TRAIN Batch 15/1400 loss 0.597017 acc 0.611015 lr 0.00040514 grad_norm 0.471048 rank 2
2025-01-10 07:47:29,549 DEBUG TRAIN Batch 15/1400 loss 0.458110 acc 0.705208 lr 0.00040514 grad_norm 0.471048 rank 1
2025-01-10 07:47:29,562 DEBUG TRAIN Batch 15/1400 loss 0.729014 acc 0.533393 lr 0.00040514 grad_norm 0.471048 rank 0
2025-01-10 07:47:58,721 DEBUG TRAIN Batch 15/1500 loss 0.625038 acc 0.621789 lr 0.00040448 grad_norm 0.510482 rank 2
2025-01-10 07:47:58,722 DEBUG TRAIN Batch 15/1500 loss 0.481987 acc 0.687805 lr 0.00040448 grad_norm 0.510482 rank 1
2025-01-10 07:47:58,743 DEBUG TRAIN Batch 15/1500 loss 0.679606 acc 0.579979 lr 0.00040448 grad_norm 0.510482 rank 0
2025-01-10 07:48:28,972 DEBUG TRAIN Batch 15/1600 loss 0.578753 acc 0.639329 lr 0.00040382 grad_norm 0.563007 rank 2
2025-01-10 07:48:28,973 DEBUG TRAIN Batch 15/1600 loss 0.393248 acc 0.740528 lr 0.00040382 grad_norm 0.563007 rank 1
2025-01-10 07:48:28,984 DEBUG TRAIN Batch 15/1600 loss 0.550842 acc 0.628571 lr 0.00040382 grad_norm 0.563007 rank 0
2025-01-10 07:48:59,589 DEBUG TRAIN Batch 15/1700 loss 0.621560 acc 0.617925 lr 0.00040316 grad_norm 0.507332 rank 2
2025-01-10 07:48:59,591 DEBUG TRAIN Batch 15/1700 loss 0.607080 acc 0.627289 lr 0.00040316 grad_norm 0.507332 rank 1
2025-01-10 07:48:59,608 DEBUG TRAIN Batch 15/1700 loss 0.586945 acc 0.644295 lr 0.00040316 grad_norm 0.507332 rank 0
2025-01-10 07:49:28,648 DEBUG TRAIN Batch 15/1800 loss 0.332737 acc 0.782719 lr 0.00040251 grad_norm 0.552538 rank 1
2025-01-10 07:49:28,648 DEBUG TRAIN Batch 15/1800 loss 0.628450 acc 0.602804 lr 0.00040251 grad_norm 0.552538 rank 2
2025-01-10 07:49:28,661 DEBUG TRAIN Batch 15/1800 loss 0.492486 acc 0.674419 lr 0.00040251 grad_norm 0.552538 rank 0
2025-01-10 07:49:58,428 DEBUG TRAIN Batch 15/1900 loss 0.446076 acc 0.714872 lr 0.00040186 grad_norm 0.539356 rank 1
2025-01-10 07:49:58,428 DEBUG TRAIN Batch 15/1900 loss 0.614992 acc 0.607447 lr 0.00040186 grad_norm 0.539356 rank 2
2025-01-10 07:49:58,572 DEBUG TRAIN Batch 15/1900 loss 0.578680 acc 0.630832 lr 0.00040186 grad_norm 0.539356 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 07:51:05,610 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 07:51:05,611 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 07:51:06,038 INFO Epoch 15 Step 15493 on_batch_end True CV rank 0
2025-01-10 07:51:06,038 INFO Epoch 15 Step 15493 on_batch_end True CV rank 1
2025-01-10 07:51:06,038 INFO Epoch 15 Step 15493 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 07:51:15,161 DEBUG CV Batch 15/100 loss 0.645511 acc 0.826087  rank 0
2025-01-10 07:51:15,399 DEBUG CV Batch 15/100 loss 0.645511 acc 0.826087  rank 2
2025-01-10 07:51:15,678 INFO Epoch 15 Step 15493 CV info lr 0.00040170038123232095 0 rank loss_1.4725972436237753 acc_0.6215097441485053
2025-01-10 07:51:15,912 DEBUG CV Batch 15/100 loss 0.645511 acc 0.826087  rank 1
2025-01-10 07:51:15,932 INFO Epoch 15 Step 15493 CV info lr 0.00040170038123232095 2 rank loss_1.4725972436237753 acc_0.6215097441485053
2025-01-10 07:51:16,451 INFO Epoch 15 Step 15493 CV info lr 0.00040170038123232095 1 rank loss_1.4725972436237753 acc_0.6215097441485053
2025-01-10 07:51:16,969 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_15_whole.pt
2025-01-10 07:51:16,990 INFO Added key: store_based_barrier_key:18 to store for rank: 0
2025-01-10 07:51:17,001 INFO Added key: store_based_barrier_key:18 to store for rank: 2
2025-01-10 07:51:17,001 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:18 with 3 nodes.
2025-01-10 07:51:17,001 INFO Added key: store_based_barrier_key:18 to store for rank: 1
2025-01-10 07:51:17,001 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:18 with 3 nodes.
2025-01-10 07:51:17,001 INFO Epoch 16 TRAIN info lr 0.00040170038123232095 rank 2
2025-01-10 07:51:17,001 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 07:51:17,005 INFO Epoch 16 TRAIN info lr 0.00040170038123232095 rank 1
2025-01-10 07:51:17,005 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 07:51:17,011 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:18 with 3 nodes.
2025-01-10 07:51:17,017 INFO Epoch 16 TRAIN info lr 0.00040170038123232095 rank 0
2025-01-10 07:51:17,017 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 07:51:47,640 DEBUG TRAIN Batch 16/100 loss 0.548020 acc 0.620293 lr 0.00040105 grad_norm 0.545535 rank 2
2025-01-10 07:51:47,640 DEBUG TRAIN Batch 16/100 loss 0.674958 acc 0.566290 lr 0.00040105 grad_norm 0.545535 rank 0
2025-01-10 07:51:47,641 DEBUG TRAIN Batch 16/100 loss 0.390482 acc 0.747485 lr 0.00040105 grad_norm 0.545535 rank 1
2025-01-10 07:52:11,519 DEBUG TRAIN Batch 16/200 loss 0.469230 acc 0.709834 lr 0.00040041 grad_norm 0.597358 rank 1
2025-01-10 07:52:11,519 DEBUG TRAIN Batch 16/200 loss 0.646693 acc 0.605364 lr 0.00040041 grad_norm 0.597358 rank 0
2025-01-10 07:52:11,519 DEBUG TRAIN Batch 16/200 loss 0.433746 acc 0.723485 lr 0.00040041 grad_norm 0.597358 rank 2
2025-01-10 07:52:35,003 DEBUG TRAIN Batch 16/300 loss 0.373789 acc 0.743091 lr 0.00039977 grad_norm 0.553504 rank 1
2025-01-10 07:52:35,004 DEBUG TRAIN Batch 16/300 loss 0.575673 acc 0.625232 lr 0.00039977 grad_norm 0.553504 rank 2
2025-01-10 07:52:35,004 DEBUG TRAIN Batch 16/300 loss 0.661864 acc 0.571006 lr 0.00039977 grad_norm 0.553504 rank 0
2025-01-10 07:53:02,960 DEBUG TRAIN Batch 16/400 loss 0.268518 acc 0.827922 lr 0.00039913 grad_norm 0.559953 rank 1
2025-01-10 07:53:02,961 DEBUG TRAIN Batch 16/400 loss 0.526237 acc 0.658052 lr 0.00039913 grad_norm 0.559953 rank 2
2025-01-10 07:53:02,967 DEBUG TRAIN Batch 16/400 loss 0.609039 acc 0.611349 lr 0.00039913 grad_norm 0.559953 rank 0
2025-01-10 07:53:30,439 DEBUG TRAIN Batch 16/500 loss 0.363276 acc 0.761267 lr 0.00039850 grad_norm 0.586874 rank 1
2025-01-10 07:53:30,440 DEBUG TRAIN Batch 16/500 loss 0.550159 acc 0.636525 lr 0.00039850 grad_norm 0.586874 rank 0
2025-01-10 07:53:30,440 DEBUG TRAIN Batch 16/500 loss 0.492617 acc 0.675676 lr 0.00039850 grad_norm 0.586874 rank 2
2025-01-10 07:53:57,946 DEBUG TRAIN Batch 16/600 loss 0.552392 acc 0.647773 lr 0.00039787 grad_norm 0.582251 rank 0
2025-01-10 07:53:57,946 DEBUG TRAIN Batch 16/600 loss 0.536485 acc 0.653346 lr 0.00039787 grad_norm 0.582251 rank 2
2025-01-10 07:53:57,947 DEBUG TRAIN Batch 16/600 loss 0.420887 acc 0.736790 lr 0.00039787 grad_norm 0.582251 rank 1
2025-01-10 07:54:25,866 DEBUG TRAIN Batch 16/700 loss 0.427661 acc 0.727595 lr 0.00039724 grad_norm 0.534653 rank 2
2025-01-10 07:54:25,866 DEBUG TRAIN Batch 16/700 loss 0.563518 acc 0.630303 lr 0.00039724 grad_norm 0.534653 rank 0
2025-01-10 07:54:25,866 DEBUG TRAIN Batch 16/700 loss 0.203748 acc 0.854545 lr 0.00039724 grad_norm 0.534653 rank 1
2025-01-10 07:54:49,584 DEBUG TRAIN Batch 16/800 loss 0.361540 acc 0.761530 lr 0.00039661 grad_norm 0.549071 rank 1
2025-01-10 07:54:49,585 DEBUG TRAIN Batch 16/800 loss 0.550030 acc 0.638889 lr 0.00039661 grad_norm 0.549071 rank 2
2025-01-10 07:54:49,585 DEBUG TRAIN Batch 16/800 loss 0.547886 acc 0.658333 lr 0.00039661 grad_norm 0.549071 rank 0
2025-01-10 07:55:17,677 DEBUG TRAIN Batch 16/900 loss 0.636141 acc 0.593833 lr 0.00039599 grad_norm 0.564336 rank 2
2025-01-10 07:55:17,677 DEBUG TRAIN Batch 16/900 loss 0.532409 acc 0.671040 lr 0.00039599 grad_norm 0.564336 rank 0
2025-01-10 07:55:17,677 DEBUG TRAIN Batch 16/900 loss 0.375343 acc 0.761062 lr 0.00039599 grad_norm 0.564336 rank 1
2025-01-10 07:55:46,075 DEBUG TRAIN Batch 16/1000 loss 0.659368 acc 0.599404 lr 0.00039537 grad_norm 0.562400 rank 2
2025-01-10 07:55:46,075 DEBUG TRAIN Batch 16/1000 loss 0.460277 acc 0.701339 lr 0.00039537 grad_norm 0.562400 rank 1
2025-01-10 07:55:46,104 DEBUG TRAIN Batch 16/1000 loss 0.588944 acc 0.645435 lr 0.00039537 grad_norm 0.562400 rank 0
2025-01-10 07:56:14,385 DEBUG TRAIN Batch 16/1100 loss 0.591611 acc 0.632173 lr 0.00039475 grad_norm 0.602266 rank 0
2025-01-10 07:56:14,385 DEBUG TRAIN Batch 16/1100 loss 0.616108 acc 0.608428 lr 0.00039475 grad_norm 0.602266 rank 2
2025-01-10 07:56:14,386 DEBUG TRAIN Batch 16/1100 loss 0.426866 acc 0.737864 lr 0.00039475 grad_norm 0.602266 rank 1
2025-01-10 07:56:38,313 DEBUG TRAIN Batch 16/1200 loss 0.482789 acc 0.696653 lr 0.00039414 grad_norm 0.552117 rank 1
2025-01-10 07:56:38,313 DEBUG TRAIN Batch 16/1200 loss 0.701057 acc 0.569519 lr 0.00039414 grad_norm 0.552117 rank 0
2025-01-10 07:56:38,313 DEBUG TRAIN Batch 16/1200 loss 0.557487 acc 0.654088 lr 0.00039414 grad_norm 0.552117 rank 2
2025-01-10 07:57:07,421 DEBUG TRAIN Batch 16/1300 loss 0.409288 acc 0.733262 lr 0.00039353 grad_norm 0.580297 rank 1
2025-01-10 07:57:07,421 DEBUG TRAIN Batch 16/1300 loss 0.554443 acc 0.642788 lr 0.00039353 grad_norm 0.580297 rank 2
2025-01-10 07:57:07,444 DEBUG TRAIN Batch 16/1300 loss 0.533852 acc 0.654271 lr 0.00039353 grad_norm 0.580297 rank 0
2025-01-10 07:57:35,736 DEBUG TRAIN Batch 16/1400 loss 0.621959 acc 0.606526 lr 0.00039292 grad_norm 0.517505 rank 0
2025-01-10 07:57:35,736 DEBUG TRAIN Batch 16/1400 loss 0.600233 acc 0.631439 lr 0.00039292 grad_norm 0.517505 rank 2
2025-01-10 07:57:35,736 DEBUG TRAIN Batch 16/1400 loss 0.258291 acc 0.822034 lr 0.00039292 grad_norm 0.517505 rank 1
2025-01-10 07:57:59,164 DEBUG TRAIN Batch 16/1500 loss 0.565093 acc 0.628546 lr 0.00039232 grad_norm 0.565049 rank 0
2025-01-10 07:57:59,165 DEBUG TRAIN Batch 16/1500 loss 0.577098 acc 0.645161 lr 0.00039232 grad_norm 0.565049 rank 2
2025-01-10 07:57:59,166 DEBUG TRAIN Batch 16/1500 loss 0.341252 acc 0.759091 lr 0.00039232 grad_norm 0.565049 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 07:59:08,123 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59984ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 07:59:08,129 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 07:59:08,595 INFO Epoch 16 Step 16261 on_batch_end True CV rank 0
2025-01-10 07:59:08,595 INFO Epoch 16 Step 16261 on_batch_end True CV rank 1
2025-01-10 07:59:08,595 INFO Epoch 16 Step 16261 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 07:59:17,667 DEBUG CV Batch 16/100 loss 0.539654 acc 0.839465  rank 0
2025-01-10 07:59:17,953 DEBUG CV Batch 16/100 loss 0.539654 acc 0.839465  rank 2
2025-01-10 07:59:18,169 INFO Epoch 16 Step 16261 CV info lr 0.00039209958209970386 0 rank loss_1.5035975954511709 acc_0.6296876876762039
2025-01-10 07:59:18,231 DEBUG CV Batch 16/100 loss 0.539654 acc 0.839465  rank 1
2025-01-10 07:59:18,500 INFO Epoch 16 Step 16261 CV info lr 0.00039209958209970386 2 rank loss_1.5035975954511709 acc_0.6296876876762039
2025-01-10 07:59:18,784 INFO Epoch 16 Step 16261 CV info lr 0.00039209958209970386 1 rank loss_1.5035975954511709 acc_0.6296876876762039
2025-01-10 07:59:19,436 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_16_whole.pt
2025-01-10 07:59:19,447 INFO Added key: store_based_barrier_key:19 to store for rank: 0
2025-01-10 07:59:19,457 INFO Added key: store_based_barrier_key:19 to store for rank: 2
2025-01-10 07:59:19,457 INFO Added key: store_based_barrier_key:19 to store for rank: 1
2025-01-10 07:59:19,458 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:19 with 3 nodes.
2025-01-10 07:59:19,458 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:19 with 3 nodes.
2025-01-10 07:59:19,461 INFO Epoch 17 TRAIN info lr 0.00039209958209970386 rank 1
2025-01-10 07:59:19,461 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 07:59:19,464 INFO Epoch 17 TRAIN info lr 0.00039209958209970386 rank 0
2025-01-10 07:59:19,464 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 07:59:19,468 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:19 with 3 nodes.
2025-01-10 07:59:19,471 INFO Epoch 17 TRAIN info lr 0.00039209958209970386 rank 2
2025-01-10 07:59:19,471 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 07:59:53,572 DEBUG TRAIN Batch 17/100 loss 0.463918 acc 0.690927 lr 0.00039150 grad_norm 0.557741 rank 0
2025-01-10 07:59:53,572 DEBUG TRAIN Batch 17/100 loss 0.491739 acc 0.668490 lr 0.00039150 grad_norm 0.557741 rank 1
2025-01-10 07:59:53,572 DEBUG TRAIN Batch 17/100 loss 0.332485 acc 0.771023 lr 0.00039150 grad_norm 0.557741 rank 2
2025-01-10 08:00:17,536 DEBUG TRAIN Batch 17/200 loss 0.568249 acc 0.640845 lr 0.00039090 grad_norm 0.589345 rank 0
2025-01-10 08:00:17,536 DEBUG TRAIN Batch 17/200 loss 0.407014 acc 0.741706 lr 0.00039090 grad_norm 0.589345 rank 2
2025-01-10 08:00:17,536 DEBUG TRAIN Batch 17/200 loss 0.436629 acc 0.736780 lr 0.00039090 grad_norm 0.589345 rank 1
2025-01-10 08:00:41,982 DEBUG TRAIN Batch 17/300 loss 0.429965 acc 0.742326 lr 0.00039030 grad_norm 0.591899 rank 2
2025-01-10 08:00:41,982 DEBUG TRAIN Batch 17/300 loss 0.312612 acc 0.793269 lr 0.00039030 grad_norm 0.591899 rank 1
2025-01-10 08:00:41,983 DEBUG TRAIN Batch 17/300 loss 0.462512 acc 0.706061 lr 0.00039030 grad_norm 0.591899 rank 0
2025-01-10 08:01:06,646 DEBUG TRAIN Batch 17/400 loss 0.207867 acc 0.856305 lr 0.00038971 grad_norm 0.563573 rank 2
2025-01-10 08:01:06,646 DEBUG TRAIN Batch 17/400 loss 0.466665 acc 0.702581 lr 0.00038971 grad_norm 0.563573 rank 0
2025-01-10 08:01:06,646 DEBUG TRAIN Batch 17/400 loss 0.537471 acc 0.641001 lr 0.00038971 grad_norm 0.563573 rank 1
2025-01-10 08:01:30,532 DEBUG TRAIN Batch 17/500 loss 0.551442 acc 0.636277 lr 0.00038912 grad_norm 0.575675 rank 1
2025-01-10 08:01:30,532 DEBUG TRAIN Batch 17/500 loss 0.256426 acc 0.826014 lr 0.00038912 grad_norm 0.575675 rank 0
2025-01-10 08:01:30,532 DEBUG TRAIN Batch 17/500 loss 0.323142 acc 0.790323 lr 0.00038912 grad_norm 0.575675 rank 2
2025-01-10 08:01:54,803 DEBUG TRAIN Batch 17/600 loss 0.495007 acc 0.659341 lr 0.00038853 grad_norm 0.577385 rank 1
2025-01-10 08:01:54,803 DEBUG TRAIN Batch 17/600 loss 0.286338 acc 0.803946 lr 0.00038853 grad_norm 0.577385 rank 2
2025-01-10 08:01:54,804 DEBUG TRAIN Batch 17/600 loss 0.506954 acc 0.675280 lr 0.00038853 grad_norm 0.577385 rank 0
2025-01-10 08:02:19,186 DEBUG TRAIN Batch 17/700 loss 0.360527 acc 0.752775 lr 0.00038795 grad_norm 0.577360 rank 2
2025-01-10 08:02:19,186 DEBUG TRAIN Batch 17/700 loss 0.306202 acc 0.767881 lr 0.00038795 grad_norm 0.577360 rank 1
2025-01-10 08:02:19,186 DEBUG TRAIN Batch 17/700 loss 0.554979 acc 0.656502 lr 0.00038795 grad_norm 0.577360 rank 0
2025-01-10 08:02:43,945 DEBUG TRAIN Batch 17/800 loss 0.460836 acc 0.691674 lr 0.00038736 grad_norm 0.592032 rank 1
2025-01-10 08:02:43,945 DEBUG TRAIN Batch 17/800 loss 0.236827 acc 0.847384 lr 0.00038736 grad_norm 0.592032 rank 2
2025-01-10 08:02:43,945 DEBUG TRAIN Batch 17/800 loss 0.531680 acc 0.662289 lr 0.00038736 grad_norm 0.592032 rank 0
2025-01-10 08:03:07,705 DEBUG TRAIN Batch 17/900 loss 0.383431 acc 0.738119 lr 0.00038678 grad_norm 0.587209 rank 2
2025-01-10 08:03:07,705 DEBUG TRAIN Batch 17/900 loss 0.441262 acc 0.719424 lr 0.00038678 grad_norm 0.587209 rank 0
2025-01-10 08:03:07,705 DEBUG TRAIN Batch 17/900 loss 0.387117 acc 0.740506 lr 0.00038678 grad_norm 0.587209 rank 1
2025-01-10 08:03:31,631 DEBUG TRAIN Batch 17/1000 loss 0.665488 acc 0.577940 lr 0.00038621 grad_norm 0.577797 rank 0
2025-01-10 08:03:31,631 DEBUG TRAIN Batch 17/1000 loss 0.628105 acc 0.597450 lr 0.00038621 grad_norm 0.577797 rank 2
2025-01-10 08:03:31,632 DEBUG TRAIN Batch 17/1000 loss 0.505788 acc 0.675497 lr 0.00038621 grad_norm 0.577797 rank 1
2025-01-10 08:03:55,099 DEBUG TRAIN Batch 17/1100 loss 0.491477 acc 0.688372 lr 0.00038563 grad_norm 0.577425 rank 1
2025-01-10 08:03:55,099 DEBUG TRAIN Batch 17/1100 loss 0.513612 acc 0.657464 lr 0.00038563 grad_norm 0.577425 rank 2
2025-01-10 08:03:55,099 DEBUG TRAIN Batch 17/1100 loss 0.583486 acc 0.642398 lr 0.00038563 grad_norm 0.577425 rank 0
2025-01-10 08:04:18,948 DEBUG TRAIN Batch 17/1200 loss 0.627175 acc 0.605058 lr 0.00038506 grad_norm 0.563059 rank 0
2025-01-10 08:04:18,949 DEBUG TRAIN Batch 17/1200 loss 0.566991 acc 0.644424 lr 0.00038506 grad_norm 0.563059 rank 2
2025-01-10 08:04:18,949 DEBUG TRAIN Batch 17/1200 loss 0.344192 acc 0.765116 lr 0.00038506 grad_norm 0.563059 rank 1
2025-01-10 08:04:42,721 DEBUG TRAIN Batch 17/1300 loss 0.477480 acc 0.701787 lr 0.00038449 grad_norm 0.589581 rank 1
2025-01-10 08:04:42,721 DEBUG TRAIN Batch 17/1300 loss 0.599011 acc 0.607014 lr 0.00038449 grad_norm 0.589581 rank 2
2025-01-10 08:04:42,721 DEBUG TRAIN Batch 17/1300 loss 0.631976 acc 0.608229 lr 0.00038449 grad_norm 0.589581 rank 0
2025-01-10 08:05:06,550 DEBUG TRAIN Batch 17/1400 loss 0.481045 acc 0.690090 lr 0.00038392 grad_norm 0.574618 rank 0
2025-01-10 08:05:06,551 DEBUG TRAIN Batch 17/1400 loss 0.513224 acc 0.666968 lr 0.00038392 grad_norm 0.574618 rank 1
2025-01-10 08:05:06,551 DEBUG TRAIN Batch 17/1400 loss 0.573328 acc 0.645662 lr 0.00038392 grad_norm 0.574618 rank 2
2025-01-10 08:05:31,664 DEBUG TRAIN Batch 17/1500 loss 0.483417 acc 0.680227 lr 0.00038336 grad_norm 0.585041 rank 1
2025-01-10 08:05:31,664 DEBUG TRAIN Batch 17/1500 loss 0.515898 acc 0.680597 lr 0.00038336 grad_norm 0.585041 rank 2
2025-01-10 08:05:31,686 DEBUG TRAIN Batch 17/1500 loss 0.410091 acc 0.729469 lr 0.00038336 grad_norm 0.585041 rank 0
2025-01-10 08:06:02,537 DEBUG TRAIN Batch 17/1600 loss 0.410328 acc 0.721680 lr 0.00038280 grad_norm 0.584086 rank 1
2025-01-10 08:06:02,537 DEBUG TRAIN Batch 17/1600 loss 0.491082 acc 0.676382 lr 0.00038280 grad_norm 0.584086 rank 2
2025-01-10 08:06:02,552 DEBUG TRAIN Batch 17/1600 loss 0.431847 acc 0.720739 lr 0.00038280 grad_norm 0.584086 rank 0
2025-01-10 08:06:27,085 DEBUG TRAIN Batch 17/1700 loss 0.523414 acc 0.651334 lr 0.00038224 grad_norm 0.571064 rank 0
2025-01-10 08:06:27,085 DEBUG TRAIN Batch 17/1700 loss 0.610710 acc 0.618964 lr 0.00038224 grad_norm 0.571064 rank 2
2025-01-10 08:06:27,085 DEBUG TRAIN Batch 17/1700 loss 0.480363 acc 0.695298 lr 0.00038224 grad_norm 0.571064 rank 1
2025-01-10 08:06:50,678 DEBUG TRAIN Batch 17/1800 loss 0.584388 acc 0.642349 lr 0.00038168 grad_norm 0.558981 rank 0
2025-01-10 08:06:50,678 DEBUG TRAIN Batch 17/1800 loss 0.517274 acc 0.655943 lr 0.00038168 grad_norm 0.558981 rank 1
2025-01-10 08:06:50,679 DEBUG TRAIN Batch 17/1800 loss 0.506542 acc 0.657143 lr 0.00038168 grad_norm 0.558981 rank 2
2025-01-10 08:07:14,509 DEBUG TRAIN Batch 17/1900 loss 0.475641 acc 0.694444 lr 0.00038112 grad_norm 0.562782 rank 0
2025-01-10 08:07:14,509 DEBUG TRAIN Batch 17/1900 loss 0.660021 acc 0.587779 lr 0.00038112 grad_norm 0.562782 rank 1
2025-01-10 08:07:14,510 DEBUG TRAIN Batch 17/1900 loss 0.736073 acc 0.544498 lr 0.00038112 grad_norm 0.562782 rank 2
2025-01-10 08:07:39,637 DEBUG TRAIN Batch 17/2000 loss 0.645231 acc 0.562099 lr 0.00038057 grad_norm 0.543133 rank 1
2025-01-10 08:07:39,637 DEBUG TRAIN Batch 17/2000 loss 0.711693 acc 0.550336 lr 0.00038057 grad_norm 0.543133 rank 2
2025-01-10 08:07:39,637 DEBUG TRAIN Batch 17/2000 loss 0.581736 acc 0.639279 lr 0.00038057 grad_norm 0.543133 rank 0
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 08:08:48,935 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 08:08:48,941 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 08:08:49,445 INFO Epoch 17 Step 17279 on_batch_end True CV rank 1
2025-01-10 08:08:49,445 INFO Epoch 17 Step 17279 on_batch_end True CV rank 0
2025-01-10 08:08:49,445 INFO Epoch 17 Step 17279 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 08:08:58,597 DEBUG CV Batch 17/100 loss 0.460048 acc 0.872910  rank 0
2025-01-10 08:08:58,904 DEBUG CV Batch 17/100 loss 0.460048 acc 0.872910  rank 2
2025-01-10 08:08:59,076 DEBUG CV Batch 17/100 loss 0.460048 acc 0.872910  rank 1
2025-01-10 08:08:59,112 INFO Epoch 17 Step 17279 CV info lr 0.0003803738935046512 0 rank loss_1.4196529203470338 acc_0.6533484715118743
2025-01-10 08:08:59,447 INFO Epoch 17 Step 17279 CV info lr 0.0003803738935046512 2 rank loss_1.4196529203470338 acc_0.6533484715118743
2025-01-10 08:08:59,592 INFO Epoch 17 Step 17279 CV info lr 0.0003803738935046512 1 rank loss_1.4196529203470338 acc_0.6533484715118743
2025-01-10 08:09:00,414 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_17_whole.pt
2025-01-10 08:09:00,436 INFO Added key: store_based_barrier_key:20 to store for rank: 0
2025-01-10 08:09:00,436 INFO Added key: store_based_barrier_key:20 to store for rank: 1
2025-01-10 08:09:00,436 INFO Added key: store_based_barrier_key:20 to store for rank: 2
2025-01-10 08:09:00,436 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:20 with 3 nodes.
2025-01-10 08:09:00,436 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:20 with 3 nodes.
2025-01-10 08:09:00,439 INFO Epoch 18 TRAIN info lr 0.0003803738935046512 rank 2
2025-01-10 08:09:00,439 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 08:09:00,441 INFO Epoch 18 TRAIN info lr 0.0003803738935046512 rank 1
2025-01-10 08:09:00,441 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 08:09:00,446 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:20 with 3 nodes.
2025-01-10 08:09:00,453 INFO Epoch 18 TRAIN info lr 0.0003803738935046512 rank 0
2025-01-10 08:09:00,453 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 08:09:33,976 DEBUG TRAIN Batch 18/100 loss 0.556069 acc 0.649654 lr 0.00037982 grad_norm 0.560008 rank 1
2025-01-10 08:09:33,976 DEBUG TRAIN Batch 18/100 loss 0.348697 acc 0.776163 lr 0.00037982 grad_norm 0.560008 rank 0
2025-01-10 08:09:33,976 DEBUG TRAIN Batch 18/100 loss 0.355140 acc 0.767857 lr 0.00037982 grad_norm 0.560008 rank 2
2025-01-10 08:09:58,026 DEBUG TRAIN Batch 18/200 loss 0.387626 acc 0.747312 lr 0.00037928 grad_norm 0.578621 rank 0
2025-01-10 08:09:58,026 DEBUG TRAIN Batch 18/200 loss 0.430179 acc 0.711986 lr 0.00037928 grad_norm 0.578621 rank 2
2025-01-10 08:09:58,026 DEBUG TRAIN Batch 18/200 loss 0.692822 acc 0.571142 lr 0.00037928 grad_norm 0.578621 rank 1
2025-01-10 08:10:23,077 DEBUG TRAIN Batch 18/300 loss 0.336307 acc 0.768101 lr 0.00037873 grad_norm 0.601038 rank 0
2025-01-10 08:10:23,077 DEBUG TRAIN Batch 18/300 loss 0.540083 acc 0.665595 lr 0.00037873 grad_norm 0.601038 rank 1
2025-01-10 08:10:23,077 DEBUG TRAIN Batch 18/300 loss 0.495558 acc 0.660477 lr 0.00037873 grad_norm 0.601038 rank 2
2025-01-10 08:10:47,390 DEBUG TRAIN Batch 18/400 loss 0.529940 acc 0.660542 lr 0.00037819 grad_norm 0.574462 rank 0
2025-01-10 08:10:47,390 DEBUG TRAIN Batch 18/400 loss 0.350177 acc 0.759420 lr 0.00037819 grad_norm 0.574462 rank 2
2025-01-10 08:10:47,391 DEBUG TRAIN Batch 18/400 loss 0.608898 acc 0.604444 lr 0.00037819 grad_norm 0.574462 rank 1
2025-01-10 08:11:11,683 DEBUG TRAIN Batch 18/500 loss 0.574070 acc 0.630262 lr 0.00037765 grad_norm 0.601968 rank 1
2025-01-10 08:11:11,684 DEBUG TRAIN Batch 18/500 loss 0.469999 acc 0.692958 lr 0.00037765 grad_norm 0.601968 rank 2
2025-01-10 08:11:11,684 DEBUG TRAIN Batch 18/500 loss 0.409244 acc 0.732426 lr 0.00037765 grad_norm 0.601968 rank 0
2025-01-10 08:11:36,687 DEBUG TRAIN Batch 18/600 loss 0.548025 acc 0.654859 lr 0.00037711 grad_norm 0.595232 rank 0
2025-01-10 08:11:36,687 DEBUG TRAIN Batch 18/600 loss 0.454506 acc 0.700178 lr 0.00037711 grad_norm 0.595232 rank 1
2025-01-10 08:11:36,688 DEBUG TRAIN Batch 18/600 loss 0.527226 acc 0.655141 lr 0.00037711 grad_norm 0.595232 rank 2
2025-01-10 08:12:01,009 DEBUG TRAIN Batch 18/700 loss 0.411249 acc 0.736153 lr 0.00037658 grad_norm 0.597653 rank 1
2025-01-10 08:12:01,009 DEBUG TRAIN Batch 18/700 loss 0.436768 acc 0.706849 lr 0.00037658 grad_norm 0.597653 rank 2
2025-01-10 08:12:01,010 DEBUG TRAIN Batch 18/700 loss 0.464352 acc 0.697987 lr 0.00037658 grad_norm 0.597653 rank 0
2025-01-10 08:12:25,225 DEBUG TRAIN Batch 18/800 loss 0.462514 acc 0.699099 lr 0.00037605 grad_norm 0.600566 rank 1
2025-01-10 08:12:25,225 DEBUG TRAIN Batch 18/800 loss 0.401388 acc 0.730233 lr 0.00037605 grad_norm 0.600566 rank 2
2025-01-10 08:12:25,225 DEBUG TRAIN Batch 18/800 loss 0.371482 acc 0.754386 lr 0.00037605 grad_norm 0.600566 rank 0
2025-01-10 08:12:49,698 DEBUG TRAIN Batch 18/900 loss 0.486813 acc 0.694170 lr 0.00037552 grad_norm 0.563055 rank 2
2025-01-10 08:12:49,699 DEBUG TRAIN Batch 18/900 loss 0.180044 acc 0.875598 lr 0.00037552 grad_norm 0.563055 rank 0
2025-01-10 08:12:49,699 DEBUG TRAIN Batch 18/900 loss 0.554257 acc 0.663130 lr 0.00037552 grad_norm 0.563055 rank 1
2025-01-10 08:13:13,315 DEBUG TRAIN Batch 18/1000 loss 0.468751 acc 0.700976 lr 0.00037499 grad_norm 0.568819 rank 0
2025-01-10 08:13:13,315 DEBUG TRAIN Batch 18/1000 loss 0.514490 acc 0.662042 lr 0.00037499 grad_norm 0.568819 rank 1
2025-01-10 08:13:13,315 DEBUG TRAIN Batch 18/1000 loss 0.224789 acc 0.863077 lr 0.00037499 grad_norm 0.568819 rank 2
2025-01-10 08:13:37,540 DEBUG TRAIN Batch 18/1100 loss 0.437553 acc 0.709845 lr 0.00037446 grad_norm 0.601682 rank 1
2025-01-10 08:13:37,540 DEBUG TRAIN Batch 18/1100 loss 0.441473 acc 0.718499 lr 0.00037446 grad_norm 0.601682 rank 2
2025-01-10 08:13:37,541 DEBUG TRAIN Batch 18/1100 loss 0.363887 acc 0.770984 lr 0.00037446 grad_norm 0.601682 rank 0
2025-01-10 08:14:02,658 DEBUG TRAIN Batch 18/1200 loss 0.404039 acc 0.729989 lr 0.00037394 grad_norm 0.556042 rank 2
2025-01-10 08:14:02,658 DEBUG TRAIN Batch 18/1200 loss 0.428776 acc 0.730699 lr 0.00037394 grad_norm 0.556042 rank 0
2025-01-10 08:14:02,659 DEBUG TRAIN Batch 18/1200 loss 0.538434 acc 0.648061 lr 0.00037394 grad_norm 0.556042 rank 1
2025-01-10 08:14:26,353 DEBUG TRAIN Batch 18/1300 loss 0.497125 acc 0.673832 lr 0.00037342 grad_norm 0.558921 rank 0
2025-01-10 08:14:26,353 DEBUG TRAIN Batch 18/1300 loss 0.371939 acc 0.741203 lr 0.00037342 grad_norm 0.558921 rank 1
2025-01-10 08:14:26,353 DEBUG TRAIN Batch 18/1300 loss 0.265519 acc 0.828680 lr 0.00037342 grad_norm 0.558921 rank 2
2025-01-10 08:14:50,670 DEBUG TRAIN Batch 18/1400 loss 0.449878 acc 0.704000 lr 0.00037290 grad_norm 0.572478 rank 1
2025-01-10 08:14:50,671 DEBUG TRAIN Batch 18/1400 loss 0.443426 acc 0.716346 lr 0.00037290 grad_norm 0.572478 rank 2
2025-01-10 08:14:50,671 DEBUG TRAIN Batch 18/1400 loss 0.458543 acc 0.694415 lr 0.00037290 grad_norm 0.572478 rank 0
2025-01-10 08:15:15,033 DEBUG TRAIN Batch 18/1500 loss 0.554983 acc 0.648810 lr 0.00037238 grad_norm 0.586215 rank 0
2025-01-10 08:15:15,033 DEBUG TRAIN Batch 18/1500 loss 0.222889 acc 0.838499 lr 0.00037238 grad_norm 0.586215 rank 2
2025-01-10 08:15:15,034 DEBUG TRAIN Batch 18/1500 loss 0.367149 acc 0.733702 lr 0.00037238 grad_norm 0.586215 rank 1
2025-01-10 08:15:39,161 DEBUG TRAIN Batch 18/1600 loss 0.530866 acc 0.651965 lr 0.00037186 grad_norm 0.612578 rank 0
2025-01-10 08:15:39,161 DEBUG TRAIN Batch 18/1600 loss 0.416510 acc 0.720632 lr 0.00037186 grad_norm 0.612578 rank 1
2025-01-10 08:15:39,161 DEBUG TRAIN Batch 18/1600 loss 0.400181 acc 0.746334 lr 0.00037186 grad_norm 0.612578 rank 2
2025-01-10 08:16:04,591 DEBUG TRAIN Batch 18/1700 loss 0.626936 acc 0.631970 lr 0.00037135 grad_norm 0.601193 rank 1
2025-01-10 08:16:04,591 DEBUG TRAIN Batch 18/1700 loss 0.448364 acc 0.716005 lr 0.00037135 grad_norm 0.601193 rank 0
2025-01-10 08:16:04,591 DEBUG TRAIN Batch 18/1700 loss 0.499580 acc 0.671790 lr 0.00037135 grad_norm 0.601193 rank 2
2025-01-10 08:16:28,780 DEBUG TRAIN Batch 18/1800 loss 0.481489 acc 0.688494 lr 0.00037084 grad_norm 0.614254 rank 1
2025-01-10 08:16:28,780 DEBUG TRAIN Batch 18/1800 loss 0.466956 acc 0.688868 lr 0.00037084 grad_norm 0.614254 rank 0
2025-01-10 08:16:28,781 DEBUG TRAIN Batch 18/1800 loss 0.500461 acc 0.693462 lr 0.00037084 grad_norm 0.614254 rank 2
2025-01-10 08:16:53,009 DEBUG TRAIN Batch 18/1900 loss 0.490758 acc 0.677757 lr 0.00037033 grad_norm 0.582903 rank 0
2025-01-10 08:16:53,009 DEBUG TRAIN Batch 18/1900 loss 0.538033 acc 0.658943 lr 0.00037033 grad_norm 0.582903 rank 1
2025-01-10 08:16:53,009 DEBUG TRAIN Batch 18/1900 loss 0.405625 acc 0.736295 lr 0.00037033 grad_norm 0.582903 rank 2
2025-01-10 08:17:16,858 DEBUG TRAIN Batch 18/2000 loss 0.350710 acc 0.767357 lr 0.00036982 grad_norm 0.598018 rank 0
2025-01-10 08:17:16,858 DEBUG TRAIN Batch 18/2000 loss 0.343092 acc 0.777083 lr 0.00036982 grad_norm 0.598018 rank 1
2025-01-10 08:17:16,858 DEBUG TRAIN Batch 18/2000 loss 0.427501 acc 0.713226 lr 0.00036982 grad_norm 0.598018 rank 2
2025-01-10 08:17:41,097 DEBUG TRAIN Batch 18/2100 loss 0.521250 acc 0.694231 lr 0.00036932 grad_norm 0.598810 rank 1
2025-01-10 08:17:41,097 DEBUG TRAIN Batch 18/2100 loss 0.545651 acc 0.652004 lr 0.00036932 grad_norm 0.598810 rank 2
2025-01-10 08:17:41,097 DEBUG TRAIN Batch 18/2100 loss 0.567627 acc 0.655387 lr 0.00036932 grad_norm 0.598810 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 08:18:46,973 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 08:18:46,973 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 08:18:47,369 INFO Epoch 18 Step 18340 on_batch_end True CV rank 0
2025-01-10 08:18:47,370 INFO Epoch 18 Step 18340 on_batch_end True CV rank 1
2025-01-10 08:18:47,370 INFO Epoch 18 Step 18340 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 08:18:56,357 DEBUG CV Batch 18/100 loss 0.390656 acc 0.894091  rank 0
2025-01-10 08:18:56,722 DEBUG CV Batch 18/100 loss 0.390656 acc 0.894091  rank 2
2025-01-10 08:18:56,880 INFO Epoch 18 Step 18340 CV info lr 0.0003692073504303206 0 rank loss_1.4156456715835815 acc_0.6670532151403135
2025-01-10 08:18:56,908 DEBUG CV Batch 18/100 loss 0.390656 acc 0.894091  rank 1
2025-01-10 08:18:57,253 INFO Epoch 18 Step 18340 CV info lr 0.0003692073504303206 2 rank loss_1.4156456715835815 acc_0.6670532151403135
2025-01-10 08:18:57,430 INFO Epoch 18 Step 18340 CV info lr 0.0003692073504303206 1 rank loss_1.4156456715835815 acc_0.6670532151403135
2025-01-10 08:18:58,188 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_18_whole.pt
2025-01-10 08:18:58,209 INFO Added key: store_based_barrier_key:21 to store for rank: 0
2025-01-10 08:18:58,210 INFO Added key: store_based_barrier_key:21 to store for rank: 1
2025-01-10 08:18:58,210 INFO Added key: store_based_barrier_key:21 to store for rank: 2
2025-01-10 08:18:58,210 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:21 with 3 nodes.
2025-01-10 08:18:58,210 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:21 with 3 nodes.
2025-01-10 08:18:58,212 INFO Epoch 19 TRAIN info lr 0.0003692073504303206 rank 1
2025-01-10 08:18:58,212 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 08:18:58,219 INFO Epoch 19 TRAIN info lr 0.0003692073504303206 rank 2
2025-01-10 08:18:58,219 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 08:18:58,220 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:21 with 3 nodes.
2025-01-10 08:18:58,227 INFO Epoch 19 TRAIN info lr 0.0003692073504303206 rank 0
2025-01-10 08:18:58,227 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 08:19:28,939 DEBUG TRAIN Batch 19/100 loss 0.372998 acc 0.743976 lr 0.00036871 grad_norm 0.572934 rank 1
2025-01-10 08:19:28,939 DEBUG TRAIN Batch 19/100 loss 0.534281 acc 0.676418 lr 0.00036871 grad_norm 0.572934 rank 0
2025-01-10 08:19:28,940 DEBUG TRAIN Batch 19/100 loss 0.354376 acc 0.771072 lr 0.00036871 grad_norm 0.572934 rank 2
2025-01-10 08:19:52,728 DEBUG TRAIN Batch 19/200 loss 0.276371 acc 0.827097 lr 0.00036820 grad_norm 0.584239 rank 1
2025-01-10 08:19:52,728 DEBUG TRAIN Batch 19/200 loss 0.550688 acc 0.643470 lr 0.00036820 grad_norm 0.584239 rank 0
2025-01-10 08:19:52,728 DEBUG TRAIN Batch 19/200 loss 0.445455 acc 0.693954 lr 0.00036820 grad_norm 0.584239 rank 2
2025-01-10 08:20:16,416 DEBUG TRAIN Batch 19/300 loss 0.446084 acc 0.712621 lr 0.00036771 grad_norm 0.597885 rank 2
2025-01-10 08:20:16,417 DEBUG TRAIN Batch 19/300 loss 0.434316 acc 0.718421 lr 0.00036771 grad_norm 0.597885 rank 0
2025-01-10 08:20:16,417 DEBUG TRAIN Batch 19/300 loss 0.427543 acc 0.715686 lr 0.00036771 grad_norm 0.597885 rank 1
2025-01-10 08:20:40,124 DEBUG TRAIN Batch 19/400 loss 0.331469 acc 0.776900 lr 0.00036721 grad_norm 0.603294 rank 0
2025-01-10 08:20:40,125 DEBUG TRAIN Batch 19/400 loss 0.494474 acc 0.677083 lr 0.00036721 grad_norm 0.603294 rank 2
2025-01-10 08:20:40,125 DEBUG TRAIN Batch 19/400 loss 0.388841 acc 0.735955 lr 0.00036721 grad_norm 0.603294 rank 1
2025-01-10 08:21:04,444 DEBUG TRAIN Batch 19/500 loss 0.201535 acc 0.856459 lr 0.00036672 grad_norm 0.582360 rank 1
2025-01-10 08:21:04,444 DEBUG TRAIN Batch 19/500 loss 0.349772 acc 0.775225 lr 0.00036672 grad_norm 0.582360 rank 0
2025-01-10 08:21:04,445 DEBUG TRAIN Batch 19/500 loss 0.584007 acc 0.644307 lr 0.00036672 grad_norm 0.582360 rank 2
2025-01-10 08:21:27,804 DEBUG TRAIN Batch 19/600 loss 0.448777 acc 0.708768 lr 0.00036622 grad_norm 0.587719 rank 2
2025-01-10 08:21:27,804 DEBUG TRAIN Batch 19/600 loss 0.420524 acc 0.723592 lr 0.00036622 grad_norm 0.587719 rank 0
2025-01-10 08:21:27,804 DEBUG TRAIN Batch 19/600 loss 0.407794 acc 0.734300 lr 0.00036622 grad_norm 0.587719 rank 1
2025-01-10 08:21:51,941 DEBUG TRAIN Batch 19/700 loss 0.443286 acc 0.712366 lr 0.00036573 grad_norm 0.579615 rank 0
2025-01-10 08:21:51,941 DEBUG TRAIN Batch 19/700 loss 0.469393 acc 0.700631 lr 0.00036573 grad_norm 0.579615 rank 2
2025-01-10 08:21:51,941 DEBUG TRAIN Batch 19/700 loss 0.457106 acc 0.704137 lr 0.00036573 grad_norm 0.579615 rank 1
2025-01-10 08:22:15,792 DEBUG TRAIN Batch 19/800 loss 0.360037 acc 0.762675 lr 0.00036525 grad_norm 0.599909 rank 0
2025-01-10 08:22:15,793 DEBUG TRAIN Batch 19/800 loss 0.353492 acc 0.761261 lr 0.00036525 grad_norm 0.599909 rank 2
2025-01-10 08:22:15,793 DEBUG TRAIN Batch 19/800 loss 0.360217 acc 0.751840 lr 0.00036525 grad_norm 0.599909 rank 1
2025-01-10 08:22:39,613 DEBUG TRAIN Batch 19/900 loss 0.486942 acc 0.680600 lr 0.00036476 grad_norm 0.582742 rank 1
2025-01-10 08:22:39,613 DEBUG TRAIN Batch 19/900 loss 0.454148 acc 0.693839 lr 0.00036476 grad_norm 0.582742 rank 2
2025-01-10 08:22:39,614 DEBUG TRAIN Batch 19/900 loss 0.261202 acc 0.831650 lr 0.00036476 grad_norm 0.582742 rank 0
2025-01-10 08:23:03,816 DEBUG TRAIN Batch 19/1000 loss 0.560188 acc 0.631439 lr 0.00036428 grad_norm 0.590581 rank 2
2025-01-10 08:23:03,816 DEBUG TRAIN Batch 19/1000 loss 0.206640 acc 0.862374 lr 0.00036428 grad_norm 0.590581 rank 0
2025-01-10 08:23:03,816 DEBUG TRAIN Batch 19/1000 loss 0.532255 acc 0.665183 lr 0.00036428 grad_norm 0.590581 rank 1
2025-01-10 08:23:28,025 DEBUG TRAIN Batch 19/1100 loss 0.444538 acc 0.713144 lr 0.00036379 grad_norm 0.594467 rank 1
2025-01-10 08:23:28,026 DEBUG TRAIN Batch 19/1100 loss 0.306642 acc 0.808554 lr 0.00036379 grad_norm 0.594467 rank 0
2025-01-10 08:23:28,026 DEBUG TRAIN Batch 19/1100 loss 0.439548 acc 0.716899 lr 0.00036379 grad_norm 0.594467 rank 2
2025-01-10 08:23:52,771 DEBUG TRAIN Batch 19/1200 loss 0.235823 acc 0.831715 lr 0.00036331 grad_norm 0.620513 rank 0
2025-01-10 08:23:52,772 DEBUG TRAIN Batch 19/1200 loss 0.358666 acc 0.765690 lr 0.00036331 grad_norm 0.620513 rank 2
2025-01-10 08:23:52,772 DEBUG TRAIN Batch 19/1200 loss 0.328360 acc 0.780822 lr 0.00036331 grad_norm 0.620513 rank 1
2025-01-10 08:24:17,022 DEBUG TRAIN Batch 19/1300 loss 0.302164 acc 0.798665 lr 0.00036283 grad_norm 0.589376 rank 0
2025-01-10 08:24:17,022 DEBUG TRAIN Batch 19/1300 loss 0.475754 acc 0.681488 lr 0.00036283 grad_norm 0.589376 rank 1
2025-01-10 08:24:17,022 DEBUG TRAIN Batch 19/1300 loss 0.371078 acc 0.760194 lr 0.00036283 grad_norm 0.589376 rank 2
2025-01-10 08:24:41,311 DEBUG TRAIN Batch 19/1400 loss 0.354332 acc 0.746550 lr 0.00036236 grad_norm 0.598879 rank 1
2025-01-10 08:24:41,312 DEBUG TRAIN Batch 19/1400 loss 0.359373 acc 0.756614 lr 0.00036236 grad_norm 0.598879 rank 2
2025-01-10 08:24:41,313 DEBUG TRAIN Batch 19/1400 loss 0.296543 acc 0.810000 lr 0.00036236 grad_norm 0.598879 rank 0
2025-01-10 08:25:06,438 DEBUG TRAIN Batch 19/1500 loss 0.221387 acc 0.863787 lr 0.00036188 grad_norm 0.598931 rank 1
2025-01-10 08:25:06,439 DEBUG TRAIN Batch 19/1500 loss 0.315552 acc 0.790456 lr 0.00036188 grad_norm 0.598931 rank 0
2025-01-10 08:25:06,439 DEBUG TRAIN Batch 19/1500 loss 0.292030 acc 0.798122 lr 0.00036188 grad_norm 0.598931 rank 2
2025-01-10 08:25:31,203 DEBUG TRAIN Batch 19/1600 loss 0.574388 acc 0.625864 lr 0.00036141 grad_norm 0.597762 rank 1
2025-01-10 08:25:31,204 DEBUG TRAIN Batch 19/1600 loss 0.236854 acc 0.843014 lr 0.00036141 grad_norm 0.597762 rank 0
2025-01-10 08:25:31,204 DEBUG TRAIN Batch 19/1600 loss 0.606618 acc 0.606713 lr 0.00036141 grad_norm 0.597762 rank 2
2025-01-10 08:25:56,247 DEBUG TRAIN Batch 19/1700 loss 0.422825 acc 0.722986 lr 0.00036094 grad_norm 0.606181 rank 0
2025-01-10 08:25:56,247 DEBUG TRAIN Batch 19/1700 loss 0.635709 acc 0.600362 lr 0.00036094 grad_norm 0.606181 rank 2
2025-01-10 08:25:56,248 DEBUG TRAIN Batch 19/1700 loss 0.663344 acc 0.582386 lr 0.00036094 grad_norm 0.606181 rank 1
2025-01-10 08:26:20,758 DEBUG TRAIN Batch 19/1800 loss 0.412557 acc 0.728070 lr 0.00036047 grad_norm 0.614491 rank 0
2025-01-10 08:26:20,758 DEBUG TRAIN Batch 19/1800 loss 0.527654 acc 0.659660 lr 0.00036047 grad_norm 0.614491 rank 2
2025-01-10 08:26:20,759 DEBUG TRAIN Batch 19/1800 loss 0.539331 acc 0.666312 lr 0.00036047 grad_norm 0.614491 rank 1
2025-01-10 08:26:44,842 DEBUG TRAIN Batch 19/1900 loss 0.626743 acc 0.602410 lr 0.00036000 grad_norm 0.570868 rank 1
2025-01-10 08:26:44,842 DEBUG TRAIN Batch 19/1900 loss 0.499228 acc 0.676445 lr 0.00036000 grad_norm 0.570868 rank 0
2025-01-10 08:26:44,842 DEBUG TRAIN Batch 19/1900 loss 0.509771 acc 0.685466 lr 0.00036000 grad_norm 0.570868 rank 2
2025-01-10 08:27:09,734 DEBUG TRAIN Batch 19/2000 loss 0.358260 acc 0.752881 lr 0.00035954 grad_norm 0.604809 rank 2
2025-01-10 08:27:09,734 DEBUG TRAIN Batch 19/2000 loss 0.316001 acc 0.776233 lr 0.00035954 grad_norm 0.604809 rank 0
2025-01-10 08:27:09,734 DEBUG TRAIN Batch 19/2000 loss 0.629414 acc 0.594796 lr 0.00035954 grad_norm 0.604809 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 08:28:13,260 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 08:28:13,262 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59997ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 08:28:13,689 INFO Epoch 19 Step 19347 on_batch_end True CV rank 0
2025-01-10 08:28:13,689 INFO Epoch 19 Step 19347 on_batch_end True CV rank 1
2025-01-10 08:28:13,689 INFO Epoch 19 Step 19347 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 08:28:22,770 DEBUG CV Batch 19/100 loss 0.344927 acc 0.894091  rank 0
2025-01-10 08:28:23,053 DEBUG CV Batch 19/100 loss 0.344927 acc 0.894091  rank 2
2025-01-10 08:28:23,258 INFO Epoch 19 Step 19347 CV info lr 0.0003594704443508718 0 rank loss_1.415109203050011 acc_0.6859883271288454
2025-01-10 08:28:23,373 DEBUG CV Batch 19/100 loss 0.344927 acc 0.894091  rank 1
2025-01-10 08:28:23,584 INFO Epoch 19 Step 19347 CV info lr 0.0003594704443508718 2 rank loss_1.415109203050011 acc_0.6859883271288454
2025-01-10 08:28:23,933 INFO Epoch 19 Step 19347 CV info lr 0.0003594704443508718 1 rank loss_1.415109203050011 acc_0.6859883271288454
2025-01-10 08:28:24,558 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_19_whole.pt
2025-01-10 08:28:24,569 INFO Added key: store_based_barrier_key:22 to store for rank: 0
2025-01-10 08:28:24,580 INFO Added key: store_based_barrier_key:22 to store for rank: 2
2025-01-10 08:28:24,580 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:22 with 3 nodes.
2025-01-10 08:28:24,580 INFO Added key: store_based_barrier_key:22 to store for rank: 1
2025-01-10 08:28:24,580 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:22 with 3 nodes.
2025-01-10 08:28:24,586 INFO Epoch 20 TRAIN info lr 0.0003594704443508718 rank 1
2025-01-10 08:28:24,586 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 08:28:24,589 INFO Epoch 20 TRAIN info lr 0.0003594704443508718 rank 2
2025-01-10 08:28:24,589 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 08:28:24,590 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:22 with 3 nodes.
2025-01-10 08:28:24,590 INFO Epoch 20 TRAIN info lr 0.0003594704443508718 rank 0
2025-01-10 08:28:24,590 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 08:29:00,701 DEBUG TRAIN Batch 20/100 loss 0.266997 acc 0.816631 lr 0.00035901 grad_norm 0.578683 rank 1
2025-01-10 08:29:00,702 DEBUG TRAIN Batch 20/100 loss 0.241906 acc 0.849624 lr 0.00035901 grad_norm 0.578683 rank 0
2025-01-10 08:29:00,702 DEBUG TRAIN Batch 20/100 loss 0.383749 acc 0.737363 lr 0.00035901 grad_norm 0.578683 rank 2
2025-01-10 08:29:24,701 DEBUG TRAIN Batch 20/200 loss 0.303081 acc 0.788484 lr 0.00035855 grad_norm 0.583077 rank 2
2025-01-10 08:29:24,702 DEBUG TRAIN Batch 20/200 loss 0.201428 acc 0.858612 lr 0.00035855 grad_norm 0.583077 rank 1
2025-01-10 08:29:24,702 DEBUG TRAIN Batch 20/200 loss 0.402693 acc 0.736232 lr 0.00035855 grad_norm 0.583077 rank 0
2025-01-10 08:29:49,414 DEBUG TRAIN Batch 20/300 loss 0.247782 acc 0.826709 lr 0.00035808 grad_norm 0.592636 rank 2
2025-01-10 08:29:49,415 DEBUG TRAIN Batch 20/300 loss 0.349330 acc 0.743802 lr 0.00035808 grad_norm 0.592636 rank 1
2025-01-10 08:29:49,415 DEBUG TRAIN Batch 20/300 loss 0.189913 acc 0.885714 lr 0.00035808 grad_norm 0.592636 rank 0
2025-01-10 08:30:13,899 DEBUG TRAIN Batch 20/400 loss 0.241501 acc 0.834270 lr 0.00035763 grad_norm 0.587839 rank 0
2025-01-10 08:30:13,899 DEBUG TRAIN Batch 20/400 loss 0.284360 acc 0.813149 lr 0.00035763 grad_norm 0.587839 rank 1
2025-01-10 08:30:13,899 DEBUG TRAIN Batch 20/400 loss 0.416486 acc 0.720280 lr 0.00035763 grad_norm 0.587839 rank 2
2025-01-10 08:30:38,908 DEBUG TRAIN Batch 20/500 loss 0.431488 acc 0.709677 lr 0.00035717 grad_norm 0.594545 rank 2
2025-01-10 08:30:38,908 DEBUG TRAIN Batch 20/500 loss 0.475455 acc 0.670223 lr 0.00035717 grad_norm 0.594545 rank 1
2025-01-10 08:30:38,908 DEBUG TRAIN Batch 20/500 loss 0.278431 acc 0.824437 lr 0.00035717 grad_norm 0.594545 rank 0
2025-01-10 08:31:03,692 DEBUG TRAIN Batch 20/600 loss 0.382584 acc 0.734064 lr 0.00035672 grad_norm 0.583067 rank 2
2025-01-10 08:31:03,692 DEBUG TRAIN Batch 20/600 loss 0.285077 acc 0.809630 lr 0.00035672 grad_norm 0.583067 rank 0
2025-01-10 08:31:03,692 DEBUG TRAIN Batch 20/600 loss 0.468855 acc 0.687861 lr 0.00035672 grad_norm 0.583067 rank 1
2025-01-10 08:31:28,124 DEBUG TRAIN Batch 20/700 loss 0.275849 acc 0.814208 lr 0.00035626 grad_norm 0.604971 rank 2
2025-01-10 08:31:28,125 DEBUG TRAIN Batch 20/700 loss 0.514601 acc 0.682218 lr 0.00035626 grad_norm 0.604971 rank 1
2025-01-10 08:31:28,125 DEBUG TRAIN Batch 20/700 loss 0.387487 acc 0.756483 lr 0.00035626 grad_norm 0.604971 rank 0
2025-01-10 08:31:52,884 DEBUG TRAIN Batch 20/800 loss 0.446642 acc 0.721154 lr 0.00035581 grad_norm 0.615826 rank 0
2025-01-10 08:31:52,884 DEBUG TRAIN Batch 20/800 loss 0.378755 acc 0.752153 lr 0.00035581 grad_norm 0.615826 rank 2
2025-01-10 08:31:52,885 DEBUG TRAIN Batch 20/800 loss 0.461013 acc 0.701413 lr 0.00035581 grad_norm 0.615826 rank 1
2025-01-10 08:32:17,078 DEBUG TRAIN Batch 20/900 loss 0.483407 acc 0.691696 lr 0.00035536 grad_norm 0.601416 rank 1
2025-01-10 08:32:17,079 DEBUG TRAIN Batch 20/900 loss 0.204647 acc 0.857367 lr 0.00035536 grad_norm 0.601416 rank 0
2025-01-10 08:32:17,079 DEBUG TRAIN Batch 20/900 loss 0.305826 acc 0.786935 lr 0.00035536 grad_norm 0.601416 rank 2
2025-01-10 08:32:41,169 DEBUG TRAIN Batch 20/1000 loss 0.393485 acc 0.734715 lr 0.00035491 grad_norm 0.606829 rank 2
2025-01-10 08:32:41,169 DEBUG TRAIN Batch 20/1000 loss 0.253014 acc 0.825789 lr 0.00035491 grad_norm 0.606829 rank 0
2025-01-10 08:32:41,169 DEBUG TRAIN Batch 20/1000 loss 0.393917 acc 0.727357 lr 0.00035491 grad_norm 0.606829 rank 1
2025-01-10 08:33:06,405 DEBUG TRAIN Batch 20/1100 loss 0.436516 acc 0.737374 lr 0.00035447 grad_norm 0.613190 rank 0
2025-01-10 08:33:06,405 DEBUG TRAIN Batch 20/1100 loss 0.349747 acc 0.754696 lr 0.00035447 grad_norm 0.613190 rank 2
2025-01-10 08:33:06,405 DEBUG TRAIN Batch 20/1100 loss 0.396480 acc 0.724664 lr 0.00035447 grad_norm 0.613190 rank 1
2025-01-10 08:33:30,336 DEBUG TRAIN Batch 20/1200 loss 0.356093 acc 0.758333 lr 0.00035402 grad_norm 0.609980 rank 0
2025-01-10 08:33:30,336 DEBUG TRAIN Batch 20/1200 loss 0.524654 acc 0.667647 lr 0.00035402 grad_norm 0.609980 rank 2
2025-01-10 08:33:30,339 DEBUG TRAIN Batch 20/1200 loss 0.302461 acc 0.792757 lr 0.00035402 grad_norm 0.609980 rank 1
2025-01-10 08:33:53,802 DEBUG TRAIN Batch 20/1300 loss 0.441177 acc 0.706767 lr 0.00035358 grad_norm 0.611753 rank 2
2025-01-10 08:33:53,802 DEBUG TRAIN Batch 20/1300 loss 0.385181 acc 0.748891 lr 0.00035358 grad_norm 0.611753 rank 0
2025-01-10 08:33:53,803 DEBUG TRAIN Batch 20/1300 loss 0.379961 acc 0.742802 lr 0.00035358 grad_norm 0.611753 rank 1
2025-01-10 08:34:18,221 DEBUG TRAIN Batch 20/1400 loss 0.403194 acc 0.743470 lr 0.00035314 grad_norm 0.624387 rank 0
2025-01-10 08:34:18,221 DEBUG TRAIN Batch 20/1400 loss 0.572688 acc 0.632379 lr 0.00035314 grad_norm 0.624387 rank 1
2025-01-10 08:34:18,221 DEBUG TRAIN Batch 20/1400 loss 0.162807 acc 0.883959 lr 0.00035314 grad_norm 0.624387 rank 2
2025-01-10 08:34:41,493 DEBUG TRAIN Batch 20/1500 loss 0.412963 acc 0.745098 lr 0.00035270 grad_norm 0.618766 rank 0
2025-01-10 08:34:41,493 DEBUG TRAIN Batch 20/1500 loss 0.436229 acc 0.697436 lr 0.00035270 grad_norm 0.618766 rank 2
2025-01-10 08:34:41,493 DEBUG TRAIN Batch 20/1500 loss 0.552453 acc 0.643059 lr 0.00035270 grad_norm 0.618766 rank 1
2025-01-10 08:35:05,662 DEBUG TRAIN Batch 20/1600 loss 0.335101 acc 0.770202 lr 0.00035226 grad_norm 0.615343 rank 2
2025-01-10 08:35:05,662 DEBUG TRAIN Batch 20/1600 loss 0.423675 acc 0.703971 lr 0.00035226 grad_norm 0.615343 rank 0
2025-01-10 08:35:05,663 DEBUG TRAIN Batch 20/1600 loss 0.345117 acc 0.751142 lr 0.00035226 grad_norm 0.615343 rank 1
2025-01-10 08:35:29,236 DEBUG TRAIN Batch 20/1700 loss 0.384643 acc 0.754386 lr 0.00035182 grad_norm 0.597486 rank 0
2025-01-10 08:35:29,237 DEBUG TRAIN Batch 20/1700 loss 0.424646 acc 0.732535 lr 0.00035182 grad_norm 0.597486 rank 2
2025-01-10 08:35:29,237 DEBUG TRAIN Batch 20/1700 loss 0.364452 acc 0.762231 lr 0.00035182 grad_norm 0.597486 rank 1
2025-01-10 08:35:52,544 DEBUG TRAIN Batch 20/1800 loss 0.463019 acc 0.685433 lr 0.00035139 grad_norm 0.612025 rank 2
2025-01-10 08:35:52,544 DEBUG TRAIN Batch 20/1800 loss 0.456811 acc 0.708895 lr 0.00035139 grad_norm 0.612025 rank 0
2025-01-10 08:35:52,544 DEBUG TRAIN Batch 20/1800 loss 0.480738 acc 0.684919 lr 0.00035139 grad_norm 0.612025 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 08:37:05,281 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 08:37:05,285 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 08:37:05,706 INFO Epoch 20 Step 20274 on_batch_end True CV rank 1
2025-01-10 08:37:05,706 INFO Epoch 20 Step 20274 on_batch_end True CV rank 0
2025-01-10 08:37:05,706 INFO Epoch 20 Step 20274 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 08:37:14,760 DEBUG CV Batch 20/100 loss 0.272685 acc 0.928651  rank 0
2025-01-10 08:37:14,951 DEBUG CV Batch 20/100 loss 0.272685 acc 0.928651  rank 2
2025-01-10 08:37:15,202 DEBUG CV Batch 20/100 loss 0.272685 acc 0.928651  rank 1
2025-01-10 08:37:15,236 INFO Epoch 20 Step 20274 CV info lr 0.00035115615354825434 0 rank loss_1.4527259893846094 acc_0.7038981063585532
2025-01-10 08:37:15,477 INFO Epoch 20 Step 20274 CV info lr 0.00035115615354825434 2 rank loss_1.4527259893846094 acc_0.7038981063585532
2025-01-10 08:37:15,700 INFO Epoch 20 Step 20274 CV info lr 0.00035115615354825434 1 rank loss_1.4527259893846094 acc_0.7038981063585532
2025-01-10 08:37:16,503 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_20_whole.pt
2025-01-10 08:37:16,514 INFO Added key: store_based_barrier_key:23 to store for rank: 0
2025-01-10 08:37:16,525 INFO Added key: store_based_barrier_key:23 to store for rank: 2
2025-01-10 08:37:16,525 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:23 with 3 nodes.
2025-01-10 08:37:16,525 INFO Added key: store_based_barrier_key:23 to store for rank: 1
2025-01-10 08:37:16,525 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:23 with 3 nodes.
2025-01-10 08:37:16,529 INFO Epoch 21 TRAIN info lr 0.00035115615354825434 rank 2
2025-01-10 08:37:16,529 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 08:37:16,535 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:23 with 3 nodes.
2025-01-10 08:37:16,535 INFO Epoch 21 TRAIN info lr 0.00035115615354825434 rank 1
2025-01-10 08:37:16,535 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 08:37:16,538 INFO Epoch 21 TRAIN info lr 0.00035115615354825434 rank 0
2025-01-10 08:37:16,539 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 08:37:47,643 DEBUG TRAIN Batch 21/100 loss 0.331614 acc 0.781690 lr 0.00035072 grad_norm 0.562761 rank 1
2025-01-10 08:37:47,644 DEBUG TRAIN Batch 21/100 loss 0.278066 acc 0.821881 lr 0.00035072 grad_norm 0.562761 rank 0
2025-01-10 08:37:47,644 DEBUG TRAIN Batch 21/100 loss 0.293320 acc 0.797160 lr 0.00035072 grad_norm 0.562761 rank 2
2025-01-10 08:38:11,591 DEBUG TRAIN Batch 21/200 loss 0.270832 acc 0.819394 lr 0.00035029 grad_norm 0.604335 rank 1
2025-01-10 08:38:11,592 DEBUG TRAIN Batch 21/200 loss 0.299703 acc 0.784899 lr 0.00035029 grad_norm 0.604335 rank 2
2025-01-10 08:38:11,592 DEBUG TRAIN Batch 21/200 loss 0.274733 acc 0.814118 lr 0.00035029 grad_norm 0.604335 rank 0
2025-01-10 08:38:35,533 DEBUG TRAIN Batch 21/300 loss 0.345712 acc 0.759036 lr 0.00034986 grad_norm 0.588995 rank 1
2025-01-10 08:38:35,533 DEBUG TRAIN Batch 21/300 loss 0.377274 acc 0.760949 lr 0.00034986 grad_norm 0.588995 rank 0
2025-01-10 08:38:35,533 DEBUG TRAIN Batch 21/300 loss 0.325632 acc 0.775549 lr 0.00034986 grad_norm 0.588995 rank 2
2025-01-10 08:38:59,261 DEBUG TRAIN Batch 21/400 loss 0.305300 acc 0.794737 lr 0.00034944 grad_norm 0.604834 rank 0
2025-01-10 08:38:59,262 DEBUG TRAIN Batch 21/400 loss 0.297847 acc 0.798645 lr 0.00034944 grad_norm 0.604834 rank 1
2025-01-10 08:38:59,262 DEBUG TRAIN Batch 21/400 loss 0.280877 acc 0.804878 lr 0.00034944 grad_norm 0.604834 rank 2
2025-01-10 08:39:23,842 DEBUG TRAIN Batch 21/500 loss 0.194200 acc 0.879159 lr 0.00034901 grad_norm 0.596062 rank 2
2025-01-10 08:39:23,843 DEBUG TRAIN Batch 21/500 loss 0.546567 acc 0.635616 lr 0.00034901 grad_norm 0.596062 rank 0
2025-01-10 08:39:23,843 DEBUG TRAIN Batch 21/500 loss 0.424131 acc 0.713504 lr 0.00034901 grad_norm 0.596062 rank 1
2025-01-10 08:39:48,027 DEBUG TRAIN Batch 21/600 loss 0.530304 acc 0.666667 lr 0.00034859 grad_norm 0.593998 rank 0
2025-01-10 08:39:48,027 DEBUG TRAIN Batch 21/600 loss 0.364829 acc 0.761165 lr 0.00034859 grad_norm 0.593998 rank 1
2025-01-10 08:39:48,027 DEBUG TRAIN Batch 21/600 loss 0.400841 acc 0.727561 lr 0.00034859 grad_norm 0.593998 rank 2
2025-01-10 08:40:12,162 DEBUG TRAIN Batch 21/700 loss 0.530008 acc 0.641359 lr 0.00034816 grad_norm 0.657011 rank 0
2025-01-10 08:40:12,163 DEBUG TRAIN Batch 21/700 loss 0.318344 acc 0.800766 lr 0.00034816 grad_norm 0.657011 rank 2
2025-01-10 08:40:12,163 DEBUG TRAIN Batch 21/700 loss 0.486970 acc 0.686895 lr 0.00034816 grad_norm 0.657011 rank 1
2025-01-10 08:40:36,981 DEBUG TRAIN Batch 21/800 loss 0.473374 acc 0.692748 lr 0.00034774 grad_norm 0.631840 rank 2
2025-01-10 08:40:36,982 DEBUG TRAIN Batch 21/800 loss 0.343461 acc 0.762615 lr 0.00034774 grad_norm 0.631840 rank 1
2025-01-10 08:40:36,982 DEBUG TRAIN Batch 21/800 loss 0.457934 acc 0.717503 lr 0.00034774 grad_norm 0.631840 rank 0
2025-01-10 08:41:02,229 DEBUG TRAIN Batch 21/900 loss 0.429253 acc 0.719617 lr 0.00034732 grad_norm 0.595394 rank 1
2025-01-10 08:41:02,229 DEBUG TRAIN Batch 21/900 loss 0.302067 acc 0.798202 lr 0.00034732 grad_norm 0.595394 rank 0
2025-01-10 08:41:02,230 DEBUG TRAIN Batch 21/900 loss 0.419789 acc 0.718057 lr 0.00034732 grad_norm 0.595394 rank 2
2025-01-10 08:41:26,297 DEBUG TRAIN Batch 21/1000 loss 0.229101 acc 0.845475 lr 0.00034690 grad_norm 0.587259 rank 0
2025-01-10 08:41:26,298 DEBUG TRAIN Batch 21/1000 loss 0.433470 acc 0.715111 lr 0.00034690 grad_norm 0.587259 rank 1
2025-01-10 08:41:26,298 DEBUG TRAIN Batch 21/1000 loss 0.452851 acc 0.692754 lr 0.00034690 grad_norm 0.587259 rank 2
2025-01-10 08:41:51,222 DEBUG TRAIN Batch 21/1100 loss 0.347770 acc 0.764637 lr 0.00034649 grad_norm 0.573322 rank 1
2025-01-10 08:41:51,222 DEBUG TRAIN Batch 21/1100 loss 0.453290 acc 0.710988 lr 0.00034649 grad_norm 0.573322 rank 2
2025-01-10 08:41:51,223 DEBUG TRAIN Batch 21/1100 loss 0.302884 acc 0.786854 lr 0.00034649 grad_norm 0.573322 rank 0
2025-01-10 08:42:15,830 DEBUG TRAIN Batch 21/1200 loss 0.439736 acc 0.701547 lr 0.00034607 grad_norm 0.630428 rank 1
2025-01-10 08:42:15,830 DEBUG TRAIN Batch 21/1200 loss 0.470035 acc 0.711538 lr 0.00034607 grad_norm 0.630428 rank 2
2025-01-10 08:42:15,831 DEBUG TRAIN Batch 21/1200 loss 0.266498 acc 0.814286 lr 0.00034607 grad_norm 0.630428 rank 0
2025-01-10 08:42:39,925 DEBUG TRAIN Batch 21/1300 loss 0.406005 acc 0.723005 lr 0.00034566 grad_norm 0.594002 rank 1
2025-01-10 08:42:39,925 DEBUG TRAIN Batch 21/1300 loss 0.381953 acc 0.747623 lr 0.00034566 grad_norm 0.594002 rank 0
2025-01-10 08:42:39,925 DEBUG TRAIN Batch 21/1300 loss 0.390561 acc 0.745941 lr 0.00034566 grad_norm 0.594002 rank 2
2025-01-10 08:43:05,127 DEBUG TRAIN Batch 21/1400 loss 0.442861 acc 0.703936 lr 0.00034525 grad_norm 0.594408 rank 0
2025-01-10 08:43:05,128 DEBUG TRAIN Batch 21/1400 loss 0.396509 acc 0.740566 lr 0.00034525 grad_norm 0.594408 rank 2
2025-01-10 08:43:05,128 DEBUG TRAIN Batch 21/1400 loss 0.343781 acc 0.768486 lr 0.00034525 grad_norm 0.594408 rank 1
2025-01-10 08:43:29,102 DEBUG TRAIN Batch 21/1500 loss 0.392520 acc 0.744144 lr 0.00034484 grad_norm 0.599127 rank 0
2025-01-10 08:43:29,102 DEBUG TRAIN Batch 21/1500 loss 0.383702 acc 0.735622 lr 0.00034484 grad_norm 0.599127 rank 2
2025-01-10 08:43:29,102 DEBUG TRAIN Batch 21/1500 loss 0.350986 acc 0.767593 lr 0.00034484 grad_norm 0.599127 rank 1
2025-01-10 08:43:53,073 DEBUG TRAIN Batch 21/1600 loss 0.445565 acc 0.717636 lr 0.00034443 grad_norm 0.608929 rank 0
2025-01-10 08:43:53,073 DEBUG TRAIN Batch 21/1600 loss 0.357651 acc 0.769070 lr 0.00034443 grad_norm 0.608929 rank 2
2025-01-10 08:43:53,073 DEBUG TRAIN Batch 21/1600 loss 0.429078 acc 0.723206 lr 0.00034443 grad_norm 0.608929 rank 1
2025-01-10 08:44:17,182 DEBUG TRAIN Batch 21/1700 loss 0.267436 acc 0.827456 lr 0.00034402 grad_norm 0.616238 rank 2
2025-01-10 08:44:17,182 DEBUG TRAIN Batch 21/1700 loss 0.507914 acc 0.688288 lr 0.00034402 grad_norm 0.616238 rank 0
2025-01-10 08:44:17,182 DEBUG TRAIN Batch 21/1700 loss 0.441267 acc 0.711728 lr 0.00034402 grad_norm 0.616238 rank 1
2025-01-10 08:44:42,537 DEBUG TRAIN Batch 21/1800 loss 0.377253 acc 0.743063 lr 0.00034361 grad_norm 0.657776 rank 2
2025-01-10 08:44:42,537 DEBUG TRAIN Batch 21/1800 loss 0.488578 acc 0.681377 lr 0.00034361 grad_norm 0.657776 rank 0
2025-01-10 08:44:42,537 DEBUG TRAIN Batch 21/1800 loss 0.519743 acc 0.645627 lr 0.00034361 grad_norm 0.657776 rank 1
2025-01-10 08:45:06,225 DEBUG TRAIN Batch 21/1900 loss 0.418453 acc 0.722674 lr 0.00034321 grad_norm 0.638210 rank 2
2025-01-10 08:45:06,226 DEBUG TRAIN Batch 21/1900 loss 0.459418 acc 0.694190 lr 0.00034321 grad_norm 0.638210 rank 0
2025-01-10 08:45:06,226 DEBUG TRAIN Batch 21/1900 loss 0.372300 acc 0.757231 lr 0.00034321 grad_norm 0.638210 rank 1
2025-01-10 08:45:29,878 DEBUG TRAIN Batch 21/2000 loss 0.383743 acc 0.734000 lr 0.00034280 grad_norm 0.633793 rank 0
2025-01-10 08:45:29,878 DEBUG TRAIN Batch 21/2000 loss 0.320860 acc 0.794798 lr 0.00034280 grad_norm 0.633793 rank 1
2025-01-10 08:45:29,878 DEBUG TRAIN Batch 21/2000 loss 0.438864 acc 0.706667 lr 0.00034280 grad_norm 0.633793 rank 2
2025-01-10 08:45:54,368 DEBUG TRAIN Batch 21/2100 loss 0.418704 acc 0.736127 lr 0.00034240 grad_norm 0.661317 rank 0
2025-01-10 08:45:54,369 DEBUG TRAIN Batch 21/2100 loss 0.412608 acc 0.726708 lr 0.00034240 grad_norm 0.661317 rank 1
2025-01-10 08:45:54,369 DEBUG TRAIN Batch 21/2100 loss 0.383963 acc 0.742438 lr 0.00034240 grad_norm 0.661317 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 08:47:04,958 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 08:47:04,964 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 08:47:05,357 INFO Epoch 21 Step 21346 on_batch_end True CV rank 2
2025-01-10 08:47:05,357 INFO Epoch 21 Step 21346 on_batch_end True CV rank 0
2025-01-10 08:47:05,357 INFO Epoch 21 Step 21346 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 08:47:14,333 DEBUG CV Batch 21/100 loss 0.254913 acc 0.925307  rank 0
2025-01-10 08:47:14,590 DEBUG CV Batch 21/100 loss 0.254913 acc 0.925307  rank 2
2025-01-10 08:47:14,872 INFO Epoch 21 Step 21346 CV info lr 0.0003422250154657477 0 rank loss_1.423364198194784 acc_0.7101443771991813
2025-01-10 08:47:15,123 INFO Epoch 21 Step 21346 CV info lr 0.0003422250154657477 2 rank loss_1.423364198194784 acc_0.7101443771991813
2025-01-10 08:47:15,376 DEBUG CV Batch 21/100 loss 0.254913 acc 0.925307  rank 1
2025-01-10 08:47:15,930 INFO Epoch 21 Step 21346 CV info lr 0.0003422250154657477 1 rank loss_1.423364198194784 acc_0.7101443771991813
2025-01-10 08:47:16,166 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_21_whole.pt
2025-01-10 08:47:16,187 INFO Added key: store_based_barrier_key:24 to store for rank: 0
2025-01-10 08:47:16,198 INFO Added key: store_based_barrier_key:24 to store for rank: 2
2025-01-10 08:47:16,198 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:24 with 3 nodes.
2025-01-10 08:47:16,198 INFO Added key: store_based_barrier_key:24 to store for rank: 1
2025-01-10 08:47:16,198 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:24 with 3 nodes.
2025-01-10 08:47:16,201 INFO Epoch 22 TRAIN info lr 0.0003422250154657477 rank 1
2025-01-10 08:47:16,201 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 08:47:16,202 INFO Epoch 22 TRAIN info lr 0.0003422250154657477 rank 2
2025-01-10 08:47:16,202 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 08:47:16,208 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:24 with 3 nodes.
2025-01-10 08:47:16,214 INFO Epoch 22 TRAIN info lr 0.0003422250154657477 rank 0
2025-01-10 08:47:16,214 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 08:47:46,200 DEBUG TRAIN Batch 22/100 loss 0.298853 acc 0.803442 lr 0.00034182 grad_norm 0.576054 rank 1
2025-01-10 08:47:46,201 DEBUG TRAIN Batch 22/100 loss 0.312719 acc 0.784631 lr 0.00034182 grad_norm 0.576054 rank 0
2025-01-10 08:47:46,201 DEBUG TRAIN Batch 22/100 loss 0.333820 acc 0.765118 lr 0.00034182 grad_norm 0.576054 rank 2
2025-01-10 08:48:09,834 DEBUG TRAIN Batch 22/200 loss 0.327207 acc 0.785055 lr 0.00034143 grad_norm 0.596061 rank 0
2025-01-10 08:48:09,834 DEBUG TRAIN Batch 22/200 loss 0.335417 acc 0.762896 lr 0.00034143 grad_norm 0.596061 rank 1
2025-01-10 08:48:09,834 DEBUG TRAIN Batch 22/200 loss 0.247500 acc 0.819594 lr 0.00034143 grad_norm 0.596061 rank 2
2025-01-10 08:48:33,200 DEBUG TRAIN Batch 22/300 loss 0.310895 acc 0.788610 lr 0.00034103 grad_norm 0.591833 rank 1
2025-01-10 08:48:33,201 DEBUG TRAIN Batch 22/300 loss 0.339814 acc 0.769517 lr 0.00034103 grad_norm 0.591833 rank 0
2025-01-10 08:48:33,201 DEBUG TRAIN Batch 22/300 loss 0.328004 acc 0.765977 lr 0.00034103 grad_norm 0.591833 rank 2
2025-01-10 08:48:57,059 DEBUG TRAIN Batch 22/400 loss 0.217974 acc 0.851190 lr 0.00034063 grad_norm 0.578008 rank 1
2025-01-10 08:48:57,059 DEBUG TRAIN Batch 22/400 loss 0.306355 acc 0.802686 lr 0.00034063 grad_norm 0.578008 rank 0
2025-01-10 08:48:57,059 DEBUG TRAIN Batch 22/400 loss 0.321270 acc 0.785905 lr 0.00034063 grad_norm 0.578008 rank 2
2025-01-10 08:49:20,906 DEBUG TRAIN Batch 22/500 loss 0.294942 acc 0.801595 lr 0.00034024 grad_norm 0.584991 rank 0
2025-01-10 08:49:20,906 DEBUG TRAIN Batch 22/500 loss 0.389850 acc 0.738053 lr 0.00034024 grad_norm 0.584991 rank 1
2025-01-10 08:49:20,906 DEBUG TRAIN Batch 22/500 loss 0.254575 acc 0.819857 lr 0.00034024 grad_norm 0.584991 rank 2
2025-01-10 08:49:45,433 DEBUG TRAIN Batch 22/600 loss 0.275530 acc 0.810559 lr 0.00033985 grad_norm 0.631975 rank 1
2025-01-10 08:49:45,433 DEBUG TRAIN Batch 22/600 loss 0.287973 acc 0.806452 lr 0.00033985 grad_norm 0.631975 rank 0
2025-01-10 08:49:45,434 DEBUG TRAIN Batch 22/600 loss 0.209504 acc 0.862374 lr 0.00033985 grad_norm 0.631975 rank 2
2025-01-10 08:50:10,528 DEBUG TRAIN Batch 22/700 loss 0.314099 acc 0.786885 lr 0.00033945 grad_norm 0.575707 rank 2
2025-01-10 08:50:10,529 DEBUG TRAIN Batch 22/700 loss 0.432173 acc 0.705234 lr 0.00033945 grad_norm 0.575707 rank 0
2025-01-10 08:50:10,529 DEBUG TRAIN Batch 22/700 loss 0.381366 acc 0.753982 lr 0.00033945 grad_norm 0.575707 rank 1
2025-01-10 08:50:35,089 DEBUG TRAIN Batch 22/800 loss 0.273873 acc 0.812777 lr 0.00033906 grad_norm 0.579373 rank 2
2025-01-10 08:50:35,090 DEBUG TRAIN Batch 22/800 loss 0.427243 acc 0.715069 lr 0.00033906 grad_norm 0.579373 rank 0
2025-01-10 08:50:35,090 DEBUG TRAIN Batch 22/800 loss 0.398413 acc 0.736253 lr 0.00033906 grad_norm 0.579373 rank 1
2025-01-10 08:50:59,914 DEBUG TRAIN Batch 22/900 loss 0.452029 acc 0.712378 lr 0.00033867 grad_norm 0.615855 rank 1
2025-01-10 08:50:59,914 DEBUG TRAIN Batch 22/900 loss 0.202601 acc 0.853222 lr 0.00033867 grad_norm 0.615855 rank 2
2025-01-10 08:50:59,914 DEBUG TRAIN Batch 22/900 loss 0.436902 acc 0.718371 lr 0.00033867 grad_norm 0.615855 rank 0
2025-01-10 08:51:25,327 DEBUG TRAIN Batch 22/1000 loss 0.366707 acc 0.774164 lr 0.00033829 grad_norm 0.595385 rank 2
2025-01-10 08:51:25,327 DEBUG TRAIN Batch 22/1000 loss 0.333868 acc 0.761270 lr 0.00033829 grad_norm 0.595385 rank 1
2025-01-10 08:51:25,327 DEBUG TRAIN Batch 22/1000 loss 0.386327 acc 0.740670 lr 0.00033829 grad_norm 0.595385 rank 0
2025-01-10 08:51:50,962 DEBUG TRAIN Batch 22/1100 loss 0.333121 acc 0.778186 lr 0.00033790 grad_norm 0.602607 rank 0
2025-01-10 08:51:50,962 DEBUG TRAIN Batch 22/1100 loss 0.284672 acc 0.800931 lr 0.00033790 grad_norm 0.602607 rank 1
2025-01-10 08:51:50,963 DEBUG TRAIN Batch 22/1100 loss 0.164586 acc 0.891200 lr 0.00033790 grad_norm 0.602607 rank 2
2025-01-10 08:52:15,856 DEBUG TRAIN Batch 22/1200 loss 0.474953 acc 0.689036 lr 0.00033751 grad_norm 0.609466 rank 0
2025-01-10 08:52:15,856 DEBUG TRAIN Batch 22/1200 loss 0.211661 acc 0.858345 lr 0.00033751 grad_norm 0.609466 rank 2
2025-01-10 08:52:15,856 DEBUG TRAIN Batch 22/1200 loss 0.360458 acc 0.765374 lr 0.00033751 grad_norm 0.609466 rank 1
2025-01-10 08:52:40,560 DEBUG TRAIN Batch 22/1300 loss 0.386982 acc 0.748227 lr 0.00033713 grad_norm 0.647018 rank 1
2025-01-10 08:52:40,560 DEBUG TRAIN Batch 22/1300 loss 0.328346 acc 0.788166 lr 0.00033713 grad_norm 0.647018 rank 2
2025-01-10 08:52:40,561 DEBUG TRAIN Batch 22/1300 loss 0.407758 acc 0.741273 lr 0.00033713 grad_norm 0.647018 rank 0
2025-01-10 08:53:05,640 DEBUG TRAIN Batch 22/1400 loss 0.365036 acc 0.749747 lr 0.00033675 grad_norm 0.634325 rank 1
2025-01-10 08:53:05,640 DEBUG TRAIN Batch 22/1400 loss 0.274034 acc 0.811530 lr 0.00033675 grad_norm 0.634325 rank 2
2025-01-10 08:53:05,640 DEBUG TRAIN Batch 22/1400 loss 0.497702 acc 0.680075 lr 0.00033675 grad_norm 0.634325 rank 0
2025-01-10 08:53:29,249 DEBUG TRAIN Batch 22/1500 loss 0.252543 acc 0.819383 lr 0.00033637 grad_norm 0.611951 rank 2
2025-01-10 08:53:29,250 DEBUG TRAIN Batch 22/1500 loss 0.409868 acc 0.714447 lr 0.00033637 grad_norm 0.611951 rank 0
2025-01-10 08:53:29,250 DEBUG TRAIN Batch 22/1500 loss 0.283928 acc 0.831050 lr 0.00033637 grad_norm 0.611951 rank 1
2025-01-10 08:53:54,499 DEBUG TRAIN Batch 22/1600 loss 0.378666 acc 0.750000 lr 0.00033599 grad_norm 0.598021 rank 2
2025-01-10 08:53:54,500 DEBUG TRAIN Batch 22/1600 loss 0.413233 acc 0.736337 lr 0.00033599 grad_norm 0.598021 rank 0
2025-01-10 08:53:54,500 DEBUG TRAIN Batch 22/1600 loss 0.368148 acc 0.736196 lr 0.00033599 grad_norm 0.598021 rank 1
2025-01-10 08:54:18,316 DEBUG TRAIN Batch 22/1700 loss 0.436118 acc 0.715412 lr 0.00033561 grad_norm 0.615444 rank 1
2025-01-10 08:54:18,317 DEBUG TRAIN Batch 22/1700 loss 0.387430 acc 0.740165 lr 0.00033561 grad_norm 0.615444 rank 0
2025-01-10 08:54:18,317 DEBUG TRAIN Batch 22/1700 loss 0.178576 acc 0.874622 lr 0.00033561 grad_norm 0.615444 rank 2
2025-01-10 08:54:42,761 DEBUG TRAIN Batch 22/1800 loss 0.367326 acc 0.762311 lr 0.00033523 grad_norm 0.625409 rank 1
2025-01-10 08:54:42,761 DEBUG TRAIN Batch 22/1800 loss 0.255407 acc 0.825971 lr 0.00033523 grad_norm 0.625409 rank 2
2025-01-10 08:54:42,761 DEBUG TRAIN Batch 22/1800 loss 0.456891 acc 0.726326 lr 0.00033523 grad_norm 0.625409 rank 0
2025-01-10 08:55:08,190 DEBUG TRAIN Batch 22/1900 loss 0.498062 acc 0.684729 lr 0.00033485 grad_norm 0.610763 rank 2
2025-01-10 08:55:08,190 DEBUG TRAIN Batch 22/1900 loss 0.204328 acc 0.868974 lr 0.00033485 grad_norm 0.610763 rank 1
2025-01-10 08:55:08,190 DEBUG TRAIN Batch 22/1900 loss 0.436158 acc 0.716486 lr 0.00033485 grad_norm 0.610763 rank 0
2025-01-10 08:55:32,144 DEBUG TRAIN Batch 22/2000 loss 0.442827 acc 0.708455 lr 0.00033448 grad_norm 0.625201 rank 2
2025-01-10 08:55:32,144 DEBUG TRAIN Batch 22/2000 loss 0.297406 acc 0.796460 lr 0.00033448 grad_norm 0.625201 rank 1
2025-01-10 08:55:32,145 DEBUG TRAIN Batch 22/2000 loss 0.390262 acc 0.733207 lr 0.00033448 grad_norm 0.625201 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 08:56:36,707 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 08:56:36,750 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 08:56:37,184 INFO Epoch 22 Step 22355 on_batch_end True CV rank 0
2025-01-10 08:56:37,184 INFO Epoch 22 Step 22355 on_batch_end True CV rank 2
2025-01-10 08:56:37,184 INFO Epoch 22 Step 22355 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 08:56:46,432 DEBUG CV Batch 22/100 loss 0.287195 acc 0.913043  rank 0
2025-01-10 08:56:46,682 DEBUG CV Batch 22/100 loss 0.287195 acc 0.913043  rank 2
2025-01-10 08:56:46,933 INFO Epoch 22 Step 22355 CV info lr 0.00033441262680307415 0 rank loss_1.4224681447080352 acc_0.7123465862190514
2025-01-10 08:56:47,192 INFO Epoch 22 Step 22355 CV info lr 0.00033441262680307415 2 rank loss_1.4224681447080352 acc_0.7123465862190514
2025-01-10 08:56:47,377 DEBUG CV Batch 22/100 loss 0.287195 acc 0.913043  rank 1
2025-01-10 08:56:47,918 INFO Epoch 22 Step 22355 CV info lr 0.00033441262680307415 1 rank loss_1.4224681447080352 acc_0.7123465862190514
2025-01-10 08:56:48,237 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_22_whole.pt
2025-01-10 08:56:48,258 INFO Added key: store_based_barrier_key:25 to store for rank: 0
2025-01-10 08:56:48,269 INFO Added key: store_based_barrier_key:25 to store for rank: 2
2025-01-10 08:56:48,269 INFO Added key: store_based_barrier_key:25 to store for rank: 1
2025-01-10 08:56:48,269 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:25 with 3 nodes.
2025-01-10 08:56:48,269 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:25 with 3 nodes.
2025-01-10 08:56:48,269 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:25 with 3 nodes.
2025-01-10 08:56:48,270 INFO Epoch 23 TRAIN info lr 0.00033441262680307415 rank 0
2025-01-10 08:56:48,270 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 08:56:48,272 INFO Epoch 23 TRAIN info lr 0.00033441262680307415 rank 1
2025-01-10 08:56:48,272 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 08:56:48,277 INFO Epoch 23 TRAIN info lr 0.00033441262680307415 rank 2
2025-01-10 08:56:48,277 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 08:57:25,661 DEBUG TRAIN Batch 23/100 loss 0.355695 acc 0.771898 lr 0.00033404 grad_norm 0.595993 rank 1
2025-01-10 08:57:25,661 DEBUG TRAIN Batch 23/100 loss 0.275841 acc 0.810861 lr 0.00033404 grad_norm 0.595993 rank 0
2025-01-10 08:57:25,661 DEBUG TRAIN Batch 23/100 loss 0.283804 acc 0.806091 lr 0.00033404 grad_norm 0.595993 rank 2
2025-01-10 08:57:50,077 DEBUG TRAIN Batch 23/200 loss 0.315196 acc 0.791743 lr 0.00033367 grad_norm 0.595367 rank 0
2025-01-10 08:57:50,078 DEBUG TRAIN Batch 23/200 loss 0.230885 acc 0.839686 lr 0.00033367 grad_norm 0.595367 rank 1
2025-01-10 08:57:50,078 DEBUG TRAIN Batch 23/200 loss 0.300631 acc 0.797567 lr 0.00033367 grad_norm 0.595367 rank 2
2025-01-10 08:58:15,036 DEBUG TRAIN Batch 23/300 loss 0.288263 acc 0.795392 lr 0.00033330 grad_norm 0.585109 rank 1
2025-01-10 08:58:15,036 DEBUG TRAIN Batch 23/300 loss 0.321784 acc 0.777990 lr 0.00033330 grad_norm 0.585109 rank 2
2025-01-10 08:58:15,036 DEBUG TRAIN Batch 23/300 loss 0.387318 acc 0.742110 lr 0.00033330 grad_norm 0.585109 rank 0
2025-01-10 08:58:39,064 DEBUG TRAIN Batch 23/400 loss 0.252785 acc 0.832244 lr 0.00033293 grad_norm 0.613950 rank 2
2025-01-10 08:58:39,065 DEBUG TRAIN Batch 23/400 loss 0.357511 acc 0.761468 lr 0.00033293 grad_norm 0.613950 rank 0
2025-01-10 08:58:39,065 DEBUG TRAIN Batch 23/400 loss 0.221184 acc 0.849010 lr 0.00033293 grad_norm 0.613950 rank 1
2025-01-10 08:59:03,930 DEBUG TRAIN Batch 23/500 loss 0.266061 acc 0.832915 lr 0.00033256 grad_norm 0.610897 rank 0
2025-01-10 08:59:03,931 DEBUG TRAIN Batch 23/500 loss 0.403806 acc 0.720729 lr 0.00033256 grad_norm 0.610897 rank 2
2025-01-10 08:59:03,931 DEBUG TRAIN Batch 23/500 loss 0.401771 acc 0.750222 lr 0.00033256 grad_norm 0.610897 rank 1
2025-01-10 08:59:28,424 DEBUG TRAIN Batch 23/600 loss 0.311371 acc 0.792894 lr 0.00033219 grad_norm 0.557364 rank 1
2025-01-10 08:59:28,424 DEBUG TRAIN Batch 23/600 loss 0.339040 acc 0.763494 lr 0.00033219 grad_norm 0.557364 rank 2
2025-01-10 08:59:28,424 DEBUG TRAIN Batch 23/600 loss 0.393898 acc 0.731413 lr 0.00033219 grad_norm 0.557364 rank 0
2025-01-10 08:59:52,405 DEBUG TRAIN Batch 23/700 loss 0.361594 acc 0.776181 lr 0.00033183 grad_norm 0.608126 rank 1
2025-01-10 08:59:52,405 DEBUG TRAIN Batch 23/700 loss 0.386876 acc 0.736888 lr 0.00033183 grad_norm 0.608126 rank 2
2025-01-10 08:59:52,405 DEBUG TRAIN Batch 23/700 loss 0.359931 acc 0.767557 lr 0.00033183 grad_norm 0.608126 rank 0
2025-01-10 09:00:17,265 DEBUG TRAIN Batch 23/800 loss 0.341176 acc 0.775047 lr 0.00033146 grad_norm 0.624302 rank 2
2025-01-10 09:00:17,265 DEBUG TRAIN Batch 23/800 loss 0.358557 acc 0.751318 lr 0.00033146 grad_norm 0.624302 rank 0
2025-01-10 09:00:17,265 DEBUG TRAIN Batch 23/800 loss 0.315076 acc 0.785640 lr 0.00033146 grad_norm 0.624302 rank 1
2025-01-10 09:00:41,645 DEBUG TRAIN Batch 23/900 loss 0.342956 acc 0.771556 lr 0.00033110 grad_norm 0.575082 rank 1
2025-01-10 09:00:41,645 DEBUG TRAIN Batch 23/900 loss 0.399197 acc 0.735473 lr 0.00033110 grad_norm 0.575082 rank 0
2025-01-10 09:00:41,646 DEBUG TRAIN Batch 23/900 loss 0.314738 acc 0.774874 lr 0.00033110 grad_norm 0.575082 rank 2
2025-01-10 09:01:06,292 DEBUG TRAIN Batch 23/1000 loss 0.340965 acc 0.771023 lr 0.00033073 grad_norm 0.663186 rank 0
2025-01-10 09:01:06,292 DEBUG TRAIN Batch 23/1000 loss 0.268078 acc 0.822329 lr 0.00033073 grad_norm 0.663186 rank 2
2025-01-10 09:01:06,293 DEBUG TRAIN Batch 23/1000 loss 0.223289 acc 0.842404 lr 0.00033073 grad_norm 0.663186 rank 1
2025-01-10 09:01:32,196 DEBUG TRAIN Batch 23/1100 loss 0.288214 acc 0.800211 lr 0.00033037 grad_norm 0.628076 rank 0
2025-01-10 09:01:32,197 DEBUG TRAIN Batch 23/1100 loss 0.367832 acc 0.753484 lr 0.00033037 grad_norm 0.628076 rank 2
2025-01-10 09:01:32,197 DEBUG TRAIN Batch 23/1100 loss 0.349471 acc 0.751131 lr 0.00033037 grad_norm 0.628076 rank 1
2025-01-10 09:01:56,433 DEBUG TRAIN Batch 23/1200 loss 0.421593 acc 0.717015 lr 0.00033001 grad_norm 0.634657 rank 0
2025-01-10 09:01:56,433 DEBUG TRAIN Batch 23/1200 loss 0.323920 acc 0.767196 lr 0.00033001 grad_norm 0.634657 rank 1
2025-01-10 09:01:56,433 DEBUG TRAIN Batch 23/1200 loss 0.370564 acc 0.747681 lr 0.00033001 grad_norm 0.634657 rank 2
2025-01-10 09:02:19,966 DEBUG TRAIN Batch 23/1300 loss 0.295460 acc 0.796660 lr 0.00032965 grad_norm 0.623658 rank 0
2025-01-10 09:02:19,967 DEBUG TRAIN Batch 23/1300 loss 0.203599 acc 0.858225 lr 0.00032965 grad_norm 0.623658 rank 2
2025-01-10 09:02:19,967 DEBUG TRAIN Batch 23/1300 loss 0.334759 acc 0.774676 lr 0.00032965 grad_norm 0.623658 rank 1
2025-01-10 09:02:44,153 DEBUG TRAIN Batch 23/1400 loss 0.335315 acc 0.783133 lr 0.00032930 grad_norm 0.611687 rank 0
2025-01-10 09:02:44,153 DEBUG TRAIN Batch 23/1400 loss 0.311607 acc 0.779130 lr 0.00032930 grad_norm 0.611687 rank 1
2025-01-10 09:02:44,153 DEBUG TRAIN Batch 23/1400 loss 0.240189 acc 0.832723 lr 0.00032930 grad_norm 0.611687 rank 2
2025-01-10 09:03:08,236 DEBUG TRAIN Batch 23/1500 loss 0.334380 acc 0.788321 lr 0.00032894 grad_norm 0.617840 rank 0
2025-01-10 09:03:08,236 DEBUG TRAIN Batch 23/1500 loss 0.334626 acc 0.763957 lr 0.00032894 grad_norm 0.617840 rank 1
2025-01-10 09:03:08,236 DEBUG TRAIN Batch 23/1500 loss 0.234762 acc 0.840654 lr 0.00032894 grad_norm 0.617840 rank 2
2025-01-10 09:03:33,047 DEBUG TRAIN Batch 23/1600 loss 0.334629 acc 0.773166 lr 0.00032858 grad_norm 0.619430 rank 0
2025-01-10 09:03:33,048 DEBUG TRAIN Batch 23/1600 loss 0.120758 acc 0.913636 lr 0.00032858 grad_norm 0.619430 rank 2
2025-01-10 09:03:33,048 DEBUG TRAIN Batch 23/1600 loss 0.267373 acc 0.818278 lr 0.00032858 grad_norm 0.619430 rank 1
2025-01-10 09:03:57,157 DEBUG TRAIN Batch 23/1700 loss 0.397873 acc 0.753234 lr 0.00032823 grad_norm 0.658165 rank 1
2025-01-10 09:03:57,157 DEBUG TRAIN Batch 23/1700 loss 0.381714 acc 0.752257 lr 0.00032823 grad_norm 0.658165 rank 0
2025-01-10 09:03:57,158 DEBUG TRAIN Batch 23/1700 loss 0.248495 acc 0.830337 lr 0.00032823 grad_norm 0.658165 rank 2
2025-01-10 09:04:21,536 DEBUG TRAIN Batch 23/1800 loss 0.316611 acc 0.797657 lr 0.00032788 grad_norm 0.609857 rank 1
2025-01-10 09:04:21,536 DEBUG TRAIN Batch 23/1800 loss 0.333785 acc 0.770727 lr 0.00032788 grad_norm 0.609857 rank 0
2025-01-10 09:04:21,537 DEBUG TRAIN Batch 23/1800 loss 0.191837 acc 0.868521 lr 0.00032788 grad_norm 0.609857 rank 2
2025-01-10 09:04:45,857 DEBUG TRAIN Batch 23/1900 loss 0.303175 acc 0.799778 lr 0.00032753 grad_norm 0.642042 rank 0
2025-01-10 09:04:45,858 DEBUG TRAIN Batch 23/1900 loss 0.342486 acc 0.765657 lr 0.00032753 grad_norm 0.642042 rank 2
2025-01-10 09:04:45,859 DEBUG TRAIN Batch 23/1900 loss 0.354969 acc 0.752515 lr 0.00032753 grad_norm 0.642042 rank 1
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 09:06:06,666 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 09:06:06,672 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 09:06:07,099 INFO Epoch 23 Step 23347 on_batch_end True CV rank 2
2025-01-10 09:06:07,099 INFO Epoch 23 Step 23347 on_batch_end True CV rank 0
2025-01-10 09:06:07,099 INFO Epoch 23 Step 23347 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 09:06:16,990 DEBUG CV Batch 23/100 loss 0.330508 acc 0.894091  rank 0
2025-01-10 09:06:17,074 DEBUG CV Batch 23/100 loss 0.330508 acc 0.894091  rank 2
2025-01-10 09:06:17,527 INFO Epoch 23 Step 23347 CV info lr 0.0003272310174415926 0 rank loss_1.5111867995900021 acc_0.7166532573469898
2025-01-10 09:06:17,578 INFO Epoch 23 Step 23347 CV info lr 0.0003272310174415926 2 rank loss_1.5111867995900021 acc_0.7166532573469898
2025-01-10 09:06:17,706 DEBUG CV Batch 23/100 loss 0.330508 acc 0.894091  rank 1
2025-01-10 09:06:18,253 INFO Epoch 23 Step 23347 CV info lr 0.0003272310174415926 1 rank loss_1.5111867995900021 acc_0.7166532573469898
2025-01-10 09:06:18,813 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_23_whole.pt
2025-01-10 09:06:18,834 INFO Added key: store_based_barrier_key:26 to store for rank: 0
2025-01-10 09:06:18,835 INFO Added key: store_based_barrier_key:26 to store for rank: 1
2025-01-10 09:06:18,835 INFO Added key: store_based_barrier_key:26 to store for rank: 2
2025-01-10 09:06:18,835 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:26 with 3 nodes.
2025-01-10 09:06:18,842 INFO Epoch 24 TRAIN info lr 0.0003272310174415926 rank 2
2025-01-10 09:06:18,842 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 09:06:18,845 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:26 with 3 nodes.
2025-01-10 09:06:18,845 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:26 with 3 nodes.
2025-01-10 09:06:18,846 INFO Epoch 24 TRAIN info lr 0.0003272310174415926 rank 1
2025-01-10 09:06:18,846 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 09:06:18,854 INFO Epoch 24 TRAIN info lr 0.0003272310174415926 rank 0
2025-01-10 09:06:18,854 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 09:06:55,693 DEBUG TRAIN Batch 24/100 loss 0.307259 acc 0.795789 lr 0.00032688 grad_norm 0.579872 rank 2
2025-01-10 09:06:55,693 DEBUG TRAIN Batch 24/100 loss 0.178990 acc 0.875634 lr 0.00032688 grad_norm 0.579872 rank 1
2025-01-10 09:06:55,694 DEBUG TRAIN Batch 24/100 loss 0.179805 acc 0.887841 lr 0.00032688 grad_norm 0.579872 rank 0
2025-01-10 09:07:19,988 DEBUG TRAIN Batch 24/200 loss 0.235730 acc 0.839352 lr 0.00032653 grad_norm 0.596177 rank 2
2025-01-10 09:07:19,988 DEBUG TRAIN Batch 24/200 loss 0.246659 acc 0.830755 lr 0.00032653 grad_norm 0.596177 rank 0
2025-01-10 09:07:19,988 DEBUG TRAIN Batch 24/200 loss 0.231303 acc 0.848369 lr 0.00032653 grad_norm 0.596177 rank 1
2025-01-10 09:07:44,634 DEBUG TRAIN Batch 24/300 loss 0.403925 acc 0.737288 lr 0.00032618 grad_norm 0.610093 rank 2
2025-01-10 09:07:44,634 DEBUG TRAIN Batch 24/300 loss 0.325340 acc 0.785271 lr 0.00032618 grad_norm 0.610093 rank 0
2025-01-10 09:07:44,634 DEBUG TRAIN Batch 24/300 loss 0.140945 acc 0.894400 lr 0.00032618 grad_norm 0.610093 rank 1
2025-01-10 09:08:08,543 DEBUG TRAIN Batch 24/400 loss 0.262307 acc 0.818985 lr 0.00032584 grad_norm 0.602098 rank 0
2025-01-10 09:08:08,543 DEBUG TRAIN Batch 24/400 loss 0.156245 acc 0.890780 lr 0.00032584 grad_norm 0.602098 rank 1
2025-01-10 09:08:08,543 DEBUG TRAIN Batch 24/400 loss 0.317767 acc 0.786139 lr 0.00032584 grad_norm 0.602098 rank 2
2025-01-10 09:08:33,036 DEBUG TRAIN Batch 24/500 loss 0.226673 acc 0.854093 lr 0.00032549 grad_norm 0.593769 rank 1
2025-01-10 09:08:33,037 DEBUG TRAIN Batch 24/500 loss 0.332184 acc 0.776532 lr 0.00032549 grad_norm 0.593769 rank 0
2025-01-10 09:08:33,037 DEBUG TRAIN Batch 24/500 loss 0.343906 acc 0.772317 lr 0.00032549 grad_norm 0.593769 rank 2
2025-01-10 09:08:58,139 DEBUG TRAIN Batch 24/600 loss 0.357268 acc 0.762477 lr 0.00032515 grad_norm 0.614829 rank 0
2025-01-10 09:08:58,139 DEBUG TRAIN Batch 24/600 loss 0.252499 acc 0.828214 lr 0.00032515 grad_norm 0.614829 rank 1
2025-01-10 09:08:58,139 DEBUG TRAIN Batch 24/600 loss 0.331712 acc 0.758811 lr 0.00032515 grad_norm 0.614829 rank 2
2025-01-10 09:09:22,383 DEBUG TRAIN Batch 24/700 loss 0.235360 acc 0.837597 lr 0.00032481 grad_norm 0.642245 rank 1
2025-01-10 09:09:22,383 DEBUG TRAIN Batch 24/700 loss 0.406482 acc 0.740234 lr 0.00032481 grad_norm 0.642245 rank 2
2025-01-10 09:09:22,384 DEBUG TRAIN Batch 24/700 loss 0.307854 acc 0.793169 lr 0.00032481 grad_norm 0.642245 rank 0
2025-01-10 09:09:47,025 DEBUG TRAIN Batch 24/800 loss 0.300971 acc 0.803478 lr 0.00032446 grad_norm 0.604552 rank 1
2025-01-10 09:09:47,025 DEBUG TRAIN Batch 24/800 loss 0.343554 acc 0.777669 lr 0.00032446 grad_norm 0.604552 rank 2
2025-01-10 09:09:47,025 DEBUG TRAIN Batch 24/800 loss 0.300205 acc 0.791342 lr 0.00032446 grad_norm 0.604552 rank 0
2025-01-10 09:10:11,401 DEBUG TRAIN Batch 24/900 loss 0.294321 acc 0.801357 lr 0.00032412 grad_norm 0.611684 rank 0
2025-01-10 09:10:11,401 DEBUG TRAIN Batch 24/900 loss 0.146626 acc 0.906442 lr 0.00032412 grad_norm 0.611684 rank 1
2025-01-10 09:10:11,402 DEBUG TRAIN Batch 24/900 loss 0.267922 acc 0.805708 lr 0.00032412 grad_norm 0.611684 rank 2
2025-01-10 09:10:35,432 DEBUG TRAIN Batch 24/1000 loss 0.183166 acc 0.871141 lr 0.00032378 grad_norm 0.613924 rank 1
2025-01-10 09:10:35,432 DEBUG TRAIN Batch 24/1000 loss 0.305260 acc 0.782027 lr 0.00032378 grad_norm 0.613924 rank 0
2025-01-10 09:10:35,432 DEBUG TRAIN Batch 24/1000 loss 0.357064 acc 0.757417 lr 0.00032378 grad_norm 0.613924 rank 2
2025-01-10 09:11:00,898 DEBUG TRAIN Batch 24/1100 loss 0.277975 acc 0.820018 lr 0.00032344 grad_norm 0.642031 rank 1
2025-01-10 09:11:00,898 DEBUG TRAIN Batch 24/1100 loss 0.349952 acc 0.767283 lr 0.00032344 grad_norm 0.642031 rank 0
2025-01-10 09:11:00,899 DEBUG TRAIN Batch 24/1100 loss 0.330969 acc 0.770000 lr 0.00032344 grad_norm 0.642031 rank 2
2025-01-10 09:11:24,836 DEBUG TRAIN Batch 24/1200 loss 0.272037 acc 0.831107 lr 0.00032311 grad_norm 0.634081 rank 1
2025-01-10 09:11:24,836 DEBUG TRAIN Batch 24/1200 loss 0.369846 acc 0.752189 lr 0.00032311 grad_norm 0.634081 rank 2
2025-01-10 09:11:24,836 DEBUG TRAIN Batch 24/1200 loss 0.366291 acc 0.741993 lr 0.00032311 grad_norm 0.634081 rank 0
2025-01-10 09:11:48,777 DEBUG TRAIN Batch 24/1300 loss 0.296930 acc 0.794944 lr 0.00032277 grad_norm 0.628497 rank 1
2025-01-10 09:11:48,777 DEBUG TRAIN Batch 24/1300 loss 0.251005 acc 0.820225 lr 0.00032277 grad_norm 0.628497 rank 2
2025-01-10 09:11:48,777 DEBUG TRAIN Batch 24/1300 loss 0.337045 acc 0.778626 lr 0.00032277 grad_norm 0.628497 rank 0
2025-01-10 09:12:13,249 DEBUG TRAIN Batch 24/1400 loss 0.375168 acc 0.754661 lr 0.00032243 grad_norm 0.631100 rank 1
2025-01-10 09:12:13,249 DEBUG TRAIN Batch 24/1400 loss 0.576769 acc 0.633367 lr 0.00032243 grad_norm 0.631100 rank 2
2025-01-10 09:12:13,249 DEBUG TRAIN Batch 24/1400 loss 0.365312 acc 0.756310 lr 0.00032243 grad_norm 0.631100 rank 0
2025-01-10 09:12:36,830 DEBUG TRAIN Batch 24/1500 loss 0.402557 acc 0.738248 lr 0.00032210 grad_norm 0.607218 rank 2
2025-01-10 09:12:36,830 DEBUG TRAIN Batch 24/1500 loss 0.357682 acc 0.766210 lr 0.00032210 grad_norm 0.607218 rank 0
2025-01-10 09:12:36,830 DEBUG TRAIN Batch 24/1500 loss 0.327342 acc 0.761905 lr 0.00032210 grad_norm 0.607218 rank 1
2025-01-10 09:13:01,229 DEBUG TRAIN Batch 24/1600 loss 0.340174 acc 0.756926 lr 0.00032176 grad_norm 0.606856 rank 0
2025-01-10 09:13:01,229 DEBUG TRAIN Batch 24/1600 loss 0.237471 acc 0.846667 lr 0.00032176 grad_norm 0.606856 rank 2
2025-01-10 09:13:01,229 DEBUG TRAIN Batch 24/1600 loss 0.238640 acc 0.826415 lr 0.00032176 grad_norm 0.606856 rank 1
2025-01-10 09:13:26,538 DEBUG TRAIN Batch 24/1700 loss 0.144551 acc 0.895349 lr 0.00032143 grad_norm 0.597724 rank 0
2025-01-10 09:13:26,538 DEBUG TRAIN Batch 24/1700 loss 0.365212 acc 0.750233 lr 0.00032143 grad_norm 0.597724 rank 1
2025-01-10 09:13:26,538 DEBUG TRAIN Batch 24/1700 loss 0.540052 acc 0.648165 lr 0.00032143 grad_norm 0.597724 rank 2
2025-01-10 09:13:50,805 DEBUG TRAIN Batch 24/1800 loss 0.330847 acc 0.763903 lr 0.00032110 grad_norm 0.616219 rank 1
2025-01-10 09:13:50,806 DEBUG TRAIN Batch 24/1800 loss 0.306325 acc 0.794559 lr 0.00032110 grad_norm 0.616219 rank 0
2025-01-10 09:13:50,806 DEBUG TRAIN Batch 24/1800 loss 0.482258 acc 0.678373 lr 0.00032110 grad_norm 0.616219 rank 2
2025-01-10 09:14:16,042 DEBUG TRAIN Batch 24/1900 loss 0.098848 acc 0.945578 lr 0.00032077 grad_norm 0.585495 rank 0
2025-01-10 09:14:16,042 DEBUG TRAIN Batch 24/1900 loss 0.278899 acc 0.815126 lr 0.00032077 grad_norm 0.585495 rank 2
2025-01-10 09:14:16,043 DEBUG TRAIN Batch 24/1900 loss 0.398474 acc 0.729167 lr 0.00032077 grad_norm 0.585495 rank 1
2025-01-10 09:14:40,421 DEBUG TRAIN Batch 24/2000 loss 0.319596 acc 0.780797 lr 0.00032044 grad_norm 0.643529 rank 2
2025-01-10 09:14:40,421 DEBUG TRAIN Batch 24/2000 loss 0.406281 acc 0.716405 lr 0.00032044 grad_norm 0.643529 rank 1
2025-01-10 09:14:40,421 DEBUG TRAIN Batch 24/2000 loss 0.354608 acc 0.770909 lr 0.00032044 grad_norm 0.643529 rank 0
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 09:15:54,037 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 09:15:54,037 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 09:15:54,501 INFO Epoch 24 Step 24376 on_batch_end True CV rank 2
2025-01-10 09:15:54,501 INFO Epoch 24 Step 24376 on_batch_end True CV rank 1
2025-01-10 09:15:54,501 INFO Epoch 24 Step 24376 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 09:16:03,783 DEBUG CV Batch 24/100 loss 0.228259 acc 0.935340  rank 0
2025-01-10 09:16:03,954 DEBUG CV Batch 24/100 loss 0.228259 acc 0.935340  rank 2
2025-01-10 09:16:04,212 DEBUG CV Batch 24/100 loss 0.228259 acc 0.935340  rank 1
2025-01-10 09:16:04,312 INFO Epoch 24 Step 24376 CV info lr 0.00032024973845214545 0 rank loss_1.4812078782144869 acc_0.7281156937804139
2025-01-10 09:16:04,490 INFO Epoch 24 Step 24376 CV info lr 0.00032024973845214545 2 rank loss_1.4812078782144869 acc_0.7281156937804139
2025-01-10 09:16:04,749 INFO Epoch 24 Step 24376 CV info lr 0.00032024973845214545 1 rank loss_1.4812078782144869 acc_0.7281156937804139
2025-01-10 09:16:05,586 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_24_whole.pt
2025-01-10 09:16:05,597 INFO Added key: store_based_barrier_key:27 to store for rank: 0
2025-01-10 09:16:05,608 INFO Added key: store_based_barrier_key:27 to store for rank: 2
2025-01-10 09:16:05,608 INFO Added key: store_based_barrier_key:27 to store for rank: 1
2025-01-10 09:16:05,608 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:27 with 3 nodes.
2025-01-10 09:16:05,608 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:27 with 3 nodes.
2025-01-10 09:16:05,610 INFO Epoch 25 TRAIN info lr 0.00032024973845214545 rank 2
2025-01-10 09:16:05,610 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 09:16:05,615 INFO Epoch 25 TRAIN info lr 0.00032024973845214545 rank 1
2025-01-10 09:16:05,615 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 09:16:05,618 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:27 with 3 nodes.
2025-01-10 09:16:05,626 INFO Epoch 25 TRAIN info lr 0.00032024973845214545 rank 0
2025-01-10 09:16:05,626 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 09:16:43,198 DEBUG TRAIN Batch 25/100 loss 0.382974 acc 0.743433 lr 0.00031992 grad_norm 0.579474 rank 2
2025-01-10 09:16:43,198 DEBUG TRAIN Batch 25/100 loss 0.430211 acc 0.715173 lr 0.00031992 grad_norm 0.579474 rank 1
2025-01-10 09:16:43,199 DEBUG TRAIN Batch 25/100 loss 0.269623 acc 0.816733 lr 0.00031992 grad_norm 0.579474 rank 0
2025-01-10 09:17:07,500 DEBUG TRAIN Batch 25/200 loss 0.221864 acc 0.848354 lr 0.00031959 grad_norm 0.594424 rank 0
2025-01-10 09:17:07,500 DEBUG TRAIN Batch 25/200 loss 0.313932 acc 0.788644 lr 0.00031959 grad_norm 0.594424 rank 1
2025-01-10 09:17:07,501 DEBUG TRAIN Batch 25/200 loss 0.343209 acc 0.762726 lr 0.00031959 grad_norm 0.594424 rank 2
2025-01-10 09:17:33,138 DEBUG TRAIN Batch 25/300 loss 0.288311 acc 0.806186 lr 0.00031927 grad_norm 0.615647 rank 0
2025-01-10 09:17:33,138 DEBUG TRAIN Batch 25/300 loss 0.383364 acc 0.739960 lr 0.00031927 grad_norm 0.615647 rank 1
2025-01-10 09:17:33,139 DEBUG TRAIN Batch 25/300 loss 0.280561 acc 0.818996 lr 0.00031927 grad_norm 0.615647 rank 2
2025-01-10 09:17:56,722 DEBUG TRAIN Batch 25/400 loss 0.347205 acc 0.775691 lr 0.00031894 grad_norm 0.626738 rank 1
2025-01-10 09:17:56,722 DEBUG TRAIN Batch 25/400 loss 0.260402 acc 0.819101 lr 0.00031894 grad_norm 0.626738 rank 0
2025-01-10 09:17:56,723 DEBUG TRAIN Batch 25/400 loss 0.248063 acc 0.819672 lr 0.00031894 grad_norm 0.626738 rank 2
2025-01-10 09:18:21,461 DEBUG TRAIN Batch 25/500 loss 0.412533 acc 0.726453 lr 0.00031862 grad_norm 0.639179 rank 1
2025-01-10 09:18:21,461 DEBUG TRAIN Batch 25/500 loss 0.259177 acc 0.832482 lr 0.00031862 grad_norm 0.639179 rank 0
2025-01-10 09:18:21,462 DEBUG TRAIN Batch 25/500 loss 0.265238 acc 0.821300 lr 0.00031862 grad_norm 0.639179 rank 2
2025-01-10 09:18:47,345 DEBUG TRAIN Batch 25/600 loss 0.248741 acc 0.836021 lr 0.00031830 grad_norm 0.618266 rank 0
2025-01-10 09:18:47,347 DEBUG TRAIN Batch 25/600 loss 0.296604 acc 0.792889 lr 0.00031830 grad_norm 0.618266 rank 2
2025-01-10 09:18:47,347 DEBUG TRAIN Batch 25/600 loss 0.300578 acc 0.788720 lr 0.00031830 grad_norm 0.618266 rank 1
2025-01-10 09:19:11,385 DEBUG TRAIN Batch 25/700 loss 0.315482 acc 0.778087 lr 0.00031798 grad_norm 0.631700 rank 1
2025-01-10 09:19:11,386 DEBUG TRAIN Batch 25/700 loss 0.304521 acc 0.799653 lr 0.00031798 grad_norm 0.631700 rank 0
2025-01-10 09:19:11,387 DEBUG TRAIN Batch 25/700 loss 0.310748 acc 0.788931 lr 0.00031798 grad_norm 0.631700 rank 2
2025-01-10 09:19:35,850 DEBUG TRAIN Batch 25/800 loss 0.285833 acc 0.811563 lr 0.00031765 grad_norm 0.621782 rank 0
2025-01-10 09:19:35,850 DEBUG TRAIN Batch 25/800 loss 0.211004 acc 0.853278 lr 0.00031765 grad_norm 0.621782 rank 1
2025-01-10 09:19:35,851 DEBUG TRAIN Batch 25/800 loss 0.291195 acc 0.807692 lr 0.00031765 grad_norm 0.621782 rank 2
2025-01-10 09:19:59,610 DEBUG TRAIN Batch 25/900 loss 0.367136 acc 0.750471 lr 0.00031733 grad_norm 0.637923 rank 0
2025-01-10 09:19:59,610 DEBUG TRAIN Batch 25/900 loss 0.344637 acc 0.769513 lr 0.00031733 grad_norm 0.637923 rank 1
2025-01-10 09:19:59,611 DEBUG TRAIN Batch 25/900 loss 0.305078 acc 0.790965 lr 0.00031733 grad_norm 0.637923 rank 2
2025-01-10 09:20:24,058 DEBUG TRAIN Batch 25/1000 loss 0.345659 acc 0.761266 lr 0.00031701 grad_norm 0.627957 rank 1
2025-01-10 09:20:24,058 DEBUG TRAIN Batch 25/1000 loss 0.374739 acc 0.731729 lr 0.00031701 grad_norm 0.627957 rank 0
2025-01-10 09:20:24,059 DEBUG TRAIN Batch 25/1000 loss 0.245019 acc 0.836269 lr 0.00031701 grad_norm 0.627957 rank 2
2025-01-10 09:20:50,125 DEBUG TRAIN Batch 25/1100 loss 0.380921 acc 0.741906 lr 0.00031670 grad_norm 0.624688 rank 0
2025-01-10 09:20:50,126 DEBUG TRAIN Batch 25/1100 loss 0.389683 acc 0.741289 lr 0.00031670 grad_norm 0.624688 rank 1
2025-01-10 09:20:50,126 DEBUG TRAIN Batch 25/1100 loss 0.269594 acc 0.821429 lr 0.00031670 grad_norm 0.624688 rank 2
2025-01-10 09:21:13,872 DEBUG TRAIN Batch 25/1200 loss 0.352250 acc 0.752964 lr 0.00031638 grad_norm 0.632897 rank 0
2025-01-10 09:21:13,872 DEBUG TRAIN Batch 25/1200 loss 0.313890 acc 0.789030 lr 0.00031638 grad_norm 0.632897 rank 1
2025-01-10 09:21:13,873 DEBUG TRAIN Batch 25/1200 loss 0.331271 acc 0.766174 lr 0.00031638 grad_norm 0.632897 rank 2
2025-01-10 09:21:38,055 DEBUG TRAIN Batch 25/1300 loss 0.260988 acc 0.832321 lr 0.00031606 grad_norm 0.652274 rank 0
2025-01-10 09:21:38,055 DEBUG TRAIN Batch 25/1300 loss 0.339232 acc 0.756780 lr 0.00031606 grad_norm 0.652274 rank 1
2025-01-10 09:21:38,055 DEBUG TRAIN Batch 25/1300 loss 0.297386 acc 0.792435 lr 0.00031606 grad_norm 0.652274 rank 2
2025-01-10 09:22:01,896 DEBUG TRAIN Batch 25/1400 loss 0.311715 acc 0.788023 lr 0.00031575 grad_norm 0.629638 rank 1
2025-01-10 09:22:01,896 DEBUG TRAIN Batch 25/1400 loss 0.225608 acc 0.853712 lr 0.00031575 grad_norm 0.629638 rank 0
2025-01-10 09:22:01,897 DEBUG TRAIN Batch 25/1400 loss 0.320899 acc 0.778289 lr 0.00031575 grad_norm 0.629638 rank 2
2025-01-10 09:22:26,062 DEBUG TRAIN Batch 25/1500 loss 0.362464 acc 0.750222 lr 0.00031543 grad_norm 0.631059 rank 2
2025-01-10 09:22:26,063 DEBUG TRAIN Batch 25/1500 loss 0.185945 acc 0.872818 lr 0.00031543 grad_norm 0.631059 rank 0
2025-01-10 09:22:26,065 DEBUG TRAIN Batch 25/1500 loss 0.268710 acc 0.810039 lr 0.00031543 grad_norm 0.631059 rank 1
2025-01-10 09:22:50,365 DEBUG TRAIN Batch 25/1600 loss 0.202517 acc 0.864769 lr 0.00031512 grad_norm 0.619601 rank 2
2025-01-10 09:22:50,366 DEBUG TRAIN Batch 25/1600 loss 0.308480 acc 0.800570 lr 0.00031512 grad_norm 0.619601 rank 1
2025-01-10 09:22:50,366 DEBUG TRAIN Batch 25/1600 loss 0.208554 acc 0.850806 lr 0.00031512 grad_norm 0.619601 rank 0
2025-01-10 09:23:14,823 DEBUG TRAIN Batch 25/1700 loss 0.226018 acc 0.840652 lr 0.00031481 grad_norm 0.631739 rank 2
2025-01-10 09:23:14,823 DEBUG TRAIN Batch 25/1700 loss 0.105140 acc 0.933333 lr 0.00031481 grad_norm 0.631739 rank 0
2025-01-10 09:23:14,823 DEBUG TRAIN Batch 25/1700 loss 0.415349 acc 0.711088 lr 0.00031481 grad_norm 0.631739 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 09:24:19,323 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 09:24:19,327 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 09:24:19,802 INFO Epoch 25 Step 25235 on_batch_end True CV rank 1
2025-01-10 09:24:19,802 INFO Epoch 25 Step 25235 on_batch_end True CV rank 0
2025-01-10 09:24:19,803 INFO Epoch 25 Step 25235 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 09:24:29,102 DEBUG CV Batch 25/100 loss 0.257394 acc 0.933110  rank 0
2025-01-10 09:24:29,582 DEBUG CV Batch 25/100 loss 0.257394 acc 0.933110  rank 2
2025-01-10 09:24:29,633 INFO Epoch 25 Step 25235 CV info lr 0.000314751892313737 0 rank loss_1.483251828373524 acc_0.7365328117943647
2025-01-10 09:24:29,741 DEBUG CV Batch 25/100 loss 0.257394 acc 0.933110  rank 1
2025-01-10 09:24:30,124 INFO Epoch 25 Step 25235 CV info lr 0.000314751892313737 2 rank loss_1.483251828373524 acc_0.7365328117943647
2025-01-10 09:24:30,272 INFO Epoch 25 Step 25235 CV info lr 0.000314751892313737 1 rank loss_1.483251828373524 acc_0.7365328117943647
2025-01-10 09:24:30,933 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_25_whole.pt
2025-01-10 09:24:30,955 INFO Added key: store_based_barrier_key:28 to store for rank: 0
2025-01-10 09:24:30,965 INFO Added key: store_based_barrier_key:28 to store for rank: 2
2025-01-10 09:24:30,965 INFO Added key: store_based_barrier_key:28 to store for rank: 1
2025-01-10 09:24:30,965 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:28 with 3 nodes.
2025-01-10 09:24:30,965 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:28 with 3 nodes.
2025-01-10 09:24:30,971 INFO Epoch 26 TRAIN info lr 0.000314751892313737 rank 1
2025-01-10 09:24:30,971 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 09:24:30,973 INFO Epoch 26 TRAIN info lr 0.000314751892313737 rank 2
2025-01-10 09:24:30,973 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 09:24:30,975 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:28 with 3 nodes.
2025-01-10 09:24:30,983 INFO Epoch 26 TRAIN info lr 0.000314751892313737 rank 0
2025-01-10 09:24:30,983 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 09:25:07,277 DEBUG TRAIN Batch 26/100 loss 0.134863 acc 0.917513 lr 0.00031444 grad_norm 0.602994 rank 2
2025-01-10 09:25:07,277 DEBUG TRAIN Batch 26/100 loss 0.311713 acc 0.766385 lr 0.00031444 grad_norm 0.602994 rank 0
2025-01-10 09:25:07,277 DEBUG TRAIN Batch 26/100 loss 0.280290 acc 0.830957 lr 0.00031444 grad_norm 0.602994 rank 1
2025-01-10 09:25:31,603 DEBUG TRAIN Batch 26/200 loss 0.203061 acc 0.846890 lr 0.00031413 grad_norm 0.664216 rank 2
2025-01-10 09:25:31,603 DEBUG TRAIN Batch 26/200 loss 0.225827 acc 0.839444 lr 0.00031413 grad_norm 0.664216 rank 0
2025-01-10 09:25:31,604 DEBUG TRAIN Batch 26/200 loss 0.331711 acc 0.767462 lr 0.00031413 grad_norm 0.664216 rank 1
2025-01-10 09:25:56,095 DEBUG TRAIN Batch 26/300 loss 0.123770 acc 0.913399 lr 0.00031382 grad_norm 0.595759 rank 2
2025-01-10 09:25:56,095 DEBUG TRAIN Batch 26/300 loss 0.336309 acc 0.776923 lr 0.00031382 grad_norm 0.595759 rank 0
2025-01-10 09:25:56,095 DEBUG TRAIN Batch 26/300 loss 0.303397 acc 0.809665 lr 0.00031382 grad_norm 0.595759 rank 1
2025-01-10 09:26:19,990 DEBUG TRAIN Batch 26/400 loss 0.133387 acc 0.902405 lr 0.00031351 grad_norm 0.630843 rank 2
2025-01-10 09:26:19,991 DEBUG TRAIN Batch 26/400 loss 0.349633 acc 0.753400 lr 0.00031351 grad_norm 0.630843 rank 0
2025-01-10 09:26:19,991 DEBUG TRAIN Batch 26/400 loss 0.234841 acc 0.835153 lr 0.00031351 grad_norm 0.630843 rank 1
2025-01-10 09:26:44,829 DEBUG TRAIN Batch 26/500 loss 0.218885 acc 0.840237 lr 0.00031320 grad_norm 0.618894 rank 2
2025-01-10 09:26:44,829 DEBUG TRAIN Batch 26/500 loss 0.303765 acc 0.793922 lr 0.00031320 grad_norm 0.618894 rank 0
2025-01-10 09:26:44,829 DEBUG TRAIN Batch 26/500 loss 0.292147 acc 0.798238 lr 0.00031320 grad_norm 0.618894 rank 1
2025-01-10 09:27:10,015 DEBUG TRAIN Batch 26/600 loss 0.330810 acc 0.773585 lr 0.00031290 grad_norm 0.575256 rank 0
2025-01-10 09:27:10,015 DEBUG TRAIN Batch 26/600 loss 0.244674 acc 0.842006 lr 0.00031290 grad_norm 0.575256 rank 1
2025-01-10 09:27:10,015 DEBUG TRAIN Batch 26/600 loss 0.226158 acc 0.850607 lr 0.00031290 grad_norm 0.575256 rank 2
2025-01-10 09:27:34,220 DEBUG TRAIN Batch 26/700 loss 0.228955 acc 0.841561 lr 0.00031259 grad_norm 0.642916 rank 2
2025-01-10 09:27:34,220 DEBUG TRAIN Batch 26/700 loss 0.207249 acc 0.856674 lr 0.00031259 grad_norm 0.642916 rank 1
2025-01-10 09:27:34,220 DEBUG TRAIN Batch 26/700 loss 0.315807 acc 0.775923 lr 0.00031259 grad_norm 0.642916 rank 0
2025-01-10 09:27:59,181 DEBUG TRAIN Batch 26/800 loss 0.301848 acc 0.775546 lr 0.00031229 grad_norm 0.608074 rank 1
2025-01-10 09:27:59,181 DEBUG TRAIN Batch 26/800 loss 0.259800 acc 0.819309 lr 0.00031229 grad_norm 0.608074 rank 2
2025-01-10 09:27:59,181 DEBUG TRAIN Batch 26/800 loss 0.270139 acc 0.814244 lr 0.00031229 grad_norm 0.608074 rank 0
2025-01-10 09:28:23,586 DEBUG TRAIN Batch 26/900 loss 0.132791 acc 0.908397 lr 0.00031198 grad_norm 0.646430 rank 2
2025-01-10 09:28:23,586 DEBUG TRAIN Batch 26/900 loss 0.296930 acc 0.791594 lr 0.00031198 grad_norm 0.646430 rank 1
2025-01-10 09:28:23,586 DEBUG TRAIN Batch 26/900 loss 0.281555 acc 0.808569 lr 0.00031198 grad_norm 0.646430 rank 0
2025-01-10 09:28:48,295 DEBUG TRAIN Batch 26/1000 loss 0.429693 acc 0.698874 lr 0.00031168 grad_norm 0.690870 rank 1
2025-01-10 09:28:48,296 DEBUG TRAIN Batch 26/1000 loss 0.288251 acc 0.819484 lr 0.00031168 grad_norm 0.690870 rank 0
2025-01-10 09:28:48,296 DEBUG TRAIN Batch 26/1000 loss 0.159677 acc 0.883916 lr 0.00031168 grad_norm 0.690870 rank 2
2025-01-10 09:29:13,590 DEBUG TRAIN Batch 26/1100 loss 0.409279 acc 0.712121 lr 0.00031138 grad_norm 0.636450 rank 1
2025-01-10 09:29:13,590 DEBUG TRAIN Batch 26/1100 loss 0.267779 acc 0.808081 lr 0.00031138 grad_norm 0.636450 rank 2
2025-01-10 09:29:13,590 DEBUG TRAIN Batch 26/1100 loss 0.234468 acc 0.833333 lr 0.00031138 grad_norm 0.636450 rank 0
2025-01-10 09:29:38,110 DEBUG TRAIN Batch 26/1200 loss 0.249269 acc 0.832127 lr 0.00031108 grad_norm 0.685023 rank 1
2025-01-10 09:29:38,110 DEBUG TRAIN Batch 26/1200 loss 0.284989 acc 0.797895 lr 0.00031108 grad_norm 0.685023 rank 2
2025-01-10 09:29:38,110 DEBUG TRAIN Batch 26/1200 loss 0.401779 acc 0.736940 lr 0.00031108 grad_norm 0.685023 rank 0
2025-01-10 09:30:03,148 DEBUG TRAIN Batch 26/1300 loss 0.231909 acc 0.835802 lr 0.00031077 grad_norm 0.667701 rank 2
2025-01-10 09:30:03,148 DEBUG TRAIN Batch 26/1300 loss 0.351649 acc 0.776256 lr 0.00031077 grad_norm 0.667701 rank 0
2025-01-10 09:30:03,148 DEBUG TRAIN Batch 26/1300 loss 0.409524 acc 0.741117 lr 0.00031077 grad_norm 0.667701 rank 1
2025-01-10 09:30:27,330 DEBUG TRAIN Batch 26/1400 loss 0.356659 acc 0.754286 lr 0.00031048 grad_norm 0.619592 rank 2
2025-01-10 09:30:27,330 DEBUG TRAIN Batch 26/1400 loss 0.332950 acc 0.793765 lr 0.00031048 grad_norm 0.619592 rank 1
2025-01-10 09:30:27,331 DEBUG TRAIN Batch 26/1400 loss 0.262334 acc 0.813297 lr 0.00031048 grad_norm 0.619592 rank 0
2025-01-10 09:30:52,089 DEBUG TRAIN Batch 26/1500 loss 0.303375 acc 0.785785 lr 0.00031018 grad_norm 0.655014 rank 2
2025-01-10 09:30:52,089 DEBUG TRAIN Batch 26/1500 loss 0.240822 acc 0.832175 lr 0.00031018 grad_norm 0.655014 rank 0
2025-01-10 09:30:52,090 DEBUG TRAIN Batch 26/1500 loss 0.313577 acc 0.767470 lr 0.00031018 grad_norm 0.655014 rank 1
2025-01-10 09:31:17,052 DEBUG TRAIN Batch 26/1600 loss 0.345909 acc 0.767465 lr 0.00030988 grad_norm 0.622876 rank 2
2025-01-10 09:31:17,052 DEBUG TRAIN Batch 26/1600 loss 0.284874 acc 0.796903 lr 0.00030988 grad_norm 0.622876 rank 0
2025-01-10 09:31:17,052 DEBUG TRAIN Batch 26/1600 loss 0.407029 acc 0.728139 lr 0.00030988 grad_norm 0.622876 rank 1
2025-01-10 09:31:41,108 DEBUG TRAIN Batch 26/1700 loss 0.316930 acc 0.783840 lr 0.00030958 grad_norm 0.626248 rank 2
2025-01-10 09:31:41,109 DEBUG TRAIN Batch 26/1700 loss 0.352841 acc 0.764266 lr 0.00030958 grad_norm 0.626248 rank 1
2025-01-10 09:31:41,109 DEBUG TRAIN Batch 26/1700 loss 0.230011 acc 0.837719 lr 0.00030958 grad_norm 0.626248 rank 0
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 09:32:42,090 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 09:32:42,099 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 09:32:42,532 INFO Epoch 26 Step 26087 on_batch_end True CV rank 1
2025-01-10 09:32:42,532 INFO Epoch 26 Step 26087 on_batch_end True CV rank 2
2025-01-10 09:32:42,533 INFO Epoch 26 Step 26087 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 09:32:51,882 DEBUG CV Batch 26/100 loss 0.268711 acc 0.916388  rank 0
2025-01-10 09:32:51,950 DEBUG CV Batch 26/100 loss 0.268711 acc 0.916388  rank 2
2025-01-10 09:32:52,282 DEBUG CV Batch 26/100 loss 0.268711 acc 0.916388  rank 1
2025-01-10 09:32:52,405 INFO Epoch 26 Step 26087 CV info lr 0.0003095693357091063 0 rank loss_1.506405144570428 acc_0.7357122156965105
2025-01-10 09:32:52,472 INFO Epoch 26 Step 26087 CV info lr 0.0003095693357091063 2 rank loss_1.506405144570428 acc_0.7357122156965105
2025-01-10 09:32:52,828 INFO Epoch 26 Step 26087 CV info lr 0.0003095693357091063 1 rank loss_1.506405144570428 acc_0.7357122156965105
2025-01-10 09:32:53,685 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_26_whole.pt
2025-01-10 09:32:53,697 INFO Added key: store_based_barrier_key:29 to store for rank: 0
2025-01-10 09:32:53,707 INFO Added key: store_based_barrier_key:29 to store for rank: 2
2025-01-10 09:32:53,707 INFO Added key: store_based_barrier_key:29 to store for rank: 1
2025-01-10 09:32:53,707 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:29 with 3 nodes.
2025-01-10 09:32:53,707 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:29 with 3 nodes.
2025-01-10 09:32:53,717 INFO Epoch 27 TRAIN info lr 0.0003095693357091063 rank 1
2025-01-10 09:32:53,717 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 09:32:53,717 INFO Epoch 27 TRAIN info lr 0.0003095693357091063 rank 2
2025-01-10 09:32:53,717 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 09:32:53,717 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:29 with 3 nodes.
2025-01-10 09:32:53,724 INFO Epoch 27 TRAIN info lr 0.0003095693357091063 rank 0
2025-01-10 09:32:53,724 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 09:33:24,537 DEBUG TRAIN Batch 27/100 loss 0.215467 acc 0.839483 lr 0.00030927 grad_norm 0.570587 rank 0
2025-01-10 09:33:24,537 DEBUG TRAIN Batch 27/100 loss 0.195940 acc 0.847804 lr 0.00030927 grad_norm 0.570587 rank 1
2025-01-10 09:33:24,537 DEBUG TRAIN Batch 27/100 loss 0.232235 acc 0.838835 lr 0.00030927 grad_norm 0.570587 rank 2
2025-01-10 09:33:48,392 DEBUG TRAIN Batch 27/200 loss 0.235400 acc 0.842011 lr 0.00030898 grad_norm 0.580440 rank 0
2025-01-10 09:33:48,392 DEBUG TRAIN Batch 27/200 loss 0.162958 acc 0.894737 lr 0.00030898 grad_norm 0.580440 rank 1
2025-01-10 09:33:48,393 DEBUG TRAIN Batch 27/200 loss 0.280354 acc 0.810329 lr 0.00030898 grad_norm 0.580440 rank 2
2025-01-10 09:34:11,841 DEBUG TRAIN Batch 27/300 loss 0.263135 acc 0.821353 lr 0.00030868 grad_norm 0.614983 rank 2
2025-01-10 09:34:11,841 DEBUG TRAIN Batch 27/300 loss 0.207363 acc 0.860021 lr 0.00030868 grad_norm 0.614983 rank 0
2025-01-10 09:34:11,842 DEBUG TRAIN Batch 27/300 loss 0.232451 acc 0.831703 lr 0.00030868 grad_norm 0.614983 rank 1
2025-01-10 09:34:35,472 DEBUG TRAIN Batch 27/400 loss 0.304301 acc 0.800581 lr 0.00030839 grad_norm 0.637260 rank 0
2025-01-10 09:34:35,473 DEBUG TRAIN Batch 27/400 loss 0.223519 acc 0.847758 lr 0.00030839 grad_norm 0.637260 rank 1
2025-01-10 09:34:35,473 DEBUG TRAIN Batch 27/400 loss 0.271486 acc 0.807613 lr 0.00030839 grad_norm 0.637260 rank 2
2025-01-10 09:34:59,270 DEBUG TRAIN Batch 27/500 loss 0.310838 acc 0.787879 lr 0.00030810 grad_norm 0.610538 rank 1
2025-01-10 09:34:59,271 DEBUG TRAIN Batch 27/500 loss 0.306965 acc 0.788086 lr 0.00030810 grad_norm 0.610538 rank 0
2025-01-10 09:34:59,271 DEBUG TRAIN Batch 27/500 loss 0.211841 acc 0.851064 lr 0.00030810 grad_norm 0.610538 rank 2
2025-01-10 09:35:23,486 DEBUG TRAIN Batch 27/600 loss 0.290270 acc 0.804124 lr 0.00030780 grad_norm 0.654200 rank 1
2025-01-10 09:35:23,486 DEBUG TRAIN Batch 27/600 loss 0.315509 acc 0.780943 lr 0.00030780 grad_norm 0.654200 rank 0
2025-01-10 09:35:23,486 DEBUG TRAIN Batch 27/600 loss 0.342955 acc 0.763021 lr 0.00030780 grad_norm 0.654200 rank 2
2025-01-10 09:35:48,639 DEBUG TRAIN Batch 27/700 loss 0.319032 acc 0.777887 lr 0.00030751 grad_norm 0.639611 rank 2
2025-01-10 09:35:48,639 DEBUG TRAIN Batch 27/700 loss 0.210683 acc 0.858081 lr 0.00030751 grad_norm 0.639611 rank 0
2025-01-10 09:35:48,640 DEBUG TRAIN Batch 27/700 loss 0.315549 acc 0.782064 lr 0.00030751 grad_norm 0.639611 rank 1
2025-01-10 09:36:12,771 DEBUG TRAIN Batch 27/800 loss 0.287059 acc 0.802277 lr 0.00030722 grad_norm 0.617338 rank 1
2025-01-10 09:36:12,771 DEBUG TRAIN Batch 27/800 loss 0.328326 acc 0.773090 lr 0.00030722 grad_norm 0.617338 rank 0
2025-01-10 09:36:12,771 DEBUG TRAIN Batch 27/800 loss 0.245790 acc 0.833144 lr 0.00030722 grad_norm 0.617338 rank 2
2025-01-10 09:36:37,444 DEBUG TRAIN Batch 27/900 loss 0.301302 acc 0.786946 lr 0.00030693 grad_norm 0.658215 rank 1
2025-01-10 09:36:37,444 DEBUG TRAIN Batch 27/900 loss 0.300578 acc 0.809972 lr 0.00030693 grad_norm 0.658215 rank 2
2025-01-10 09:36:37,444 DEBUG TRAIN Batch 27/900 loss 0.310787 acc 0.785450 lr 0.00030693 grad_norm 0.658215 rank 0
2025-01-10 09:37:02,752 DEBUG TRAIN Batch 27/1000 loss 0.166726 acc 0.884417 lr 0.00030664 grad_norm 0.611207 rank 1
2025-01-10 09:37:02,752 DEBUG TRAIN Batch 27/1000 loss 0.169120 acc 0.872757 lr 0.00030664 grad_norm 0.611207 rank 0
2025-01-10 09:37:02,752 DEBUG TRAIN Batch 27/1000 loss 0.270449 acc 0.825234 lr 0.00030664 grad_norm 0.611207 rank 2
2025-01-10 09:37:27,621 DEBUG TRAIN Batch 27/1100 loss 0.304332 acc 0.795499 lr 0.00030636 grad_norm 0.622588 rank 2
2025-01-10 09:37:27,621 DEBUG TRAIN Batch 27/1100 loss 0.317861 acc 0.784400 lr 0.00030636 grad_norm 0.622588 rank 0
2025-01-10 09:37:27,622 DEBUG TRAIN Batch 27/1100 loss 0.179221 acc 0.879506 lr 0.00030636 grad_norm 0.622588 rank 1
2025-01-10 09:37:52,355 DEBUG TRAIN Batch 27/1200 loss 0.115943 acc 0.916248 lr 0.00030607 grad_norm 0.632858 rank 1
2025-01-10 09:37:52,355 DEBUG TRAIN Batch 27/1200 loss 0.309497 acc 0.788789 lr 0.00030607 grad_norm 0.632858 rank 0
2025-01-10 09:37:52,356 DEBUG TRAIN Batch 27/1200 loss 0.309598 acc 0.791625 lr 0.00030607 grad_norm 0.632858 rank 2
2025-01-10 09:38:16,327 DEBUG TRAIN Batch 27/1300 loss 0.110395 acc 0.920659 lr 0.00030578 grad_norm 0.600259 rank 1
2025-01-10 09:38:16,327 DEBUG TRAIN Batch 27/1300 loss 0.284688 acc 0.805479 lr 0.00030578 grad_norm 0.600259 rank 0
2025-01-10 09:38:16,328 DEBUG TRAIN Batch 27/1300 loss 0.278458 acc 0.811031 lr 0.00030578 grad_norm 0.600259 rank 2
2025-01-10 09:38:40,716 DEBUG TRAIN Batch 27/1400 loss 0.144044 acc 0.900383 lr 0.00030550 grad_norm 0.642222 rank 1
2025-01-10 09:38:40,716 DEBUG TRAIN Batch 27/1400 loss 0.327358 acc 0.779070 lr 0.00030550 grad_norm 0.642222 rank 0
2025-01-10 09:38:40,716 DEBUG TRAIN Batch 27/1400 loss 0.227830 acc 0.852911 lr 0.00030550 grad_norm 0.642222 rank 2
2025-01-10 09:39:05,950 DEBUG TRAIN Batch 27/1500 loss 0.224076 acc 0.853818 lr 0.00030521 grad_norm 0.631840 rank 1
2025-01-10 09:39:05,951 DEBUG TRAIN Batch 27/1500 loss 0.252956 acc 0.829746 lr 0.00030521 grad_norm 0.631840 rank 2
2025-01-10 09:39:05,951 DEBUG TRAIN Batch 27/1500 loss 0.298399 acc 0.803437 lr 0.00030521 grad_norm 0.631840 rank 0
2025-01-10 09:39:29,894 DEBUG TRAIN Batch 27/1600 loss 0.166307 acc 0.887019 lr 0.00030493 grad_norm 0.641769 rank 1
2025-01-10 09:39:29,894 DEBUG TRAIN Batch 27/1600 loss 0.250764 acc 0.832545 lr 0.00030493 grad_norm 0.641769 rank 2
2025-01-10 09:39:29,895 DEBUG TRAIN Batch 27/1600 loss 0.299074 acc 0.794340 lr 0.00030493 grad_norm 0.641769 rank 0
2025-01-10 09:39:54,331 DEBUG TRAIN Batch 27/1700 loss 0.290414 acc 0.815298 lr 0.00030465 grad_norm 0.605559 rank 1
2025-01-10 09:39:54,331 DEBUG TRAIN Batch 27/1700 loss 0.221276 acc 0.849751 lr 0.00030465 grad_norm 0.605559 rank 2
2025-01-10 09:39:54,331 DEBUG TRAIN Batch 27/1700 loss 0.254926 acc 0.820000 lr 0.00030465 grad_norm 0.605559 rank 0
2025-01-10 09:40:19,299 DEBUG TRAIN Batch 27/1800 loss 0.235965 acc 0.829524 lr 0.00030436 grad_norm 0.645242 rank 2
2025-01-10 09:40:19,299 DEBUG TRAIN Batch 27/1800 loss 0.289742 acc 0.800393 lr 0.00030436 grad_norm 0.645242 rank 0
2025-01-10 09:40:19,300 DEBUG TRAIN Batch 27/1800 loss 0.127421 acc 0.925397 lr 0.00030436 grad_norm 0.645242 rank 1
2025-01-10 09:40:43,356 DEBUG TRAIN Batch 27/1900 loss 0.254850 acc 0.804767 lr 0.00030408 grad_norm 0.662510 rank 2
2025-01-10 09:40:43,356 DEBUG TRAIN Batch 27/1900 loss 0.179983 acc 0.875969 lr 0.00030408 grad_norm 0.662510 rank 0
2025-01-10 09:40:43,357 DEBUG TRAIN Batch 27/1900 loss 0.145306 acc 0.896067 lr 0.00030408 grad_norm 0.662510 rank 1
2025-01-10 09:41:08,583 DEBUG TRAIN Batch 27/2000 loss 0.201267 acc 0.871445 lr 0.00030380 grad_norm 0.657649 rank 1
2025-01-10 09:41:08,583 DEBUG TRAIN Batch 27/2000 loss 0.285734 acc 0.801217 lr 0.00030380 grad_norm 0.657649 rank 2
2025-01-10 09:41:08,583 DEBUG TRAIN Batch 27/2000 loss 0.358458 acc 0.767686 lr 0.00030380 grad_norm 0.657649 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 09:42:24,774 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 09:42:24,777 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 09:42:25,218 INFO Epoch 27 Step 27120 on_batch_end True CV rank 0
2025-01-10 09:42:25,218 INFO Epoch 27 Step 27120 on_batch_end True CV rank 1
2025-01-10 09:42:25,218 INFO Epoch 27 Step 27120 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 09:42:34,283 DEBUG CV Batch 27/100 loss 0.201435 acc 0.942029  rank 0
2025-01-10 09:42:34,811 INFO Epoch 27 Step 27120 CV info lr 0.0003036163547232877 0 rank loss_1.5282471485174538 acc_0.7450153712640729
2025-01-10 09:42:34,934 DEBUG CV Batch 27/100 loss 0.201435 acc 0.942029  rank 2
2025-01-10 09:42:35,098 DEBUG CV Batch 27/100 loss 0.201435 acc 0.942029  rank 1
2025-01-10 09:42:35,488 INFO Epoch 27 Step 27120 CV info lr 0.0003036163547232877 2 rank loss_1.5282471485174538 acc_0.7450153712640729
2025-01-10 09:42:35,660 INFO Epoch 27 Step 27120 CV info lr 0.0003036163547232877 1 rank loss_1.5282471485174538 acc_0.7450153712640729
2025-01-10 09:42:36,094 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_27_whole.pt
2025-01-10 09:42:36,105 INFO Added key: store_based_barrier_key:30 to store for rank: 0
2025-01-10 09:42:36,116 INFO Added key: store_based_barrier_key:30 to store for rank: 1
2025-01-10 09:42:36,116 INFO Added key: store_based_barrier_key:30 to store for rank: 2
2025-01-10 09:42:36,116 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:30 with 3 nodes.
2025-01-10 09:42:36,116 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:30 with 3 nodes.
2025-01-10 09:42:36,118 INFO Epoch 28 TRAIN info lr 0.0003036163547232877 rank 2
2025-01-10 09:42:36,118 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 09:42:36,124 INFO Epoch 28 TRAIN info lr 0.0003036163547232877 rank 1
2025-01-10 09:42:36,124 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 09:42:36,126 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:30 with 3 nodes.
2025-01-10 09:42:36,129 INFO Epoch 28 TRAIN info lr 0.0003036163547232877 rank 0
2025-01-10 09:42:36,129 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 09:43:07,006 DEBUG TRAIN Batch 28/100 loss 0.255054 acc 0.817158 lr 0.00030334 grad_norm 0.608843 rank 2
2025-01-10 09:43:07,007 DEBUG TRAIN Batch 28/100 loss 0.242951 acc 0.837959 lr 0.00030334 grad_norm 0.608843 rank 1
2025-01-10 09:43:07,007 DEBUG TRAIN Batch 28/100 loss 0.258781 acc 0.823028 lr 0.00030334 grad_norm 0.608843 rank 0
2025-01-10 09:43:30,822 DEBUG TRAIN Batch 28/200 loss 0.248332 acc 0.828821 lr 0.00030306 grad_norm 0.620247 rank 0
2025-01-10 09:43:30,822 DEBUG TRAIN Batch 28/200 loss 0.145897 acc 0.911911 lr 0.00030306 grad_norm 0.620247 rank 2
2025-01-10 09:43:30,822 DEBUG TRAIN Batch 28/200 loss 0.352311 acc 0.757374 lr 0.00030306 grad_norm 0.620247 rank 1
2025-01-10 09:43:54,537 DEBUG TRAIN Batch 28/300 loss 0.276025 acc 0.811050 lr 0.00030278 grad_norm 0.609137 rank 1
2025-01-10 09:43:54,537 DEBUG TRAIN Batch 28/300 loss 0.208665 acc 0.846813 lr 0.00030278 grad_norm 0.609137 rank 2
2025-01-10 09:43:54,537 DEBUG TRAIN Batch 28/300 loss 0.273357 acc 0.819945 lr 0.00030278 grad_norm 0.609137 rank 0
2025-01-10 09:44:18,747 DEBUG TRAIN Batch 28/400 loss 0.151853 acc 0.895447 lr 0.00030250 grad_norm 0.603077 rank 1
2025-01-10 09:44:18,747 DEBUG TRAIN Batch 28/400 loss 0.231981 acc 0.845761 lr 0.00030250 grad_norm 0.603077 rank 0
2025-01-10 09:44:18,748 DEBUG TRAIN Batch 28/400 loss 0.231328 acc 0.838221 lr 0.00030250 grad_norm 0.603077 rank 2
2025-01-10 09:44:43,289 DEBUG TRAIN Batch 28/500 loss 0.321713 acc 0.768672 lr 0.00030223 grad_norm 0.599986 rank 1
2025-01-10 09:44:43,290 DEBUG TRAIN Batch 28/500 loss 0.194096 acc 0.867925 lr 0.00030223 grad_norm 0.599986 rank 2
2025-01-10 09:44:43,290 DEBUG TRAIN Batch 28/500 loss 0.222598 acc 0.864655 lr 0.00030223 grad_norm 0.599986 rank 0
2025-01-10 09:45:08,012 DEBUG TRAIN Batch 28/600 loss 0.177241 acc 0.883188 lr 0.00030195 grad_norm 0.620810 rank 2
2025-01-10 09:45:08,013 DEBUG TRAIN Batch 28/600 loss 0.272561 acc 0.816522 lr 0.00030195 grad_norm 0.620810 rank 0
2025-01-10 09:45:08,013 DEBUG TRAIN Batch 28/600 loss 0.326380 acc 0.777778 lr 0.00030195 grad_norm 0.620810 rank 1
2025-01-10 09:45:32,671 DEBUG TRAIN Batch 28/700 loss 0.244789 acc 0.830827 lr 0.00030168 grad_norm 0.621049 rank 2
2025-01-10 09:45:32,671 DEBUG TRAIN Batch 28/700 loss 0.222695 acc 0.844350 lr 0.00030168 grad_norm 0.621049 rank 0
2025-01-10 09:45:32,671 DEBUG TRAIN Batch 28/700 loss 0.163657 acc 0.891089 lr 0.00030168 grad_norm 0.621049 rank 1
2025-01-10 09:45:56,756 DEBUG TRAIN Batch 28/800 loss 0.244254 acc 0.823869 lr 0.00030140 grad_norm 0.616584 rank 2
2025-01-10 09:45:56,756 DEBUG TRAIN Batch 28/800 loss 0.214280 acc 0.858038 lr 0.00030140 grad_norm 0.616584 rank 0
2025-01-10 09:45:56,756 DEBUG TRAIN Batch 28/800 loss 0.178395 acc 0.871490 lr 0.00030140 grad_norm 0.616584 rank 1
2025-01-10 09:46:22,251 DEBUG TRAIN Batch 28/900 loss 0.283816 acc 0.814208 lr 0.00030113 grad_norm 0.613673 rank 0
2025-01-10 09:46:22,251 DEBUG TRAIN Batch 28/900 loss 0.175255 acc 0.872050 lr 0.00030113 grad_norm 0.613673 rank 1
2025-01-10 09:46:22,251 DEBUG TRAIN Batch 28/900 loss 0.163056 acc 0.889294 lr 0.00030113 grad_norm 0.613673 rank 2
2025-01-10 09:46:46,244 DEBUG TRAIN Batch 28/1000 loss 0.299639 acc 0.782453 lr 0.00030086 grad_norm 0.636160 rank 0
2025-01-10 09:46:46,244 DEBUG TRAIN Batch 28/1000 loss 0.284400 acc 0.795218 lr 0.00030086 grad_norm 0.636160 rank 1
2025-01-10 09:46:46,245 DEBUG TRAIN Batch 28/1000 loss 0.231802 acc 0.837231 lr 0.00030086 grad_norm 0.636160 rank 2
2025-01-10 09:47:10,967 DEBUG TRAIN Batch 28/1100 loss 0.222403 acc 0.848245 lr 0.00030058 grad_norm 0.611970 rank 0
2025-01-10 09:47:10,967 DEBUG TRAIN Batch 28/1100 loss 0.150034 acc 0.898588 lr 0.00030058 grad_norm 0.611970 rank 2
2025-01-10 09:47:10,967 DEBUG TRAIN Batch 28/1100 loss 0.123398 acc 0.916800 lr 0.00030058 grad_norm 0.611970 rank 1
2025-01-10 09:47:35,646 DEBUG TRAIN Batch 28/1200 loss 0.215872 acc 0.854749 lr 0.00030031 grad_norm 0.600881 rank 1
2025-01-10 09:47:35,646 DEBUG TRAIN Batch 28/1200 loss 0.248383 acc 0.832898 lr 0.00030031 grad_norm 0.600881 rank 2
2025-01-10 09:47:35,647 DEBUG TRAIN Batch 28/1200 loss 0.270805 acc 0.809198 lr 0.00030031 grad_norm 0.600881 rank 0
2025-01-10 09:47:59,862 DEBUG TRAIN Batch 28/1300 loss 0.283267 acc 0.800000 lr 0.00030004 grad_norm 0.626168 rank 0
2025-01-10 09:47:59,862 DEBUG TRAIN Batch 28/1300 loss 0.300178 acc 0.808511 lr 0.00030004 grad_norm 0.626168 rank 1
2025-01-10 09:47:59,862 DEBUG TRAIN Batch 28/1300 loss 0.193879 acc 0.874690 lr 0.00030004 grad_norm 0.626168 rank 2
2025-01-10 09:48:24,891 DEBUG TRAIN Batch 28/1400 loss 0.253282 acc 0.838235 lr 0.00029977 grad_norm 0.632749 rank 1
2025-01-10 09:48:24,891 DEBUG TRAIN Batch 28/1400 loss 0.259252 acc 0.816840 lr 0.00029977 grad_norm 0.632749 rank 0
2025-01-10 09:48:24,891 DEBUG TRAIN Batch 28/1400 loss 0.305883 acc 0.788940 lr 0.00029977 grad_norm 0.632749 rank 2
2025-01-10 09:48:51,041 DEBUG TRAIN Batch 28/1500 loss 0.192433 acc 0.870550 lr 0.00029950 grad_norm 0.650407 rank 1
2025-01-10 09:48:51,042 DEBUG TRAIN Batch 28/1500 loss 0.269448 acc 0.814499 lr 0.00029950 grad_norm 0.650407 rank 0
2025-01-10 09:48:51,042 DEBUG TRAIN Batch 28/1500 loss 0.309858 acc 0.784909 lr 0.00029950 grad_norm 0.650407 rank 2
2025-01-10 09:49:15,027 DEBUG TRAIN Batch 28/1600 loss 0.213525 acc 0.846230 lr 0.00029923 grad_norm 0.627756 rank 0
2025-01-10 09:49:15,027 DEBUG TRAIN Batch 28/1600 loss 0.232985 acc 0.833182 lr 0.00029923 grad_norm 0.627756 rank 2
2025-01-10 09:49:15,027 DEBUG TRAIN Batch 28/1600 loss 0.307354 acc 0.789762 lr 0.00029923 grad_norm 0.627756 rank 1
2025-01-10 09:49:38,914 DEBUG TRAIN Batch 28/1700 loss 0.228917 acc 0.842767 lr 0.00029897 grad_norm 0.652284 rank 2
2025-01-10 09:49:38,915 DEBUG TRAIN Batch 28/1700 loss 0.294271 acc 0.808244 lr 0.00029897 grad_norm 0.652284 rank 0
2025-01-10 09:49:38,915 DEBUG TRAIN Batch 28/1700 loss 0.271029 acc 0.812500 lr 0.00029897 grad_norm 0.652284 rank 1
2025-01-10 09:50:03,338 DEBUG TRAIN Batch 28/1800 loss 0.247952 acc 0.820158 lr 0.00029870 grad_norm 0.634613 rank 1
2025-01-10 09:50:03,338 DEBUG TRAIN Batch 28/1800 loss 0.258152 acc 0.821005 lr 0.00029870 grad_norm 0.634613 rank 2
2025-01-10 09:50:03,338 DEBUG TRAIN Batch 28/1800 loss 0.257328 acc 0.825893 lr 0.00029870 grad_norm 0.634613 rank 0
2025-01-10 09:50:27,262 DEBUG TRAIN Batch 28/1900 loss 0.307775 acc 0.772887 lr 0.00029843 grad_norm 0.641515 rank 0
2025-01-10 09:50:27,262 DEBUG TRAIN Batch 28/1900 loss 0.263215 acc 0.811550 lr 0.00029843 grad_norm 0.641515 rank 1
2025-01-10 09:50:27,262 DEBUG TRAIN Batch 28/1900 loss 0.234840 acc 0.845188 lr 0.00029843 grad_norm 0.641515 rank 2
2025-01-10 09:50:51,305 DEBUG TRAIN Batch 28/2000 loss 0.250773 acc 0.823475 lr 0.00029817 grad_norm 0.679304 rank 2
2025-01-10 09:50:51,305 DEBUG TRAIN Batch 28/2000 loss 0.212403 acc 0.853357 lr 0.00029817 grad_norm 0.679304 rank 0
2025-01-10 09:50:51,305 DEBUG TRAIN Batch 28/2000 loss 0.233690 acc 0.835947 lr 0.00029817 grad_norm 0.679304 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 09:52:08,664 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59996ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 09:52:08,665 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 09:52:09,072 INFO Epoch 28 Step 28155 on_batch_end True CV rank 1
2025-01-10 09:52:09,072 INFO Epoch 28 Step 28155 on_batch_end True CV rank 0
2025-01-10 09:52:09,072 INFO Epoch 28 Step 28155 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 09:52:18,066 DEBUG CV Batch 28/100 loss 0.178448 acc 0.942029  rank 0
2025-01-10 09:52:18,475 DEBUG CV Batch 28/100 loss 0.178448 acc 0.942029  rank 2
2025-01-10 09:52:18,583 INFO Epoch 28 Step 28155 CV info lr 0.00029798351481602687 0 rank loss_1.5417152166431933 acc_0.750339419695369
2025-01-10 09:52:19,008 INFO Epoch 28 Step 28155 CV info lr 0.00029798351481602687 2 rank loss_1.5417152166431933 acc_0.750339419695369
2025-01-10 09:52:19,011 DEBUG CV Batch 28/100 loss 0.178448 acc 0.942029  rank 1
2025-01-10 09:52:19,564 INFO Epoch 28 Step 28155 CV info lr 0.00029798351481602687 1 rank loss_1.5417152166431933 acc_0.750339419695369
2025-01-10 09:52:19,870 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_28_whole.pt
2025-01-10 09:52:19,881 INFO Added key: store_based_barrier_key:31 to store for rank: 0
2025-01-10 09:52:19,891 INFO Added key: store_based_barrier_key:31 to store for rank: 2
2025-01-10 09:52:19,892 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:31 with 3 nodes.
2025-01-10 09:52:19,891 INFO Added key: store_based_barrier_key:31 to store for rank: 1
2025-01-10 09:52:19,892 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:31 with 3 nodes.
2025-01-10 09:52:19,893 INFO Epoch 29 TRAIN info lr 0.00029798351481602687 rank 2
2025-01-10 09:52:19,893 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 09:52:19,899 INFO Epoch 29 TRAIN info lr 0.00029798351481602687 rank 1
2025-01-10 09:52:19,899 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 09:52:19,902 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:31 with 3 nodes.
2025-01-10 09:52:19,903 INFO Epoch 29 TRAIN info lr 0.00029798351481602687 rank 0
2025-01-10 09:52:19,903 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 09:52:53,332 DEBUG TRAIN Batch 29/100 loss 0.335218 acc 0.773186 lr 0.00029772 grad_norm 0.608741 rank 0
2025-01-10 09:52:53,332 DEBUG TRAIN Batch 29/100 loss 0.183926 acc 0.878296 lr 0.00029772 grad_norm 0.608741 rank 2
2025-01-10 09:52:53,333 DEBUG TRAIN Batch 29/100 loss 0.154045 acc 0.890511 lr 0.00029772 grad_norm 0.608741 rank 1
2025-01-10 09:53:17,481 DEBUG TRAIN Batch 29/200 loss 0.213648 acc 0.852755 lr 0.00029746 grad_norm 0.606033 rank 1
2025-01-10 09:53:17,481 DEBUG TRAIN Batch 29/200 loss 0.246909 acc 0.834802 lr 0.00029746 grad_norm 0.606033 rank 0
2025-01-10 09:53:17,482 DEBUG TRAIN Batch 29/200 loss 0.216973 acc 0.852283 lr 0.00029746 grad_norm 0.606033 rank 2
2025-01-10 09:53:42,363 DEBUG TRAIN Batch 29/300 loss 0.233035 acc 0.842256 lr 0.00029719 grad_norm 0.626913 rank 2
2025-01-10 09:53:42,363 DEBUG TRAIN Batch 29/300 loss 0.375443 acc 0.748509 lr 0.00029719 grad_norm 0.626913 rank 0
2025-01-10 09:53:42,363 DEBUG TRAIN Batch 29/300 loss 0.213163 acc 0.861165 lr 0.00029719 grad_norm 0.626913 rank 1
2025-01-10 09:54:06,906 DEBUG TRAIN Batch 29/400 loss 0.215164 acc 0.841965 lr 0.00029693 grad_norm 0.659221 rank 1
2025-01-10 09:54:06,907 DEBUG TRAIN Batch 29/400 loss 0.196790 acc 0.854945 lr 0.00029693 grad_norm 0.659221 rank 2
2025-01-10 09:54:06,907 DEBUG TRAIN Batch 29/400 loss 0.316722 acc 0.768627 lr 0.00029693 grad_norm 0.659221 rank 0
2025-01-10 09:54:31,017 DEBUG TRAIN Batch 29/500 loss 0.211666 acc 0.846813 lr 0.00029667 grad_norm 0.621648 rank 2
2025-01-10 09:54:31,017 DEBUG TRAIN Batch 29/500 loss 0.163990 acc 0.893761 lr 0.00029667 grad_norm 0.621648 rank 0
2025-01-10 09:54:31,017 DEBUG TRAIN Batch 29/500 loss 0.182298 acc 0.869748 lr 0.00029667 grad_norm 0.621648 rank 1
2025-01-10 09:54:55,335 DEBUG TRAIN Batch 29/600 loss 0.225981 acc 0.843330 lr 0.00029641 grad_norm 0.645358 rank 1
2025-01-10 09:54:55,335 DEBUG TRAIN Batch 29/600 loss 0.210615 acc 0.856992 lr 0.00029641 grad_norm 0.645358 rank 2
2025-01-10 09:54:55,336 DEBUG TRAIN Batch 29/600 loss 0.214930 acc 0.850000 lr 0.00029641 grad_norm 0.645358 rank 0
2025-01-10 09:55:19,627 DEBUG TRAIN Batch 29/700 loss 0.230560 acc 0.837599 lr 0.00029615 grad_norm 0.649066 rank 1
2025-01-10 09:55:19,627 DEBUG TRAIN Batch 29/700 loss 0.223719 acc 0.842246 lr 0.00029615 grad_norm 0.649066 rank 2
2025-01-10 09:55:19,627 DEBUG TRAIN Batch 29/700 loss 0.159957 acc 0.894895 lr 0.00029615 grad_norm 0.649066 rank 0
2025-01-10 09:55:43,869 DEBUG TRAIN Batch 29/800 loss 0.184799 acc 0.874449 lr 0.00029589 grad_norm 0.585439 rank 1
2025-01-10 09:55:43,870 DEBUG TRAIN Batch 29/800 loss 0.267636 acc 0.815050 lr 0.00029589 grad_norm 0.585439 rank 0
2025-01-10 09:55:43,870 DEBUG TRAIN Batch 29/800 loss 0.213606 acc 0.861883 lr 0.00029589 grad_norm 0.585439 rank 2
2025-01-10 09:56:08,072 DEBUG TRAIN Batch 29/900 loss 0.251011 acc 0.833667 lr 0.00029563 grad_norm 0.632334 rank 2
2025-01-10 09:56:08,072 DEBUG TRAIN Batch 29/900 loss 0.248575 acc 0.829417 lr 0.00029563 grad_norm 0.632334 rank 0
2025-01-10 09:56:08,072 DEBUG TRAIN Batch 29/900 loss 0.257279 acc 0.833479 lr 0.00029563 grad_norm 0.632334 rank 1
2025-01-10 09:56:31,964 DEBUG TRAIN Batch 29/1000 loss 0.267234 acc 0.808411 lr 0.00029537 grad_norm 0.627513 rank 0
2025-01-10 09:56:31,965 DEBUG TRAIN Batch 29/1000 loss 0.219385 acc 0.841802 lr 0.00029537 grad_norm 0.627513 rank 1
2025-01-10 09:56:31,965 DEBUG TRAIN Batch 29/1000 loss 0.254511 acc 0.825447 lr 0.00029537 grad_norm 0.627513 rank 2
2025-01-10 09:56:56,610 DEBUG TRAIN Batch 29/1100 loss 0.209728 acc 0.854806 lr 0.00029511 grad_norm 0.623501 rank 1
2025-01-10 09:56:56,610 DEBUG TRAIN Batch 29/1100 loss 0.215646 acc 0.863920 lr 0.00029511 grad_norm 0.623501 rank 2
2025-01-10 09:56:56,611 DEBUG TRAIN Batch 29/1100 loss 0.278437 acc 0.803670 lr 0.00029511 grad_norm 0.623501 rank 0
2025-01-10 09:57:20,489 DEBUG TRAIN Batch 29/1200 loss 0.216520 acc 0.854350 lr 0.00029486 grad_norm 0.609242 rank 0
2025-01-10 09:57:20,490 DEBUG TRAIN Batch 29/1200 loss 0.325962 acc 0.779209 lr 0.00029486 grad_norm 0.609242 rank 2
2025-01-10 09:57:20,490 DEBUG TRAIN Batch 29/1200 loss 0.238622 acc 0.824226 lr 0.00029486 grad_norm 0.609242 rank 1
2025-01-10 09:57:44,939 DEBUG TRAIN Batch 29/1300 loss 0.249731 acc 0.831451 lr 0.00029460 grad_norm 0.621575 rank 0
2025-01-10 09:57:44,939 DEBUG TRAIN Batch 29/1300 loss 0.161938 acc 0.896437 lr 0.00029460 grad_norm 0.621575 rank 1
2025-01-10 09:57:44,940 DEBUG TRAIN Batch 29/1300 loss 0.345647 acc 0.756609 lr 0.00029460 grad_norm 0.621575 rank 2
2025-01-10 09:58:09,618 DEBUG TRAIN Batch 29/1400 loss 0.238475 acc 0.838335 lr 0.00029435 grad_norm 0.638384 rank 2
2025-01-10 09:58:09,619 DEBUG TRAIN Batch 29/1400 loss 0.219644 acc 0.848602 lr 0.00029435 grad_norm 0.638384 rank 0
2025-01-10 09:58:09,619 DEBUG TRAIN Batch 29/1400 loss 0.149170 acc 0.887372 lr 0.00029435 grad_norm 0.638384 rank 1
2025-01-10 09:58:33,499 DEBUG TRAIN Batch 29/1500 loss 0.212880 acc 0.841016 lr 0.00029409 grad_norm 0.681809 rank 1
2025-01-10 09:58:33,499 DEBUG TRAIN Batch 29/1500 loss 0.182505 acc 0.871609 lr 0.00029409 grad_norm 0.681809 rank 0
2025-01-10 09:58:33,499 DEBUG TRAIN Batch 29/1500 loss 0.228365 acc 0.848775 lr 0.00029409 grad_norm 0.681809 rank 2
2025-01-10 09:58:57,331 DEBUG TRAIN Batch 29/1600 loss 0.270541 acc 0.815134 lr 0.00029384 grad_norm 0.640673 rank 1
2025-01-10 09:58:57,332 DEBUG TRAIN Batch 29/1600 loss 0.180779 acc 0.881551 lr 0.00029384 grad_norm 0.640673 rank 0
2025-01-10 09:58:57,332 DEBUG TRAIN Batch 29/1600 loss 0.226317 acc 0.845685 lr 0.00029384 grad_norm 0.640673 rank 2
2025-01-10 09:59:21,128 DEBUG TRAIN Batch 29/1700 loss 0.230775 acc 0.817661 lr 0.00029358 grad_norm 0.635884 rank 1
2025-01-10 09:59:21,128 DEBUG TRAIN Batch 29/1700 loss 0.242877 acc 0.828947 lr 0.00029358 grad_norm 0.635884 rank 0
2025-01-10 09:59:21,129 DEBUG TRAIN Batch 29/1700 loss 0.159625 acc 0.896725 lr 0.00029358 grad_norm 0.635884 rank 2
2025-01-10 09:59:45,991 DEBUG TRAIN Batch 29/1800 loss 0.237685 acc 0.834901 lr 0.00029333 grad_norm 0.664730 rank 2
2025-01-10 09:59:45,991 DEBUG TRAIN Batch 29/1800 loss 0.257822 acc 0.818016 lr 0.00029333 grad_norm 0.664730 rank 1
2025-01-10 09:59:45,991 DEBUG TRAIN Batch 29/1800 loss 0.344822 acc 0.764706 lr 0.00029333 grad_norm 0.664730 rank 0
2025-01-10 10:00:10,257 DEBUG TRAIN Batch 29/1900 loss 0.174241 acc 0.875949 lr 0.00029308 grad_norm 0.627994 rank 2
2025-01-10 10:00:10,257 DEBUG TRAIN Batch 29/1900 loss 0.220003 acc 0.843045 lr 0.00029308 grad_norm 0.627994 rank 0
2025-01-10 10:00:10,257 DEBUG TRAIN Batch 29/1900 loss 0.315495 acc 0.776636 lr 0.00029308 grad_norm 0.627994 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 10:01:29,509 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 10:01:29,509 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 10:01:29,977 INFO Epoch 29 Step 29144 on_batch_end True CV rank 1
2025-01-10 10:01:29,977 INFO Epoch 29 Step 29144 on_batch_end True CV rank 0
2025-01-10 10:01:29,977 INFO Epoch 29 Step 29144 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 10:01:39,618 DEBUG CV Batch 29/100 loss 0.139725 acc 0.950948  rank 0
2025-01-10 10:01:39,685 DEBUG CV Batch 29/100 loss 0.139725 acc 0.950948  rank 2
2025-01-10 10:01:39,964 DEBUG CV Batch 29/100 loss 0.139725 acc 0.950948  rank 1
2025-01-10 10:01:40,161 INFO Epoch 29 Step 29144 CV info lr 0.00029288385030021004 0 rank loss_1.5640624203114657 acc_0.7532400488853455
2025-01-10 10:01:40,221 INFO Epoch 29 Step 29144 CV info lr 0.00029288385030021004 2 rank loss_1.5640624203114657 acc_0.7532400488853455
2025-01-10 10:01:40,519 INFO Epoch 29 Step 29144 CV info lr 0.00029288385030021004 1 rank loss_1.5640624203114657 acc_0.7532400488853455
2025-01-10 10:01:41,462 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_29_whole.pt
2025-01-10 10:01:41,474 INFO Added key: store_based_barrier_key:32 to store for rank: 0
2025-01-10 10:01:41,484 INFO Added key: store_based_barrier_key:32 to store for rank: 2
2025-01-10 10:01:41,484 INFO Added key: store_based_barrier_key:32 to store for rank: 1
2025-01-10 10:01:41,484 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:32 with 3 nodes.
2025-01-10 10:01:41,484 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:32 with 3 nodes.
2025-01-10 10:01:41,485 INFO Epoch 30 TRAIN info lr 0.00029288385030021004 rank 2
2025-01-10 10:01:41,485 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 10:01:41,489 INFO Epoch 30 TRAIN info lr 0.00029288385030021004 rank 1
2025-01-10 10:01:41,489 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 10:01:41,494 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:32 with 3 nodes.
2025-01-10 10:01:41,497 INFO Epoch 30 TRAIN info lr 0.00029288385030021004 rank 0
2025-01-10 10:01:41,497 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 10:02:12,813 DEBUG TRAIN Batch 30/100 loss 0.228181 acc 0.846465 lr 0.00029263 grad_norm 0.610346 rank 1
2025-01-10 10:02:12,813 DEBUG TRAIN Batch 30/100 loss 0.257354 acc 0.822154 lr 0.00029263 grad_norm 0.610346 rank 2
2025-01-10 10:02:12,908 DEBUG TRAIN Batch 30/100 loss 0.299302 acc 0.804214 lr 0.00029263 grad_norm 0.610346 rank 0
2025-01-10 10:02:37,244 DEBUG TRAIN Batch 30/200 loss 0.205805 acc 0.865633 lr 0.00029238 grad_norm 0.658755 rank 2
2025-01-10 10:02:37,244 DEBUG TRAIN Batch 30/200 loss 0.172005 acc 0.877153 lr 0.00029238 grad_norm 0.658755 rank 0
2025-01-10 10:02:37,244 DEBUG TRAIN Batch 30/200 loss 0.240693 acc 0.826512 lr 0.00029238 grad_norm 0.658755 rank 1
2025-01-10 10:03:01,271 DEBUG TRAIN Batch 30/300 loss 0.217536 acc 0.847637 lr 0.00029213 grad_norm 0.601503 rank 1
2025-01-10 10:03:01,272 DEBUG TRAIN Batch 30/300 loss 0.271956 acc 0.817922 lr 0.00029213 grad_norm 0.601503 rank 2
2025-01-10 10:03:01,272 DEBUG TRAIN Batch 30/300 loss 0.300593 acc 0.804810 lr 0.00029213 grad_norm 0.601503 rank 0
2025-01-10 10:03:25,215 DEBUG TRAIN Batch 30/400 loss 0.230604 acc 0.848233 lr 0.00029188 grad_norm 0.631704 rank 2
2025-01-10 10:03:25,215 DEBUG TRAIN Batch 30/400 loss 0.199751 acc 0.852222 lr 0.00029188 grad_norm 0.631704 rank 1
2025-01-10 10:03:25,216 DEBUG TRAIN Batch 30/400 loss 0.312856 acc 0.788393 lr 0.00029188 grad_norm 0.631704 rank 0
2025-01-10 10:03:49,473 DEBUG TRAIN Batch 30/500 loss 0.228699 acc 0.840000 lr 0.00029164 grad_norm 0.633304 rank 2
2025-01-10 10:03:49,473 DEBUG TRAIN Batch 30/500 loss 0.167138 acc 0.871739 lr 0.00029164 grad_norm 0.633304 rank 0
2025-01-10 10:03:49,473 DEBUG TRAIN Batch 30/500 loss 0.245524 acc 0.833185 lr 0.00029164 grad_norm 0.633304 rank 1
2025-01-10 10:04:12,848 DEBUG TRAIN Batch 30/600 loss 0.201290 acc 0.854976 lr 0.00029139 grad_norm 0.622213 rank 1
2025-01-10 10:04:12,848 DEBUG TRAIN Batch 30/600 loss 0.281551 acc 0.812830 lr 0.00029139 grad_norm 0.622213 rank 2
2025-01-10 10:04:12,848 DEBUG TRAIN Batch 30/600 loss 0.151909 acc 0.900249 lr 0.00029139 grad_norm 0.622213 rank 0
2025-01-10 10:04:36,441 DEBUG TRAIN Batch 30/700 loss 0.175362 acc 0.875309 lr 0.00029114 grad_norm 0.580719 rank 1
2025-01-10 10:04:36,441 DEBUG TRAIN Batch 30/700 loss 0.142402 acc 0.911405 lr 0.00029114 grad_norm 0.580719 rank 0
2025-01-10 10:04:36,442 DEBUG TRAIN Batch 30/700 loss 0.225378 acc 0.841682 lr 0.00029114 grad_norm 0.580719 rank 2
2025-01-10 10:05:00,562 DEBUG TRAIN Batch 30/800 loss 0.229335 acc 0.843137 lr 0.00029089 grad_norm 0.602786 rank 1
2025-01-10 10:05:00,562 DEBUG TRAIN Batch 30/800 loss 0.125183 acc 0.899846 lr 0.00029089 grad_norm 0.602786 rank 0
2025-01-10 10:05:00,563 DEBUG TRAIN Batch 30/800 loss 0.235039 acc 0.845275 lr 0.00029089 grad_norm 0.602786 rank 2
2025-01-10 10:05:24,490 DEBUG TRAIN Batch 30/900 loss 0.195438 acc 0.859521 lr 0.00029065 grad_norm 0.600891 rank 1
2025-01-10 10:05:24,491 DEBUG TRAIN Batch 30/900 loss 0.163596 acc 0.887471 lr 0.00029065 grad_norm 0.600891 rank 2
2025-01-10 10:05:24,491 DEBUG TRAIN Batch 30/900 loss 0.144718 acc 0.907469 lr 0.00029065 grad_norm 0.600891 rank 0
2025-01-10 10:05:48,437 DEBUG TRAIN Batch 30/1000 loss 0.287366 acc 0.808917 lr 0.00029040 grad_norm 0.649976 rank 2
2025-01-10 10:05:48,437 DEBUG TRAIN Batch 30/1000 loss 0.268294 acc 0.800360 lr 0.00029040 grad_norm 0.649976 rank 1
2025-01-10 10:05:48,437 DEBUG TRAIN Batch 30/1000 loss 0.197359 acc 0.851621 lr 0.00029040 grad_norm 0.649976 rank 0
2025-01-10 10:06:12,553 DEBUG TRAIN Batch 30/1100 loss 0.214934 acc 0.841513 lr 0.00029016 grad_norm 0.635513 rank 2
2025-01-10 10:06:12,554 DEBUG TRAIN Batch 30/1100 loss 0.211857 acc 0.855838 lr 0.00029016 grad_norm 0.635513 rank 1
2025-01-10 10:06:12,554 DEBUG TRAIN Batch 30/1100 loss 0.260684 acc 0.820669 lr 0.00029016 grad_norm 0.635513 rank 0
2025-01-10 10:06:37,161 DEBUG TRAIN Batch 30/1200 loss 0.199054 acc 0.863892 lr 0.00028991 grad_norm 0.624746 rank 1
2025-01-10 10:06:37,161 DEBUG TRAIN Batch 30/1200 loss 0.313627 acc 0.781620 lr 0.00028991 grad_norm 0.624746 rank 2
2025-01-10 10:06:37,161 DEBUG TRAIN Batch 30/1200 loss 0.109547 acc 0.917722 lr 0.00028991 grad_norm 0.624746 rank 0
2025-01-10 10:07:01,306 DEBUG TRAIN Batch 30/1300 loss 0.240925 acc 0.829291 lr 0.00028967 grad_norm 0.625731 rank 1
2025-01-10 10:07:01,307 DEBUG TRAIN Batch 30/1300 loss 0.315543 acc 0.780734 lr 0.00028967 grad_norm 0.625731 rank 2
2025-01-10 10:07:01,307 DEBUG TRAIN Batch 30/1300 loss 0.304725 acc 0.791232 lr 0.00028967 grad_norm 0.625731 rank 0
2025-01-10 10:07:25,435 DEBUG TRAIN Batch 30/1400 loss 0.208443 acc 0.862291 lr 0.00028943 grad_norm 0.646750 rank 1
2025-01-10 10:07:25,435 DEBUG TRAIN Batch 30/1400 loss 0.331340 acc 0.766889 lr 0.00028943 grad_norm 0.646750 rank 2
2025-01-10 10:07:25,435 DEBUG TRAIN Batch 30/1400 loss 0.306654 acc 0.781897 lr 0.00028943 grad_norm 0.646750 rank 0
2025-01-10 10:07:50,837 DEBUG TRAIN Batch 30/1500 loss 0.247871 acc 0.828125 lr 0.00028919 grad_norm 0.605836 rank 1
2025-01-10 10:07:50,837 DEBUG TRAIN Batch 30/1500 loss 0.306622 acc 0.796371 lr 0.00028919 grad_norm 0.605836 rank 2
2025-01-10 10:07:50,838 DEBUG TRAIN Batch 30/1500 loss 0.140446 acc 0.905983 lr 0.00028919 grad_norm 0.605836 rank 0
2025-01-10 10:08:14,953 DEBUG TRAIN Batch 30/1600 loss 0.266350 acc 0.822894 lr 0.00028894 grad_norm 0.718512 rank 2
2025-01-10 10:08:14,954 DEBUG TRAIN Batch 30/1600 loss 0.234228 acc 0.825076 lr 0.00028894 grad_norm 0.718512 rank 1
2025-01-10 10:08:14,955 DEBUG TRAIN Batch 30/1600 loss 0.279052 acc 0.801117 lr 0.00028894 grad_norm 0.718512 rank 0
2025-01-10 10:08:39,740 DEBUG TRAIN Batch 30/1700 loss 0.231133 acc 0.842209 lr 0.00028870 grad_norm 0.633165 rank 1
2025-01-10 10:08:39,740 DEBUG TRAIN Batch 30/1700 loss 0.253542 acc 0.830583 lr 0.00028870 grad_norm 0.633165 rank 0
2025-01-10 10:08:39,740 DEBUG TRAIN Batch 30/1700 loss 0.382939 acc 0.750436 lr 0.00028870 grad_norm 0.633165 rank 2
2025-01-10 10:09:05,211 DEBUG TRAIN Batch 30/1800 loss 0.295434 acc 0.781857 lr 0.00028846 grad_norm 0.655826 rank 2
2025-01-10 10:09:05,211 DEBUG TRAIN Batch 30/1800 loss 0.262947 acc 0.821881 lr 0.00028846 grad_norm 0.655826 rank 1
2025-01-10 10:09:05,211 DEBUG TRAIN Batch 30/1800 loss 0.246174 acc 0.823178 lr 0.00028846 grad_norm 0.655826 rank 0
2025-01-10 10:09:30,391 DEBUG TRAIN Batch 30/1900 loss 0.334522 acc 0.767790 lr 0.00028822 grad_norm 0.649290 rank 2
2025-01-10 10:09:30,391 DEBUG TRAIN Batch 30/1900 loss 0.199750 acc 0.855285 lr 0.00028822 grad_norm 0.649290 rank 1
2025-01-10 10:09:30,392 DEBUG TRAIN Batch 30/1900 loss 0.144779 acc 0.903692 lr 0.00028822 grad_norm 0.649290 rank 0
2025-01-10 10:09:55,421 DEBUG TRAIN Batch 30/2000 loss 0.126248 acc 0.918963 lr 0.00028798 grad_norm 0.641070 rank 1
2025-01-10 10:09:55,421 DEBUG TRAIN Batch 30/2000 loss 0.266152 acc 0.812222 lr 0.00028798 grad_norm 0.641070 rank 2
2025-01-10 10:09:55,421 DEBUG TRAIN Batch 30/2000 loss 0.276395 acc 0.808636 lr 0.00028798 grad_norm 0.641070 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 10:11:07,460 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59983ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 10:11:07,477 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 10:11:07,932 INFO Epoch 30 Step 30168 on_batch_end True CV rank 1
2025-01-10 10:11:07,932 INFO Epoch 30 Step 30168 on_batch_end True CV rank 0
2025-01-10 10:11:07,932 INFO Epoch 30 Step 30168 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 10:11:17,226 DEBUG CV Batch 30/100 loss 0.142215 acc 0.948718  rank 0
2025-01-10 10:11:17,467 DEBUG CV Batch 30/100 loss 0.142215 acc 0.948718  rank 2
2025-01-10 10:11:17,656 DEBUG CV Batch 30/100 loss 0.142215 acc 0.948718  rank 1
2025-01-10 10:11:17,768 INFO Epoch 30 Step 30168 CV info lr 0.0002878702232722778 0 rank loss_1.583827796147058 acc_0.755681107964432
2025-01-10 10:11:18,004 INFO Epoch 30 Step 30168 CV info lr 0.0002878702232722778 2 rank loss_1.583827796147058 acc_0.755681107964432
2025-01-10 10:11:18,204 INFO Epoch 30 Step 30168 CV info lr 0.0002878702232722778 1 rank loss_1.583827796147058 acc_0.755681107964432
2025-01-10 10:11:19,064 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_30_whole.pt
2025-01-10 10:11:19,076 INFO Added key: store_based_barrier_key:33 to store for rank: 0
2025-01-10 10:11:19,086 INFO Added key: store_based_barrier_key:33 to store for rank: 2
2025-01-10 10:11:19,086 INFO Added key: store_based_barrier_key:33 to store for rank: 1
2025-01-10 10:11:19,086 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:33 with 3 nodes.
2025-01-10 10:11:19,094 INFO Epoch 31 TRAIN info lr 0.0002878702232722778 rank 1
2025-01-10 10:11:19,094 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 10:11:19,096 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:33 with 3 nodes.
2025-01-10 10:11:19,096 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:33 with 3 nodes.
2025-01-10 10:11:19,098 INFO Epoch 31 TRAIN info lr 0.0002878702232722778 rank 2
2025-01-10 10:11:19,098 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 10:11:19,105 INFO Epoch 31 TRAIN info lr 0.0002878702232722778 rank 0
2025-01-10 10:11:19,105 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 10:11:50,423 DEBUG TRAIN Batch 31/100 loss 0.193331 acc 0.868502 lr 0.00028763 grad_norm 0.603344 rank 1
2025-01-10 10:11:50,423 DEBUG TRAIN Batch 31/100 loss 0.251665 acc 0.836383 lr 0.00028763 grad_norm 0.603344 rank 2
2025-01-10 10:11:50,423 DEBUG TRAIN Batch 31/100 loss 0.150343 acc 0.900308 lr 0.00028763 grad_norm 0.603344 rank 0
2025-01-10 10:12:14,429 DEBUG TRAIN Batch 31/200 loss 0.188453 acc 0.861731 lr 0.00028739 grad_norm 0.607535 rank 0
2025-01-10 10:12:14,429 DEBUG TRAIN Batch 31/200 loss 0.189380 acc 0.877577 lr 0.00028739 grad_norm 0.607535 rank 2
2025-01-10 10:12:14,429 DEBUG TRAIN Batch 31/200 loss 0.148156 acc 0.882129 lr 0.00028739 grad_norm 0.607535 rank 1
2025-01-10 10:12:38,378 DEBUG TRAIN Batch 31/300 loss 0.251850 acc 0.829222 lr 0.00028716 grad_norm 0.620433 rank 1
2025-01-10 10:12:38,378 DEBUG TRAIN Batch 31/300 loss 0.265111 acc 0.828545 lr 0.00028716 grad_norm 0.620433 rank 2
2025-01-10 10:12:38,379 DEBUG TRAIN Batch 31/300 loss 0.188211 acc 0.880884 lr 0.00028716 grad_norm 0.620433 rank 0
2025-01-10 10:13:02,101 DEBUG TRAIN Batch 31/400 loss 0.174183 acc 0.877637 lr 0.00028692 grad_norm 0.636702 rank 0
2025-01-10 10:13:02,101 DEBUG TRAIN Batch 31/400 loss 0.243149 acc 0.819802 lr 0.00028692 grad_norm 0.636702 rank 1
2025-01-10 10:13:02,102 DEBUG TRAIN Batch 31/400 loss 0.246304 acc 0.822060 lr 0.00028692 grad_norm 0.636702 rank 2
2025-01-10 10:13:26,543 DEBUG TRAIN Batch 31/500 loss 0.305237 acc 0.792952 lr 0.00028668 grad_norm 0.614047 rank 0
2025-01-10 10:13:26,543 DEBUG TRAIN Batch 31/500 loss 0.232697 acc 0.828169 lr 0.00028668 grad_norm 0.614047 rank 1
2025-01-10 10:13:26,543 DEBUG TRAIN Batch 31/500 loss 0.166603 acc 0.877490 lr 0.00028668 grad_norm 0.614047 rank 2
2025-01-10 10:13:49,796 DEBUG TRAIN Batch 31/600 loss 0.218920 acc 0.835603 lr 0.00028645 grad_norm 0.615482 rank 0
2025-01-10 10:13:49,797 DEBUG TRAIN Batch 31/600 loss 0.195935 acc 0.865261 lr 0.00028645 grad_norm 0.615482 rank 1
2025-01-10 10:13:49,797 DEBUG TRAIN Batch 31/600 loss 0.182969 acc 0.872506 lr 0.00028645 grad_norm 0.615482 rank 2
2025-01-10 10:14:14,155 DEBUG TRAIN Batch 31/700 loss 0.219790 acc 0.846383 lr 0.00028621 grad_norm 0.615764 rank 2
2025-01-10 10:14:14,155 DEBUG TRAIN Batch 31/700 loss 0.221122 acc 0.843779 lr 0.00028621 grad_norm 0.615764 rank 1
2025-01-10 10:14:14,155 DEBUG TRAIN Batch 31/700 loss 0.193211 acc 0.852298 lr 0.00028621 grad_norm 0.615764 rank 0
2025-01-10 10:14:38,288 DEBUG TRAIN Batch 31/800 loss 0.149106 acc 0.904694 lr 0.00028598 grad_norm 0.587804 rank 0
2025-01-10 10:14:38,288 DEBUG TRAIN Batch 31/800 loss 0.125279 acc 0.916195 lr 0.00028598 grad_norm 0.587804 rank 2
2025-01-10 10:14:38,288 DEBUG TRAIN Batch 31/800 loss 0.207710 acc 0.848697 lr 0.00028598 grad_norm 0.587804 rank 1
2025-01-10 10:15:02,515 DEBUG TRAIN Batch 31/900 loss 0.169398 acc 0.875472 lr 0.00028575 grad_norm 0.624367 rank 1
2025-01-10 10:15:02,515 DEBUG TRAIN Batch 31/900 loss 0.325071 acc 0.782723 lr 0.00028575 grad_norm 0.624367 rank 2
2025-01-10 10:15:02,515 DEBUG TRAIN Batch 31/900 loss 0.262706 acc 0.804527 lr 0.00028575 grad_norm 0.624367 rank 0
2025-01-10 10:15:26,621 DEBUG TRAIN Batch 31/1000 loss 0.200076 acc 0.869490 lr 0.00028551 grad_norm 0.654567 rank 1
2025-01-10 10:15:26,622 DEBUG TRAIN Batch 31/1000 loss 0.336852 acc 0.755732 lr 0.00028551 grad_norm 0.654567 rank 0
2025-01-10 10:15:26,622 DEBUG TRAIN Batch 31/1000 loss 0.270941 acc 0.810997 lr 0.00028551 grad_norm 0.654567 rank 2
2025-01-10 10:15:51,853 DEBUG TRAIN Batch 31/1100 loss 0.275740 acc 0.805477 lr 0.00028528 grad_norm 0.613059 rank 2
2025-01-10 10:15:51,853 DEBUG TRAIN Batch 31/1100 loss 0.131750 acc 0.911565 lr 0.00028528 grad_norm 0.613059 rank 0
2025-01-10 10:15:51,853 DEBUG TRAIN Batch 31/1100 loss 0.214076 acc 0.857939 lr 0.00028528 grad_norm 0.613059 rank 1
2025-01-10 10:16:15,970 DEBUG TRAIN Batch 31/1200 loss 0.225908 acc 0.839384 lr 0.00028505 grad_norm 0.632369 rank 0
2025-01-10 10:16:15,970 DEBUG TRAIN Batch 31/1200 loss 0.351396 acc 0.753731 lr 0.00028505 grad_norm 0.632369 rank 1
2025-01-10 10:16:15,970 DEBUG TRAIN Batch 31/1200 loss 0.272699 acc 0.800948 lr 0.00028505 grad_norm 0.632369 rank 2
2025-01-10 10:16:40,246 DEBUG TRAIN Batch 31/1300 loss 0.253561 acc 0.812689 lr 0.00028482 grad_norm 0.665856 rank 1
2025-01-10 10:16:40,246 DEBUG TRAIN Batch 31/1300 loss 0.221871 acc 0.847826 lr 0.00028482 grad_norm 0.665856 rank 0
2025-01-10 10:16:40,247 DEBUG TRAIN Batch 31/1300 loss 0.227686 acc 0.846585 lr 0.00028482 grad_norm 0.665856 rank 2
2025-01-10 10:17:06,006 DEBUG TRAIN Batch 31/1400 loss 0.229420 acc 0.854668 lr 0.00028459 grad_norm 0.609355 rank 2
2025-01-10 10:17:06,006 DEBUG TRAIN Batch 31/1400 loss 0.159165 acc 0.889251 lr 0.00028459 grad_norm 0.609355 rank 1
2025-01-10 10:17:06,006 DEBUG TRAIN Batch 31/1400 loss 0.210218 acc 0.856227 lr 0.00028459 grad_norm 0.609355 rank 0
2025-01-10 10:17:30,201 DEBUG TRAIN Batch 31/1500 loss 0.232395 acc 0.838883 lr 0.00028436 grad_norm 0.642994 rank 0
2025-01-10 10:17:30,201 DEBUG TRAIN Batch 31/1500 loss 0.313587 acc 0.791381 lr 0.00028436 grad_norm 0.642994 rank 1
2025-01-10 10:17:30,202 DEBUG TRAIN Batch 31/1500 loss 0.231520 acc 0.843750 lr 0.00028436 grad_norm 0.642994 rank 2
2025-01-10 10:17:54,672 DEBUG TRAIN Batch 31/1600 loss 0.189606 acc 0.868819 lr 0.00028413 grad_norm 0.612303 rank 0
2025-01-10 10:17:54,672 DEBUG TRAIN Batch 31/1600 loss 0.328985 acc 0.770925 lr 0.00028413 grad_norm 0.612303 rank 1
2025-01-10 10:17:54,673 DEBUG TRAIN Batch 31/1600 loss 0.192011 acc 0.870117 lr 0.00028413 grad_norm 0.612303 rank 2
2025-01-10 10:18:19,303 DEBUG TRAIN Batch 31/1700 loss 0.229009 acc 0.844732 lr 0.00028390 grad_norm 0.590815 rank 0
2025-01-10 10:18:19,304 DEBUG TRAIN Batch 31/1700 loss 0.148679 acc 0.889552 lr 0.00028390 grad_norm 0.590815 rank 1
2025-01-10 10:18:19,304 DEBUG TRAIN Batch 31/1700 loss 0.209110 acc 0.843396 lr 0.00028390 grad_norm 0.590815 rank 2
2025-01-10 10:18:43,679 DEBUG TRAIN Batch 31/1800 loss 0.231287 acc 0.842251 lr 0.00028367 grad_norm 0.633415 rank 2
2025-01-10 10:18:43,679 DEBUG TRAIN Batch 31/1800 loss 0.235417 acc 0.822757 lr 0.00028367 grad_norm 0.633415 rank 0
2025-01-10 10:18:43,679 DEBUG TRAIN Batch 31/1800 loss 0.248925 acc 0.821031 lr 0.00028367 grad_norm 0.633415 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 10:20:07,091 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 10:20:07,100 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 10:20:07,569 INFO Epoch 31 Step 31114 on_batch_end True CV rank 0
2025-01-10 10:20:07,569 INFO Epoch 31 Step 31114 on_batch_end True CV rank 1
2025-01-10 10:20:07,569 INFO Epoch 31 Step 31114 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 10:20:16,649 DEBUG CV Batch 31/100 loss 0.128835 acc 0.959866  rank 0
2025-01-10 10:20:17,058 DEBUG CV Batch 31/100 loss 0.128835 acc 0.959866  rank 2
2025-01-10 10:20:17,154 INFO Epoch 31 Step 31114 CV info lr 0.00028346019441053804 0 rank loss_1.591003225364706 acc_0.76130703536042
2025-01-10 10:20:17,225 DEBUG CV Batch 31/100 loss 0.128835 acc 0.959866  rank 1
2025-01-10 10:20:17,601 INFO Epoch 31 Step 31114 CV info lr 0.00028346019441053804 2 rank loss_1.591003225364706 acc_0.76130703536042
2025-01-10 10:20:17,769 INFO Epoch 31 Step 31114 CV info lr 0.00028346019441053804 1 rank loss_1.591003225364706 acc_0.76130703536042
2025-01-10 10:20:18,442 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_31_whole.pt
2025-01-10 10:20:18,454 INFO Added key: store_based_barrier_key:34 to store for rank: 0
2025-01-10 10:20:18,464 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:34 with 3 nodes.
2025-01-10 10:20:18,464 INFO Added key: store_based_barrier_key:34 to store for rank: 1
2025-01-10 10:20:18,464 INFO Added key: store_based_barrier_key:34 to store for rank: 2
2025-01-10 10:20:18,464 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:34 with 3 nodes.
2025-01-10 10:20:18,464 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:34 with 3 nodes.
2025-01-10 10:20:18,464 INFO Epoch 32 TRAIN info lr 0.00028346019441053804 rank 1
2025-01-10 10:20:18,464 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 10:20:18,465 INFO Epoch 32 TRAIN info lr 0.00028346019441053804 rank 0
2025-01-10 10:20:18,465 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 10:20:18,466 INFO Epoch 32 TRAIN info lr 0.00028346019441053804 rank 2
2025-01-10 10:20:18,466 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 10:20:54,495 DEBUG TRAIN Batch 32/100 loss 0.180281 acc 0.879473 lr 0.00028323 grad_norm 0.572915 rank 1
2025-01-10 10:20:54,495 DEBUG TRAIN Batch 32/100 loss 0.163693 acc 0.880550 lr 0.00028323 grad_norm 0.572915 rank 2
2025-01-10 10:20:54,495 DEBUG TRAIN Batch 32/100 loss 0.186320 acc 0.871197 lr 0.00028323 grad_norm 0.572915 rank 0
2025-01-10 10:21:19,207 DEBUG TRAIN Batch 32/200 loss 0.166726 acc 0.887283 lr 0.00028301 grad_norm 0.571584 rank 1
2025-01-10 10:21:19,208 DEBUG TRAIN Batch 32/200 loss 0.110259 acc 0.938412 lr 0.00028301 grad_norm 0.571584 rank 2
2025-01-10 10:21:19,208 DEBUG TRAIN Batch 32/200 loss 0.162325 acc 0.892771 lr 0.00028301 grad_norm 0.571584 rank 0
2025-01-10 10:21:43,916 DEBUG TRAIN Batch 32/300 loss 0.150035 acc 0.893460 lr 0.00028278 grad_norm 0.572511 rank 2
2025-01-10 10:21:43,916 DEBUG TRAIN Batch 32/300 loss 0.172941 acc 0.880486 lr 0.00028278 grad_norm 0.572511 rank 0
2025-01-10 10:21:43,916 DEBUG TRAIN Batch 32/300 loss 0.214876 acc 0.860401 lr 0.00028278 grad_norm 0.572511 rank 1
2025-01-10 10:22:08,496 DEBUG TRAIN Batch 32/400 loss 0.183387 acc 0.861304 lr 0.00028255 grad_norm 0.615688 rank 0
2025-01-10 10:22:08,496 DEBUG TRAIN Batch 32/400 loss 0.198815 acc 0.862132 lr 0.00028255 grad_norm 0.615688 rank 1
2025-01-10 10:22:08,496 DEBUG TRAIN Batch 32/400 loss 0.190760 acc 0.869307 lr 0.00028255 grad_norm 0.615688 rank 2
2025-01-10 10:22:33,108 DEBUG TRAIN Batch 32/500 loss 0.196545 acc 0.868335 lr 0.00028233 grad_norm 0.612338 rank 1
2025-01-10 10:22:33,109 DEBUG TRAIN Batch 32/500 loss 0.216679 acc 0.846816 lr 0.00028233 grad_norm 0.612338 rank 2
2025-01-10 10:22:33,109 DEBUG TRAIN Batch 32/500 loss 0.162548 acc 0.891304 lr 0.00028233 grad_norm 0.612338 rank 0
2025-01-10 10:22:58,084 DEBUG TRAIN Batch 32/600 loss 0.181348 acc 0.869668 lr 0.00028210 grad_norm 0.579620 rank 0
2025-01-10 10:22:58,084 DEBUG TRAIN Batch 32/600 loss 0.194475 acc 0.880048 lr 0.00028210 grad_norm 0.579620 rank 2
2025-01-10 10:22:58,084 DEBUG TRAIN Batch 32/600 loss 0.222677 acc 0.832007 lr 0.00028210 grad_norm 0.579620 rank 1
2025-01-10 10:23:22,455 DEBUG TRAIN Batch 32/700 loss 0.221552 acc 0.846154 lr 0.00028188 grad_norm 0.622436 rank 2
2025-01-10 10:23:22,455 DEBUG TRAIN Batch 32/700 loss 0.208367 acc 0.850340 lr 0.00028188 grad_norm 0.622436 rank 0
2025-01-10 10:23:22,455 DEBUG TRAIN Batch 32/700 loss 0.209609 acc 0.850237 lr 0.00028188 grad_norm 0.622436 rank 1
2025-01-10 10:23:47,947 DEBUG TRAIN Batch 32/800 loss 0.237949 acc 0.833647 lr 0.00028166 grad_norm 0.606479 rank 1
2025-01-10 10:23:47,947 DEBUG TRAIN Batch 32/800 loss 0.213531 acc 0.854396 lr 0.00028166 grad_norm 0.606479 rank 2
2025-01-10 10:23:47,948 DEBUG TRAIN Batch 32/800 loss 0.146367 acc 0.888889 lr 0.00028166 grad_norm 0.606479 rank 0
2025-01-10 10:24:12,773 DEBUG TRAIN Batch 32/900 loss 0.278310 acc 0.807381 lr 0.00028143 grad_norm 0.604844 rank 0
2025-01-10 10:24:12,773 DEBUG TRAIN Batch 32/900 loss 0.175514 acc 0.874498 lr 0.00028143 grad_norm 0.604844 rank 2
2025-01-10 10:24:12,773 DEBUG TRAIN Batch 32/900 loss 0.240021 acc 0.841228 lr 0.00028143 grad_norm 0.604844 rank 1
2025-01-10 10:24:37,014 DEBUG TRAIN Batch 32/1000 loss 0.265521 acc 0.819498 lr 0.00028121 grad_norm 0.604016 rank 0
2025-01-10 10:24:37,014 DEBUG TRAIN Batch 32/1000 loss 0.246686 acc 0.829545 lr 0.00028121 grad_norm 0.604016 rank 1
2025-01-10 10:24:37,014 DEBUG TRAIN Batch 32/1000 loss 0.194670 acc 0.863880 lr 0.00028121 grad_norm 0.604016 rank 2
2025-01-10 10:25:02,795 DEBUG TRAIN Batch 32/1100 loss 0.237439 acc 0.843972 lr 0.00028099 grad_norm 0.610257 rank 0
2025-01-10 10:25:02,796 DEBUG TRAIN Batch 32/1100 loss 0.233149 acc 0.844689 lr 0.00028099 grad_norm 0.610257 rank 1
2025-01-10 10:25:02,796 DEBUG TRAIN Batch 32/1100 loss 0.234040 acc 0.846425 lr 0.00028099 grad_norm 0.610257 rank 2
2025-01-10 10:25:27,216 DEBUG TRAIN Batch 32/1200 loss 0.166180 acc 0.875281 lr 0.00028077 grad_norm 0.622434 rank 1
2025-01-10 10:25:27,216 DEBUG TRAIN Batch 32/1200 loss 0.165314 acc 0.883978 lr 0.00028077 grad_norm 0.622434 rank 2
2025-01-10 10:25:27,216 DEBUG TRAIN Batch 32/1200 loss 0.215852 acc 0.842397 lr 0.00028077 grad_norm 0.622434 rank 0
2025-01-10 10:25:51,842 DEBUG TRAIN Batch 32/1300 loss 0.202655 acc 0.860196 lr 0.00028054 grad_norm 0.621187 rank 0
2025-01-10 10:25:51,842 DEBUG TRAIN Batch 32/1300 loss 0.225902 acc 0.838847 lr 0.00028054 grad_norm 0.621187 rank 1
2025-01-10 10:25:51,842 DEBUG TRAIN Batch 32/1300 loss 0.224669 acc 0.849434 lr 0.00028054 grad_norm 0.621187 rank 2
2025-01-10 10:26:15,457 DEBUG TRAIN Batch 32/1400 loss 0.233400 acc 0.835145 lr 0.00028032 grad_norm 0.623728 rank 1
2025-01-10 10:26:15,458 DEBUG TRAIN Batch 32/1400 loss 0.156699 acc 0.888309 lr 0.00028032 grad_norm 0.623728 rank 2
2025-01-10 10:26:15,458 DEBUG TRAIN Batch 32/1400 loss 0.249921 acc 0.831347 lr 0.00028032 grad_norm 0.623728 rank 0
2025-01-10 10:26:39,591 DEBUG TRAIN Batch 32/1500 loss 0.247041 acc 0.836296 lr 0.00028010 grad_norm 0.650761 rank 1
2025-01-10 10:26:39,591 DEBUG TRAIN Batch 32/1500 loss 0.194243 acc 0.860396 lr 0.00028010 grad_norm 0.650761 rank 0
2025-01-10 10:26:39,591 DEBUG TRAIN Batch 32/1500 loss 0.218764 acc 0.847328 lr 0.00028010 grad_norm 0.650761 rank 2
2025-01-10 10:27:03,711 DEBUG TRAIN Batch 32/1600 loss 0.312414 acc 0.788121 lr 0.00027988 grad_norm 0.638824 rank 0
2025-01-10 10:27:03,711 DEBUG TRAIN Batch 32/1600 loss 0.277584 acc 0.808743 lr 0.00027988 grad_norm 0.638824 rank 1
2025-01-10 10:27:03,711 DEBUG TRAIN Batch 32/1600 loss 0.175249 acc 0.876842 lr 0.00027988 grad_norm 0.638824 rank 2
2025-01-10 10:27:27,333 DEBUG TRAIN Batch 32/1700 loss 0.288429 acc 0.808090 lr 0.00027967 grad_norm 0.650608 rank 0
2025-01-10 10:27:27,333 DEBUG TRAIN Batch 32/1700 loss 0.262350 acc 0.822682 lr 0.00027967 grad_norm 0.650608 rank 1
2025-01-10 10:27:27,333 DEBUG TRAIN Batch 32/1700 loss 0.297980 acc 0.781475 lr 0.00027967 grad_norm 0.650608 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 10:28:27,847 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 10:28:27,851 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 10:28:28,294 INFO Epoch 32 Step 31965 on_batch_end True CV rank 0
2025-01-10 10:28:28,294 INFO Epoch 32 Step 31965 on_batch_end True CV rank 2
2025-01-10 10:28:28,294 INFO Epoch 32 Step 31965 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 10:28:37,486 DEBUG CV Batch 32/100 loss 0.118910 acc 0.962096  rank 0
2025-01-10 10:28:37,642 DEBUG CV Batch 32/100 loss 0.118910 acc 0.962096  rank 2
2025-01-10 10:28:37,990 INFO Epoch 32 Step 31965 CV info lr 0.0002796614789011295 0 rank loss_1.6139941744408326 acc_0.7567870312354021
2025-01-10 10:28:38,029 DEBUG CV Batch 32/100 loss 0.118910 acc 0.962096  rank 1
2025-01-10 10:28:38,194 INFO Epoch 32 Step 31965 CV info lr 0.0002796614789011295 2 rank loss_1.6139941744408326 acc_0.7567870312354021
2025-01-10 10:28:38,577 INFO Epoch 32 Step 31965 CV info lr 0.0002796614789011295 1 rank loss_1.6139941744408326 acc_0.7567870312354021
2025-01-10 10:28:39,265 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_32_whole.pt
2025-01-10 10:28:39,276 INFO Added key: store_based_barrier_key:35 to store for rank: 0
2025-01-10 10:28:39,286 INFO Added key: store_based_barrier_key:35 to store for rank: 2
2025-01-10 10:28:39,286 INFO Added key: store_based_barrier_key:35 to store for rank: 1
2025-01-10 10:28:39,287 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:35 with 3 nodes.
2025-01-10 10:28:39,287 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:35 with 3 nodes.
2025-01-10 10:28:39,288 INFO Epoch 33 TRAIN info lr 0.0002796614789011295 rank 1
2025-01-10 10:28:39,289 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 10:28:39,296 INFO Epoch 33 TRAIN info lr 0.0002796614789011295 rank 2
2025-01-10 10:28:39,296 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 10:28:39,297 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:35 with 3 nodes.
2025-01-10 10:28:39,303 INFO Epoch 33 TRAIN info lr 0.0002796614789011295 rank 0
2025-01-10 10:28:39,303 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 10:29:11,235 DEBUG TRAIN Batch 33/100 loss 0.191215 acc 0.866870 lr 0.00027944 grad_norm 0.590509 rank 1
2025-01-10 10:29:11,235 DEBUG TRAIN Batch 33/100 loss 0.209000 acc 0.846894 lr 0.00027944 grad_norm 0.590509 rank 2
2025-01-10 10:29:11,235 DEBUG TRAIN Batch 33/100 loss 0.150629 acc 0.902135 lr 0.00027944 grad_norm 0.590509 rank 0
2025-01-10 10:29:35,264 DEBUG TRAIN Batch 33/200 loss 0.144851 acc 0.896021 lr 0.00027923 grad_norm 0.635137 rank 1
2025-01-10 10:29:35,264 DEBUG TRAIN Batch 33/200 loss 0.143543 acc 0.905895 lr 0.00027923 grad_norm 0.635137 rank 0
2025-01-10 10:29:35,264 DEBUG TRAIN Batch 33/200 loss 0.160718 acc 0.878563 lr 0.00027923 grad_norm 0.635137 rank 2
2025-01-10 10:30:00,382 DEBUG TRAIN Batch 33/300 loss 0.214488 acc 0.860947 lr 0.00027901 grad_norm 0.624359 rank 0
2025-01-10 10:30:00,383 DEBUG TRAIN Batch 33/300 loss 0.224928 acc 0.849778 lr 0.00027901 grad_norm 0.624359 rank 2
2025-01-10 10:30:00,383 DEBUG TRAIN Batch 33/300 loss 0.165032 acc 0.873354 lr 0.00027901 grad_norm 0.624359 rank 1
2025-01-10 10:30:23,987 DEBUG TRAIN Batch 33/400 loss 0.243932 acc 0.836906 lr 0.00027879 grad_norm 0.622391 rank 2
2025-01-10 10:30:23,987 DEBUG TRAIN Batch 33/400 loss 0.154742 acc 0.889714 lr 0.00027879 grad_norm 0.622391 rank 1
2025-01-10 10:30:23,988 DEBUG TRAIN Batch 33/400 loss 0.162321 acc 0.883978 lr 0.00027879 grad_norm 0.622391 rank 0
2025-01-10 10:30:48,359 DEBUG TRAIN Batch 33/500 loss 0.214105 acc 0.846154 lr 0.00027857 grad_norm 0.625789 rank 0
2025-01-10 10:30:48,359 DEBUG TRAIN Batch 33/500 loss 0.261721 acc 0.827103 lr 0.00027857 grad_norm 0.625789 rank 1
2025-01-10 10:30:48,359 DEBUG TRAIN Batch 33/500 loss 0.206427 acc 0.857914 lr 0.00027857 grad_norm 0.625789 rank 2
2025-01-10 10:31:12,450 DEBUG TRAIN Batch 33/600 loss 0.243346 acc 0.845740 lr 0.00027836 grad_norm 0.620653 rank 0
2025-01-10 10:31:12,450 DEBUG TRAIN Batch 33/600 loss 0.141494 acc 0.919643 lr 0.00027836 grad_norm 0.620653 rank 2
2025-01-10 10:31:12,451 DEBUG TRAIN Batch 33/600 loss 0.262114 acc 0.806481 lr 0.00027836 grad_norm 0.620653 rank 1
2025-01-10 10:31:36,904 DEBUG TRAIN Batch 33/700 loss 0.194956 acc 0.858676 lr 0.00027814 grad_norm 0.627810 rank 1
2025-01-10 10:31:36,904 DEBUG TRAIN Batch 33/700 loss 0.228069 acc 0.839365 lr 0.00027814 grad_norm 0.627810 rank 0
2025-01-10 10:31:36,904 DEBUG TRAIN Batch 33/700 loss 0.189481 acc 0.878341 lr 0.00027814 grad_norm 0.627810 rank 2
2025-01-10 10:32:00,716 DEBUG TRAIN Batch 33/800 loss 0.224702 acc 0.842153 lr 0.00027793 grad_norm 0.643571 rank 0
2025-01-10 10:32:00,716 DEBUG TRAIN Batch 33/800 loss 0.253813 acc 0.822917 lr 0.00027793 grad_norm 0.643571 rank 1
2025-01-10 10:32:00,716 DEBUG TRAIN Batch 33/800 loss 0.203864 acc 0.863958 lr 0.00027793 grad_norm 0.643571 rank 2
2025-01-10 10:32:25,008 DEBUG TRAIN Batch 33/900 loss 0.259424 acc 0.802548 lr 0.00027771 grad_norm 0.653369 rank 1
2025-01-10 10:32:25,009 DEBUG TRAIN Batch 33/900 loss 0.179637 acc 0.865717 lr 0.00027771 grad_norm 0.653369 rank 0
2025-01-10 10:32:25,009 DEBUG TRAIN Batch 33/900 loss 0.213391 acc 0.843373 lr 0.00027771 grad_norm 0.653369 rank 2
2025-01-10 10:32:48,906 DEBUG TRAIN Batch 33/1000 loss 0.234068 acc 0.835993 lr 0.00027750 grad_norm 0.607578 rank 0
2025-01-10 10:32:48,907 DEBUG TRAIN Batch 33/1000 loss 0.171525 acc 0.883953 lr 0.00027750 grad_norm 0.607578 rank 2
2025-01-10 10:32:48,907 DEBUG TRAIN Batch 33/1000 loss 0.203231 acc 0.860624 lr 0.00027750 grad_norm 0.607578 rank 1
2025-01-10 10:33:13,316 DEBUG TRAIN Batch 33/1100 loss 0.163439 acc 0.886892 lr 0.00027729 grad_norm 0.634509 rank 2
2025-01-10 10:33:13,316 DEBUG TRAIN Batch 33/1100 loss 0.224972 acc 0.845045 lr 0.00027729 grad_norm 0.634509 rank 0
2025-01-10 10:33:13,316 DEBUG TRAIN Batch 33/1100 loss 0.196248 acc 0.866487 lr 0.00027729 grad_norm 0.634509 rank 1
2025-01-10 10:33:37,666 DEBUG TRAIN Batch 33/1200 loss 0.187670 acc 0.879668 lr 0.00027707 grad_norm 0.615034 rank 2
2025-01-10 10:33:37,667 DEBUG TRAIN Batch 33/1200 loss 0.290063 acc 0.803730 lr 0.00027707 grad_norm 0.615034 rank 0
2025-01-10 10:33:37,667 DEBUG TRAIN Batch 33/1200 loss 0.148991 acc 0.899482 lr 0.00027707 grad_norm 0.615034 rank 1
2025-01-10 10:34:01,023 DEBUG TRAIN Batch 33/1300 loss 0.187736 acc 0.867257 lr 0.00027686 grad_norm 0.630325 rank 2
2025-01-10 10:34:01,024 DEBUG TRAIN Batch 33/1300 loss 0.310650 acc 0.794224 lr 0.00027686 grad_norm 0.630325 rank 0
2025-01-10 10:34:01,024 DEBUG TRAIN Batch 33/1300 loss 0.184059 acc 0.866466 lr 0.00027686 grad_norm 0.630325 rank 1
2025-01-10 10:34:25,407 DEBUG TRAIN Batch 33/1400 loss 0.212512 acc 0.856068 lr 0.00027665 grad_norm 0.595197 rank 1
2025-01-10 10:34:25,408 DEBUG TRAIN Batch 33/1400 loss 0.193361 acc 0.878417 lr 0.00027665 grad_norm 0.595197 rank 2
2025-01-10 10:34:25,408 DEBUG TRAIN Batch 33/1400 loss 0.284503 acc 0.796452 lr 0.00027665 grad_norm 0.595197 rank 0
2025-01-10 10:34:50,108 DEBUG TRAIN Batch 33/1500 loss 0.218605 acc 0.848079 lr 0.00027644 grad_norm 0.589532 rank 2
2025-01-10 10:34:50,108 DEBUG TRAIN Batch 33/1500 loss 0.202854 acc 0.856184 lr 0.00027644 grad_norm 0.589532 rank 1
2025-01-10 10:34:50,108 DEBUG TRAIN Batch 33/1500 loss 0.185401 acc 0.870118 lr 0.00027644 grad_norm 0.589532 rank 0
2025-01-10 10:35:13,998 DEBUG TRAIN Batch 33/1600 loss 0.191034 acc 0.858746 lr 0.00027623 grad_norm 0.593189 rank 0
2025-01-10 10:35:13,999 DEBUG TRAIN Batch 33/1600 loss 0.192691 acc 0.859962 lr 0.00027623 grad_norm 0.593189 rank 1
2025-01-10 10:35:13,999 DEBUG TRAIN Batch 33/1600 loss 0.190509 acc 0.865193 lr 0.00027623 grad_norm 0.593189 rank 2
2025-01-10 10:35:39,472 DEBUG TRAIN Batch 33/1700 loss 0.172167 acc 0.880038 lr 0.00027602 grad_norm 0.602116 rank 0
2025-01-10 10:35:39,473 DEBUG TRAIN Batch 33/1700 loss 0.216828 acc 0.856762 lr 0.00027602 grad_norm 0.602116 rank 1
2025-01-10 10:35:39,473 DEBUG TRAIN Batch 33/1700 loss 0.122479 acc 0.913559 lr 0.00027602 grad_norm 0.602116 rank 2
2025-01-10 10:36:03,352 DEBUG TRAIN Batch 33/1800 loss 0.186557 acc 0.864154 lr 0.00027581 grad_norm 0.588642 rank 0
2025-01-10 10:36:03,352 DEBUG TRAIN Batch 33/1800 loss 0.171495 acc 0.871443 lr 0.00027581 grad_norm 0.588642 rank 2
2025-01-10 10:36:03,511 DEBUG TRAIN Batch 33/1800 loss 0.210948 acc 0.853982 lr 0.00027581 grad_norm 0.588642 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 10:37:20,567 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 10:37:20,571 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 10:37:20,996 INFO Epoch 33 Step 32901 on_batch_end True CV rank 2
2025-01-10 10:37:20,996 INFO Epoch 33 Step 32901 on_batch_end True CV rank 1
2025-01-10 10:37:20,996 INFO Epoch 33 Step 32901 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 10:37:30,383 DEBUG CV Batch 33/100 loss 0.136858 acc 0.955407  rank 2
2025-01-10 10:37:30,422 DEBUG CV Batch 33/100 loss 0.136858 acc 0.955407  rank 0
2025-01-10 10:37:30,638 DEBUG CV Batch 33/100 loss 0.136858 acc 0.955407  rank 1
2025-01-10 10:37:30,916 INFO Epoch 33 Step 32901 CV info lr 0.0002756547339601475 2 rank loss_1.6667663746497088 acc_0.7583789079074275
2025-01-10 10:37:30,943 INFO Epoch 33 Step 32901 CV info lr 0.0002756547339601475 0 rank loss_1.6667663746497088 acc_0.7583789079074275
2025-01-10 10:37:31,183 INFO Epoch 33 Step 32901 CV info lr 0.0002756547339601475 1 rank loss_1.6667663746497088 acc_0.7583789079074275
2025-01-10 10:37:32,221 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_33_whole.pt
2025-01-10 10:37:32,243 INFO Added key: store_based_barrier_key:36 to store for rank: 0
2025-01-10 10:37:32,253 INFO Added key: store_based_barrier_key:36 to store for rank: 2
2025-01-10 10:37:32,253 INFO Added key: store_based_barrier_key:36 to store for rank: 1
2025-01-10 10:37:32,253 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:36 with 3 nodes.
2025-01-10 10:37:32,253 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:36 with 3 nodes.
2025-01-10 10:37:32,261 INFO Epoch 34 TRAIN info lr 0.0002756547339601475 rank 2
2025-01-10 10:37:32,261 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 10:37:32,262 INFO Epoch 34 TRAIN info lr 0.0002756547339601475 rank 1
2025-01-10 10:37:32,262 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 10:37:32,263 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:36 with 3 nodes.
2025-01-10 10:37:32,265 INFO Epoch 34 TRAIN info lr 0.0002756547339601475 rank 0
2025-01-10 10:37:32,265 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 10:38:06,138 DEBUG TRAIN Batch 34/100 loss 0.139519 acc 0.892713 lr 0.00027545 grad_norm 0.548594 rank 2
2025-01-10 10:38:06,139 DEBUG TRAIN Batch 34/100 loss 0.126208 acc 0.906788 lr 0.00027545 grad_norm 0.548594 rank 0
2025-01-10 10:38:06,139 DEBUG TRAIN Batch 34/100 loss 0.173243 acc 0.879793 lr 0.00027545 grad_norm 0.548594 rank 1
2025-01-10 10:38:30,129 DEBUG TRAIN Batch 34/200 loss 0.115375 acc 0.913669 lr 0.00027524 grad_norm 0.586138 rank 2
2025-01-10 10:38:30,129 DEBUG TRAIN Batch 34/200 loss 0.163120 acc 0.888683 lr 0.00027524 grad_norm 0.586138 rank 0
2025-01-10 10:38:30,129 DEBUG TRAIN Batch 34/200 loss 0.196792 acc 0.873454 lr 0.00027524 grad_norm 0.586138 rank 1
2025-01-10 10:38:55,245 DEBUG TRAIN Batch 34/300 loss 0.144744 acc 0.906542 lr 0.00027503 grad_norm 0.580747 rank 0
2025-01-10 10:38:55,245 DEBUG TRAIN Batch 34/300 loss 0.192499 acc 0.869231 lr 0.00027503 grad_norm 0.580747 rank 2
2025-01-10 10:38:55,245 DEBUG TRAIN Batch 34/300 loss 0.174626 acc 0.878218 lr 0.00027503 grad_norm 0.580747 rank 1
2025-01-10 10:39:19,180 DEBUG TRAIN Batch 34/400 loss 0.091810 acc 0.940111 lr 0.00027482 grad_norm 0.562441 rank 2
2025-01-10 10:39:19,180 DEBUG TRAIN Batch 34/400 loss 0.158648 acc 0.895582 lr 0.00027482 grad_norm 0.562441 rank 1
2025-01-10 10:39:19,182 DEBUG TRAIN Batch 34/400 loss 0.180924 acc 0.882353 lr 0.00027482 grad_norm 0.562441 rank 0
2025-01-10 10:39:43,529 DEBUG TRAIN Batch 34/500 loss 0.150184 acc 0.895062 lr 0.00027461 grad_norm 0.617797 rank 2
2025-01-10 10:39:43,529 DEBUG TRAIN Batch 34/500 loss 0.354203 acc 0.762787 lr 0.00027461 grad_norm 0.617797 rank 1
2025-01-10 10:39:43,529 DEBUG TRAIN Batch 34/500 loss 0.199734 acc 0.849251 lr 0.00027461 grad_norm 0.617797 rank 0
2025-01-10 10:40:08,139 DEBUG TRAIN Batch 34/600 loss 0.212394 acc 0.838596 lr 0.00027441 grad_norm 0.610501 rank 1
2025-01-10 10:40:08,140 DEBUG TRAIN Batch 34/600 loss 0.243657 acc 0.832477 lr 0.00027441 grad_norm 0.610501 rank 0
2025-01-10 10:40:08,140 DEBUG TRAIN Batch 34/600 loss 0.140518 acc 0.903110 lr 0.00027441 grad_norm 0.610501 rank 2
2025-01-10 10:40:32,531 DEBUG TRAIN Batch 34/700 loss 0.195653 acc 0.876555 lr 0.00027420 grad_norm 0.610842 rank 2
2025-01-10 10:40:32,531 DEBUG TRAIN Batch 34/700 loss 0.304565 acc 0.801324 lr 0.00027420 grad_norm 0.610842 rank 1
2025-01-10 10:40:32,531 DEBUG TRAIN Batch 34/700 loss 0.232644 acc 0.840111 lr 0.00027420 grad_norm 0.610842 rank 0
2025-01-10 10:40:57,339 DEBUG TRAIN Batch 34/800 loss 0.322893 acc 0.793497 lr 0.00027399 grad_norm 0.613386 rank 1
2025-01-10 10:40:57,340 DEBUG TRAIN Batch 34/800 loss 0.080621 acc 0.942982 lr 0.00027399 grad_norm 0.613386 rank 2
2025-01-10 10:40:57,340 DEBUG TRAIN Batch 34/800 loss 0.228163 acc 0.851339 lr 0.00027399 grad_norm 0.613386 rank 0
2025-01-10 10:41:20,916 DEBUG TRAIN Batch 34/900 loss 0.208394 acc 0.848365 lr 0.00027379 grad_norm 0.594737 rank 1
2025-01-10 10:41:20,917 DEBUG TRAIN Batch 34/900 loss 0.171799 acc 0.885036 lr 0.00027379 grad_norm 0.594737 rank 2
2025-01-10 10:41:20,917 DEBUG TRAIN Batch 34/900 loss 0.230176 acc 0.832252 lr 0.00027379 grad_norm 0.594737 rank 0
2025-01-10 10:41:45,148 DEBUG TRAIN Batch 34/1000 loss 0.153628 acc 0.895610 lr 0.00027358 grad_norm 0.605334 rank 2
2025-01-10 10:41:45,148 DEBUG TRAIN Batch 34/1000 loss 0.217082 acc 0.850136 lr 0.00027358 grad_norm 0.605334 rank 0
2025-01-10 10:41:45,148 DEBUG TRAIN Batch 34/1000 loss 0.169647 acc 0.886364 lr 0.00027358 grad_norm 0.605334 rank 1
2025-01-10 10:42:08,726 DEBUG TRAIN Batch 34/1100 loss 0.171167 acc 0.887939 lr 0.00027338 grad_norm 0.628644 rank 1
2025-01-10 10:42:08,726 DEBUG TRAIN Batch 34/1100 loss 0.239012 acc 0.836966 lr 0.00027338 grad_norm 0.628644 rank 0
2025-01-10 10:42:08,727 DEBUG TRAIN Batch 34/1100 loss 0.175095 acc 0.889772 lr 0.00027338 grad_norm 0.628644 rank 2
2025-01-10 10:42:32,915 DEBUG TRAIN Batch 34/1200 loss 0.141251 acc 0.894565 lr 0.00027318 grad_norm 0.624234 rank 2
2025-01-10 10:42:32,915 DEBUG TRAIN Batch 34/1200 loss 0.227775 acc 0.848030 lr 0.00027318 grad_norm 0.624234 rank 0
2025-01-10 10:42:32,915 DEBUG TRAIN Batch 34/1200 loss 0.129370 acc 0.912229 lr 0.00027318 grad_norm 0.624234 rank 1
2025-01-10 10:42:57,207 DEBUG TRAIN Batch 34/1300 loss 0.159323 acc 0.895131 lr 0.00027297 grad_norm 0.606861 rank 1
2025-01-10 10:42:57,208 DEBUG TRAIN Batch 34/1300 loss 0.217572 acc 0.857988 lr 0.00027297 grad_norm 0.606861 rank 0
2025-01-10 10:42:57,208 DEBUG TRAIN Batch 34/1300 loss 0.219206 acc 0.855535 lr 0.00027297 grad_norm 0.606861 rank 2
2025-01-10 10:43:21,105 DEBUG TRAIN Batch 34/1400 loss 0.260969 acc 0.824107 lr 0.00027277 grad_norm 0.639132 rank 2
2025-01-10 10:43:21,105 DEBUG TRAIN Batch 34/1400 loss 0.191873 acc 0.866183 lr 0.00027277 grad_norm 0.639132 rank 1
2025-01-10 10:43:21,107 DEBUG TRAIN Batch 34/1400 loss 0.137680 acc 0.902292 lr 0.00027277 grad_norm 0.639132 rank 0
2025-01-10 10:43:45,231 DEBUG TRAIN Batch 34/1500 loss 0.201044 acc 0.858369 lr 0.00027257 grad_norm 0.616510 rank 1
2025-01-10 10:43:45,231 DEBUG TRAIN Batch 34/1500 loss 0.252219 acc 0.830999 lr 0.00027257 grad_norm 0.616510 rank 2
2025-01-10 10:43:45,232 DEBUG TRAIN Batch 34/1500 loss 0.231646 acc 0.842435 lr 0.00027257 grad_norm 0.616510 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 10:45:03,406 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 10:45:03,410 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 10:45:03,825 INFO Epoch 34 Step 33690 on_batch_end True CV rank 2
2025-01-10 10:45:03,825 INFO Epoch 34 Step 33690 on_batch_end True CV rank 0
2025-01-10 10:45:03,825 INFO Epoch 34 Step 33690 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 10:45:12,960 DEBUG CV Batch 34/100 loss 0.111118 acc 0.966555  rank 0
2025-01-10 10:45:13,170 DEBUG CV Batch 34/100 loss 0.111118 acc 0.966555  rank 2
2025-01-10 10:45:13,483 INFO Epoch 34 Step 33690 CV info lr 0.0002724077749339476 0 rank loss_1.6591939707204961 acc_0.7617369746429878
2025-01-10 10:45:13,603 DEBUG CV Batch 34/100 loss 0.111118 acc 0.966555  rank 1
2025-01-10 10:45:13,687 INFO Epoch 34 Step 33690 CV info lr 0.0002724077749339476 2 rank loss_1.6591939707204961 acc_0.7617369746429878
2025-01-10 10:45:14,162 INFO Epoch 34 Step 33690 CV info lr 0.0002724077749339476 1 rank loss_1.6591939707204961 acc_0.7617369746429878
2025-01-10 10:45:14,845 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_34_whole.pt
2025-01-10 10:45:14,857 INFO Added key: store_based_barrier_key:37 to store for rank: 0
2025-01-10 10:45:14,867 INFO Added key: store_based_barrier_key:37 to store for rank: 1
2025-01-10 10:45:14,867 INFO Added key: store_based_barrier_key:37 to store for rank: 2
2025-01-10 10:45:14,867 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:37 with 3 nodes.
2025-01-10 10:45:14,867 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:37 with 3 nodes.
2025-01-10 10:45:14,867 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:37 with 3 nodes.
2025-01-10 10:45:14,869 INFO Epoch 35 TRAIN info lr 0.0002724077749339476 rank 2
2025-01-10 10:45:14,869 INFO Epoch 35 TRAIN info lr 0.0002724077749339476 rank 0
2025-01-10 10:45:14,869 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 10:45:14,869 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 10:45:14,877 INFO Epoch 35 TRAIN info lr 0.0002724077749339476 rank 1
2025-01-10 10:45:14,877 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 10:45:48,904 DEBUG TRAIN Batch 35/100 loss 0.163165 acc 0.889599 lr 0.00027221 grad_norm 0.572762 rank 1
2025-01-10 10:45:48,904 DEBUG TRAIN Batch 35/100 loss 0.217610 acc 0.848352 lr 0.00027221 grad_norm 0.572762 rank 0
2025-01-10 10:45:48,904 DEBUG TRAIN Batch 35/100 loss 0.211295 acc 0.856256 lr 0.00027221 grad_norm 0.572762 rank 2
2025-01-10 10:46:13,058 DEBUG TRAIN Batch 35/200 loss 0.109703 acc 0.925752 lr 0.00027200 grad_norm 0.582633 rank 1
2025-01-10 10:46:13,058 DEBUG TRAIN Batch 35/200 loss 0.136138 acc 0.908033 lr 0.00027200 grad_norm 0.582633 rank 2
2025-01-10 10:46:13,058 DEBUG TRAIN Batch 35/200 loss 0.229942 acc 0.843602 lr 0.00027200 grad_norm 0.582633 rank 0
2025-01-10 10:46:38,619 DEBUG TRAIN Batch 35/300 loss 0.229968 acc 0.850044 lr 0.00027180 grad_norm 0.601860 rank 2
2025-01-10 10:46:38,619 DEBUG TRAIN Batch 35/300 loss 0.165229 acc 0.888589 lr 0.00027180 grad_norm 0.601860 rank 1
2025-01-10 10:46:38,619 DEBUG TRAIN Batch 35/300 loss 0.141619 acc 0.896166 lr 0.00027180 grad_norm 0.601860 rank 0
2025-01-10 10:47:03,510 DEBUG TRAIN Batch 35/400 loss 0.184534 acc 0.874783 lr 0.00027160 grad_norm 0.615303 rank 2
2025-01-10 10:47:03,510 DEBUG TRAIN Batch 35/400 loss 0.289987 acc 0.806186 lr 0.00027160 grad_norm 0.615303 rank 0
2025-01-10 10:47:03,510 DEBUG TRAIN Batch 35/400 loss 0.124262 acc 0.920290 lr 0.00027160 grad_norm 0.615303 rank 1
2025-01-10 10:47:27,586 DEBUG TRAIN Batch 35/500 loss 0.184798 acc 0.877698 lr 0.00027140 grad_norm 0.600783 rank 2
2025-01-10 10:47:27,586 DEBUG TRAIN Batch 35/500 loss 0.279916 acc 0.808838 lr 0.00027140 grad_norm 0.600783 rank 0
2025-01-10 10:47:27,586 DEBUG TRAIN Batch 35/500 loss 0.154717 acc 0.889184 lr 0.00027140 grad_norm 0.600783 rank 1
2025-01-10 10:47:52,517 DEBUG TRAIN Batch 35/600 loss 0.229621 acc 0.826176 lr 0.00027120 grad_norm 0.595550 rank 0
2025-01-10 10:47:52,517 DEBUG TRAIN Batch 35/600 loss 0.147466 acc 0.893996 lr 0.00027120 grad_norm 0.595550 rank 1
2025-01-10 10:47:52,517 DEBUG TRAIN Batch 35/600 loss 0.198177 acc 0.867308 lr 0.00027120 grad_norm 0.595550 rank 2
2025-01-10 10:48:17,040 DEBUG TRAIN Batch 35/700 loss 0.138014 acc 0.905734 lr 0.00027100 grad_norm 0.589723 rank 1
2025-01-10 10:48:17,041 DEBUG TRAIN Batch 35/700 loss 0.192046 acc 0.873942 lr 0.00027100 grad_norm 0.589723 rank 2
2025-01-10 10:48:17,041 DEBUG TRAIN Batch 35/700 loss 0.163694 acc 0.897019 lr 0.00027100 grad_norm 0.589723 rank 0
2025-01-10 10:48:42,116 DEBUG TRAIN Batch 35/800 loss 0.189287 acc 0.868581 lr 0.00027080 grad_norm 0.635039 rank 2
2025-01-10 10:48:42,116 DEBUG TRAIN Batch 35/800 loss 0.146905 acc 0.905720 lr 0.00027080 grad_norm 0.635039 rank 1
2025-01-10 10:48:42,116 DEBUG TRAIN Batch 35/800 loss 0.226562 acc 0.840479 lr 0.00027080 grad_norm 0.635039 rank 0
2025-01-10 10:49:06,229 DEBUG TRAIN Batch 35/900 loss 0.272328 acc 0.820763 lr 0.00027061 grad_norm 0.619669 rank 1
2025-01-10 10:49:06,229 DEBUG TRAIN Batch 35/900 loss 0.229914 acc 0.836066 lr 0.00027061 grad_norm 0.619669 rank 0
2025-01-10 10:49:06,229 DEBUG TRAIN Batch 35/900 loss 0.175009 acc 0.873849 lr 0.00027061 grad_norm 0.619669 rank 2
2025-01-10 10:49:30,200 DEBUG TRAIN Batch 35/1000 loss 0.274137 acc 0.820513 lr 0.00027041 grad_norm 0.602087 rank 1
2025-01-10 10:49:30,200 DEBUG TRAIN Batch 35/1000 loss 0.188428 acc 0.872227 lr 0.00027041 grad_norm 0.602087 rank 2
2025-01-10 10:49:30,202 DEBUG TRAIN Batch 35/1000 loss 0.201004 acc 0.859762 lr 0.00027041 grad_norm 0.602087 rank 0
2025-01-10 10:49:54,423 DEBUG TRAIN Batch 35/1100 loss 0.198276 acc 0.868321 lr 0.00027021 grad_norm 0.619372 rank 0
2025-01-10 10:49:54,423 DEBUG TRAIN Batch 35/1100 loss 0.268049 acc 0.816227 lr 0.00027021 grad_norm 0.619372 rank 1
2025-01-10 10:49:54,423 DEBUG TRAIN Batch 35/1100 loss 0.171655 acc 0.882101 lr 0.00027021 grad_norm 0.619372 rank 2
2025-01-10 10:50:18,104 DEBUG TRAIN Batch 35/1200 loss 0.242314 acc 0.827893 lr 0.00027001 grad_norm 0.637901 rank 1
2025-01-10 10:50:18,104 DEBUG TRAIN Batch 35/1200 loss 0.194999 acc 0.878571 lr 0.00027001 grad_norm 0.637901 rank 2
2025-01-10 10:50:18,105 DEBUG TRAIN Batch 35/1200 loss 0.197651 acc 0.866604 lr 0.00027001 grad_norm 0.637901 rank 0
2025-01-10 10:50:42,244 DEBUG TRAIN Batch 35/1300 loss 0.189119 acc 0.876744 lr 0.00026982 grad_norm 0.654503 rank 1
2025-01-10 10:50:42,244 DEBUG TRAIN Batch 35/1300 loss 0.201857 acc 0.863167 lr 0.00026982 grad_norm 0.654503 rank 0
2025-01-10 10:50:42,245 DEBUG TRAIN Batch 35/1300 loss 0.177540 acc 0.871762 lr 0.00026982 grad_norm 0.654503 rank 2
2025-01-10 10:51:05,888 DEBUG TRAIN Batch 35/1400 loss 0.217489 acc 0.838961 lr 0.00026962 grad_norm 0.615431 rank 1
2025-01-10 10:51:05,889 DEBUG TRAIN Batch 35/1400 loss 0.181948 acc 0.875607 lr 0.00026962 grad_norm 0.615431 rank 2
2025-01-10 10:51:05,889 DEBUG TRAIN Batch 35/1400 loss 0.181038 acc 0.880214 lr 0.00026962 grad_norm 0.615431 rank 0
2025-01-10 10:51:29,835 DEBUG TRAIN Batch 35/1500 loss 0.166374 acc 0.890424 lr 0.00026943 grad_norm 0.619565 rank 0
2025-01-10 10:51:29,835 DEBUG TRAIN Batch 35/1500 loss 0.214651 acc 0.852706 lr 0.00026943 grad_norm 0.619565 rank 1
2025-01-10 10:51:29,835 DEBUG TRAIN Batch 35/1500 loss 0.168098 acc 0.885045 lr 0.00026943 grad_norm 0.619565 rank 2
2025-01-10 10:51:54,127 DEBUG TRAIN Batch 35/1600 loss 0.209840 acc 0.852014 lr 0.00026923 grad_norm 0.625376 rank 1
2025-01-10 10:51:54,127 DEBUG TRAIN Batch 35/1600 loss 0.195228 acc 0.867273 lr 0.00026923 grad_norm 0.625376 rank 2
2025-01-10 10:51:54,127 DEBUG TRAIN Batch 35/1600 loss 0.209506 acc 0.854613 lr 0.00026923 grad_norm 0.625376 rank 0
2025-01-10 10:52:18,575 DEBUG TRAIN Batch 35/1700 loss 0.170668 acc 0.877095 lr 0.00026904 grad_norm 0.624158 rank 0
2025-01-10 10:52:18,575 DEBUG TRAIN Batch 35/1700 loss 0.201721 acc 0.858577 lr 0.00026904 grad_norm 0.624158 rank 1
2025-01-10 10:52:18,575 DEBUG TRAIN Batch 35/1700 loss 0.201760 acc 0.849289 lr 0.00026904 grad_norm 0.624158 rank 2
2025-01-10 10:52:42,264 DEBUG TRAIN Batch 35/1800 loss 0.171792 acc 0.876043 lr 0.00026884 grad_norm 0.605976 rank 2
2025-01-10 10:52:42,265 DEBUG TRAIN Batch 35/1800 loss 0.172714 acc 0.885714 lr 0.00026884 grad_norm 0.605976 rank 0
2025-01-10 10:52:42,265 DEBUG TRAIN Batch 35/1800 loss 0.197220 acc 0.863879 lr 0.00026884 grad_norm 0.605976 rank 1
2025-01-10 10:53:07,364 DEBUG TRAIN Batch 35/1900 loss 0.311615 acc 0.786309 lr 0.00026865 grad_norm 0.642249 rank 1
2025-01-10 10:53:07,364 DEBUG TRAIN Batch 35/1900 loss 0.161119 acc 0.878049 lr 0.00026865 grad_norm 0.642249 rank 2
2025-01-10 10:53:07,364 DEBUG TRAIN Batch 35/1900 loss 0.196407 acc 0.857440 lr 0.00026865 grad_norm 0.642249 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 10:54:27,599 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 10:54:27,607 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 10:54:27,979 INFO Epoch 35 Step 34680 on_batch_end True CV rank 2
2025-01-10 10:54:27,979 INFO Epoch 35 Step 34680 on_batch_end True CV rank 0
2025-01-10 10:54:27,979 INFO Epoch 35 Step 34680 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 10:54:37,386 DEBUG CV Batch 35/100 loss 0.103129 acc 0.969900  rank 2
2025-01-10 10:54:37,392 DEBUG CV Batch 35/100 loss 0.103129 acc 0.969900  rank 0
2025-01-10 10:54:37,768 DEBUG CV Batch 35/100 loss 0.103129 acc 0.969900  rank 1
2025-01-10 10:54:37,905 INFO Epoch 35 Step 34680 CV info lr 0.0002684914497574344 2 rank loss_1.6510533567746741 acc_0.7653548074396033
2025-01-10 10:54:37,907 INFO Epoch 35 Step 34680 CV info lr 0.0002684914497574344 0 rank loss_1.6510533567746741 acc_0.7653548074396033
2025-01-10 10:54:38,298 INFO Epoch 35 Step 34680 CV info lr 0.0002684914497574344 1 rank loss_1.6510533567746741 acc_0.7653548074396033
2025-01-10 10:54:39,259 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_35_whole.pt
2025-01-10 10:54:39,281 INFO Added key: store_based_barrier_key:38 to store for rank: 1
2025-01-10 10:54:39,280 INFO Added key: store_based_barrier_key:38 to store for rank: 0
2025-01-10 10:54:39,281 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:38 with 3 nodes.
2025-01-10 10:54:39,281 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:38 with 3 nodes.
2025-01-10 10:54:39,281 INFO Added key: store_based_barrier_key:38 to store for rank: 2
2025-01-10 10:54:39,281 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:38 with 3 nodes.
2025-01-10 10:54:39,288 INFO Epoch 36 TRAIN info lr 0.0002684914497574344 rank 1
2025-01-10 10:54:39,288 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 10:54:39,289 INFO Epoch 36 TRAIN info lr 0.0002684914497574344 rank 0
2025-01-10 10:54:39,289 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 10:54:39,290 INFO Epoch 36 TRAIN info lr 0.0002684914497574344 rank 2
2025-01-10 10:54:39,290 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 10:55:10,974 DEBUG TRAIN Batch 36/100 loss 0.130800 acc 0.924290 lr 0.00026830 grad_norm 0.571105 rank 1
2025-01-10 10:55:10,974 DEBUG TRAIN Batch 36/100 loss 0.163068 acc 0.891579 lr 0.00026830 grad_norm 0.571105 rank 2
2025-01-10 10:55:10,975 DEBUG TRAIN Batch 36/100 loss 0.151709 acc 0.887810 lr 0.00026830 grad_norm 0.571105 rank 0
2025-01-10 10:55:34,874 DEBUG TRAIN Batch 36/200 loss 0.112546 acc 0.930261 lr 0.00026811 grad_norm 0.594721 rank 2
2025-01-10 10:55:34,874 DEBUG TRAIN Batch 36/200 loss 0.184198 acc 0.861440 lr 0.00026811 grad_norm 0.594721 rank 0
2025-01-10 10:55:34,874 DEBUG TRAIN Batch 36/200 loss 0.141278 acc 0.888589 lr 0.00026811 grad_norm 0.594721 rank 1
2025-01-10 10:55:58,606 DEBUG TRAIN Batch 36/300 loss 0.181043 acc 0.873704 lr 0.00026791 grad_norm 0.609104 rank 0
2025-01-10 10:55:58,606 DEBUG TRAIN Batch 36/300 loss 0.141044 acc 0.908684 lr 0.00026791 grad_norm 0.609104 rank 1
2025-01-10 10:55:58,606 DEBUG TRAIN Batch 36/300 loss 0.188444 acc 0.862895 lr 0.00026791 grad_norm 0.609104 rank 2
2025-01-10 10:56:22,457 DEBUG TRAIN Batch 36/400 loss 0.206000 acc 0.864791 lr 0.00026772 grad_norm 0.592341 rank 0
2025-01-10 10:56:22,457 DEBUG TRAIN Batch 36/400 loss 0.140500 acc 0.895711 lr 0.00026772 grad_norm 0.592341 rank 1
2025-01-10 10:56:22,457 DEBUG TRAIN Batch 36/400 loss 0.191022 acc 0.863594 lr 0.00026772 grad_norm 0.592341 rank 2
2025-01-10 10:56:46,409 DEBUG TRAIN Batch 36/500 loss 0.192297 acc 0.856649 lr 0.00026753 grad_norm 0.581189 rank 2
2025-01-10 10:56:46,409 DEBUG TRAIN Batch 36/500 loss 0.148349 acc 0.903525 lr 0.00026753 grad_norm 0.581189 rank 0
2025-01-10 10:56:46,410 DEBUG TRAIN Batch 36/500 loss 0.182910 acc 0.872490 lr 0.00026753 grad_norm 0.581189 rank 1
2025-01-10 10:57:10,069 DEBUG TRAIN Batch 36/600 loss 0.193093 acc 0.875436 lr 0.00026734 grad_norm 0.570347 rank 2
2025-01-10 10:57:10,069 DEBUG TRAIN Batch 36/600 loss 0.120228 acc 0.914875 lr 0.00026734 grad_norm 0.570347 rank 0
2025-01-10 10:57:10,069 DEBUG TRAIN Batch 36/600 loss 0.161684 acc 0.892039 lr 0.00026734 grad_norm 0.570347 rank 1
2025-01-10 10:57:33,828 DEBUG TRAIN Batch 36/700 loss 0.213508 acc 0.854991 lr 0.00026715 grad_norm 0.599084 rank 1
2025-01-10 10:57:33,828 DEBUG TRAIN Batch 36/700 loss 0.148231 acc 0.903604 lr 0.00026715 grad_norm 0.599084 rank 0
2025-01-10 10:57:33,828 DEBUG TRAIN Batch 36/700 loss 0.210019 acc 0.853846 lr 0.00026715 grad_norm 0.599084 rank 2
2025-01-10 10:57:57,244 DEBUG TRAIN Batch 36/800 loss 0.152346 acc 0.882765 lr 0.00026696 grad_norm 0.579522 rank 0
2025-01-10 10:57:57,245 DEBUG TRAIN Batch 36/800 loss 0.173116 acc 0.863510 lr 0.00026696 grad_norm 0.579522 rank 2
2025-01-10 10:57:57,245 DEBUG TRAIN Batch 36/800 loss 0.216970 acc 0.864717 lr 0.00026696 grad_norm 0.579522 rank 1
2025-01-10 10:58:21,359 DEBUG TRAIN Batch 36/900 loss 0.181579 acc 0.874780 lr 0.00026677 grad_norm 0.610792 rank 0
2025-01-10 10:58:21,359 DEBUG TRAIN Batch 36/900 loss 0.205155 acc 0.854512 lr 0.00026677 grad_norm 0.610792 rank 2
2025-01-10 10:58:21,359 DEBUG TRAIN Batch 36/900 loss 0.173536 acc 0.884732 lr 0.00026677 grad_norm 0.610792 rank 1
2025-01-10 10:58:44,988 DEBUG TRAIN Batch 36/1000 loss 0.198236 acc 0.855455 lr 0.00026658 grad_norm 0.614608 rank 2
2025-01-10 10:58:44,988 DEBUG TRAIN Batch 36/1000 loss 0.136004 acc 0.905717 lr 0.00026658 grad_norm 0.614608 rank 0
2025-01-10 10:58:44,988 DEBUG TRAIN Batch 36/1000 loss 0.198022 acc 0.858182 lr 0.00026658 grad_norm 0.614608 rank 1
2025-01-10 10:59:09,671 DEBUG TRAIN Batch 36/1100 loss 0.219047 acc 0.841165 lr 0.00026639 grad_norm 0.638121 rank 2
2025-01-10 10:59:09,671 DEBUG TRAIN Batch 36/1100 loss 0.225597 acc 0.860377 lr 0.00026639 grad_norm 0.638121 rank 1
2025-01-10 10:59:09,672 DEBUG TRAIN Batch 36/1100 loss 0.174679 acc 0.868536 lr 0.00026639 grad_norm 0.638121 rank 0
2025-01-10 10:59:34,073 DEBUG TRAIN Batch 36/1200 loss 0.196839 acc 0.860648 lr 0.00026620 grad_norm 0.630628 rank 2
2025-01-10 10:59:34,073 DEBUG TRAIN Batch 36/1200 loss 0.163426 acc 0.892518 lr 0.00026620 grad_norm 0.630628 rank 1
2025-01-10 10:59:34,074 DEBUG TRAIN Batch 36/1200 loss 0.256558 acc 0.828571 lr 0.00026620 grad_norm 0.630628 rank 0
2025-01-10 10:59:58,174 DEBUG TRAIN Batch 36/1300 loss 0.183721 acc 0.865785 lr 0.00026601 grad_norm 0.591144 rank 1
2025-01-10 10:59:58,174 DEBUG TRAIN Batch 36/1300 loss 0.135620 acc 0.907865 lr 0.00026601 grad_norm 0.591144 rank 2
2025-01-10 10:59:58,175 DEBUG TRAIN Batch 36/1300 loss 0.214095 acc 0.840256 lr 0.00026601 grad_norm 0.591144 rank 0
2025-01-10 11:00:22,917 DEBUG TRAIN Batch 36/1400 loss 0.203156 acc 0.864086 lr 0.00026582 grad_norm 0.615365 rank 1
2025-01-10 11:00:22,918 DEBUG TRAIN Batch 36/1400 loss 0.240439 acc 0.833486 lr 0.00026582 grad_norm 0.615365 rank 0
2025-01-10 11:00:22,918 DEBUG TRAIN Batch 36/1400 loss 0.143752 acc 0.894207 lr 0.00026582 grad_norm 0.615365 rank 2
2025-01-10 11:00:48,052 DEBUG TRAIN Batch 36/1500 loss 0.293208 acc 0.784491 lr 0.00026563 grad_norm 0.625648 rank 0
2025-01-10 11:00:48,053 DEBUG TRAIN Batch 36/1500 loss 0.180577 acc 0.875260 lr 0.00026563 grad_norm 0.625648 rank 2
2025-01-10 11:00:48,053 DEBUG TRAIN Batch 36/1500 loss 0.186260 acc 0.867435 lr 0.00026563 grad_norm 0.625648 rank 1
2025-01-10 11:01:12,669 DEBUG TRAIN Batch 36/1600 loss 0.099685 acc 0.941748 lr 0.00026545 grad_norm 0.608023 rank 2
2025-01-10 11:01:12,669 DEBUG TRAIN Batch 36/1600 loss 0.232629 acc 0.832146 lr 0.00026545 grad_norm 0.608023 rank 0
2025-01-10 11:01:12,670 DEBUG TRAIN Batch 36/1600 loss 0.179656 acc 0.863107 lr 0.00026545 grad_norm 0.608023 rank 1
2025-01-10 11:01:36,630 DEBUG TRAIN Batch 36/1700 loss 0.137939 acc 0.897690 lr 0.00026526 grad_norm 0.627982 rank 0
2025-01-10 11:01:36,630 DEBUG TRAIN Batch 36/1700 loss 0.181062 acc 0.865182 lr 0.00026526 grad_norm 0.627982 rank 1
2025-01-10 11:01:36,630 DEBUG TRAIN Batch 36/1700 loss 0.166823 acc 0.883613 lr 0.00026526 grad_norm 0.627982 rank 2
2025-01-10 11:02:01,935 DEBUG TRAIN Batch 36/1800 loss 0.187900 acc 0.864391 lr 0.00026507 grad_norm 0.612064 rank 1
2025-01-10 11:02:01,936 DEBUG TRAIN Batch 36/1800 loss 0.174626 acc 0.878261 lr 0.00026507 grad_norm 0.612064 rank 2
2025-01-10 11:02:01,936 DEBUG TRAIN Batch 36/1800 loss 0.211961 acc 0.852373 lr 0.00026507 grad_norm 0.612064 rank 0
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 11:03:22,996 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 11:03:23,006 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 11:03:23,466 INFO Epoch 36 Step 35621 on_batch_end True CV rank 2
2025-01-10 11:03:23,466 INFO Epoch 36 Step 35621 on_batch_end True CV rank 0
2025-01-10 11:03:23,466 INFO Epoch 36 Step 35621 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 11:03:32,697 DEBUG CV Batch 36/100 loss 0.075630 acc 0.978818  rank 2
2025-01-10 11:03:32,780 DEBUG CV Batch 36/100 loss 0.075630 acc 0.978818  rank 0
2025-01-10 11:03:33,170 DEBUG CV Batch 36/100 loss 0.075630 acc 0.978818  rank 1
2025-01-10 11:03:33,230 INFO Epoch 36 Step 35621 CV info lr 0.0002649213446077548 2 rank loss_1.6777141042739938 acc_0.7664117119029948
2025-01-10 11:03:33,303 INFO Epoch 36 Step 35621 CV info lr 0.0002649213446077548 0 rank loss_1.6777141042739938 acc_0.7664117119029948
2025-01-10 11:03:33,729 INFO Epoch 36 Step 35621 CV info lr 0.0002649213446077548 1 rank loss_1.6777141042739938 acc_0.7664117119029948
2025-01-10 11:03:34,594 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_36_whole.pt
2025-01-10 11:03:34,615 INFO Added key: store_based_barrier_key:39 to store for rank: 0
2025-01-10 11:03:34,626 INFO Added key: store_based_barrier_key:39 to store for rank: 2
2025-01-10 11:03:34,626 INFO Added key: store_based_barrier_key:39 to store for rank: 1
2025-01-10 11:03:34,626 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:39 with 3 nodes.
2025-01-10 11:03:34,626 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:39 with 3 nodes.
2025-01-10 11:03:34,633 INFO Epoch 37 TRAIN info lr 0.0002649213446077548 rank 1
2025-01-10 11:03:34,633 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 11:03:34,636 INFO Epoch 37 TRAIN info lr 0.0002649213446077548 rank 2
2025-01-10 11:03:34,636 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 11:03:34,636 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:39 with 3 nodes.
2025-01-10 11:03:34,646 INFO Epoch 37 TRAIN info lr 0.0002649213446077548 rank 0
2025-01-10 11:03:34,646 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 11:04:05,954 DEBUG TRAIN Batch 37/100 loss 0.224614 acc 0.836331 lr 0.00026474 grad_norm 0.556365 rank 1
2025-01-10 11:04:05,954 DEBUG TRAIN Batch 37/100 loss 0.148840 acc 0.894454 lr 0.00026474 grad_norm 0.556365 rank 0
2025-01-10 11:04:05,955 DEBUG TRAIN Batch 37/100 loss 0.134866 acc 0.909490 lr 0.00026474 grad_norm 0.556365 rank 2
2025-01-10 11:04:30,060 DEBUG TRAIN Batch 37/200 loss 0.093433 acc 0.937948 lr 0.00026455 grad_norm 0.579058 rank 0
2025-01-10 11:04:30,060 DEBUG TRAIN Batch 37/200 loss 0.110589 acc 0.930643 lr 0.00026455 grad_norm 0.579058 rank 2
2025-01-10 11:04:30,060 DEBUG TRAIN Batch 37/200 loss 0.145419 acc 0.900744 lr 0.00026455 grad_norm 0.579058 rank 1
2025-01-10 11:04:54,005 DEBUG TRAIN Batch 37/300 loss 0.210598 acc 0.844486 lr 0.00026437 grad_norm 0.591538 rank 1
2025-01-10 11:04:54,005 DEBUG TRAIN Batch 37/300 loss 0.177117 acc 0.879374 lr 0.00026437 grad_norm 0.591538 rank 2
2025-01-10 11:04:54,006 DEBUG TRAIN Batch 37/300 loss 0.144259 acc 0.906015 lr 0.00026437 grad_norm 0.591538 rank 0
2025-01-10 11:05:18,032 DEBUG TRAIN Batch 37/400 loss 0.222114 acc 0.843448 lr 0.00026418 grad_norm 0.607840 rank 1
2025-01-10 11:05:18,033 DEBUG TRAIN Batch 37/400 loss 0.196202 acc 0.872202 lr 0.00026418 grad_norm 0.607840 rank 2
2025-01-10 11:05:18,033 DEBUG TRAIN Batch 37/400 loss 0.096458 acc 0.928212 lr 0.00026418 grad_norm 0.607840 rank 0
2025-01-10 11:05:42,036 DEBUG TRAIN Batch 37/500 loss 0.180787 acc 0.876394 lr 0.00026400 grad_norm 0.574625 rank 1
2025-01-10 11:05:42,037 DEBUG TRAIN Batch 37/500 loss 0.156619 acc 0.892079 lr 0.00026400 grad_norm 0.574625 rank 2
2025-01-10 11:05:42,037 DEBUG TRAIN Batch 37/500 loss 0.105462 acc 0.925184 lr 0.00026400 grad_norm 0.574625 rank 0
2025-01-10 11:06:05,409 DEBUG TRAIN Batch 37/600 loss 0.101085 acc 0.934940 lr 0.00026381 grad_norm 0.593586 rank 0
2025-01-10 11:06:05,409 DEBUG TRAIN Batch 37/600 loss 0.140652 acc 0.894794 lr 0.00026381 grad_norm 0.593586 rank 2
2025-01-10 11:06:05,410 DEBUG TRAIN Batch 37/600 loss 0.199383 acc 0.864187 lr 0.00026381 grad_norm 0.593586 rank 1
2025-01-10 11:06:29,371 DEBUG TRAIN Batch 37/700 loss 0.165687 acc 0.888589 lr 0.00026363 grad_norm 0.625197 rank 2
2025-01-10 11:06:29,371 DEBUG TRAIN Batch 37/700 loss 0.163620 acc 0.885246 lr 0.00026363 grad_norm 0.625197 rank 0
2025-01-10 11:06:29,371 DEBUG TRAIN Batch 37/700 loss 0.159448 acc 0.886000 lr 0.00026363 grad_norm 0.625197 rank 1
2025-01-10 11:06:53,805 DEBUG TRAIN Batch 37/800 loss 0.208603 acc 0.862369 lr 0.00026345 grad_norm 0.611160 rank 1
2025-01-10 11:06:53,805 DEBUG TRAIN Batch 37/800 loss 0.213011 acc 0.855963 lr 0.00026345 grad_norm 0.611160 rank 2
2025-01-10 11:06:53,805 DEBUG TRAIN Batch 37/800 loss 0.092866 acc 0.936963 lr 0.00026345 grad_norm 0.611160 rank 0
2025-01-10 11:07:18,091 DEBUG TRAIN Batch 37/900 loss 0.115750 acc 0.913554 lr 0.00026326 grad_norm 0.576856 rank 0
2025-01-10 11:07:18,092 DEBUG TRAIN Batch 37/900 loss 0.154018 acc 0.893333 lr 0.00026326 grad_norm 0.576856 rank 2
2025-01-10 11:07:18,091 DEBUG TRAIN Batch 37/900 loss 0.136663 acc 0.908367 lr 0.00026326 grad_norm 0.576856 rank 1
2025-01-10 11:07:43,294 DEBUG TRAIN Batch 37/1000 loss 0.108116 acc 0.936409 lr 0.00026308 grad_norm 0.586782 rank 0
2025-01-10 11:07:43,294 DEBUG TRAIN Batch 37/1000 loss 0.105614 acc 0.927869 lr 0.00026308 grad_norm 0.586782 rank 1
2025-01-10 11:07:43,295 DEBUG TRAIN Batch 37/1000 loss 0.158580 acc 0.899642 lr 0.00026308 grad_norm 0.586782 rank 2
2025-01-10 11:08:07,911 DEBUG TRAIN Batch 37/1100 loss 0.222664 acc 0.844156 lr 0.00026290 grad_norm 0.634719 rank 0
2025-01-10 11:08:07,911 DEBUG TRAIN Batch 37/1100 loss 0.158630 acc 0.899281 lr 0.00026290 grad_norm 0.634719 rank 1
2025-01-10 11:08:07,911 DEBUG TRAIN Batch 37/1100 loss 0.200045 acc 0.860294 lr 0.00026290 grad_norm 0.634719 rank 2
2025-01-10 11:08:33,695 DEBUG TRAIN Batch 37/1200 loss 0.216398 acc 0.855046 lr 0.00026272 grad_norm 0.637213 rank 2
2025-01-10 11:08:33,695 DEBUG TRAIN Batch 37/1200 loss 0.118899 acc 0.920368 lr 0.00026272 grad_norm 0.637213 rank 0
2025-01-10 11:08:33,696 DEBUG TRAIN Batch 37/1200 loss 0.220788 acc 0.843675 lr 0.00026272 grad_norm 0.637213 rank 1
2025-01-10 11:08:58,607 DEBUG TRAIN Batch 37/1300 loss 0.127415 acc 0.911733 lr 0.00026254 grad_norm 0.612359 rank 1
2025-01-10 11:08:58,607 DEBUG TRAIN Batch 37/1300 loss 0.212060 acc 0.842057 lr 0.00026254 grad_norm 0.612359 rank 2
2025-01-10 11:08:58,608 DEBUG TRAIN Batch 37/1300 loss 0.182106 acc 0.874657 lr 0.00026254 grad_norm 0.612359 rank 0
2025-01-10 11:09:23,227 DEBUG TRAIN Batch 37/1400 loss 0.178116 acc 0.878947 lr 0.00026236 grad_norm 0.642241 rank 2
2025-01-10 11:09:23,228 DEBUG TRAIN Batch 37/1400 loss 0.162473 acc 0.893832 lr 0.00026236 grad_norm 0.642241 rank 0
2025-01-10 11:09:23,230 DEBUG TRAIN Batch 37/1400 loss 0.162507 acc 0.892009 lr 0.00026236 grad_norm 0.642241 rank 1
2025-01-10 11:09:48,653 DEBUG TRAIN Batch 37/1500 loss 0.168185 acc 0.889683 lr 0.00026218 grad_norm 0.586357 rank 2
2025-01-10 11:09:48,653 DEBUG TRAIN Batch 37/1500 loss 0.178269 acc 0.885276 lr 0.00026218 grad_norm 0.586357 rank 0
2025-01-10 11:09:48,653 DEBUG TRAIN Batch 37/1500 loss 0.098028 acc 0.931973 lr 0.00026218 grad_norm 0.586357 rank 1
2025-01-10 11:10:12,584 DEBUG TRAIN Batch 37/1600 loss 0.160452 acc 0.890438 lr 0.00026200 grad_norm 0.636869 rank 2
2025-01-10 11:10:12,584 DEBUG TRAIN Batch 37/1600 loss 0.153532 acc 0.900763 lr 0.00026200 grad_norm 0.636869 rank 1
2025-01-10 11:10:12,584 DEBUG TRAIN Batch 37/1600 loss 0.190224 acc 0.863398 lr 0.00026200 grad_norm 0.636869 rank 0
2025-01-10 11:10:36,997 DEBUG TRAIN Batch 37/1700 loss 0.154903 acc 0.893873 lr 0.00026182 grad_norm 0.630710 rank 0
2025-01-10 11:10:36,997 DEBUG TRAIN Batch 37/1700 loss 0.155739 acc 0.894792 lr 0.00026182 grad_norm 0.630710 rank 2
2025-01-10 11:10:36,997 DEBUG TRAIN Batch 37/1700 loss 0.186300 acc 0.871658 lr 0.00026182 grad_norm 0.630710 rank 1
2025-01-10 11:11:03,060 DEBUG TRAIN Batch 37/1800 loss 0.173824 acc 0.875341 lr 0.00026164 grad_norm 0.638998 rank 2
2025-01-10 11:11:03,060 DEBUG TRAIN Batch 37/1800 loss 0.208269 acc 0.859019 lr 0.00026164 grad_norm 0.638998 rank 0
2025-01-10 11:11:03,060 DEBUG TRAIN Batch 37/1800 loss 0.154435 acc 0.902002 lr 0.00026164 grad_norm 0.638998 rank 1
2025-01-10 11:11:26,956 DEBUG TRAIN Batch 37/1900 loss 0.222265 acc 0.856171 lr 0.00026146 grad_norm 0.639980 rank 0
2025-01-10 11:11:26,957 DEBUG TRAIN Batch 37/1900 loss 0.148476 acc 0.886203 lr 0.00026146 grad_norm 0.639980 rank 2
2025-01-10 11:11:26,957 DEBUG TRAIN Batch 37/1900 loss 0.233355 acc 0.827550 lr 0.00026146 grad_norm 0.639980 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 11:12:33,443 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 11:12:33,446 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 11:12:33,909 INFO Epoch 37 Step 36584 on_batch_end True CV rank 1
2025-01-10 11:12:33,909 INFO Epoch 37 Step 36584 on_batch_end True CV rank 0
2025-01-10 11:12:33,909 INFO Epoch 37 Step 36584 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 11:12:42,866 DEBUG CV Batch 37/100 loss 0.097844 acc 0.973244  rank 0
2025-01-10 11:12:43,213 DEBUG CV Batch 37/100 loss 0.097844 acc 0.973244  rank 2
2025-01-10 11:12:43,393 INFO Epoch 37 Step 36584 CV info lr 0.000261411332079712 0 rank loss_1.6951473455451298 acc_0.7676782647245809
2025-01-10 11:12:43,570 DEBUG CV Batch 37/100 loss 0.097844 acc 0.973244  rank 1
2025-01-10 11:12:43,718 INFO Epoch 37 Step 36584 CV info lr 0.000261411332079712 2 rank loss_1.6951473455451298 acc_0.7676782647245809
2025-01-10 11:12:44,108 INFO Epoch 37 Step 36584 CV info lr 0.000261411332079712 1 rank loss_1.6951473455451298 acc_0.7676782647245809
2025-01-10 11:12:44,678 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_37_whole.pt
2025-01-10 11:12:44,690 INFO Added key: store_based_barrier_key:40 to store for rank: 0
2025-01-10 11:12:44,700 INFO Added key: store_based_barrier_key:40 to store for rank: 2
2025-01-10 11:12:44,700 INFO Added key: store_based_barrier_key:40 to store for rank: 1
2025-01-10 11:12:44,700 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:40 with 3 nodes.
2025-01-10 11:12:44,700 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:40 with 3 nodes.
2025-01-10 11:12:44,700 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:40 with 3 nodes.
2025-01-10 11:12:44,700 INFO Epoch 38 TRAIN info lr 0.000261411332079712 rank 2
2025-01-10 11:12:44,701 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 11:12:44,704 INFO Epoch 38 TRAIN info lr 0.000261411332079712 rank 0
2025-01-10 11:12:44,704 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 11:12:44,707 INFO Epoch 38 TRAIN info lr 0.000261411332079712 rank 1
2025-01-10 11:12:44,707 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 11:13:21,399 DEBUG TRAIN Batch 38/100 loss 0.146088 acc 0.907121 lr 0.00026123 grad_norm 0.525368 rank 2
2025-01-10 11:13:21,399 DEBUG TRAIN Batch 38/100 loss 0.162001 acc 0.883128 lr 0.00026123 grad_norm 0.525368 rank 0
2025-01-10 11:13:21,400 DEBUG TRAIN Batch 38/100 loss 0.145084 acc 0.904072 lr 0.00026123 grad_norm 0.525368 rank 1
2025-01-10 11:13:45,749 DEBUG TRAIN Batch 38/200 loss 0.093492 acc 0.936264 lr 0.00026105 grad_norm 0.557218 rank 1
2025-01-10 11:13:45,749 DEBUG TRAIN Batch 38/200 loss 0.116238 acc 0.912769 lr 0.00026105 grad_norm 0.557218 rank 0
2025-01-10 11:13:45,749 DEBUG TRAIN Batch 38/200 loss 0.127594 acc 0.906448 lr 0.00026105 grad_norm 0.557218 rank 2
2025-01-10 11:14:10,925 DEBUG TRAIN Batch 38/300 loss 0.157001 acc 0.891941 lr 0.00026088 grad_norm 0.535994 rank 1
2025-01-10 11:14:10,925 DEBUG TRAIN Batch 38/300 loss 0.160192 acc 0.888780 lr 0.00026088 grad_norm 0.535994 rank 2
2025-01-10 11:14:10,925 DEBUG TRAIN Batch 38/300 loss 0.179162 acc 0.877384 lr 0.00026088 grad_norm 0.535994 rank 0
2025-01-10 11:14:35,510 DEBUG TRAIN Batch 38/400 loss 0.106923 acc 0.925121 lr 0.00026070 grad_norm 0.592097 rank 1
2025-01-10 11:14:35,510 DEBUG TRAIN Batch 38/400 loss 0.154628 acc 0.883671 lr 0.00026070 grad_norm 0.592097 rank 2
2025-01-10 11:14:35,511 DEBUG TRAIN Batch 38/400 loss 0.146064 acc 0.884265 lr 0.00026070 grad_norm 0.592097 rank 0
2025-01-10 11:15:00,293 DEBUG TRAIN Batch 38/500 loss 0.204772 acc 0.863594 lr 0.00026052 grad_norm 0.598320 rank 1
2025-01-10 11:15:00,293 DEBUG TRAIN Batch 38/500 loss 0.209208 acc 0.847729 lr 0.00026052 grad_norm 0.598320 rank 2
2025-01-10 11:15:00,293 DEBUG TRAIN Batch 38/500 loss 0.144539 acc 0.904348 lr 0.00026052 grad_norm 0.598320 rank 0
2025-01-10 11:15:25,268 DEBUG TRAIN Batch 38/600 loss 0.233212 acc 0.831135 lr 0.00026035 grad_norm 0.600469 rank 1
2025-01-10 11:15:25,269 DEBUG TRAIN Batch 38/600 loss 0.174821 acc 0.885308 lr 0.00026035 grad_norm 0.600469 rank 0
2025-01-10 11:15:25,269 DEBUG TRAIN Batch 38/600 loss 0.205681 acc 0.868607 lr 0.00026035 grad_norm 0.600469 rank 2
2025-01-10 11:15:49,526 DEBUG TRAIN Batch 38/700 loss 0.156493 acc 0.894399 lr 0.00026017 grad_norm 0.585380 rank 0
2025-01-10 11:15:49,526 DEBUG TRAIN Batch 38/700 loss 0.182702 acc 0.874178 lr 0.00026017 grad_norm 0.585380 rank 1
2025-01-10 11:15:49,526 DEBUG TRAIN Batch 38/700 loss 0.197596 acc 0.867647 lr 0.00026017 grad_norm 0.585380 rank 2
2025-01-10 11:16:15,153 DEBUG TRAIN Batch 38/800 loss 0.175019 acc 0.885437 lr 0.00025999 grad_norm 0.595644 rank 1
2025-01-10 11:16:15,154 DEBUG TRAIN Batch 38/800 loss 0.175763 acc 0.874362 lr 0.00025999 grad_norm 0.595644 rank 2
2025-01-10 11:16:15,154 DEBUG TRAIN Batch 38/800 loss 0.157024 acc 0.887765 lr 0.00025999 grad_norm 0.595644 rank 0
2025-01-10 11:16:39,289 DEBUG TRAIN Batch 38/900 loss 0.177579 acc 0.882299 lr 0.00025982 grad_norm 0.615063 rank 0
2025-01-10 11:16:39,289 DEBUG TRAIN Batch 38/900 loss 0.141003 acc 0.895662 lr 0.00025982 grad_norm 0.615063 rank 2
2025-01-10 11:16:39,289 DEBUG TRAIN Batch 38/900 loss 0.207132 acc 0.858144 lr 0.00025982 grad_norm 0.615063 rank 1
2025-01-10 11:17:03,754 DEBUG TRAIN Batch 38/1000 loss 0.188004 acc 0.875127 lr 0.00025964 grad_norm 0.618383 rank 1
2025-01-10 11:17:03,754 DEBUG TRAIN Batch 38/1000 loss 0.193281 acc 0.864794 lr 0.00025964 grad_norm 0.618383 rank 0
2025-01-10 11:17:03,755 DEBUG TRAIN Batch 38/1000 loss 0.220045 acc 0.851950 lr 0.00025964 grad_norm 0.618383 rank 2
2025-01-10 11:17:29,660 DEBUG TRAIN Batch 38/1100 loss 0.217699 acc 0.857914 lr 0.00025947 grad_norm 0.603519 rank 1
2025-01-10 11:17:29,660 DEBUG TRAIN Batch 38/1100 loss 0.196640 acc 0.859699 lr 0.00025947 grad_norm 0.603519 rank 2
2025-01-10 11:17:29,661 DEBUG TRAIN Batch 38/1100 loss 0.158362 acc 0.895425 lr 0.00025947 grad_norm 0.603519 rank 0
2025-01-10 11:17:53,376 DEBUG TRAIN Batch 38/1200 loss 0.142506 acc 0.896897 lr 0.00025929 grad_norm 0.582798 rank 2
2025-01-10 11:17:53,377 DEBUG TRAIN Batch 38/1200 loss 0.179822 acc 0.875000 lr 0.00025929 grad_norm 0.582798 rank 0
2025-01-10 11:17:53,377 DEBUG TRAIN Batch 38/1200 loss 0.214367 acc 0.852651 lr 0.00025929 grad_norm 0.582798 rank 1
2025-01-10 11:18:17,056 DEBUG TRAIN Batch 38/1300 loss 0.154826 acc 0.897502 lr 0.00025912 grad_norm 0.586910 rank 0
2025-01-10 11:18:17,056 DEBUG TRAIN Batch 38/1300 loss 0.131530 acc 0.905146 lr 0.00025912 grad_norm 0.586910 rank 2
2025-01-10 11:18:17,056 DEBUG TRAIN Batch 38/1300 loss 0.160182 acc 0.883899 lr 0.00025912 grad_norm 0.586910 rank 1
2025-01-10 11:18:40,665 DEBUG TRAIN Batch 38/1400 loss 0.193591 acc 0.869406 lr 0.00025895 grad_norm 0.595648 rank 1
2025-01-10 11:18:40,665 DEBUG TRAIN Batch 38/1400 loss 0.164843 acc 0.873340 lr 0.00025895 grad_norm 0.595648 rank 2
2025-01-10 11:18:40,665 DEBUG TRAIN Batch 38/1400 loss 0.129048 acc 0.906344 lr 0.00025895 grad_norm 0.595648 rank 0
2025-01-10 11:19:03,857 DEBUG TRAIN Batch 38/1500 loss 0.177433 acc 0.865990 lr 0.00025877 grad_norm 0.591983 rank 1
2025-01-10 11:19:03,857 DEBUG TRAIN Batch 38/1500 loss 0.137019 acc 0.906348 lr 0.00025877 grad_norm 0.591983 rank 0
2025-01-10 11:19:03,857 DEBUG TRAIN Batch 38/1500 loss 0.136462 acc 0.913979 lr 0.00025877 grad_norm 0.591983 rank 2
2025-01-10 11:19:27,506 DEBUG TRAIN Batch 38/1600 loss 0.230223 acc 0.830172 lr 0.00025860 grad_norm 0.624523 rank 2
2025-01-10 11:19:27,506 DEBUG TRAIN Batch 38/1600 loss 0.232687 acc 0.842369 lr 0.00025860 grad_norm 0.624523 rank 1
2025-01-10 11:19:27,506 DEBUG TRAIN Batch 38/1600 loss 0.153895 acc 0.903369 lr 0.00025860 grad_norm 0.624523 rank 0
2025-01-10 11:19:52,053 DEBUG TRAIN Batch 38/1700 loss 0.256926 acc 0.814329 lr 0.00025843 grad_norm 0.646366 rank 1
2025-01-10 11:19:52,053 DEBUG TRAIN Batch 38/1700 loss 0.145639 acc 0.896086 lr 0.00025843 grad_norm 0.646366 rank 2
2025-01-10 11:19:52,054 DEBUG TRAIN Batch 38/1700 loss 0.188214 acc 0.871183 lr 0.00025843 grad_norm 0.646366 rank 0
2025-01-10 11:20:16,194 DEBUG TRAIN Batch 38/1800 loss 0.275806 acc 0.822715 lr 0.00025825 grad_norm 0.624676 rank 1
2025-01-10 11:20:16,194 DEBUG TRAIN Batch 38/1800 loss 0.155582 acc 0.898630 lr 0.00025825 grad_norm 0.624676 rank 0
2025-01-10 11:20:16,194 DEBUG TRAIN Batch 38/1800 loss 0.153694 acc 0.885266 lr 0.00025825 grad_norm 0.624676 rank 2
2025-01-10 11:20:41,155 DEBUG TRAIN Batch 38/1900 loss 0.202343 acc 0.860177 lr 0.00025808 grad_norm 0.633837 rank 2
2025-01-10 11:20:41,155 DEBUG TRAIN Batch 38/1900 loss 0.222428 acc 0.834401 lr 0.00025808 grad_norm 0.633837 rank 0
2025-01-10 11:20:41,155 DEBUG TRAIN Batch 38/1900 loss 0.223998 acc 0.843225 lr 0.00025808 grad_norm 0.633837 rank 1
2025-01-10 11:21:04,881 DEBUG TRAIN Batch 38/2000 loss 0.182305 acc 0.882040 lr 0.00025791 grad_norm 0.636861 rank 0
2025-01-10 11:21:04,881 DEBUG TRAIN Batch 38/2000 loss 0.170506 acc 0.872017 lr 0.00025791 grad_norm 0.636861 rank 2
2025-01-10 11:21:04,882 DEBUG TRAIN Batch 38/2000 loss 0.196193 acc 0.853838 lr 0.00025791 grad_norm 0.636861 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 11:22:07,337 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 11:22:07,344 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 11:22:07,742 INFO Epoch 38 Step 37589 on_batch_end True CV rank 1
2025-01-10 11:22:07,742 INFO Epoch 38 Step 37589 on_batch_end True CV rank 0
2025-01-10 11:22:07,743 INFO Epoch 38 Step 37589 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 11:22:16,835 DEBUG CV Batch 38/100 loss 0.087680 acc 0.972129  rank 0
2025-01-10 11:22:17,343 INFO Epoch 38 Step 37589 CV info lr 0.0002578930380398211 0 rank loss_1.7402146897327744 acc_0.7677058399769298
2025-01-10 11:22:17,463 DEBUG CV Batch 38/100 loss 0.087680 acc 0.972129  rank 2
2025-01-10 11:22:17,766 DEBUG CV Batch 38/100 loss 0.087680 acc 0.972129  rank 1
2025-01-10 11:22:18,014 INFO Epoch 38 Step 37589 CV info lr 0.0002578930380398211 2 rank loss_1.7402146897327744 acc_0.7677058399769298
2025-01-10 11:22:18,307 INFO Epoch 38 Step 37589 CV info lr 0.0002578930380398211 1 rank loss_1.7402146897327744 acc_0.7677058399769298
2025-01-10 11:22:18,614 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_38_whole.pt
2025-01-10 11:22:18,636 INFO Added key: store_based_barrier_key:41 to store for rank: 0
2025-01-10 11:22:18,647 INFO Added key: store_based_barrier_key:41 to store for rank: 2
2025-01-10 11:22:18,647 INFO Added key: store_based_barrier_key:41 to store for rank: 1
2025-01-10 11:22:18,647 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:41 with 3 nodes.
2025-01-10 11:22:18,647 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:41 with 3 nodes.
2025-01-10 11:22:18,654 INFO Epoch 39 TRAIN info lr 0.0002578930380398211 rank 1
2025-01-10 11:22:18,654 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 11:22:18,657 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:41 with 3 nodes.
2025-01-10 11:22:18,657 INFO Epoch 39 TRAIN info lr 0.0002578930380398211 rank 2
2025-01-10 11:22:18,657 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 11:22:18,665 INFO Epoch 39 TRAIN info lr 0.0002578930380398211 rank 0
2025-01-10 11:22:18,665 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 11:22:50,590 DEBUG TRAIN Batch 39/100 loss 0.116944 acc 0.922388 lr 0.00025772 grad_norm 0.573293 rank 2
2025-01-10 11:22:50,590 DEBUG TRAIN Batch 39/100 loss 0.216063 acc 0.851109 lr 0.00025772 grad_norm 0.573293 rank 0
2025-01-10 11:22:50,590 DEBUG TRAIN Batch 39/100 loss 0.124618 acc 0.916754 lr 0.00025772 grad_norm 0.573293 rank 1
2025-01-10 11:23:14,646 DEBUG TRAIN Batch 39/200 loss 0.151364 acc 0.889393 lr 0.00025755 grad_norm 0.602077 rank 1
2025-01-10 11:23:14,646 DEBUG TRAIN Batch 39/200 loss 0.182658 acc 0.863171 lr 0.00025755 grad_norm 0.602077 rank 0
2025-01-10 11:23:14,646 DEBUG TRAIN Batch 39/200 loss 0.137551 acc 0.898486 lr 0.00025755 grad_norm 0.602077 rank 2
2025-01-10 11:23:39,257 DEBUG TRAIN Batch 39/300 loss 0.129102 acc 0.905418 lr 0.00025738 grad_norm 0.585393 rank 1
2025-01-10 11:23:39,258 DEBUG TRAIN Batch 39/300 loss 0.161866 acc 0.892754 lr 0.00025738 grad_norm 0.585393 rank 2
2025-01-10 11:23:39,258 DEBUG TRAIN Batch 39/300 loss 0.289197 acc 0.822243 lr 0.00025738 grad_norm 0.585393 rank 0
2025-01-10 11:24:03,030 DEBUG TRAIN Batch 39/400 loss 0.126711 acc 0.905640 lr 0.00025721 grad_norm 0.578724 rank 2
2025-01-10 11:24:03,030 DEBUG TRAIN Batch 39/400 loss 0.127770 acc 0.915339 lr 0.00025721 grad_norm 0.578724 rank 1
2025-01-10 11:24:03,030 DEBUG TRAIN Batch 39/400 loss 0.220666 acc 0.863542 lr 0.00025721 grad_norm 0.578724 rank 0
2025-01-10 11:24:27,684 DEBUG TRAIN Batch 39/500 loss 0.140810 acc 0.899816 lr 0.00025704 grad_norm 0.583503 rank 2
2025-01-10 11:24:27,684 DEBUG TRAIN Batch 39/500 loss 0.165941 acc 0.895985 lr 0.00025704 grad_norm 0.583503 rank 0
2025-01-10 11:24:27,684 DEBUG TRAIN Batch 39/500 loss 0.182775 acc 0.876200 lr 0.00025704 grad_norm 0.583503 rank 1
2025-01-10 11:24:51,834 DEBUG TRAIN Batch 39/600 loss 0.137135 acc 0.901530 lr 0.00025687 grad_norm 0.601336 rank 2
2025-01-10 11:24:51,835 DEBUG TRAIN Batch 39/600 loss 0.157732 acc 0.876308 lr 0.00025687 grad_norm 0.601336 rank 0
2025-01-10 11:24:51,835 DEBUG TRAIN Batch 39/600 loss 0.128632 acc 0.910543 lr 0.00025687 grad_norm 0.601336 rank 1
2025-01-10 11:25:15,865 DEBUG TRAIN Batch 39/700 loss 0.166706 acc 0.882133 lr 0.00025670 grad_norm 0.594657 rank 2
2025-01-10 11:25:15,866 DEBUG TRAIN Batch 39/700 loss 0.140093 acc 0.896078 lr 0.00025670 grad_norm 0.594657 rank 0
2025-01-10 11:25:15,866 DEBUG TRAIN Batch 39/700 loss 0.166404 acc 0.886941 lr 0.00025670 grad_norm 0.594657 rank 1
2025-01-10 11:25:39,797 DEBUG TRAIN Batch 39/800 loss 0.124917 acc 0.910354 lr 0.00025653 grad_norm 0.581017 rank 1
2025-01-10 11:25:39,797 DEBUG TRAIN Batch 39/800 loss 0.106596 acc 0.931373 lr 0.00025653 grad_norm 0.581017 rank 0
2025-01-10 11:25:39,798 DEBUG TRAIN Batch 39/800 loss 0.174487 acc 0.877531 lr 0.00025653 grad_norm 0.581017 rank 2
2025-01-10 11:26:03,410 DEBUG TRAIN Batch 39/900 loss 0.139375 acc 0.904096 lr 0.00025636 grad_norm 0.581859 rank 0
2025-01-10 11:26:03,411 DEBUG TRAIN Batch 39/900 loss 0.137931 acc 0.899683 lr 0.00025636 grad_norm 0.581859 rank 1
2025-01-10 11:26:03,411 DEBUG TRAIN Batch 39/900 loss 0.182724 acc 0.875607 lr 0.00025636 grad_norm 0.581859 rank 2
2025-01-10 11:26:27,535 DEBUG TRAIN Batch 39/1000 loss 0.186323 acc 0.882212 lr 0.00025619 grad_norm 0.613172 rank 2
2025-01-10 11:26:27,535 DEBUG TRAIN Batch 39/1000 loss 0.141547 acc 0.893123 lr 0.00025619 grad_norm 0.613172 rank 0
2025-01-10 11:26:27,535 DEBUG TRAIN Batch 39/1000 loss 0.164470 acc 0.890732 lr 0.00025619 grad_norm 0.613172 rank 1
2025-01-10 11:26:52,164 DEBUG TRAIN Batch 39/1100 loss 0.179198 acc 0.883317 lr 0.00025603 grad_norm 0.583249 rank 2
2025-01-10 11:26:52,164 DEBUG TRAIN Batch 39/1100 loss 0.105727 acc 0.927655 lr 0.00025603 grad_norm 0.583249 rank 0
2025-01-10 11:26:52,164 DEBUG TRAIN Batch 39/1100 loss 0.166755 acc 0.888252 lr 0.00025603 grad_norm 0.583249 rank 1
2025-01-10 11:27:16,507 DEBUG TRAIN Batch 39/1200 loss 0.142278 acc 0.896916 lr 0.00025586 grad_norm 0.588578 rank 1
2025-01-10 11:27:16,507 DEBUG TRAIN Batch 39/1200 loss 0.149423 acc 0.897273 lr 0.00025586 grad_norm 0.588578 rank 0
2025-01-10 11:27:16,508 DEBUG TRAIN Batch 39/1200 loss 0.161827 acc 0.896694 lr 0.00025586 grad_norm 0.588578 rank 2
2025-01-10 11:27:40,421 DEBUG TRAIN Batch 39/1300 loss 0.170504 acc 0.878392 lr 0.00025569 grad_norm 0.587631 rank 0
2025-01-10 11:27:40,422 DEBUG TRAIN Batch 39/1300 loss 0.157716 acc 0.887435 lr 0.00025569 grad_norm 0.587631 rank 2
2025-01-10 11:27:40,422 DEBUG TRAIN Batch 39/1300 loss 0.144017 acc 0.911521 lr 0.00025569 grad_norm 0.587631 rank 1
2025-01-10 11:28:05,363 DEBUG TRAIN Batch 39/1400 loss 0.071562 acc 0.950820 lr 0.00025552 grad_norm 0.576132 rank 0
2025-01-10 11:28:05,363 DEBUG TRAIN Batch 39/1400 loss 0.145919 acc 0.892061 lr 0.00025552 grad_norm 0.576132 rank 1
2025-01-10 11:28:05,363 DEBUG TRAIN Batch 39/1400 loss 0.189668 acc 0.868762 lr 0.00025552 grad_norm 0.576132 rank 2
2025-01-10 11:28:28,811 DEBUG TRAIN Batch 39/1500 loss 0.069376 acc 0.958824 lr 0.00025536 grad_norm 0.603316 rank 0
2025-01-10 11:28:28,811 DEBUG TRAIN Batch 39/1500 loss 0.189584 acc 0.854976 lr 0.00025536 grad_norm 0.603316 rank 1
2025-01-10 11:28:28,811 DEBUG TRAIN Batch 39/1500 loss 0.142157 acc 0.901829 lr 0.00025536 grad_norm 0.603316 rank 2
2025-01-10 11:28:53,252 DEBUG TRAIN Batch 39/1600 loss 0.161675 acc 0.889599 lr 0.00025519 grad_norm 0.603861 rank 1
2025-01-10 11:28:53,252 DEBUG TRAIN Batch 39/1600 loss 0.175193 acc 0.873849 lr 0.00025519 grad_norm 0.603861 rank 2
2025-01-10 11:28:53,253 DEBUG TRAIN Batch 39/1600 loss 0.130151 acc 0.905660 lr 0.00025519 grad_norm 0.603861 rank 0
2025-01-10 11:29:18,021 DEBUG TRAIN Batch 39/1700 loss 0.172162 acc 0.878004 lr 0.00025503 grad_norm 0.591161 rank 0
2025-01-10 11:29:18,021 DEBUG TRAIN Batch 39/1700 loss 0.145401 acc 0.893166 lr 0.00025503 grad_norm 0.591161 rank 1
2025-01-10 11:29:18,021 DEBUG TRAIN Batch 39/1700 loss 0.172651 acc 0.879786 lr 0.00025503 grad_norm 0.591161 rank 2
2025-01-10 11:29:41,766 DEBUG TRAIN Batch 39/1800 loss 0.136483 acc 0.908257 lr 0.00025486 grad_norm 0.582170 rank 0
2025-01-10 11:29:41,766 DEBUG TRAIN Batch 39/1800 loss 0.154243 acc 0.897000 lr 0.00025486 grad_norm 0.582170 rank 2
2025-01-10 11:29:41,766 DEBUG TRAIN Batch 39/1800 loss 0.153657 acc 0.883234 lr 0.00025486 grad_norm 0.582170 rank 1
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 11:30:53,738 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 11:30:53,741 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 11:30:54,144 INFO Epoch 39 Step 38514 on_batch_end True CV rank 2
2025-01-10 11:30:54,144 INFO Epoch 39 Step 38514 on_batch_end True CV rank 0
2025-01-10 11:30:54,144 INFO Epoch 39 Step 38514 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 11:31:03,142 DEBUG CV Batch 39/100 loss 0.070906 acc 0.979933  rank 0
2025-01-10 11:31:03,535 DEBUG CV Batch 39/100 loss 0.070906 acc 0.979933  rank 2
2025-01-10 11:31:03,658 INFO Epoch 39 Step 38514 CV info lr 0.00025477727678800775 0 rank loss_1.7495469866124422 acc_0.7691383480764272
2025-01-10 11:31:03,899 DEBUG CV Batch 39/100 loss 0.070906 acc 0.979933  rank 1
2025-01-10 11:31:04,071 INFO Epoch 39 Step 38514 CV info lr 0.00025477727678800775 2 rank loss_1.7495469866124422 acc_0.7691383480764272
2025-01-10 11:31:04,457 INFO Epoch 39 Step 38514 CV info lr 0.00025477727678800775 1 rank loss_1.7495469866124422 acc_0.7691383480764272
2025-01-10 11:31:04,958 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_39_whole.pt
2025-01-10 11:31:04,970 INFO Added key: store_based_barrier_key:42 to store for rank: 0
2025-01-10 11:31:04,980 INFO Added key: store_based_barrier_key:42 to store for rank: 2
2025-01-10 11:31:04,980 INFO Added key: store_based_barrier_key:42 to store for rank: 1
2025-01-10 11:31:04,980 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:42 with 3 nodes.
2025-01-10 11:31:04,980 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:42 with 3 nodes.
2025-01-10 11:31:04,981 INFO Epoch 40 TRAIN info lr 0.00025477727678800775 rank 0
2025-01-10 11:31:04,981 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 11:31:04,986 INFO Epoch 40 TRAIN info lr 0.00025477727678800775 rank 1
2025-01-10 11:31:04,986 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 11:31:04,990 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:42 with 3 nodes.
2025-01-10 11:31:04,998 INFO Epoch 40 TRAIN info lr 0.00025477727678800775 rank 2
2025-01-10 11:31:04,998 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 11:31:41,143 DEBUG TRAIN Batch 40/100 loss 0.119513 acc 0.915026 lr 0.00025461 grad_norm 0.530841 rank 2
2025-01-10 11:31:41,143 DEBUG TRAIN Batch 40/100 loss 0.076339 acc 0.943517 lr 0.00025461 grad_norm 0.530841 rank 0
2025-01-10 11:31:41,144 DEBUG TRAIN Batch 40/100 loss 0.149618 acc 0.889178 lr 0.00025461 grad_norm 0.530841 rank 1
2025-01-10 11:32:05,201 DEBUG TRAIN Batch 40/200 loss 0.142621 acc 0.900087 lr 0.00025445 grad_norm 0.548855 rank 2
2025-01-10 11:32:05,201 DEBUG TRAIN Batch 40/200 loss 0.134317 acc 0.903696 lr 0.00025445 grad_norm 0.548855 rank 0
2025-01-10 11:32:05,203 DEBUG TRAIN Batch 40/200 loss 0.080666 acc 0.941469 lr 0.00025445 grad_norm 0.548855 rank 1
2025-01-10 11:32:29,666 DEBUG TRAIN Batch 40/300 loss 0.095524 acc 0.936893 lr 0.00025428 grad_norm 0.559333 rank 0
2025-01-10 11:32:29,666 DEBUG TRAIN Batch 40/300 loss 0.133735 acc 0.909091 lr 0.00025428 grad_norm 0.559333 rank 2
2025-01-10 11:32:29,666 DEBUG TRAIN Batch 40/300 loss 0.132667 acc 0.900756 lr 0.00025428 grad_norm 0.559333 rank 1
2025-01-10 11:32:53,736 DEBUG TRAIN Batch 40/400 loss 0.117856 acc 0.915578 lr 0.00025412 grad_norm 0.545998 rank 2
2025-01-10 11:32:53,736 DEBUG TRAIN Batch 40/400 loss 0.064502 acc 0.953324 lr 0.00025412 grad_norm 0.545998 rank 0
2025-01-10 11:32:53,736 DEBUG TRAIN Batch 40/400 loss 0.140631 acc 0.910811 lr 0.00025412 grad_norm 0.545998 rank 1
2025-01-10 11:33:19,303 DEBUG TRAIN Batch 40/500 loss 0.085265 acc 0.946449 lr 0.00025395 grad_norm 0.540711 rank 0
2025-01-10 11:33:19,302 DEBUG TRAIN Batch 40/500 loss 0.138582 acc 0.910160 lr 0.00025395 grad_norm 0.540711 rank 1
2025-01-10 11:33:19,303 DEBUG TRAIN Batch 40/500 loss 0.149217 acc 0.893116 lr 0.00025395 grad_norm 0.540711 rank 2
2025-01-10 11:33:44,798 DEBUG TRAIN Batch 40/600 loss 0.147345 acc 0.893375 lr 0.00025379 grad_norm 0.588899 rank 1
2025-01-10 11:33:44,799 DEBUG TRAIN Batch 40/600 loss 0.125100 acc 0.917391 lr 0.00025379 grad_norm 0.588899 rank 2
2025-01-10 11:33:44,799 DEBUG TRAIN Batch 40/600 loss 0.119581 acc 0.914046 lr 0.00025379 grad_norm 0.588899 rank 0
2025-01-10 11:34:09,212 DEBUG TRAIN Batch 40/700 loss 0.153276 acc 0.892546 lr 0.00025363 grad_norm 0.572145 rank 1
2025-01-10 11:34:09,213 DEBUG TRAIN Batch 40/700 loss 0.145228 acc 0.896898 lr 0.00025363 grad_norm 0.572145 rank 2
2025-01-10 11:34:09,213 DEBUG TRAIN Batch 40/700 loss 0.092161 acc 0.930556 lr 0.00025363 grad_norm 0.572145 rank 0
2025-01-10 11:34:35,367 DEBUG TRAIN Batch 40/800 loss 0.181815 acc 0.869934 lr 0.00025346 grad_norm 0.591817 rank 1
2025-01-10 11:34:35,367 DEBUG TRAIN Batch 40/800 loss 0.116765 acc 0.922395 lr 0.00025346 grad_norm 0.591817 rank 2
2025-01-10 11:34:35,368 DEBUG TRAIN Batch 40/800 loss 0.101234 acc 0.935043 lr 0.00025346 grad_norm 0.591817 rank 0
2025-01-10 11:34:59,785 DEBUG TRAIN Batch 40/900 loss 0.141062 acc 0.914410 lr 0.00025330 grad_norm 0.586753 rank 1
2025-01-10 11:34:59,786 DEBUG TRAIN Batch 40/900 loss 0.101708 acc 0.932024 lr 0.00025330 grad_norm 0.586753 rank 0
2025-01-10 11:34:59,788 DEBUG TRAIN Batch 40/900 loss 0.142701 acc 0.902554 lr 0.00025330 grad_norm 0.586753 rank 2
2025-01-10 11:35:23,957 DEBUG TRAIN Batch 40/1000 loss 0.203483 acc 0.853122 lr 0.00025314 grad_norm 0.604307 rank 1
2025-01-10 11:35:23,957 DEBUG TRAIN Batch 40/1000 loss 0.107466 acc 0.924324 lr 0.00025314 grad_norm 0.604307 rank 0
2025-01-10 11:35:23,957 DEBUG TRAIN Batch 40/1000 loss 0.113555 acc 0.924122 lr 0.00025314 grad_norm 0.604307 rank 2
2025-01-10 11:35:49,272 DEBUG TRAIN Batch 40/1100 loss 0.157447 acc 0.881993 lr 0.00025298 grad_norm 0.619158 rank 2
2025-01-10 11:35:49,272 DEBUG TRAIN Batch 40/1100 loss 0.168691 acc 0.886922 lr 0.00025298 grad_norm 0.619158 rank 0
2025-01-10 11:35:49,272 DEBUG TRAIN Batch 40/1100 loss 0.169205 acc 0.873500 lr 0.00025298 grad_norm 0.619158 rank 1
2025-01-10 11:36:12,895 DEBUG TRAIN Batch 40/1200 loss 0.172748 acc 0.880000 lr 0.00025282 grad_norm 0.628951 rank 0
2025-01-10 11:36:12,895 DEBUG TRAIN Batch 40/1200 loss 0.152491 acc 0.890424 lr 0.00025282 grad_norm 0.628951 rank 2
2025-01-10 11:36:12,896 DEBUG TRAIN Batch 40/1200 loss 0.188254 acc 0.866667 lr 0.00025282 grad_norm 0.628951 rank 1
2025-01-10 11:36:36,883 DEBUG TRAIN Batch 40/1300 loss 0.140205 acc 0.910683 lr 0.00025265 grad_norm 0.605304 rank 1
2025-01-10 11:36:36,883 DEBUG TRAIN Batch 40/1300 loss 0.142318 acc 0.889988 lr 0.00025265 grad_norm 0.605304 rank 0
2025-01-10 11:36:36,883 DEBUG TRAIN Batch 40/1300 loss 0.202338 acc 0.866667 lr 0.00025265 grad_norm 0.605304 rank 2
2025-01-10 11:37:00,946 DEBUG TRAIN Batch 40/1400 loss 0.220477 acc 0.853818 lr 0.00025249 grad_norm 0.603814 rank 0
2025-01-10 11:37:00,947 DEBUG TRAIN Batch 40/1400 loss 0.102219 acc 0.933842 lr 0.00025249 grad_norm 0.603814 rank 1
2025-01-10 11:37:00,947 DEBUG TRAIN Batch 40/1400 loss 0.163894 acc 0.886773 lr 0.00025249 grad_norm 0.603814 rank 2
2025-01-10 11:37:24,881 DEBUG TRAIN Batch 40/1500 loss 0.150834 acc 0.896587 lr 0.00025233 grad_norm 0.615678 rank 2
2025-01-10 11:37:24,881 DEBUG TRAIN Batch 40/1500 loss 0.186322 acc 0.869934 lr 0.00025233 grad_norm 0.615678 rank 0
2025-01-10 11:37:24,881 DEBUG TRAIN Batch 40/1500 loss 0.185683 acc 0.869168 lr 0.00025233 grad_norm 0.615678 rank 1
2025-01-10 11:37:49,509 DEBUG TRAIN Batch 40/1600 loss 0.194230 acc 0.871197 lr 0.00025217 grad_norm 0.607037 rank 0
2025-01-10 11:37:49,509 DEBUG TRAIN Batch 40/1600 loss 0.108861 acc 0.920732 lr 0.00025217 grad_norm 0.607037 rank 1
2025-01-10 11:37:49,509 DEBUG TRAIN Batch 40/1600 loss 0.129086 acc 0.909761 lr 0.00025217 grad_norm 0.607037 rank 2
2025-01-10 11:38:13,294 DEBUG TRAIN Batch 40/1700 loss 0.145217 acc 0.886752 lr 0.00025201 grad_norm 0.608781 rank 1
2025-01-10 11:38:13,294 DEBUG TRAIN Batch 40/1700 loss 0.124686 acc 0.914425 lr 0.00025201 grad_norm 0.608781 rank 2
2025-01-10 11:38:13,294 DEBUG TRAIN Batch 40/1700 loss 0.170564 acc 0.881709 lr 0.00025201 grad_norm 0.608781 rank 0
2025-01-10 11:38:37,372 DEBUG TRAIN Batch 40/1800 loss 0.103797 acc 0.918491 lr 0.00025185 grad_norm 0.585919 rank 1
2025-01-10 11:38:37,372 DEBUG TRAIN Batch 40/1800 loss 0.165799 acc 0.881786 lr 0.00025185 grad_norm 0.585919 rank 2
2025-01-10 11:38:37,372 DEBUG TRAIN Batch 40/1800 loss 0.223965 acc 0.849823 lr 0.00025185 grad_norm 0.585919 rank 0
2025-01-10 11:39:01,242 DEBUG TRAIN Batch 40/1900 loss 0.187640 acc 0.885047 lr 0.00025169 grad_norm 0.588638 rank 0
2025-01-10 11:39:01,243 DEBUG TRAIN Batch 40/1900 loss 0.100241 acc 0.937500 lr 0.00025169 grad_norm 0.588638 rank 2
2025-01-10 11:39:01,243 DEBUG TRAIN Batch 40/1900 loss 0.182010 acc 0.871514 lr 0.00025169 grad_norm 0.588638 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 11:40:14,204 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 11:40:14,211 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 11:40:14,586 INFO Epoch 40 Step 39490 on_batch_end True CV rank 0
2025-01-10 11:40:14,586 INFO Epoch 40 Step 39490 on_batch_end True CV rank 1
2025-01-10 11:40:14,586 INFO Epoch 40 Step 39490 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 11:40:23,671 DEBUG CV Batch 40/100 loss 0.071809 acc 0.982163  rank 0
2025-01-10 11:40:24,012 DEBUG CV Batch 40/100 loss 0.071809 acc 0.982163  rank 2
2025-01-10 11:40:24,187 INFO Epoch 40 Step 39490 CV info lr 0.00025160915398934365 0 rank loss_1.7507639381495352 acc_0.771590574660845
2025-01-10 11:40:24,286 DEBUG CV Batch 40/100 loss 0.071809 acc 0.982163  rank 1
2025-01-10 11:40:24,546 INFO Epoch 40 Step 39490 CV info lr 0.00025160915398934365 2 rank loss_1.7507639381495352 acc_0.771590574660845
2025-01-10 11:40:24,833 INFO Epoch 40 Step 39490 CV info lr 0.00025160915398934365 1 rank loss_1.7507639381495352 acc_0.771590574660845
2025-01-10 11:40:25,493 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_40_whole.pt
2025-01-10 11:40:25,504 INFO Added key: store_based_barrier_key:43 to store for rank: 0
2025-01-10 11:40:25,515 INFO Added key: store_based_barrier_key:43 to store for rank: 1
2025-01-10 11:40:25,515 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:43 with 3 nodes.
2025-01-10 11:40:25,515 INFO Added key: store_based_barrier_key:43 to store for rank: 2
2025-01-10 11:40:25,515 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:43 with 3 nodes.
2025-01-10 11:40:25,519 INFO Epoch 41 TRAIN info lr 0.00025160915398934365 rank 1
2025-01-10 11:40:25,519 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 11:40:25,520 INFO Epoch 41 TRAIN info lr 0.00025160915398934365 rank 2
2025-01-10 11:40:25,520 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 11:40:25,525 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:43 with 3 nodes.
2025-01-10 11:40:25,529 INFO Epoch 41 TRAIN info lr 0.00025160915398934365 rank 0
2025-01-10 11:40:25,529 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 11:40:56,092 DEBUG TRAIN Batch 41/100 loss 0.151528 acc 0.912953 lr 0.00025145 grad_norm 0.592873 rank 1
2025-01-10 11:40:56,092 DEBUG TRAIN Batch 41/100 loss 0.120352 acc 0.922175 lr 0.00025145 grad_norm 0.592873 rank 0
2025-01-10 11:40:56,093 DEBUG TRAIN Batch 41/100 loss 0.117331 acc 0.916314 lr 0.00025145 grad_norm 0.592873 rank 2
2025-01-10 11:41:19,952 DEBUG TRAIN Batch 41/200 loss 0.141268 acc 0.901890 lr 0.00025129 grad_norm 0.575989 rank 1
2025-01-10 11:41:19,952 DEBUG TRAIN Batch 41/200 loss 0.122015 acc 0.911873 lr 0.00025129 grad_norm 0.575989 rank 0
2025-01-10 11:41:19,952 DEBUG TRAIN Batch 41/200 loss 0.160939 acc 0.890221 lr 0.00025129 grad_norm 0.575989 rank 2
2025-01-10 11:41:43,493 DEBUG TRAIN Batch 41/300 loss 0.112758 acc 0.928105 lr 0.00025113 grad_norm 0.578149 rank 2
2025-01-10 11:41:43,494 DEBUG TRAIN Batch 41/300 loss 0.146284 acc 0.902072 lr 0.00025113 grad_norm 0.578149 rank 0
2025-01-10 11:41:43,494 DEBUG TRAIN Batch 41/300 loss 0.142109 acc 0.898655 lr 0.00025113 grad_norm 0.578149 rank 1
2025-01-10 11:42:07,567 DEBUG TRAIN Batch 41/400 loss 0.109543 acc 0.920847 lr 0.00025097 grad_norm 0.581419 rank 2
2025-01-10 11:42:07,567 DEBUG TRAIN Batch 41/400 loss 0.149019 acc 0.889205 lr 0.00025097 grad_norm 0.581419 rank 1
2025-01-10 11:42:07,568 DEBUG TRAIN Batch 41/400 loss 0.150724 acc 0.904447 lr 0.00025097 grad_norm 0.581419 rank 0
2025-01-10 11:42:32,299 DEBUG TRAIN Batch 41/500 loss 0.175403 acc 0.877808 lr 0.00025082 grad_norm 0.600303 rank 0
2025-01-10 11:42:32,299 DEBUG TRAIN Batch 41/500 loss 0.096449 acc 0.940375 lr 0.00025082 grad_norm 0.600303 rank 2
2025-01-10 11:42:32,299 DEBUG TRAIN Batch 41/500 loss 0.158434 acc 0.881061 lr 0.00025082 grad_norm 0.600303 rank 1
2025-01-10 11:42:56,272 DEBUG TRAIN Batch 41/600 loss 0.145800 acc 0.895749 lr 0.00025066 grad_norm 0.598513 rank 1
2025-01-10 11:42:56,272 DEBUG TRAIN Batch 41/600 loss 0.170104 acc 0.878277 lr 0.00025066 grad_norm 0.598513 rank 0
2025-01-10 11:42:56,272 DEBUG TRAIN Batch 41/600 loss 0.090042 acc 0.938531 lr 0.00025066 grad_norm 0.598513 rank 2
2025-01-10 11:43:20,563 DEBUG TRAIN Batch 41/700 loss 0.089403 acc 0.943226 lr 0.00025050 grad_norm 0.576980 rank 2
2025-01-10 11:43:20,563 DEBUG TRAIN Batch 41/700 loss 0.175503 acc 0.884886 lr 0.00025050 grad_norm 0.576980 rank 0
2025-01-10 11:43:20,564 DEBUG TRAIN Batch 41/700 loss 0.142618 acc 0.900797 lr 0.00025050 grad_norm 0.576980 rank 1
2025-01-10 11:43:46,158 DEBUG TRAIN Batch 41/800 loss 0.096485 acc 0.930812 lr 0.00025034 grad_norm 0.581852 rank 2
2025-01-10 11:43:46,159 DEBUG TRAIN Batch 41/800 loss 0.151227 acc 0.892857 lr 0.00025034 grad_norm 0.581852 rank 1
2025-01-10 11:43:46,159 DEBUG TRAIN Batch 41/800 loss 0.188673 acc 0.882461 lr 0.00025034 grad_norm 0.581852 rank 0
2025-01-10 11:44:10,002 DEBUG TRAIN Batch 41/900 loss 0.146654 acc 0.893224 lr 0.00025019 grad_norm 0.589072 rank 0
2025-01-10 11:44:10,003 DEBUG TRAIN Batch 41/900 loss 0.090957 acc 0.939904 lr 0.00025019 grad_norm 0.589072 rank 2
2025-01-10 11:44:10,003 DEBUG TRAIN Batch 41/900 loss 0.118999 acc 0.914460 lr 0.00025019 grad_norm 0.589072 rank 1
2025-01-10 11:44:34,369 DEBUG TRAIN Batch 41/1000 loss 0.114079 acc 0.918919 lr 0.00025003 grad_norm 0.578375 rank 1
2025-01-10 11:44:34,370 DEBUG TRAIN Batch 41/1000 loss 0.171093 acc 0.879776 lr 0.00025003 grad_norm 0.578375 rank 2
2025-01-10 11:44:34,370 DEBUG TRAIN Batch 41/1000 loss 0.188104 acc 0.855172 lr 0.00025003 grad_norm 0.578375 rank 0
2025-01-10 11:44:59,103 DEBUG TRAIN Batch 41/1100 loss 0.100252 acc 0.919935 lr 0.00024988 grad_norm 0.600693 rank 2
2025-01-10 11:44:59,103 DEBUG TRAIN Batch 41/1100 loss 0.155528 acc 0.893360 lr 0.00024988 grad_norm 0.600693 rank 1
2025-01-10 11:44:59,103 DEBUG TRAIN Batch 41/1100 loss 0.159599 acc 0.883768 lr 0.00024988 grad_norm 0.600693 rank 0
2025-01-10 11:45:23,159 DEBUG TRAIN Batch 41/1200 loss 0.083894 acc 0.943642 lr 0.00024972 grad_norm 0.569559 rank 2
2025-01-10 11:45:23,159 DEBUG TRAIN Batch 41/1200 loss 0.148085 acc 0.890511 lr 0.00024972 grad_norm 0.569559 rank 1
2025-01-10 11:45:23,160 DEBUG TRAIN Batch 41/1200 loss 0.130040 acc 0.906314 lr 0.00024972 grad_norm 0.569559 rank 0
2025-01-10 11:45:48,102 DEBUG TRAIN Batch 41/1300 loss 0.171224 acc 0.888790 lr 0.00024956 grad_norm 0.609371 rank 0
2025-01-10 11:45:48,102 DEBUG TRAIN Batch 41/1300 loss 0.118138 acc 0.919101 lr 0.00024956 grad_norm 0.609371 rank 1
2025-01-10 11:45:48,102 DEBUG TRAIN Batch 41/1300 loss 0.120863 acc 0.926061 lr 0.00024956 grad_norm 0.609371 rank 2
2025-01-10 11:46:13,160 DEBUG TRAIN Batch 41/1400 loss 0.128024 acc 0.917699 lr 0.00024941 grad_norm 0.576676 rank 1
2025-01-10 11:46:13,161 DEBUG TRAIN Batch 41/1400 loss 0.131456 acc 0.910434 lr 0.00024941 grad_norm 0.576676 rank 2
2025-01-10 11:46:13,160 DEBUG TRAIN Batch 41/1400 loss 0.130289 acc 0.900675 lr 0.00024941 grad_norm 0.576676 rank 0
2025-01-10 11:46:37,593 DEBUG TRAIN Batch 41/1500 loss 0.175364 acc 0.874107 lr 0.00024925 grad_norm 0.622973 rank 0
2025-01-10 11:46:37,593 DEBUG TRAIN Batch 41/1500 loss 0.181814 acc 0.879961 lr 0.00024925 grad_norm 0.622973 rank 1
2025-01-10 11:46:37,594 DEBUG TRAIN Batch 41/1500 loss 0.133576 acc 0.918206 lr 0.00024925 grad_norm 0.622973 rank 2
2025-01-10 11:47:01,855 DEBUG TRAIN Batch 41/1600 loss 0.160753 acc 0.893276 lr 0.00024910 grad_norm 0.579963 rank 1
2025-01-10 11:47:01,855 DEBUG TRAIN Batch 41/1600 loss 0.147705 acc 0.897978 lr 0.00024910 grad_norm 0.579963 rank 0
2025-01-10 11:47:01,855 DEBUG TRAIN Batch 41/1600 loss 0.120080 acc 0.910160 lr 0.00024910 grad_norm 0.579963 rank 2
2025-01-10 11:47:27,657 DEBUG TRAIN Batch 41/1700 loss 0.149353 acc 0.894634 lr 0.00024894 grad_norm 0.597368 rank 0
2025-01-10 11:47:27,658 DEBUG TRAIN Batch 41/1700 loss 0.148272 acc 0.897267 lr 0.00024894 grad_norm 0.597368 rank 1
2025-01-10 11:47:27,658 DEBUG TRAIN Batch 41/1700 loss 0.103495 acc 0.923567 lr 0.00024894 grad_norm 0.597368 rank 2
2025-01-10 11:47:52,549 DEBUG TRAIN Batch 41/1800 loss 0.137687 acc 0.899091 lr 0.00024879 grad_norm 0.584869 rank 2
2025-01-10 11:47:52,550 DEBUG TRAIN Batch 41/1800 loss 0.102852 acc 0.925087 lr 0.00024879 grad_norm 0.584869 rank 0
2025-01-10 11:47:52,550 DEBUG TRAIN Batch 41/1800 loss 0.149849 acc 0.903047 lr 0.00024879 grad_norm 0.584869 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 11:49:12,363 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 11:49:12,364 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 11:49:12,760 INFO Epoch 41 Step 40431 on_batch_end True CV rank 2
2025-01-10 11:49:12,760 INFO Epoch 41 Step 40431 on_batch_end True CV rank 0
2025-01-10 11:49:12,760 INFO Epoch 41 Step 40431 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 11:49:21,982 DEBUG CV Batch 41/100 loss 0.066392 acc 0.978818  rank 0
2025-01-10 11:49:21,983 DEBUG CV Batch 41/100 loss 0.066392 acc 0.978818  rank 2
2025-01-10 11:49:22,478 INFO Epoch 41 Step 40431 CV info lr 0.00024866391261304247 0 rank loss_1.7777868594582145 acc_0.7707819537374011
2025-01-10 11:49:22,519 DEBUG CV Batch 41/100 loss 0.066392 acc 0.978818  rank 1
2025-01-10 11:49:22,536 INFO Epoch 41 Step 40431 CV info lr 0.00024866391261304247 2 rank loss_1.7777868594582145 acc_0.7707819537374011
2025-01-10 11:49:23,067 INFO Epoch 41 Step 40431 CV info lr 0.00024866391261304247 1 rank loss_1.7777868594582145 acc_0.7707819537374011
2025-01-10 11:49:23,760 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_41_whole.pt
2025-01-10 11:49:23,783 INFO Added key: store_based_barrier_key:44 to store for rank: 0
2025-01-10 11:49:23,793 INFO Added key: store_based_barrier_key:44 to store for rank: 2
2025-01-10 11:49:23,793 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:44 with 3 nodes.
2025-01-10 11:49:23,793 INFO Added key: store_based_barrier_key:44 to store for rank: 1
2025-01-10 11:49:23,793 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:44 with 3 nodes.
2025-01-10 11:49:23,796 INFO Epoch 42 TRAIN info lr 0.00024866391261304247 rank 2
2025-01-10 11:49:23,796 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 11:49:23,800 INFO Epoch 42 TRAIN info lr 0.00024866391261304247 rank 1
2025-01-10 11:49:23,800 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 11:49:23,803 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:44 with 3 nodes.
2025-01-10 11:49:23,806 INFO Epoch 42 TRAIN info lr 0.00024866391261304247 rank 0
2025-01-10 11:49:23,806 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 11:50:00,570 DEBUG TRAIN Batch 42/100 loss 0.121376 acc 0.923159 lr 0.00024851 grad_norm 0.571243 rank 2
2025-01-10 11:50:00,571 DEBUG TRAIN Batch 42/100 loss 0.160359 acc 0.880107 lr 0.00024851 grad_norm 0.571243 rank 0
2025-01-10 11:50:00,571 DEBUG TRAIN Batch 42/100 loss 0.085699 acc 0.957071 lr 0.00024851 grad_norm 0.571243 rank 1
2025-01-10 11:50:24,617 DEBUG TRAIN Batch 42/200 loss 0.129150 acc 0.915039 lr 0.00024836 grad_norm 0.544520 rank 1
2025-01-10 11:50:24,617 DEBUG TRAIN Batch 42/200 loss 0.133123 acc 0.904431 lr 0.00024836 grad_norm 0.544520 rank 0
2025-01-10 11:50:24,617 DEBUG TRAIN Batch 42/200 loss 0.158807 acc 0.892502 lr 0.00024836 grad_norm 0.544520 rank 2
2025-01-10 11:50:49,251 DEBUG TRAIN Batch 42/300 loss 0.111753 acc 0.917708 lr 0.00024820 grad_norm 0.557624 rank 0
2025-01-10 11:50:49,252 DEBUG TRAIN Batch 42/300 loss 0.164625 acc 0.883349 lr 0.00024820 grad_norm 0.557624 rank 2
2025-01-10 11:50:49,252 DEBUG TRAIN Batch 42/300 loss 0.081020 acc 0.937807 lr 0.00024820 grad_norm 0.557624 rank 1
2025-01-10 11:51:13,117 DEBUG TRAIN Batch 42/400 loss 0.098558 acc 0.941007 lr 0.00024805 grad_norm 0.552567 rank 1
2025-01-10 11:51:13,117 DEBUG TRAIN Batch 42/400 loss 0.150028 acc 0.898642 lr 0.00024805 grad_norm 0.552567 rank 2
2025-01-10 11:51:13,117 DEBUG TRAIN Batch 42/400 loss 0.140189 acc 0.903019 lr 0.00024805 grad_norm 0.552567 rank 0
2025-01-10 11:51:37,912 DEBUG TRAIN Batch 42/500 loss 0.117361 acc 0.929193 lr 0.00024790 grad_norm 0.615158 rank 1
2025-01-10 11:51:37,912 DEBUG TRAIN Batch 42/500 loss 0.118681 acc 0.918862 lr 0.00024790 grad_norm 0.615158 rank 0
2025-01-10 11:51:37,912 DEBUG TRAIN Batch 42/500 loss 0.130681 acc 0.920455 lr 0.00024790 grad_norm 0.615158 rank 2
2025-01-10 11:52:03,067 DEBUG TRAIN Batch 42/600 loss 0.136276 acc 0.903019 lr 0.00024775 grad_norm 0.586929 rank 1
2025-01-10 11:52:03,068 DEBUG TRAIN Batch 42/600 loss 0.099161 acc 0.928230 lr 0.00024775 grad_norm 0.586929 rank 0
2025-01-10 11:52:03,068 DEBUG TRAIN Batch 42/600 loss 0.142200 acc 0.902597 lr 0.00024775 grad_norm 0.586929 rank 2
2025-01-10 11:52:27,994 DEBUG TRAIN Batch 42/700 loss 0.168438 acc 0.889081 lr 0.00024759 grad_norm 0.558356 rank 2
2025-01-10 11:52:27,994 DEBUG TRAIN Batch 42/700 loss 0.103364 acc 0.933005 lr 0.00024759 grad_norm 0.558356 rank 0
2025-01-10 11:52:27,994 DEBUG TRAIN Batch 42/700 loss 0.132083 acc 0.917327 lr 0.00024759 grad_norm 0.558356 rank 1
2025-01-10 11:52:52,861 DEBUG TRAIN Batch 42/800 loss 0.140853 acc 0.893392 lr 0.00024744 grad_norm 0.599325 rank 1
2025-01-10 11:52:52,861 DEBUG TRAIN Batch 42/800 loss 0.130528 acc 0.905028 lr 0.00024744 grad_norm 0.599325 rank 2
2025-01-10 11:52:52,862 DEBUG TRAIN Batch 42/800 loss 0.123230 acc 0.914918 lr 0.00024744 grad_norm 0.599325 rank 0
2025-01-10 11:53:17,508 DEBUG TRAIN Batch 42/900 loss 0.179149 acc 0.874542 lr 0.00024729 grad_norm 0.591131 rank 0
2025-01-10 11:53:17,508 DEBUG TRAIN Batch 42/900 loss 0.073850 acc 0.957121 lr 0.00024729 grad_norm 0.591131 rank 1
2025-01-10 11:53:17,508 DEBUG TRAIN Batch 42/900 loss 0.182851 acc 0.878683 lr 0.00024729 grad_norm 0.591131 rank 2
2025-01-10 11:53:41,932 DEBUG TRAIN Batch 42/1000 loss 0.080965 acc 0.945205 lr 0.00024714 grad_norm 0.548914 rank 1
2025-01-10 11:53:41,932 DEBUG TRAIN Batch 42/1000 loss 0.113540 acc 0.915315 lr 0.00024714 grad_norm 0.548914 rank 0
2025-01-10 11:53:41,932 DEBUG TRAIN Batch 42/1000 loss 0.120285 acc 0.920193 lr 0.00024714 grad_norm 0.548914 rank 2
2025-01-10 11:54:07,127 DEBUG TRAIN Batch 42/1100 loss 0.146735 acc 0.910101 lr 0.00024699 grad_norm 0.568769 rank 1
2025-01-10 11:54:07,127 DEBUG TRAIN Batch 42/1100 loss 0.107653 acc 0.927165 lr 0.00024699 grad_norm 0.568769 rank 0
2025-01-10 11:54:07,127 DEBUG TRAIN Batch 42/1100 loss 0.073230 acc 0.941558 lr 0.00024699 grad_norm 0.568769 rank 2
2025-01-10 11:54:31,411 DEBUG TRAIN Batch 42/1200 loss 0.140223 acc 0.903727 lr 0.00024684 grad_norm 0.555634 rank 1
2025-01-10 11:54:31,411 DEBUG TRAIN Batch 42/1200 loss 0.090282 acc 0.939181 lr 0.00024684 grad_norm 0.555634 rank 0
2025-01-10 11:54:31,411 DEBUG TRAIN Batch 42/1200 loss 0.154770 acc 0.892889 lr 0.00024684 grad_norm 0.555634 rank 2
2025-01-10 11:54:55,681 DEBUG TRAIN Batch 42/1300 loss 0.158520 acc 0.877998 lr 0.00024669 grad_norm 0.613177 rank 2
2025-01-10 11:54:55,681 DEBUG TRAIN Batch 42/1300 loss 0.212920 acc 0.851180 lr 0.00024669 grad_norm 0.613177 rank 1
2025-01-10 11:54:55,681 DEBUG TRAIN Batch 42/1300 loss 0.153355 acc 0.900742 lr 0.00024669 grad_norm 0.613177 rank 0
2025-01-10 11:55:20,058 DEBUG TRAIN Batch 42/1400 loss 0.152975 acc 0.888340 lr 0.00024654 grad_norm 0.619205 rank 2
2025-01-10 11:55:20,058 DEBUG TRAIN Batch 42/1400 loss 0.155129 acc 0.884615 lr 0.00024654 grad_norm 0.619205 rank 0
2025-01-10 11:55:20,058 DEBUG TRAIN Batch 42/1400 loss 0.169603 acc 0.883142 lr 0.00024654 grad_norm 0.619205 rank 1
2025-01-10 11:55:43,980 DEBUG TRAIN Batch 42/1500 loss 0.143398 acc 0.901274 lr 0.00024639 grad_norm 0.578310 rank 1
2025-01-10 11:55:43,981 DEBUG TRAIN Batch 42/1500 loss 0.113950 acc 0.919373 lr 0.00024639 grad_norm 0.578310 rank 2
2025-01-10 11:55:43,981 DEBUG TRAIN Batch 42/1500 loss 0.125116 acc 0.914226 lr 0.00024639 grad_norm 0.578310 rank 0
2025-01-10 11:56:08,680 DEBUG TRAIN Batch 42/1600 loss 0.174507 acc 0.879388 lr 0.00024624 grad_norm 0.629852 rank 1
2025-01-10 11:56:08,681 DEBUG TRAIN Batch 42/1600 loss 0.161630 acc 0.883568 lr 0.00024624 grad_norm 0.629852 rank 0
2025-01-10 11:56:08,681 DEBUG TRAIN Batch 42/1600 loss 0.175927 acc 0.885714 lr 0.00024624 grad_norm 0.629852 rank 2
2025-01-10 11:56:32,078 DEBUG TRAIN Batch 42/1700 loss 0.166779 acc 0.885849 lr 0.00024609 grad_norm 0.605124 rank 1
2025-01-10 11:56:32,079 DEBUG TRAIN Batch 42/1700 loss 0.159511 acc 0.889109 lr 0.00024609 grad_norm 0.605124 rank 2
2025-01-10 11:56:32,079 DEBUG TRAIN Batch 42/1700 loss 0.151665 acc 0.902256 lr 0.00024609 grad_norm 0.605124 rank 0
2025-01-10 11:56:56,330 DEBUG TRAIN Batch 42/1800 loss 0.182616 acc 0.868225 lr 0.00024594 grad_norm 0.621030 rank 1
2025-01-10 11:56:56,331 DEBUG TRAIN Batch 42/1800 loss 0.166544 acc 0.879812 lr 0.00024594 grad_norm 0.621030 rank 0
2025-01-10 11:56:56,331 DEBUG TRAIN Batch 42/1800 loss 0.159767 acc 0.888345 lr 0.00024594 grad_norm 0.621030 rank 2
2025-01-10 11:57:20,288 DEBUG TRAIN Batch 42/1900 loss 0.158504 acc 0.885326 lr 0.00024579 grad_norm 0.642871 rank 0
2025-01-10 11:57:20,288 DEBUG TRAIN Batch 42/1900 loss 0.181103 acc 0.868449 lr 0.00024579 grad_norm 0.642871 rank 1
2025-01-10 11:57:20,288 DEBUG TRAIN Batch 42/1900 loss 0.147787 acc 0.901064 lr 0.00024579 grad_norm 0.642871 rank 2
2025-01-10 11:57:44,092 DEBUG TRAIN Batch 42/2000 loss 0.187199 acc 0.864668 lr 0.00024564 grad_norm 0.660114 rank 1
2025-01-10 11:57:44,092 DEBUG TRAIN Batch 42/2000 loss 0.177170 acc 0.876740 lr 0.00024564 grad_norm 0.660114 rank 2
2025-01-10 11:57:44,092 DEBUG TRAIN Batch 42/2000 loss 0.181973 acc 0.880383 lr 0.00024564 grad_norm 0.660114 rank 0
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 11:58:53,827 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 11:58:53,839 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 11:58:54,227 INFO Epoch 42 Step 41451 on_batch_end True CV rank 2
2025-01-10 11:58:54,227 INFO Epoch 42 Step 41451 on_batch_end True CV rank 1
2025-01-10 11:58:54,227 INFO Epoch 42 Step 41451 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 11:59:03,574 DEBUG CV Batch 42/100 loss 0.077219 acc 0.973244  rank 2
2025-01-10 11:59:03,753 DEBUG CV Batch 42/100 loss 0.077219 acc 0.973244  rank 0
2025-01-10 11:59:03,999 DEBUG CV Batch 42/100 loss 0.077219 acc 0.973244  rank 1
2025-01-10 11:59:04,104 INFO Epoch 42 Step 41451 CV info lr 0.00024558537379505105 2 rank loss_1.7895669387081605 acc_0.7706339540973044
2025-01-10 11:59:04,290 INFO Epoch 42 Step 41451 CV info lr 0.00024558537379505105 0 rank loss_1.7895669387081605 acc_0.7706339540973044
2025-01-10 11:59:04,542 INFO Epoch 42 Step 41451 CV info lr 0.00024558537379505105 1 rank loss_1.7895669387081605 acc_0.7706339540973044
2025-01-10 11:59:05,753 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_42_whole.pt
2025-01-10 11:59:05,775 INFO Added key: store_based_barrier_key:45 to store for rank: 0
2025-01-10 11:59:05,776 INFO Added key: store_based_barrier_key:45 to store for rank: 2
2025-01-10 11:59:05,775 INFO Added key: store_based_barrier_key:45 to store for rank: 1
2025-01-10 11:59:05,776 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:45 with 3 nodes.
2025-01-10 11:59:05,776 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:45 with 3 nodes.
2025-01-10 11:59:05,785 INFO Epoch 43 TRAIN info lr 0.00024558537379505105 rank 2
2025-01-10 11:59:05,785 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 11:59:05,786 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:45 with 3 nodes.
2025-01-10 11:59:05,786 INFO Epoch 43 TRAIN info lr 0.00024558537379505105 rank 1
2025-01-10 11:59:05,786 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 11:59:05,794 INFO Epoch 43 TRAIN info lr 0.00024558537379505105 rank 0
2025-01-10 11:59:05,794 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 11:59:42,689 DEBUG TRAIN Batch 43/100 loss 0.133655 acc 0.903965 lr 0.00024544 grad_norm 0.537730 rank 0
2025-01-10 11:59:42,689 DEBUG TRAIN Batch 43/100 loss 0.119919 acc 0.917917 lr 0.00024544 grad_norm 0.537730 rank 2
2025-01-10 11:59:42,689 DEBUG TRAIN Batch 43/100 loss 0.118489 acc 0.922676 lr 0.00024544 grad_norm 0.537730 rank 1
2025-01-10 12:00:06,654 DEBUG TRAIN Batch 43/200 loss 0.103235 acc 0.927221 lr 0.00024529 grad_norm 0.538953 rank 2
2025-01-10 12:00:06,655 DEBUG TRAIN Batch 43/200 loss 0.119036 acc 0.914313 lr 0.00024529 grad_norm 0.538953 rank 0
2025-01-10 12:00:06,655 DEBUG TRAIN Batch 43/200 loss 0.110670 acc 0.927945 lr 0.00024529 grad_norm 0.538953 rank 1
2025-01-10 12:00:31,089 DEBUG TRAIN Batch 43/300 loss 0.106676 acc 0.939880 lr 0.00024514 grad_norm 0.547360 rank 1
2025-01-10 12:00:31,090 DEBUG TRAIN Batch 43/300 loss 0.148686 acc 0.900596 lr 0.00024514 grad_norm 0.547360 rank 0
2025-01-10 12:00:31,090 DEBUG TRAIN Batch 43/300 loss 0.131588 acc 0.901852 lr 0.00024514 grad_norm 0.547360 rank 2
2025-01-10 12:00:55,652 DEBUG TRAIN Batch 43/400 loss 0.154653 acc 0.897366 lr 0.00024500 grad_norm 0.554141 rank 1
2025-01-10 12:00:55,652 DEBUG TRAIN Batch 43/400 loss 0.092956 acc 0.931987 lr 0.00024500 grad_norm 0.554141 rank 2
2025-01-10 12:00:55,652 DEBUG TRAIN Batch 43/400 loss 0.113548 acc 0.917219 lr 0.00024500 grad_norm 0.554141 rank 0
2025-01-10 12:01:20,088 DEBUG TRAIN Batch 43/500 loss 0.112592 acc 0.919075 lr 0.00024485 grad_norm 0.584036 rank 2
2025-01-10 12:01:20,089 DEBUG TRAIN Batch 43/500 loss 0.169120 acc 0.891221 lr 0.00024485 grad_norm 0.584036 rank 0
2025-01-10 12:01:20,089 DEBUG TRAIN Batch 43/500 loss 0.137351 acc 0.904357 lr 0.00024485 grad_norm 0.584036 rank 1
2025-01-10 12:01:45,316 DEBUG TRAIN Batch 43/600 loss 0.157862 acc 0.891767 lr 0.00024470 grad_norm 0.569241 rank 2
2025-01-10 12:01:45,316 DEBUG TRAIN Batch 43/600 loss 0.151149 acc 0.885799 lr 0.00024470 grad_norm 0.569241 rank 0
2025-01-10 12:01:45,317 DEBUG TRAIN Batch 43/600 loss 0.110236 acc 0.922680 lr 0.00024470 grad_norm 0.569241 rank 1
2025-01-10 12:02:09,724 DEBUG TRAIN Batch 43/700 loss 0.157360 acc 0.886467 lr 0.00024456 grad_norm 0.560742 rank 2
2025-01-10 12:02:09,725 DEBUG TRAIN Batch 43/700 loss 0.179480 acc 0.881462 lr 0.00024456 grad_norm 0.560742 rank 1
2025-01-10 12:02:09,725 DEBUG TRAIN Batch 43/700 loss 0.119215 acc 0.916772 lr 0.00024456 grad_norm 0.560742 rank 0
2025-01-10 12:02:35,125 DEBUG TRAIN Batch 43/800 loss 0.153351 acc 0.882294 lr 0.00024441 grad_norm 0.565632 rank 2
2025-01-10 12:02:35,125 DEBUG TRAIN Batch 43/800 loss 0.163520 acc 0.886899 lr 0.00024441 grad_norm 0.565632 rank 0
2025-01-10 12:02:35,126 DEBUG TRAIN Batch 43/800 loss 0.162595 acc 0.889980 lr 0.00024441 grad_norm 0.565632 rank 1
2025-01-10 12:02:58,737 DEBUG TRAIN Batch 43/900 loss 0.151066 acc 0.882229 lr 0.00024426 grad_norm 0.563199 rank 2
2025-01-10 12:02:58,737 DEBUG TRAIN Batch 43/900 loss 0.083861 acc 0.947307 lr 0.00024426 grad_norm 0.563199 rank 0
2025-01-10 12:02:58,737 DEBUG TRAIN Batch 43/900 loss 0.164320 acc 0.886531 lr 0.00024426 grad_norm 0.563199 rank 1
2025-01-10 12:03:23,083 DEBUG TRAIN Batch 43/1000 loss 0.142237 acc 0.896091 lr 0.00024412 grad_norm 0.561435 rank 1
2025-01-10 12:03:23,083 DEBUG TRAIN Batch 43/1000 loss 0.120954 acc 0.922925 lr 0.00024412 grad_norm 0.561435 rank 0
2025-01-10 12:03:23,084 DEBUG TRAIN Batch 43/1000 loss 0.180725 acc 0.883080 lr 0.00024412 grad_norm 0.561435 rank 2
2025-01-10 12:03:48,539 DEBUG TRAIN Batch 43/1100 loss 0.169641 acc 0.892857 lr 0.00024397 grad_norm 0.597333 rank 0
2025-01-10 12:03:48,539 DEBUG TRAIN Batch 43/1100 loss 0.198085 acc 0.865036 lr 0.00024397 grad_norm 0.597333 rank 2
2025-01-10 12:03:48,539 DEBUG TRAIN Batch 43/1100 loss 0.133171 acc 0.907520 lr 0.00024397 grad_norm 0.597333 rank 1
2025-01-10 12:04:12,422 DEBUG TRAIN Batch 43/1200 loss 0.095759 acc 0.936860 lr 0.00024383 grad_norm 0.589999 rank 2
2025-01-10 12:04:12,422 DEBUG TRAIN Batch 43/1200 loss 0.153623 acc 0.891821 lr 0.00024383 grad_norm 0.589999 rank 1
2025-01-10 12:04:12,423 DEBUG TRAIN Batch 43/1200 loss 0.193910 acc 0.869231 lr 0.00024383 grad_norm 0.589999 rank 0
2025-01-10 12:04:36,023 DEBUG TRAIN Batch 43/1300 loss 0.110100 acc 0.923226 lr 0.00024368 grad_norm 0.586599 rank 1
2025-01-10 12:04:36,023 DEBUG TRAIN Batch 43/1300 loss 0.156738 acc 0.886674 lr 0.00024368 grad_norm 0.586599 rank 0
2025-01-10 12:04:36,023 DEBUG TRAIN Batch 43/1300 loss 0.126519 acc 0.908613 lr 0.00024368 grad_norm 0.586599 rank 2
2025-01-10 12:05:00,253 DEBUG TRAIN Batch 43/1400 loss 0.207845 acc 0.852761 lr 0.00024354 grad_norm 0.589009 rank 0
2025-01-10 12:05:00,253 DEBUG TRAIN Batch 43/1400 loss 0.118298 acc 0.924706 lr 0.00024354 grad_norm 0.589009 rank 1
2025-01-10 12:05:00,253 DEBUG TRAIN Batch 43/1400 loss 0.137904 acc 0.888670 lr 0.00024354 grad_norm 0.589009 rank 2
2025-01-10 12:05:24,350 DEBUG TRAIN Batch 43/1500 loss 0.171695 acc 0.873358 lr 0.00024339 grad_norm 0.620833 rank 1
2025-01-10 12:05:24,351 DEBUG TRAIN Batch 43/1500 loss 0.190167 acc 0.864086 lr 0.00024339 grad_norm 0.620833 rank 2
2025-01-10 12:05:24,351 DEBUG TRAIN Batch 43/1500 loss 0.127132 acc 0.907712 lr 0.00024339 grad_norm 0.620833 rank 0
2025-01-10 12:05:48,877 DEBUG TRAIN Batch 43/1600 loss 0.141299 acc 0.894191 lr 0.00024325 grad_norm 0.595950 rank 0
2025-01-10 12:05:48,877 DEBUG TRAIN Batch 43/1600 loss 0.167815 acc 0.887906 lr 0.00024325 grad_norm 0.595950 rank 2
2025-01-10 12:05:48,877 DEBUG TRAIN Batch 43/1600 loss 0.130174 acc 0.918338 lr 0.00024325 grad_norm 0.595950 rank 1
2025-01-10 12:06:12,647 DEBUG TRAIN Batch 43/1700 loss 0.121173 acc 0.919670 lr 0.00024311 grad_norm 0.586335 rank 0
2025-01-10 12:06:12,647 DEBUG TRAIN Batch 43/1700 loss 0.128188 acc 0.917460 lr 0.00024311 grad_norm 0.586335 rank 1
2025-01-10 12:06:12,647 DEBUG TRAIN Batch 43/1700 loss 0.174656 acc 0.874770 lr 0.00024311 grad_norm 0.586335 rank 2
2025-01-10 12:06:36,623 DEBUG TRAIN Batch 43/1800 loss 0.179268 acc 0.885996 lr 0.00024296 grad_norm 0.593271 rank 0
2025-01-10 12:06:36,624 DEBUG TRAIN Batch 43/1800 loss 0.118522 acc 0.926506 lr 0.00024296 grad_norm 0.593271 rank 1
2025-01-10 12:06:36,624 DEBUG TRAIN Batch 43/1800 loss 0.195325 acc 0.863233 lr 0.00024296 grad_norm 0.593271 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 12:08:01,493 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 12:08:01,500 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 12:08:01,955 INFO Epoch 43 Step 42400 on_batch_end True CV rank 1
2025-01-10 12:08:01,955 INFO Epoch 43 Step 42400 on_batch_end True CV rank 2
2025-01-10 12:08:01,955 INFO Epoch 43 Step 42400 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 12:08:11,370 DEBUG CV Batch 43/100 loss 0.063421 acc 0.981048  rank 2
2025-01-10 12:08:11,380 DEBUG CV Batch 43/100 loss 0.063421 acc 0.981048  rank 0
2025-01-10 12:08:11,626 DEBUG CV Batch 43/100 loss 0.063421 acc 0.981048  rank 1
2025-01-10 12:08:11,905 INFO Epoch 43 Step 42400 CV info lr 0.00024282146558931604 2 rank loss_1.837457942335229 acc_0.7704478293134455
2025-01-10 12:08:11,906 INFO Epoch 43 Step 42400 CV info lr 0.00024282146558931604 0 rank loss_1.837457942335229 acc_0.7704478293134455
2025-01-10 12:08:12,178 INFO Epoch 43 Step 42400 CV info lr 0.00024282146558931604 1 rank loss_1.837457942335229 acc_0.7704478293134455
2025-01-10 12:08:13,168 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_43_whole.pt
2025-01-10 12:08:13,190 INFO Added key: store_based_barrier_key:46 to store for rank: 0
2025-01-10 12:08:13,200 INFO Added key: store_based_barrier_key:46 to store for rank: 2
2025-01-10 12:08:13,201 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:46 with 3 nodes.
2025-01-10 12:08:13,201 INFO Added key: store_based_barrier_key:46 to store for rank: 1
2025-01-10 12:08:13,201 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:46 with 3 nodes.
2025-01-10 12:08:13,201 INFO Epoch 44 TRAIN info lr 0.00024282146558931604 rank 1
2025-01-10 12:08:13,201 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 12:08:13,203 INFO Epoch 44 TRAIN info lr 0.00024282146558931604 rank 2
2025-01-10 12:08:13,203 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 12:08:13,210 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:46 with 3 nodes.
2025-01-10 12:08:13,215 INFO Epoch 44 TRAIN info lr 0.00024282146558931604 rank 0
2025-01-10 12:08:13,215 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 12:08:47,242 DEBUG TRAIN Batch 44/100 loss 0.075731 acc 0.945752 lr 0.00024268 grad_norm 0.553166 rank 2
2025-01-10 12:08:47,243 DEBUG TRAIN Batch 44/100 loss 0.145041 acc 0.912088 lr 0.00024268 grad_norm 0.553166 rank 0
2025-01-10 12:08:47,243 DEBUG TRAIN Batch 44/100 loss 0.135048 acc 0.909938 lr 0.00024268 grad_norm 0.553166 rank 1
2025-01-10 12:09:11,511 DEBUG TRAIN Batch 44/200 loss 0.149264 acc 0.895349 lr 0.00024254 grad_norm 0.569574 rank 1
2025-01-10 12:09:11,511 DEBUG TRAIN Batch 44/200 loss 0.090112 acc 0.930705 lr 0.00024254 grad_norm 0.569574 rank 2
2025-01-10 12:09:11,511 DEBUG TRAIN Batch 44/200 loss 0.123506 acc 0.915633 lr 0.00024254 grad_norm 0.569574 rank 0
2025-01-10 12:09:36,066 DEBUG TRAIN Batch 44/300 loss 0.125304 acc 0.917300 lr 0.00024239 grad_norm 0.562854 rank 2
2025-01-10 12:09:36,066 DEBUG TRAIN Batch 44/300 loss 0.135217 acc 0.911824 lr 0.00024239 grad_norm 0.562854 rank 0
2025-01-10 12:09:36,066 DEBUG TRAIN Batch 44/300 loss 0.158370 acc 0.894096 lr 0.00024239 grad_norm 0.562854 rank 1
2025-01-10 12:10:00,208 DEBUG TRAIN Batch 44/400 loss 0.134663 acc 0.903587 lr 0.00024225 grad_norm 0.586137 rank 0
2025-01-10 12:10:00,208 DEBUG TRAIN Batch 44/400 loss 0.133791 acc 0.910596 lr 0.00024225 grad_norm 0.586137 rank 1
2025-01-10 12:10:00,208 DEBUG TRAIN Batch 44/400 loss 0.095556 acc 0.940460 lr 0.00024225 grad_norm 0.586137 rank 2
2025-01-10 12:10:24,416 DEBUG TRAIN Batch 44/500 loss 0.079272 acc 0.947635 lr 0.00024211 grad_norm 0.528140 rank 0
2025-01-10 12:10:24,416 DEBUG TRAIN Batch 44/500 loss 0.139870 acc 0.904135 lr 0.00024211 grad_norm 0.528140 rank 1
2025-01-10 12:10:24,416 DEBUG TRAIN Batch 44/500 loss 0.087608 acc 0.949692 lr 0.00024211 grad_norm 0.528140 rank 2
2025-01-10 12:10:48,683 DEBUG TRAIN Batch 44/600 loss 0.111465 acc 0.915072 lr 0.00024197 grad_norm 0.553010 rank 2
2025-01-10 12:10:48,683 DEBUG TRAIN Batch 44/600 loss 0.112450 acc 0.914914 lr 0.00024197 grad_norm 0.553010 rank 1
2025-01-10 12:10:48,684 DEBUG TRAIN Batch 44/600 loss 0.123300 acc 0.909774 lr 0.00024197 grad_norm 0.553010 rank 0
2025-01-10 12:11:14,140 DEBUG TRAIN Batch 44/700 loss 0.106177 acc 0.923888 lr 0.00024183 grad_norm 0.604877 rank 1
2025-01-10 12:11:14,140 DEBUG TRAIN Batch 44/700 loss 0.155599 acc 0.887067 lr 0.00024183 grad_norm 0.604877 rank 0
2025-01-10 12:11:14,141 DEBUG TRAIN Batch 44/700 loss 0.163085 acc 0.887500 lr 0.00024183 grad_norm 0.604877 rank 2
2025-01-10 12:11:38,550 DEBUG TRAIN Batch 44/800 loss 0.147811 acc 0.909007 lr 0.00024168 grad_norm 0.544711 rank 0
2025-01-10 12:11:38,550 DEBUG TRAIN Batch 44/800 loss 0.148398 acc 0.904813 lr 0.00024168 grad_norm 0.544711 rank 1
2025-01-10 12:11:38,551 DEBUG TRAIN Batch 44/800 loss 0.079993 acc 0.950746 lr 0.00024168 grad_norm 0.544711 rank 2
2025-01-10 12:12:02,853 DEBUG TRAIN Batch 44/900 loss 0.162325 acc 0.889616 lr 0.00024154 grad_norm 0.596441 rank 1
2025-01-10 12:12:02,854 DEBUG TRAIN Batch 44/900 loss 0.144169 acc 0.899390 lr 0.00024154 grad_norm 0.596441 rank 0
2025-01-10 12:12:02,854 DEBUG TRAIN Batch 44/900 loss 0.159424 acc 0.882187 lr 0.00024154 grad_norm 0.596441 rank 2
2025-01-10 12:12:28,301 DEBUG TRAIN Batch 44/1000 loss 0.157345 acc 0.893514 lr 0.00024140 grad_norm 0.550436 rank 2
2025-01-10 12:12:28,301 DEBUG TRAIN Batch 44/1000 loss 0.140001 acc 0.898981 lr 0.00024140 grad_norm 0.550436 rank 1
2025-01-10 12:12:28,302 DEBUG TRAIN Batch 44/1000 loss 0.159921 acc 0.884290 lr 0.00024140 grad_norm 0.550436 rank 0
2025-01-10 12:12:52,288 DEBUG TRAIN Batch 44/1100 loss 0.140767 acc 0.899826 lr 0.00024126 grad_norm 0.568186 rank 0
2025-01-10 12:12:52,288 DEBUG TRAIN Batch 44/1100 loss 0.136757 acc 0.909276 lr 0.00024126 grad_norm 0.568186 rank 1
2025-01-10 12:12:52,289 DEBUG TRAIN Batch 44/1100 loss 0.144591 acc 0.900293 lr 0.00024126 grad_norm 0.568186 rank 2
2025-01-10 12:13:17,126 DEBUG TRAIN Batch 44/1200 loss 0.153960 acc 0.883766 lr 0.00024112 grad_norm 0.596991 rank 1
2025-01-10 12:13:17,126 DEBUG TRAIN Batch 44/1200 loss 0.144628 acc 0.900106 lr 0.00024112 grad_norm 0.596991 rank 2
2025-01-10 12:13:17,127 DEBUG TRAIN Batch 44/1200 loss 0.104653 acc 0.932099 lr 0.00024112 grad_norm 0.596991 rank 0
2025-01-10 12:13:42,041 DEBUG TRAIN Batch 44/1300 loss 0.143900 acc 0.900812 lr 0.00024098 grad_norm 0.597871 rank 2
2025-01-10 12:13:42,041 DEBUG TRAIN Batch 44/1300 loss 0.169683 acc 0.877833 lr 0.00024098 grad_norm 0.597871 rank 0
2025-01-10 12:13:42,041 DEBUG TRAIN Batch 44/1300 loss 0.162556 acc 0.887170 lr 0.00024098 grad_norm 0.597871 rank 1
2025-01-10 12:14:06,515 DEBUG TRAIN Batch 44/1400 loss 0.139035 acc 0.921053 lr 0.00024084 grad_norm 0.647432 rank 2
2025-01-10 12:14:06,515 DEBUG TRAIN Batch 44/1400 loss 0.142038 acc 0.899811 lr 0.00024084 grad_norm 0.647432 rank 1
2025-01-10 12:14:06,515 DEBUG TRAIN Batch 44/1400 loss 0.194492 acc 0.862194 lr 0.00024084 grad_norm 0.647432 rank 0
2025-01-10 12:14:32,153 DEBUG TRAIN Batch 44/1500 loss 0.139111 acc 0.897998 lr 0.00024070 grad_norm 0.539701 rank 2
2025-01-10 12:14:32,153 DEBUG TRAIN Batch 44/1500 loss 0.119713 acc 0.921550 lr 0.00024070 grad_norm 0.539701 rank 1
2025-01-10 12:14:32,154 DEBUG TRAIN Batch 44/1500 loss 0.152320 acc 0.895131 lr 0.00024070 grad_norm 0.539701 rank 0
2025-01-10 12:14:56,943 DEBUG TRAIN Batch 44/1600 loss 0.123055 acc 0.916016 lr 0.00024056 grad_norm 0.574225 rank 1
2025-01-10 12:14:56,943 DEBUG TRAIN Batch 44/1600 loss 0.189466 acc 0.865317 lr 0.00024056 grad_norm 0.574225 rank 0
2025-01-10 12:14:56,944 DEBUG TRAIN Batch 44/1600 loss 0.168920 acc 0.891325 lr 0.00024056 grad_norm 0.574225 rank 2
2025-01-10 12:15:20,457 DEBUG TRAIN Batch 44/1700 loss 0.111338 acc 0.926425 lr 0.00024042 grad_norm 0.567453 rank 1
2025-01-10 12:15:20,457 DEBUG TRAIN Batch 44/1700 loss 0.183184 acc 0.873188 lr 0.00024042 grad_norm 0.567453 rank 0
2025-01-10 12:15:20,458 DEBUG TRAIN Batch 44/1700 loss 0.136537 acc 0.912145 lr 0.00024042 grad_norm 0.567453 rank 2
2025-01-10 12:15:45,323 DEBUG TRAIN Batch 44/1800 loss 0.107063 acc 0.926650 lr 0.00024028 grad_norm 0.605539 rank 1
2025-01-10 12:15:45,324 DEBUG TRAIN Batch 44/1800 loss 0.198337 acc 0.865702 lr 0.00024028 grad_norm 0.605539 rank 0
2025-01-10 12:15:45,324 DEBUG TRAIN Batch 44/1800 loss 0.144406 acc 0.903475 lr 0.00024028 grad_norm 0.605539 rank 2
2025-01-10 12:16:09,220 DEBUG TRAIN Batch 44/1900 loss 0.162930 acc 0.890960 lr 0.00024015 grad_norm 0.612090 rank 1
2025-01-10 12:16:09,220 DEBUG TRAIN Batch 44/1900 loss 0.134554 acc 0.911205 lr 0.00024015 grad_norm 0.612090 rank 2
2025-01-10 12:16:09,220 DEBUG TRAIN Batch 44/1900 loss 0.151909 acc 0.893138 lr 0.00024015 grad_norm 0.612090 rank 0
2025-01-10 12:16:33,163 DEBUG TRAIN Batch 44/2000 loss 0.164290 acc 0.887912 lr 0.00024001 grad_norm 0.613158 rank 1
2025-01-10 12:16:33,163 DEBUG TRAIN Batch 44/2000 loss 0.178898 acc 0.878049 lr 0.00024001 grad_norm 0.613158 rank 2
2025-01-10 12:16:33,163 DEBUG TRAIN Batch 44/2000 loss 0.189395 acc 0.869361 lr 0.00024001 grad_norm 0.613158 rank 0
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 12:17:44,144 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 12:17:44,145 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 12:17:44,538 INFO Epoch 44 Step 43423 on_batch_end True CV rank 2
2025-01-10 12:17:44,538 INFO Epoch 44 Step 43423 on_batch_end True CV rank 0
2025-01-10 12:17:44,538 INFO Epoch 44 Step 43423 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 12:17:53,914 DEBUG CV Batch 44/100 loss 0.061046 acc 0.979933  rank 0
2025-01-10 12:17:53,970 DEBUG CV Batch 44/100 loss 0.061046 acc 0.979933  rank 2
2025-01-10 12:17:54,297 DEBUG CV Batch 44/100 loss 0.061046 acc 0.979933  rank 1
2025-01-10 12:17:54,419 INFO Epoch 44 Step 43423 CV info lr 0.00023994410912974758 0 rank loss_1.8144131131274135 acc_0.7716938550012153
2025-01-10 12:17:54,506 INFO Epoch 44 Step 43423 CV info lr 0.00023994410912974758 2 rank loss_1.8144131131274135 acc_0.7716938550012153
2025-01-10 12:17:54,833 INFO Epoch 44 Step 43423 CV info lr 0.00023994410912974758 1 rank loss_1.8144131131274135 acc_0.7716938550012153
2025-01-10 12:17:55,695 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_44_whole.pt
2025-01-10 12:17:55,707 INFO Added key: store_based_barrier_key:47 to store for rank: 0
2025-01-10 12:17:55,717 INFO Added key: store_based_barrier_key:47 to store for rank: 2
2025-01-10 12:17:55,717 INFO Added key: store_based_barrier_key:47 to store for rank: 1
2025-01-10 12:17:55,717 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:47 with 3 nodes.
2025-01-10 12:17:55,717 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:47 with 3 nodes.
2025-01-10 12:17:55,723 INFO Epoch 45 TRAIN info lr 0.00023994410912974758 rank 2
2025-01-10 12:17:55,723 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 12:17:55,727 INFO Epoch 45 TRAIN info lr 0.00023994410912974758 rank 1
2025-01-10 12:17:55,727 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 12:17:55,727 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:47 with 3 nodes.
2025-01-10 12:17:55,728 INFO Epoch 45 TRAIN info lr 0.00023994410912974758 rank 0
2025-01-10 12:17:55,728 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 12:18:32,345 DEBUG TRAIN Batch 45/100 loss 0.122858 acc 0.916519 lr 0.00023981 grad_norm 0.539127 rank 2
2025-01-10 12:18:32,345 DEBUG TRAIN Batch 45/100 loss 0.139254 acc 0.904509 lr 0.00023981 grad_norm 0.539127 rank 0
2025-01-10 12:18:32,345 DEBUG TRAIN Batch 45/100 loss 0.077230 acc 0.944030 lr 0.00023981 grad_norm 0.539127 rank 1
2025-01-10 12:18:56,755 DEBUG TRAIN Batch 45/200 loss 0.081552 acc 0.941463 lr 0.00023967 grad_norm 0.551697 rank 0
2025-01-10 12:18:56,755 DEBUG TRAIN Batch 45/200 loss 0.087603 acc 0.943249 lr 0.00023967 grad_norm 0.551697 rank 1
2025-01-10 12:18:56,755 DEBUG TRAIN Batch 45/200 loss 0.196881 acc 0.858070 lr 0.00023967 grad_norm 0.551697 rank 2
2025-01-10 12:19:21,473 DEBUG TRAIN Batch 45/300 loss 0.169312 acc 0.886858 lr 0.00023953 grad_norm 0.565698 rank 2
2025-01-10 12:19:21,473 DEBUG TRAIN Batch 45/300 loss 0.145612 acc 0.898305 lr 0.00023953 grad_norm 0.565698 rank 0
2025-01-10 12:19:21,473 DEBUG TRAIN Batch 45/300 loss 0.068933 acc 0.953795 lr 0.00023953 grad_norm 0.565698 rank 1
2025-01-10 12:19:45,234 DEBUG TRAIN Batch 45/400 loss 0.161001 acc 0.889474 lr 0.00023939 grad_norm 0.595699 rank 0
2025-01-10 12:19:45,234 DEBUG TRAIN Batch 45/400 loss 0.204970 acc 0.853222 lr 0.00023939 grad_norm 0.595699 rank 2
2025-01-10 12:19:45,234 DEBUG TRAIN Batch 45/400 loss 0.071992 acc 0.953824 lr 0.00023939 grad_norm 0.595699 rank 1
2025-01-10 12:20:10,409 DEBUG TRAIN Batch 45/500 loss 0.085694 acc 0.939181 lr 0.00023926 grad_norm 0.550058 rank 1
2025-01-10 12:20:10,409 DEBUG TRAIN Batch 45/500 loss 0.118582 acc 0.923958 lr 0.00023926 grad_norm 0.550058 rank 2
2025-01-10 12:20:10,409 DEBUG TRAIN Batch 45/500 loss 0.129861 acc 0.907821 lr 0.00023926 grad_norm 0.550058 rank 0
2025-01-10 12:20:35,104 DEBUG TRAIN Batch 45/600 loss 0.141641 acc 0.901501 lr 0.00023912 grad_norm 0.548090 rank 2
2025-01-10 12:20:35,104 DEBUG TRAIN Batch 45/600 loss 0.105073 acc 0.928050 lr 0.00023912 grad_norm 0.548090 rank 1
2025-01-10 12:20:35,104 DEBUG TRAIN Batch 45/600 loss 0.132161 acc 0.914397 lr 0.00023912 grad_norm 0.548090 rank 0
2025-01-10 12:20:59,265 DEBUG TRAIN Batch 45/700 loss 0.081230 acc 0.943617 lr 0.00023898 grad_norm 0.561750 rank 1
2025-01-10 12:20:59,265 DEBUG TRAIN Batch 45/700 loss 0.120693 acc 0.915480 lr 0.00023898 grad_norm 0.561750 rank 2
2025-01-10 12:20:59,265 DEBUG TRAIN Batch 45/700 loss 0.123746 acc 0.905488 lr 0.00023898 grad_norm 0.561750 rank 0
2025-01-10 12:21:24,451 DEBUG TRAIN Batch 45/800 loss 0.070385 acc 0.949324 lr 0.00023885 grad_norm 0.582967 rank 1
2025-01-10 12:21:24,451 DEBUG TRAIN Batch 45/800 loss 0.153976 acc 0.907921 lr 0.00023885 grad_norm 0.582967 rank 2
2025-01-10 12:21:24,451 DEBUG TRAIN Batch 45/800 loss 0.150854 acc 0.890423 lr 0.00023885 grad_norm 0.582967 rank 0
2025-01-10 12:21:48,288 DEBUG TRAIN Batch 45/900 loss 0.072845 acc 0.951662 lr 0.00023871 grad_norm 0.579360 rank 1
2025-01-10 12:21:48,288 DEBUG TRAIN Batch 45/900 loss 0.152542 acc 0.893204 lr 0.00023871 grad_norm 0.579360 rank 0
2025-01-10 12:21:48,288 DEBUG TRAIN Batch 45/900 loss 0.138764 acc 0.906953 lr 0.00023871 grad_norm 0.579360 rank 2
2025-01-10 12:22:12,519 DEBUG TRAIN Batch 45/1000 loss 0.164589 acc 0.880884 lr 0.00023857 grad_norm 0.573969 rank 0
2025-01-10 12:22:12,519 DEBUG TRAIN Batch 45/1000 loss 0.098038 acc 0.927322 lr 0.00023857 grad_norm 0.573969 rank 1
2025-01-10 12:22:12,519 DEBUG TRAIN Batch 45/1000 loss 0.123899 acc 0.917391 lr 0.00023857 grad_norm 0.573969 rank 2
2025-01-10 12:22:38,018 DEBUG TRAIN Batch 45/1100 loss 0.165710 acc 0.889088 lr 0.00023844 grad_norm 0.583120 rank 2
2025-01-10 12:22:38,019 DEBUG TRAIN Batch 45/1100 loss 0.095586 acc 0.932048 lr 0.00023844 grad_norm 0.583120 rank 1
2025-01-10 12:22:38,019 DEBUG TRAIN Batch 45/1100 loss 0.125076 acc 0.910023 lr 0.00023844 grad_norm 0.583120 rank 0
2025-01-10 12:23:01,808 DEBUG TRAIN Batch 45/1200 loss 0.188492 acc 0.874202 lr 0.00023830 grad_norm 0.626021 rank 1
2025-01-10 12:23:01,809 DEBUG TRAIN Batch 45/1200 loss 0.156717 acc 0.897579 lr 0.00023830 grad_norm 0.626021 rank 2
2025-01-10 12:23:01,809 DEBUG TRAIN Batch 45/1200 loss 0.168098 acc 0.884716 lr 0.00023830 grad_norm 0.626021 rank 0
2025-01-10 12:23:26,518 DEBUG TRAIN Batch 45/1300 loss 0.145199 acc 0.896186 lr 0.00023817 grad_norm 0.606107 rank 2
2025-01-10 12:23:26,519 DEBUG TRAIN Batch 45/1300 loss 0.118528 acc 0.913730 lr 0.00023817 grad_norm 0.606107 rank 1
2025-01-10 12:23:26,519 DEBUG TRAIN Batch 45/1300 loss 0.167884 acc 0.893435 lr 0.00023817 grad_norm 0.606107 rank 0
2025-01-10 12:23:50,496 DEBUG TRAIN Batch 45/1400 loss 0.106592 acc 0.928442 lr 0.00023803 grad_norm 0.577050 rank 0
2025-01-10 12:23:50,496 DEBUG TRAIN Batch 45/1400 loss 0.165306 acc 0.884259 lr 0.00023803 grad_norm 0.577050 rank 1
2025-01-10 12:23:50,497 DEBUG TRAIN Batch 45/1400 loss 0.173496 acc 0.877901 lr 0.00023803 grad_norm 0.577050 rank 2
2025-01-10 12:24:14,568 DEBUG TRAIN Batch 45/1500 loss 0.158573 acc 0.886385 lr 0.00023790 grad_norm 0.595084 rank 1
2025-01-10 12:24:14,568 DEBUG TRAIN Batch 45/1500 loss 0.150470 acc 0.893738 lr 0.00023790 grad_norm 0.595084 rank 2
2025-01-10 12:24:14,569 DEBUG TRAIN Batch 45/1500 loss 0.128915 acc 0.914137 lr 0.00023790 grad_norm 0.595084 rank 0
2025-01-10 12:24:39,118 DEBUG TRAIN Batch 45/1600 loss 0.116619 acc 0.917944 lr 0.00023776 grad_norm 0.581480 rank 1
2025-01-10 12:24:39,119 DEBUG TRAIN Batch 45/1600 loss 0.181135 acc 0.880597 lr 0.00023776 grad_norm 0.581480 rank 2
2025-01-10 12:24:39,119 DEBUG TRAIN Batch 45/1600 loss 0.112586 acc 0.914410 lr 0.00023776 grad_norm 0.581480 rank 0
2025-01-10 12:25:03,685 DEBUG TRAIN Batch 45/1700 loss 0.070763 acc 0.946848 lr 0.00023763 grad_norm 0.585174 rank 1
2025-01-10 12:25:03,685 DEBUG TRAIN Batch 45/1700 loss 0.152945 acc 0.896620 lr 0.00023763 grad_norm 0.585174 rank 2
2025-01-10 12:25:03,685 DEBUG TRAIN Batch 45/1700 loss 0.113018 acc 0.919094 lr 0.00023763 grad_norm 0.585174 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 12:26:25,180 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 12:26:25,183 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 12:26:25,637 INFO Epoch 45 Step 44317 on_batch_end True CV rank 0
2025-01-10 12:26:25,637 INFO Epoch 45 Step 44317 on_batch_end True CV rank 1
2025-01-10 12:26:25,637 INFO Epoch 45 Step 44317 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 12:26:35,105 DEBUG CV Batch 45/100 loss 0.043918 acc 0.985507  rank 2
2025-01-10 12:26:35,214 DEBUG CV Batch 45/100 loss 0.043918 acc 0.985507  rank 0
2025-01-10 12:26:35,529 DEBUG CV Batch 45/100 loss 0.043918 acc 0.985507  rank 1
2025-01-10 12:26:35,632 INFO Epoch 45 Step 44317 CV info lr 0.00023751160124060408 2 rank loss_1.845098062067113 acc_0.774092297935695
2025-01-10 12:26:35,749 INFO Epoch 45 Step 44317 CV info lr 0.00023751160124060408 0 rank loss_1.845098062067113 acc_0.774092297935695
2025-01-10 12:26:36,091 INFO Epoch 45 Step 44317 CV info lr 0.00023751160124060408 1 rank loss_1.845098062067113 acc_0.774092297935695
2025-01-10 12:26:37,097 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_45_whole.pt
2025-01-10 12:26:37,118 INFO Added key: store_based_barrier_key:48 to store for rank: 0
2025-01-10 12:26:37,119 INFO Added key: store_based_barrier_key:48 to store for rank: 1
2025-01-10 12:26:37,119 INFO Added key: store_based_barrier_key:48 to store for rank: 2
2025-01-10 12:26:37,119 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:48 with 3 nodes.
2025-01-10 12:26:37,125 INFO Epoch 46 TRAIN info lr 0.00023751160124060408 rank 2
2025-01-10 12:26:37,125 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 12:26:37,129 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:48 with 3 nodes.
2025-01-10 12:26:37,129 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:48 with 3 nodes.
2025-01-10 12:26:37,131 INFO Epoch 46 TRAIN info lr 0.00023751160124060408 rank 0
2025-01-10 12:26:37,131 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 12:26:37,135 INFO Epoch 46 TRAIN info lr 0.00023751160124060408 rank 1
2025-01-10 12:26:37,135 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 12:27:08,970 DEBUG TRAIN Batch 46/100 loss 0.128223 acc 0.917981 lr 0.00023738 grad_norm 0.565318 rank 2
2025-01-10 12:27:08,970 DEBUG TRAIN Batch 46/100 loss 0.137969 acc 0.902923 lr 0.00023738 grad_norm 0.565318 rank 1
2025-01-10 12:27:08,970 DEBUG TRAIN Batch 46/100 loss 0.106886 acc 0.923391 lr 0.00023738 grad_norm 0.565318 rank 0
2025-01-10 12:27:32,985 DEBUG TRAIN Batch 46/200 loss 0.123350 acc 0.918332 lr 0.00023724 grad_norm 0.608593 rank 2
2025-01-10 12:27:32,985 DEBUG TRAIN Batch 46/200 loss 0.151363 acc 0.899355 lr 0.00023724 grad_norm 0.608593 rank 1
2025-01-10 12:27:32,986 DEBUG TRAIN Batch 46/200 loss 0.130224 acc 0.901809 lr 0.00023724 grad_norm 0.608593 rank 0
2025-01-10 12:27:56,839 DEBUG TRAIN Batch 46/300 loss 0.128794 acc 0.915709 lr 0.00023711 grad_norm 0.532579 rank 2
2025-01-10 12:27:56,839 DEBUG TRAIN Batch 46/300 loss 0.121545 acc 0.921827 lr 0.00023711 grad_norm 0.532579 rank 1
2025-01-10 12:27:56,839 DEBUG TRAIN Batch 46/300 loss 0.111765 acc 0.920762 lr 0.00023711 grad_norm 0.532579 rank 0
2025-01-10 12:28:20,480 DEBUG TRAIN Batch 46/400 loss 0.094773 acc 0.939326 lr 0.00023698 grad_norm 0.563074 rank 0
2025-01-10 12:28:20,480 DEBUG TRAIN Batch 46/400 loss 0.143944 acc 0.890355 lr 0.00023698 grad_norm 0.563074 rank 1
2025-01-10 12:28:20,480 DEBUG TRAIN Batch 46/400 loss 0.129817 acc 0.918699 lr 0.00023698 grad_norm 0.563074 rank 2
2025-01-10 12:28:44,857 DEBUG TRAIN Batch 46/500 loss 0.159114 acc 0.889093 lr 0.00023684 grad_norm 0.552124 rank 2
2025-01-10 12:28:44,857 DEBUG TRAIN Batch 46/500 loss 0.144238 acc 0.895379 lr 0.00023684 grad_norm 0.552124 rank 1
2025-01-10 12:28:44,858 DEBUG TRAIN Batch 46/500 loss 0.149526 acc 0.899531 lr 0.00023684 grad_norm 0.552124 rank 0
2025-01-10 12:29:08,142 DEBUG TRAIN Batch 46/600 loss 0.135151 acc 0.905697 lr 0.00023671 grad_norm 0.577327 rank 0
2025-01-10 12:29:08,142 DEBUG TRAIN Batch 46/600 loss 0.167293 acc 0.886364 lr 0.00023671 grad_norm 0.577327 rank 1
2025-01-10 12:29:08,142 DEBUG TRAIN Batch 46/600 loss 0.124595 acc 0.911732 lr 0.00023671 grad_norm 0.577327 rank 2
2025-01-10 12:29:32,279 DEBUG TRAIN Batch 46/700 loss 0.145936 acc 0.898131 lr 0.00023658 grad_norm 0.553719 rank 2
2025-01-10 12:29:32,279 DEBUG TRAIN Batch 46/700 loss 0.152693 acc 0.891892 lr 0.00023658 grad_norm 0.553719 rank 1
2025-01-10 12:29:32,280 DEBUG TRAIN Batch 46/700 loss 0.137609 acc 0.897297 lr 0.00023658 grad_norm 0.553719 rank 0
2025-01-10 12:29:55,610 DEBUG TRAIN Batch 46/800 loss 0.122633 acc 0.912840 lr 0.00023645 grad_norm 0.547951 rank 1
2025-01-10 12:29:55,611 DEBUG TRAIN Batch 46/800 loss 0.115296 acc 0.911065 lr 0.00023645 grad_norm 0.547951 rank 2
2025-01-10 12:29:55,611 DEBUG TRAIN Batch 46/800 loss 0.083904 acc 0.947761 lr 0.00023645 grad_norm 0.547951 rank 0
2025-01-10 12:30:19,947 DEBUG TRAIN Batch 46/900 loss 0.176646 acc 0.877820 lr 0.00023631 grad_norm 0.597974 rank 1
2025-01-10 12:30:19,947 DEBUG TRAIN Batch 46/900 loss 0.118745 acc 0.919118 lr 0.00023631 grad_norm 0.597974 rank 2
2025-01-10 12:30:19,947 DEBUG TRAIN Batch 46/900 loss 0.115155 acc 0.924784 lr 0.00023631 grad_norm 0.597974 rank 0
2025-01-10 12:30:43,529 DEBUG TRAIN Batch 46/1000 loss 0.172989 acc 0.882923 lr 0.00023618 grad_norm 0.583455 rank 0
2025-01-10 12:30:43,529 DEBUG TRAIN Batch 46/1000 loss 0.121327 acc 0.915725 lr 0.00023618 grad_norm 0.583455 rank 1
2025-01-10 12:30:43,529 DEBUG TRAIN Batch 46/1000 loss 0.147543 acc 0.901291 lr 0.00023618 grad_norm 0.583455 rank 2
2025-01-10 12:31:07,993 DEBUG TRAIN Batch 46/1100 loss 0.135868 acc 0.901163 lr 0.00023605 grad_norm 0.590134 rank 1
2025-01-10 12:31:07,993 DEBUG TRAIN Batch 46/1100 loss 0.146993 acc 0.898899 lr 0.00023605 grad_norm 0.590134 rank 0
2025-01-10 12:31:07,993 DEBUG TRAIN Batch 46/1100 loss 0.144911 acc 0.893597 lr 0.00023605 grad_norm 0.590134 rank 2
2025-01-10 12:31:31,853 DEBUG TRAIN Batch 46/1200 loss 0.121520 acc 0.921028 lr 0.00023592 grad_norm 0.552095 rank 2
2025-01-10 12:31:31,853 DEBUG TRAIN Batch 46/1200 loss 0.106598 acc 0.927199 lr 0.00023592 grad_norm 0.552095 rank 0
2025-01-10 12:31:31,853 DEBUG TRAIN Batch 46/1200 loss 0.146058 acc 0.899197 lr 0.00023592 grad_norm 0.552095 rank 1
2025-01-10 12:31:55,877 DEBUG TRAIN Batch 46/1300 loss 0.136310 acc 0.904324 lr 0.00023579 grad_norm 0.556586 rank 1
2025-01-10 12:31:55,877 DEBUG TRAIN Batch 46/1300 loss 0.149096 acc 0.896185 lr 0.00023579 grad_norm 0.556586 rank 2
2025-01-10 12:31:55,878 DEBUG TRAIN Batch 46/1300 loss 0.142674 acc 0.910314 lr 0.00023579 grad_norm 0.556586 rank 0
2025-01-10 12:32:20,887 DEBUG TRAIN Batch 46/1400 loss 0.140397 acc 0.902464 lr 0.00023566 grad_norm 0.581978 rank 1
2025-01-10 12:32:20,888 DEBUG TRAIN Batch 46/1400 loss 0.172416 acc 0.882474 lr 0.00023566 grad_norm 0.581978 rank 0
2025-01-10 12:32:20,888 DEBUG TRAIN Batch 46/1400 loss 0.124886 acc 0.914634 lr 0.00023566 grad_norm 0.581978 rank 2
2025-01-10 12:32:45,411 DEBUG TRAIN Batch 46/1500 loss 0.151262 acc 0.905431 lr 0.00023553 grad_norm 0.570289 rank 2
2025-01-10 12:32:45,411 DEBUG TRAIN Batch 46/1500 loss 0.152581 acc 0.885819 lr 0.00023553 grad_norm 0.570289 rank 0
2025-01-10 12:32:45,412 DEBUG TRAIN Batch 46/1500 loss 0.128958 acc 0.903922 lr 0.00023553 grad_norm 0.570289 rank 1
2025-01-10 12:33:09,294 DEBUG TRAIN Batch 46/1600 loss 0.168402 acc 0.890162 lr 0.00023540 grad_norm 0.606861 rank 2
2025-01-10 12:33:09,294 DEBUG TRAIN Batch 46/1600 loss 0.100295 acc 0.928212 lr 0.00023540 grad_norm 0.606861 rank 0
2025-01-10 12:33:09,294 DEBUG TRAIN Batch 46/1600 loss 0.159491 acc 0.894075 lr 0.00023540 grad_norm 0.606861 rank 1
2025-01-10 12:33:34,506 DEBUG TRAIN Batch 46/1700 loss 0.130049 acc 0.907753 lr 0.00023527 grad_norm 0.563333 rank 1
2025-01-10 12:33:34,507 DEBUG TRAIN Batch 46/1700 loss 0.161792 acc 0.897032 lr 0.00023527 grad_norm 0.563333 rank 0
2025-01-10 12:33:34,507 DEBUG TRAIN Batch 46/1700 loss 0.120207 acc 0.912953 lr 0.00023527 grad_norm 0.563333 rank 2
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 12:34:53,240 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 12:34:53,249 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 12:34:53,717 INFO Epoch 46 Step 45206 on_batch_end True CV rank 1
2025-01-10 12:34:53,717 INFO Epoch 46 Step 45206 on_batch_end True CV rank 0
2025-01-10 12:34:53,717 INFO Epoch 46 Step 45206 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 12:35:02,846 DEBUG CV Batch 46/100 loss 0.056490 acc 0.982163  rank 0
2025-01-10 12:35:03,049 DEBUG CV Batch 46/100 loss 0.056490 acc 0.982163  rank 2
2025-01-10 12:35:03,372 INFO Epoch 46 Step 45206 CV info lr 0.00023516460934330688 0 rank loss_1.8728345048352422 acc_0.7741957918593758
2025-01-10 12:35:03,511 DEBUG CV Batch 46/100 loss 0.056490 acc 0.982163  rank 1
2025-01-10 12:35:03,587 INFO Epoch 46 Step 45206 CV info lr 0.00023516460934330688 2 rank loss_1.8728345048352422 acc_0.7741957918593758
2025-01-10 12:35:04,050 INFO Epoch 46 Step 45206 CV info lr 0.00023516460934330688 1 rank loss_1.8728345048352422 acc_0.7741957918593758
2025-01-10 12:35:04,659 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_46_whole.pt
2025-01-10 12:35:04,671 INFO Added key: store_based_barrier_key:49 to store for rank: 0
2025-01-10 12:35:04,681 INFO Added key: store_based_barrier_key:49 to store for rank: 2
2025-01-10 12:35:04,681 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:49 with 3 nodes.
2025-01-10 12:35:04,681 INFO Added key: store_based_barrier_key:49 to store for rank: 1
2025-01-10 12:35:04,681 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:49 with 3 nodes.
2025-01-10 12:35:04,681 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:49 with 3 nodes.
2025-01-10 12:35:04,685 INFO Epoch 47 TRAIN info lr 0.00023516460934330688 rank 2
2025-01-10 12:35:04,685 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 12:35:04,687 INFO Epoch 47 TRAIN info lr 0.00023516460934330688 rank 0
2025-01-10 12:35:04,687 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 12:35:04,688 INFO Epoch 47 TRAIN info lr 0.00023516460934330688 rank 1
2025-01-10 12:35:04,688 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 12:35:41,188 DEBUG TRAIN Batch 47/100 loss 0.108179 acc 0.927690 lr 0.00023503 grad_norm 0.536834 rank 2
2025-01-10 12:35:41,188 DEBUG TRAIN Batch 47/100 loss 0.145426 acc 0.888889 lr 0.00023503 grad_norm 0.536834 rank 0
2025-01-10 12:35:41,188 DEBUG TRAIN Batch 47/100 loss 0.073391 acc 0.952020 lr 0.00023503 grad_norm 0.536834 rank 1
2025-01-10 12:36:05,324 DEBUG TRAIN Batch 47/200 loss 0.104419 acc 0.932184 lr 0.00023490 grad_norm 0.553637 rank 0
2025-01-10 12:36:05,324 DEBUG TRAIN Batch 47/200 loss 0.124328 acc 0.919231 lr 0.00023490 grad_norm 0.553637 rank 1
2025-01-10 12:36:05,324 DEBUG TRAIN Batch 47/200 loss 0.120450 acc 0.915799 lr 0.00023490 grad_norm 0.553637 rank 2
2025-01-10 12:36:29,665 DEBUG TRAIN Batch 47/300 loss 0.128959 acc 0.906341 lr 0.00023478 grad_norm 0.535612 rank 2
2025-01-10 12:36:29,665 DEBUG TRAIN Batch 47/300 loss 0.068813 acc 0.947200 lr 0.00023478 grad_norm 0.535612 rank 1
2025-01-10 12:36:29,665 DEBUG TRAIN Batch 47/300 loss 0.143676 acc 0.897153 lr 0.00023478 grad_norm 0.535612 rank 0
2025-01-10 12:36:53,569 DEBUG TRAIN Batch 47/400 loss 0.091556 acc 0.938462 lr 0.00023465 grad_norm 0.546225 rank 0
2025-01-10 12:36:53,569 DEBUG TRAIN Batch 47/400 loss 0.067972 acc 0.946704 lr 0.00023465 grad_norm 0.546225 rank 1
2025-01-10 12:36:53,570 DEBUG TRAIN Batch 47/400 loss 0.134107 acc 0.905284 lr 0.00023465 grad_norm 0.546225 rank 2
2025-01-10 12:37:18,726 DEBUG TRAIN Batch 47/500 loss 0.090312 acc 0.941959 lr 0.00023452 grad_norm 0.554819 rank 1
2025-01-10 12:37:18,726 DEBUG TRAIN Batch 47/500 loss 0.114057 acc 0.923166 lr 0.00023452 grad_norm 0.554819 rank 2
2025-01-10 12:37:18,726 DEBUG TRAIN Batch 47/500 loss 0.130286 acc 0.900943 lr 0.00023452 grad_norm 0.554819 rank 0
2025-01-10 12:37:44,334 DEBUG TRAIN Batch 47/600 loss 0.164940 acc 0.888093 lr 0.00023439 grad_norm 0.577405 rank 2
2025-01-10 12:37:44,334 DEBUG TRAIN Batch 47/600 loss 0.115856 acc 0.920455 lr 0.00023439 grad_norm 0.577405 rank 0
2025-01-10 12:37:44,334 DEBUG TRAIN Batch 47/600 loss 0.084204 acc 0.942632 lr 0.00023439 grad_norm 0.577405 rank 1
2025-01-10 12:38:10,017 DEBUG TRAIN Batch 47/700 loss 0.130106 acc 0.917355 lr 0.00023426 grad_norm 0.549942 rank 2
2025-01-10 12:38:10,017 DEBUG TRAIN Batch 47/700 loss 0.082013 acc 0.941372 lr 0.00023426 grad_norm 0.549942 rank 1
2025-01-10 12:38:10,017 DEBUG TRAIN Batch 47/700 loss 0.203165 acc 0.866667 lr 0.00023426 grad_norm 0.549942 rank 0
2025-01-10 12:38:34,731 DEBUG TRAIN Batch 47/800 loss 0.143649 acc 0.898221 lr 0.00023413 grad_norm 0.560757 rank 0
2025-01-10 12:38:34,731 DEBUG TRAIN Batch 47/800 loss 0.121463 acc 0.919878 lr 0.00023413 grad_norm 0.560757 rank 2
2025-01-10 12:38:34,731 DEBUG TRAIN Batch 47/800 loss 0.129135 acc 0.912587 lr 0.00023413 grad_norm 0.560757 rank 1
2025-01-10 12:38:58,911 DEBUG TRAIN Batch 47/900 loss 0.063932 acc 0.952978 lr 0.00023400 grad_norm 0.559580 rank 1
2025-01-10 12:38:58,911 DEBUG TRAIN Batch 47/900 loss 0.188741 acc 0.876797 lr 0.00023400 grad_norm 0.559580 rank 0
2025-01-10 12:38:58,911 DEBUG TRAIN Batch 47/900 loss 0.101097 acc 0.927725 lr 0.00023400 grad_norm 0.559580 rank 2
2025-01-10 12:39:24,072 DEBUG TRAIN Batch 47/1000 loss 0.155741 acc 0.883459 lr 0.00023387 grad_norm 0.574698 rank 2
2025-01-10 12:39:24,072 DEBUG TRAIN Batch 47/1000 loss 0.065004 acc 0.950207 lr 0.00023387 grad_norm 0.574698 rank 1
2025-01-10 12:39:24,072 DEBUG TRAIN Batch 47/1000 loss 0.157200 acc 0.881565 lr 0.00023387 grad_norm 0.574698 rank 0
2025-01-10 12:39:49,424 DEBUG TRAIN Batch 47/1100 loss 0.111369 acc 0.922840 lr 0.00023375 grad_norm 0.566869 rank 1
2025-01-10 12:39:49,424 DEBUG TRAIN Batch 47/1100 loss 0.108904 acc 0.917496 lr 0.00023375 grad_norm 0.566869 rank 0
2025-01-10 12:39:49,424 DEBUG TRAIN Batch 47/1100 loss 0.112675 acc 0.920810 lr 0.00023375 grad_norm 0.566869 rank 2
2025-01-10 12:40:13,545 DEBUG TRAIN Batch 47/1200 loss 0.106653 acc 0.923483 lr 0.00023362 grad_norm 0.566292 rank 1
2025-01-10 12:40:13,545 DEBUG TRAIN Batch 47/1200 loss 0.158971 acc 0.886512 lr 0.00023362 grad_norm 0.566292 rank 0
2025-01-10 12:40:13,546 DEBUG TRAIN Batch 47/1200 loss 0.122833 acc 0.916225 lr 0.00023362 grad_norm 0.566292 rank 2
2025-01-10 12:40:37,425 DEBUG TRAIN Batch 47/1300 loss 0.117728 acc 0.926099 lr 0.00023349 grad_norm 0.551806 rank 1
2025-01-10 12:40:37,425 DEBUG TRAIN Batch 47/1300 loss 0.132906 acc 0.909756 lr 0.00023349 grad_norm 0.551806 rank 2
2025-01-10 12:40:37,425 DEBUG TRAIN Batch 47/1300 loss 0.125803 acc 0.912698 lr 0.00023349 grad_norm 0.551806 rank 0
2025-01-10 12:41:01,260 DEBUG TRAIN Batch 47/1400 loss 0.122254 acc 0.913165 lr 0.00023336 grad_norm 0.582651 rank 2
2025-01-10 12:41:01,260 DEBUG TRAIN Batch 47/1400 loss 0.154013 acc 0.897750 lr 0.00023336 grad_norm 0.582651 rank 1
2025-01-10 12:41:01,260 DEBUG TRAIN Batch 47/1400 loss 0.132762 acc 0.905893 lr 0.00023336 grad_norm 0.582651 rank 0
2025-01-10 12:41:25,045 DEBUG TRAIN Batch 47/1500 loss 0.116770 acc 0.914823 lr 0.00023324 grad_norm 0.592372 rank 1
2025-01-10 12:41:25,045 DEBUG TRAIN Batch 47/1500 loss 0.157311 acc 0.891244 lr 0.00023324 grad_norm 0.592372 rank 2
2025-01-10 12:41:25,045 DEBUG TRAIN Batch 47/1500 loss 0.144804 acc 0.905622 lr 0.00023324 grad_norm 0.592372 rank 0
2025-01-10 12:41:49,396 DEBUG TRAIN Batch 47/1600 loss 0.125694 acc 0.908946 lr 0.00023311 grad_norm 0.593593 rank 0
2025-01-10 12:41:49,396 DEBUG TRAIN Batch 47/1600 loss 0.165750 acc 0.875455 lr 0.00023311 grad_norm 0.593593 rank 1
2025-01-10 12:41:49,396 DEBUG TRAIN Batch 47/1600 loss 0.156932 acc 0.891037 lr 0.00023311 grad_norm 0.593593 rank 2
2025-01-10 12:42:12,914 DEBUG TRAIN Batch 47/1700 loss 0.160597 acc 0.896054 lr 0.00023298 grad_norm 0.585993 rank 1
2025-01-10 12:42:12,914 DEBUG TRAIN Batch 47/1700 loss 0.142411 acc 0.904364 lr 0.00023298 grad_norm 0.585993 rank 2
2025-01-10 12:42:12,915 DEBUG TRAIN Batch 47/1700 loss 0.158673 acc 0.897638 lr 0.00023298 grad_norm 0.585993 rank 0
2025-01-10 12:42:36,958 DEBUG TRAIN Batch 47/1800 loss 0.114977 acc 0.926696 lr 0.00023286 grad_norm 0.559541 rank 2
2025-01-10 12:42:36,958 DEBUG TRAIN Batch 47/1800 loss 0.107131 acc 0.920616 lr 0.00023286 grad_norm 0.559541 rank 0
2025-01-10 12:42:36,958 DEBUG TRAIN Batch 47/1800 loss 0.123750 acc 0.909774 lr 0.00023286 grad_norm 0.559541 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 12:43:39,885 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 12:43:39,886 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 12:43:40,306 INFO Epoch 47 Step 46112 on_batch_end True CV rank 1
2025-01-10 12:43:40,306 INFO Epoch 47 Step 46112 on_batch_end True CV rank 0
2025-01-10 12:43:40,306 INFO Epoch 47 Step 46112 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 12:43:49,379 DEBUG CV Batch 47/100 loss 0.050116 acc 0.982163  rank 0
2025-01-10 12:43:49,726 DEBUG CV Batch 47/100 loss 0.050116 acc 0.982163  rank 2
2025-01-10 12:43:49,865 DEBUG CV Batch 47/100 loss 0.050116 acc 0.982163  rank 1
2025-01-10 12:43:49,914 INFO Epoch 47 Step 46112 CV info lr 0.00023284291345367016 0 rank loss_1.8986862865521719 acc_0.7741304854290527
2025-01-10 12:43:50,268 INFO Epoch 47 Step 46112 CV info lr 0.00023284291345367016 2 rank loss_1.8986862865521719 acc_0.7741304854290527
2025-01-10 12:43:50,413 INFO Epoch 47 Step 46112 CV info lr 0.00023284291345367016 1 rank loss_1.8986862865521719 acc_0.7741304854290527
2025-01-10 12:43:51,184 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_47_whole.pt
2025-01-10 12:43:51,205 INFO Added key: store_based_barrier_key:50 to store for rank: 0
2025-01-10 12:43:51,206 INFO Added key: store_based_barrier_key:50 to store for rank: 1
2025-01-10 12:43:51,206 INFO Added key: store_based_barrier_key:50 to store for rank: 2
2025-01-10 12:43:51,206 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:50 with 3 nodes.
2025-01-10 12:43:51,207 INFO Epoch 48 TRAIN info lr 0.00023284291345367016 rank 2
2025-01-10 12:43:51,207 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 12:43:51,216 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:50 with 3 nodes.
2025-01-10 12:43:51,216 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:50 with 3 nodes.
2025-01-10 12:43:51,217 INFO Epoch 48 TRAIN info lr 0.00023284291345367016 rank 0
2025-01-10 12:43:51,217 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 12:43:51,219 INFO Epoch 48 TRAIN info lr 0.00023284291345367016 rank 1
2025-01-10 12:43:51,219 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 12:44:22,932 DEBUG TRAIN Batch 48/100 loss 0.164655 acc 0.894189 lr 0.00023272 grad_norm 0.557722 rank 2
2025-01-10 12:44:22,932 DEBUG TRAIN Batch 48/100 loss 0.136814 acc 0.900735 lr 0.00023272 grad_norm 0.557722 rank 1
2025-01-10 12:44:22,932 DEBUG TRAIN Batch 48/100 loss 0.116185 acc 0.924720 lr 0.00023272 grad_norm 0.557722 rank 0
2025-01-10 12:44:47,048 DEBUG TRAIN Batch 48/200 loss 0.114867 acc 0.925926 lr 0.00023259 grad_norm 0.559455 rank 2
2025-01-10 12:44:47,048 DEBUG TRAIN Batch 48/200 loss 0.119977 acc 0.915556 lr 0.00023259 grad_norm 0.559455 rank 1
2025-01-10 12:44:47,048 DEBUG TRAIN Batch 48/200 loss 0.118651 acc 0.920817 lr 0.00023259 grad_norm 0.559455 rank 0
2025-01-10 12:45:11,189 DEBUG TRAIN Batch 48/300 loss 0.133788 acc 0.910123 lr 0.00023247 grad_norm 0.541153 rank 1
2025-01-10 12:45:11,189 DEBUG TRAIN Batch 48/300 loss 0.146279 acc 0.897790 lr 0.00023247 grad_norm 0.541153 rank 2
2025-01-10 12:45:11,189 DEBUG TRAIN Batch 48/300 loss 0.119436 acc 0.917918 lr 0.00023247 grad_norm 0.541153 rank 0
2025-01-10 12:45:34,998 DEBUG TRAIN Batch 48/400 loss 0.125192 acc 0.907164 lr 0.00023234 grad_norm 0.552059 rank 1
2025-01-10 12:45:34,998 DEBUG TRAIN Batch 48/400 loss 0.125721 acc 0.921527 lr 0.00023234 grad_norm 0.552059 rank 0
2025-01-10 12:45:34,999 DEBUG TRAIN Batch 48/400 loss 0.114439 acc 0.916667 lr 0.00023234 grad_norm 0.552059 rank 2
2025-01-10 12:45:59,551 DEBUG TRAIN Batch 48/500 loss 0.082633 acc 0.944068 lr 0.00023221 grad_norm 0.555682 rank 1
2025-01-10 12:45:59,551 DEBUG TRAIN Batch 48/500 loss 0.118433 acc 0.926306 lr 0.00023221 grad_norm 0.555682 rank 0
2025-01-10 12:45:59,552 DEBUG TRAIN Batch 48/500 loss 0.130961 acc 0.909644 lr 0.00023221 grad_norm 0.555682 rank 2
2025-01-10 12:46:23,908 DEBUG TRAIN Batch 48/600 loss 0.136034 acc 0.913424 lr 0.00023209 grad_norm 0.559847 rank 1
2025-01-10 12:46:23,909 DEBUG TRAIN Batch 48/600 loss 0.124210 acc 0.911091 lr 0.00023209 grad_norm 0.559847 rank 0
2025-01-10 12:46:23,909 DEBUG TRAIN Batch 48/600 loss 0.134404 acc 0.908778 lr 0.00023209 grad_norm 0.559847 rank 2
2025-01-10 12:46:47,911 DEBUG TRAIN Batch 48/700 loss 0.124015 acc 0.910280 lr 0.00023196 grad_norm 0.546146 rank 1
2025-01-10 12:46:47,912 DEBUG TRAIN Batch 48/700 loss 0.095187 acc 0.939723 lr 0.00023196 grad_norm 0.546146 rank 0
2025-01-10 12:46:47,912 DEBUG TRAIN Batch 48/700 loss 0.122932 acc 0.919844 lr 0.00023196 grad_norm 0.546146 rank 2
2025-01-10 12:47:11,507 DEBUG TRAIN Batch 48/800 loss 0.051823 acc 0.970050 lr 0.00023184 grad_norm 0.555157 rank 1
2025-01-10 12:47:11,507 DEBUG TRAIN Batch 48/800 loss 0.183053 acc 0.875112 lr 0.00023184 grad_norm 0.555157 rank 0
2025-01-10 12:47:11,508 DEBUG TRAIN Batch 48/800 loss 0.106506 acc 0.929085 lr 0.00023184 grad_norm 0.555157 rank 2
2025-01-10 12:47:35,830 DEBUG TRAIN Batch 48/900 loss 0.104773 acc 0.924574 lr 0.00023172 grad_norm 0.564755 rank 0
2025-01-10 12:47:35,830 DEBUG TRAIN Batch 48/900 loss 0.128740 acc 0.909563 lr 0.00023172 grad_norm 0.564755 rank 1
2025-01-10 12:47:35,830 DEBUG TRAIN Batch 48/900 loss 0.100419 acc 0.931291 lr 0.00023172 grad_norm 0.564755 rank 2
2025-01-10 12:48:00,226 DEBUG TRAIN Batch 48/1000 loss 0.135422 acc 0.905232 lr 0.00023159 grad_norm 0.587472 rank 2
2025-01-10 12:48:00,226 DEBUG TRAIN Batch 48/1000 loss 0.082860 acc 0.943820 lr 0.00023159 grad_norm 0.587472 rank 0
2025-01-10 12:48:00,226 DEBUG TRAIN Batch 48/1000 loss 0.123155 acc 0.922980 lr 0.00023159 grad_norm 0.587472 rank 1
2025-01-10 12:48:25,058 DEBUG TRAIN Batch 48/1100 loss 0.152098 acc 0.897658 lr 0.00023147 grad_norm 0.568771 rank 1
2025-01-10 12:48:25,058 DEBUG TRAIN Batch 48/1100 loss 0.119932 acc 0.916974 lr 0.00023147 grad_norm 0.568771 rank 2
2025-01-10 12:48:25,059 DEBUG TRAIN Batch 48/1100 loss 0.156098 acc 0.890892 lr 0.00023147 grad_norm 0.568771 rank 0
2025-01-10 12:48:48,975 DEBUG TRAIN Batch 48/1200 loss 0.158147 acc 0.893673 lr 0.00023134 grad_norm 0.581173 rank 1
2025-01-10 12:48:48,975 DEBUG TRAIN Batch 48/1200 loss 0.129338 acc 0.902080 lr 0.00023134 grad_norm 0.581173 rank 2
2025-01-10 12:48:48,975 DEBUG TRAIN Batch 48/1200 loss 0.137601 acc 0.910732 lr 0.00023134 grad_norm 0.581173 rank 0
2025-01-10 12:49:12,759 DEBUG TRAIN Batch 48/1300 loss 0.134344 acc 0.910476 lr 0.00023122 grad_norm 0.567889 rank 1
2025-01-10 12:49:12,759 DEBUG TRAIN Batch 48/1300 loss 0.149118 acc 0.899577 lr 0.00023122 grad_norm 0.567889 rank 0
2025-01-10 12:49:12,760 DEBUG TRAIN Batch 48/1300 loss 0.117755 acc 0.920696 lr 0.00023122 grad_norm 0.567889 rank 2
2025-01-10 12:49:37,097 DEBUG TRAIN Batch 48/1400 loss 0.127864 acc 0.912796 lr 0.00023110 grad_norm 0.590510 rank 1
2025-01-10 12:49:37,098 DEBUG TRAIN Batch 48/1400 loss 0.159705 acc 0.884120 lr 0.00023110 grad_norm 0.590510 rank 2
2025-01-10 12:49:37,098 DEBUG TRAIN Batch 48/1400 loss 0.112305 acc 0.920301 lr 0.00023110 grad_norm 0.590510 rank 0
2025-01-10 12:50:01,195 DEBUG TRAIN Batch 48/1500 loss 0.157428 acc 0.888998 lr 0.00023097 grad_norm 0.578368 rank 0
2025-01-10 12:50:01,195 DEBUG TRAIN Batch 48/1500 loss 0.104208 acc 0.930642 lr 0.00023097 grad_norm 0.578368 rank 1
2025-01-10 12:50:01,195 DEBUG TRAIN Batch 48/1500 loss 0.149362 acc 0.897537 lr 0.00023097 grad_norm 0.578368 rank 2
2025-01-10 12:50:25,097 DEBUG TRAIN Batch 48/1600 loss 0.129382 acc 0.905561 lr 0.00023085 grad_norm 0.604812 rank 0
2025-01-10 12:50:25,097 DEBUG TRAIN Batch 48/1600 loss 0.157408 acc 0.881988 lr 0.00023085 grad_norm 0.604812 rank 2
2025-01-10 12:50:25,097 DEBUG TRAIN Batch 48/1600 loss 0.134624 acc 0.895419 lr 0.00023085 grad_norm 0.604812 rank 1
2025-01-10 12:50:49,685 DEBUG TRAIN Batch 48/1700 loss 0.141521 acc 0.898188 lr 0.00023073 grad_norm 0.582204 rank 1
2025-01-10 12:50:49,685 DEBUG TRAIN Batch 48/1700 loss 0.149086 acc 0.900356 lr 0.00023073 grad_norm 0.582204 rank 0
2025-01-10 12:50:49,687 DEBUG TRAIN Batch 48/1700 loss 0.160315 acc 0.891725 lr 0.00023073 grad_norm 0.582204 rank 2
2025-01-10 12:51:13,480 DEBUG TRAIN Batch 48/1800 loss 0.123014 acc 0.900293 lr 0.00023060 grad_norm 0.675069 rank 1
2025-01-10 12:51:13,480 DEBUG TRAIN Batch 48/1800 loss 0.113542 acc 0.917460 lr 0.00023060 grad_norm 0.675069 rank 0
2025-01-10 12:51:13,481 DEBUG TRAIN Batch 48/1800 loss 0.158733 acc 0.892112 lr 0.00023060 grad_norm 0.675069 rank 2
2025-01-10 12:51:37,102 DEBUG TRAIN Batch 48/1900 loss 0.127177 acc 0.903259 lr 0.00023048 grad_norm 0.598292 rank 1
2025-01-10 12:51:37,103 DEBUG TRAIN Batch 48/1900 loss 0.140371 acc 0.901522 lr 0.00023048 grad_norm 0.598292 rank 0
2025-01-10 12:51:37,103 DEBUG TRAIN Batch 48/1900 loss 0.143068 acc 0.904762 lr 0.00023048 grad_norm 0.598292 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 12:52:41,968 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 12:52:41,971 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 12:52:42,372 INFO Epoch 48 Step 47072 on_batch_end True CV rank 1
2025-01-10 12:52:42,372 INFO Epoch 48 Step 47072 on_batch_end True CV rank 2
2025-01-10 12:52:42,372 INFO Epoch 48 Step 47072 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 12:52:51,523 DEBUG CV Batch 48/100 loss 0.038979 acc 0.987737  rank 0
2025-01-10 12:52:51,790 DEBUG CV Batch 48/100 loss 0.038979 acc 0.987737  rank 2
2025-01-10 12:52:52,022 INFO Epoch 48 Step 47072 CV info lr 0.00023045634980150607 0 rank loss_1.883468068825702 acc_0.7741653774129716
2025-01-10 12:52:52,060 DEBUG CV Batch 48/100 loss 0.038979 acc 0.987737  rank 1
2025-01-10 12:52:52,334 INFO Epoch 48 Step 47072 CV info lr 0.00023045634980150607 2 rank loss_1.883468068825702 acc_0.7741653774129716
2025-01-10 12:52:52,613 INFO Epoch 48 Step 47072 CV info lr 0.00023045634980150607 1 rank loss_1.883468068825702 acc_0.7741653774129716
2025-01-10 12:52:53,309 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_48_whole.pt
2025-01-10 12:52:53,330 INFO Added key: store_based_barrier_key:51 to store for rank: 0
2025-01-10 12:52:53,341 INFO Added key: store_based_barrier_key:51 to store for rank: 1
2025-01-10 12:52:53,341 INFO Added key: store_based_barrier_key:51 to store for rank: 2
2025-01-10 12:52:53,341 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:51 with 3 nodes.
2025-01-10 12:52:53,341 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:51 with 3 nodes.
2025-01-10 12:52:53,344 INFO Epoch 49 TRAIN info lr 0.00023045634980150607 rank 1
2025-01-10 12:52:53,344 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 12:52:53,351 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:51 with 3 nodes.
2025-01-10 12:52:53,351 INFO Epoch 49 TRAIN info lr 0.00023045634980150607 rank 2
2025-01-10 12:52:53,351 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 12:52:53,361 INFO Epoch 49 TRAIN info lr 0.00023045634980150607 rank 0
2025-01-10 12:52:53,361 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 12:53:24,702 DEBUG TRAIN Batch 49/100 loss 0.105273 acc 0.917722 lr 0.00023033 grad_norm 0.503255 rank 0
2025-01-10 12:53:24,702 DEBUG TRAIN Batch 49/100 loss 0.085618 acc 0.950785 lr 0.00023033 grad_norm 0.503255 rank 1
2025-01-10 12:53:24,702 DEBUG TRAIN Batch 49/100 loss 0.086180 acc 0.936373 lr 0.00023033 grad_norm 0.503255 rank 2
2025-01-10 12:53:48,465 DEBUG TRAIN Batch 49/200 loss 0.103290 acc 0.925387 lr 0.00023021 grad_norm 0.516807 rank 2
2025-01-10 12:53:48,466 DEBUG TRAIN Batch 49/200 loss 0.091631 acc 0.929929 lr 0.00023021 grad_norm 0.516807 rank 0
2025-01-10 12:53:48,466 DEBUG TRAIN Batch 49/200 loss 0.098878 acc 0.931125 lr 0.00023021 grad_norm 0.516807 rank 1
2025-01-10 12:54:12,330 DEBUG TRAIN Batch 49/300 loss 0.109637 acc 0.924977 lr 0.00023009 grad_norm 0.539494 rank 1
2025-01-10 12:54:12,331 DEBUG TRAIN Batch 49/300 loss 0.116943 acc 0.919635 lr 0.00023009 grad_norm 0.539494 rank 0
2025-01-10 12:54:12,331 DEBUG TRAIN Batch 49/300 loss 0.127589 acc 0.916745 lr 0.00023009 grad_norm 0.539494 rank 2
2025-01-10 12:54:36,298 DEBUG TRAIN Batch 49/400 loss 0.115964 acc 0.929062 lr 0.00022997 grad_norm 0.572602 rank 0
2025-01-10 12:54:36,299 DEBUG TRAIN Batch 49/400 loss 0.135280 acc 0.904340 lr 0.00022997 grad_norm 0.572602 rank 2
2025-01-10 12:54:36,299 DEBUG TRAIN Batch 49/400 loss 0.108272 acc 0.926543 lr 0.00022997 grad_norm 0.572602 rank 1
2025-01-10 12:55:00,592 DEBUG TRAIN Batch 49/500 loss 0.118705 acc 0.918967 lr 0.00022985 grad_norm 0.503329 rank 0
2025-01-10 12:55:00,592 DEBUG TRAIN Batch 49/500 loss 0.107186 acc 0.929142 lr 0.00022985 grad_norm 0.503329 rank 1
2025-01-10 12:55:00,593 DEBUG TRAIN Batch 49/500 loss 0.053088 acc 0.963492 lr 0.00022985 grad_norm 0.503329 rank 2
2025-01-10 12:55:25,001 DEBUG TRAIN Batch 49/600 loss 0.159593 acc 0.889369 lr 0.00022973 grad_norm 0.563868 rank 2
2025-01-10 12:55:25,001 DEBUG TRAIN Batch 49/600 loss 0.111755 acc 0.918762 lr 0.00022973 grad_norm 0.563868 rank 0
2025-01-10 12:55:25,002 DEBUG TRAIN Batch 49/600 loss 0.119656 acc 0.910733 lr 0.00022973 grad_norm 0.563868 rank 1
2025-01-10 12:55:50,463 DEBUG TRAIN Batch 49/700 loss 0.120371 acc 0.916667 lr 0.00022960 grad_norm 0.517843 rank 1
2025-01-10 12:55:50,463 DEBUG TRAIN Batch 49/700 loss 0.095100 acc 0.930233 lr 0.00022960 grad_norm 0.517843 rank 2
2025-01-10 12:55:50,463 DEBUG TRAIN Batch 49/700 loss 0.106486 acc 0.927083 lr 0.00022960 grad_norm 0.517843 rank 0
2025-01-10 12:56:15,630 DEBUG TRAIN Batch 49/800 loss 0.103326 acc 0.924171 lr 0.00022948 grad_norm 0.543978 rank 1
2025-01-10 12:56:15,630 DEBUG TRAIN Batch 49/800 loss 0.100469 acc 0.932221 lr 0.00022948 grad_norm 0.543978 rank 0
2025-01-10 12:56:15,631 DEBUG TRAIN Batch 49/800 loss 0.107830 acc 0.931325 lr 0.00022948 grad_norm 0.543978 rank 2
2025-01-10 12:56:40,371 DEBUG TRAIN Batch 49/900 loss 0.126456 acc 0.903509 lr 0.00022936 grad_norm 0.552684 rank 0
2025-01-10 12:56:40,371 DEBUG TRAIN Batch 49/900 loss 0.099750 acc 0.927752 lr 0.00022936 grad_norm 0.552684 rank 1
2025-01-10 12:56:40,371 DEBUG TRAIN Batch 49/900 loss 0.121221 acc 0.917998 lr 0.00022936 grad_norm 0.552684 rank 2
2025-01-10 12:57:05,875 DEBUG TRAIN Batch 49/1000 loss 0.109117 acc 0.930254 lr 0.00022924 grad_norm 0.535298 rank 2
2025-01-10 12:57:05,875 DEBUG TRAIN Batch 49/1000 loss 0.120198 acc 0.919295 lr 0.00022924 grad_norm 0.535298 rank 1
2025-01-10 12:57:05,876 DEBUG TRAIN Batch 49/1000 loss 0.120531 acc 0.921077 lr 0.00022924 grad_norm 0.535298 rank 0
2025-01-10 12:57:30,754 DEBUG TRAIN Batch 49/1100 loss 0.124669 acc 0.912029 lr 0.00022912 grad_norm 0.602161 rank 1
2025-01-10 12:57:30,754 DEBUG TRAIN Batch 49/1100 loss 0.154943 acc 0.886179 lr 0.00022912 grad_norm 0.602161 rank 2
2025-01-10 12:57:30,755 DEBUG TRAIN Batch 49/1100 loss 0.143159 acc 0.889698 lr 0.00022912 grad_norm 0.602161 rank 0
2025-01-10 12:57:56,061 DEBUG TRAIN Batch 49/1200 loss 0.088745 acc 0.928246 lr 0.00022900 grad_norm 0.630644 rank 1
2025-01-10 12:57:56,062 DEBUG TRAIN Batch 49/1200 loss 0.152708 acc 0.886087 lr 0.00022900 grad_norm 0.630644 rank 2
2025-01-10 12:57:56,062 DEBUG TRAIN Batch 49/1200 loss 0.117884 acc 0.919508 lr 0.00022900 grad_norm 0.630644 rank 0
2025-01-10 12:58:20,721 DEBUG TRAIN Batch 49/1300 loss 0.120085 acc 0.904762 lr 0.00022888 grad_norm 0.569408 rank 2
2025-01-10 12:58:20,721 DEBUG TRAIN Batch 49/1300 loss 0.152349 acc 0.903733 lr 0.00022888 grad_norm 0.569408 rank 1
2025-01-10 12:58:20,722 DEBUG TRAIN Batch 49/1300 loss 0.144185 acc 0.905759 lr 0.00022888 grad_norm 0.569408 rank 0
2025-01-10 12:58:44,790 DEBUG TRAIN Batch 49/1400 loss 0.140259 acc 0.904555 lr 0.00022876 grad_norm 0.581684 rank 1
2025-01-10 12:58:44,790 DEBUG TRAIN Batch 49/1400 loss 0.150771 acc 0.895551 lr 0.00022876 grad_norm 0.581684 rank 0
2025-01-10 12:58:44,791 DEBUG TRAIN Batch 49/1400 loss 0.127477 acc 0.918264 lr 0.00022876 grad_norm 0.581684 rank 2
2025-01-10 12:59:09,895 DEBUG TRAIN Batch 49/1500 loss 0.159429 acc 0.884201 lr 0.00022864 grad_norm 0.569082 rank 0
2025-01-10 12:59:09,895 DEBUG TRAIN Batch 49/1500 loss 0.158203 acc 0.896235 lr 0.00022864 grad_norm 0.569082 rank 1
2025-01-10 12:59:09,895 DEBUG TRAIN Batch 49/1500 loss 0.144528 acc 0.886467 lr 0.00022864 grad_norm 0.569082 rank 2
2025-01-10 12:59:34,068 DEBUG TRAIN Batch 49/1600 loss 0.168457 acc 0.886408 lr 0.00022852 grad_norm 0.582818 rank 1
2025-01-10 12:59:34,068 DEBUG TRAIN Batch 49/1600 loss 0.136739 acc 0.902418 lr 0.00022852 grad_norm 0.582818 rank 2
2025-01-10 12:59:34,068 DEBUG TRAIN Batch 49/1600 loss 0.136930 acc 0.901998 lr 0.00022852 grad_norm 0.582818 rank 0
2025-01-10 12:59:57,723 DEBUG TRAIN Batch 49/1700 loss 0.124309 acc 0.915957 lr 0.00022840 grad_norm 0.639648 rank 1
2025-01-10 12:59:57,723 DEBUG TRAIN Batch 49/1700 loss 0.146534 acc 0.882293 lr 0.00022840 grad_norm 0.639648 rank 0
2025-01-10 12:59:57,723 DEBUG TRAIN Batch 49/1700 loss 0.140812 acc 0.904902 lr 0.00022840 grad_norm 0.639648 rank 2
2025-01-10 13:00:21,596 DEBUG TRAIN Batch 49/1800 loss 0.142017 acc 0.894691 lr 0.00022828 grad_norm 0.601085 rank 1
2025-01-10 13:00:21,596 DEBUG TRAIN Batch 49/1800 loss 0.102234 acc 0.925373 lr 0.00022828 grad_norm 0.601085 rank 0
2025-01-10 13:00:21,596 DEBUG TRAIN Batch 49/1800 loss 0.138178 acc 0.909796 lr 0.00022828 grad_norm 0.601085 rank 2
2025-01-10 13:00:45,419 DEBUG TRAIN Batch 49/1900 loss 0.138343 acc 0.900826 lr 0.00022817 grad_norm 0.587318 rank 1
2025-01-10 13:00:45,419 DEBUG TRAIN Batch 49/1900 loss 0.131941 acc 0.898578 lr 0.00022817 grad_norm 0.587318 rank 2
2025-01-10 13:00:45,419 DEBUG TRAIN Batch 49/1900 loss 0.130181 acc 0.913580 lr 0.00022817 grad_norm 0.587318 rank 0
2025-01-10 13:01:08,964 DEBUG TRAIN Batch 49/2000 loss 0.141561 acc 0.909474 lr 0.00022805 grad_norm 0.569250 rank 2
2025-01-10 13:01:08,965 DEBUG TRAIN Batch 49/2000 loss 0.133472 acc 0.907814 lr 0.00022805 grad_norm 0.569250 rank 1
2025-01-10 13:01:08,965 DEBUG TRAIN Batch 49/2000 loss 0.118172 acc 0.921951 lr 0.00022805 grad_norm 0.569250 rank 0
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 13:02:25,010 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 13:02:25,019 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 13:02:25,449 INFO Epoch 49 Step 48106 on_batch_end True CV rank 0
2025-01-10 13:02:25,449 INFO Epoch 49 Step 48106 on_batch_end True CV rank 1
2025-01-10 13:02:25,449 INFO Epoch 49 Step 48106 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 13:02:34,602 DEBUG CV Batch 49/100 loss 0.049074 acc 0.979933  rank 0
2025-01-10 13:02:35,044 DEBUG CV Batch 49/100 loss 0.049074 acc 0.979933  rank 2
2025-01-10 13:02:35,148 INFO Epoch 49 Step 48106 CV info lr 0.00022796615847362367 0 rank loss_1.9081822648366684 acc_0.7742006204891623
2025-01-10 13:02:35,214 DEBUG CV Batch 49/100 loss 0.049074 acc 0.979933  rank 1
2025-01-10 13:02:35,615 INFO Epoch 49 Step 48106 CV info lr 0.00022796615847362367 2 rank loss_1.9081822648366684 acc_0.7742006204891623
2025-01-10 13:02:35,742 INFO Epoch 49 Step 48106 CV info lr 0.00022796615847362367 1 rank loss_1.9081822648366684 acc_0.7742006204891623
2025-01-10 13:02:36,448 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_49_whole.pt
2025-01-10 13:02:36,460 INFO Added key: store_based_barrier_key:52 to store for rank: 0
2025-01-10 13:02:36,471 INFO Added key: store_based_barrier_key:52 to store for rank: 2
2025-01-10 13:02:36,471 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:52 with 3 nodes.
2025-01-10 13:02:36,471 INFO Added key: store_based_barrier_key:52 to store for rank: 1
2025-01-10 13:02:36,471 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:52 with 3 nodes.
2025-01-10 13:02:36,471 INFO Epoch 50 TRAIN info lr 0.00022796615847362367 rank 1
2025-01-10 13:02:36,471 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 13:02:36,480 INFO Epoch 50 TRAIN info lr 0.00022796615847362367 rank 2
2025-01-10 13:02:36,480 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 13:02:36,481 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:52 with 3 nodes.
2025-01-10 13:02:36,488 INFO Epoch 50 TRAIN info lr 0.00022796615847362367 rank 0
2025-01-10 13:02:36,488 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 13:03:09,650 DEBUG TRAIN Batch 50/100 loss 0.091129 acc 0.944105 lr 0.00022785 grad_norm 0.502200 rank 1
2025-01-10 13:03:09,650 DEBUG TRAIN Batch 50/100 loss 0.093390 acc 0.932140 lr 0.00022785 grad_norm 0.502200 rank 2
2025-01-10 13:03:09,651 DEBUG TRAIN Batch 50/100 loss 0.083803 acc 0.937755 lr 0.00022785 grad_norm 0.502200 rank 0
2025-01-10 13:03:33,804 DEBUG TRAIN Batch 50/200 loss 0.111831 acc 0.927189 lr 0.00022773 grad_norm 0.527959 rank 1
2025-01-10 13:03:33,805 DEBUG TRAIN Batch 50/200 loss 0.126954 acc 0.907246 lr 0.00022773 grad_norm 0.527959 rank 2
2025-01-10 13:03:33,805 DEBUG TRAIN Batch 50/200 loss 0.108193 acc 0.924641 lr 0.00022773 grad_norm 0.527959 rank 0
2025-01-10 13:03:57,980 DEBUG TRAIN Batch 50/300 loss 0.109973 acc 0.919231 lr 0.00022761 grad_norm 0.537583 rank 0
2025-01-10 13:03:57,980 DEBUG TRAIN Batch 50/300 loss 0.092268 acc 0.937829 lr 0.00022761 grad_norm 0.537583 rank 2
2025-01-10 13:03:57,980 DEBUG TRAIN Batch 50/300 loss 0.153523 acc 0.879279 lr 0.00022761 grad_norm 0.537583 rank 1
2025-01-10 13:04:22,206 DEBUG TRAIN Batch 50/400 loss 0.121055 acc 0.917471 lr 0.00022749 grad_norm 0.540379 rank 1
2025-01-10 13:04:22,207 DEBUG TRAIN Batch 50/400 loss 0.123983 acc 0.912127 lr 0.00022749 grad_norm 0.540379 rank 2
2025-01-10 13:04:22,207 DEBUG TRAIN Batch 50/400 loss 0.079125 acc 0.946903 lr 0.00022749 grad_norm 0.540379 rank 0
2025-01-10 13:04:46,263 DEBUG TRAIN Batch 50/500 loss 0.136339 acc 0.909363 lr 0.00022738 grad_norm 0.559825 rank 1
2025-01-10 13:04:46,264 DEBUG TRAIN Batch 50/500 loss 0.102345 acc 0.927984 lr 0.00022738 grad_norm 0.559825 rank 0
2025-01-10 13:04:46,264 DEBUG TRAIN Batch 50/500 loss 0.129168 acc 0.913158 lr 0.00022738 grad_norm 0.559825 rank 2
2025-01-10 13:05:10,152 DEBUG TRAIN Batch 50/600 loss 0.171219 acc 0.890991 lr 0.00022726 grad_norm 0.573084 rank 1
2025-01-10 13:05:10,153 DEBUG TRAIN Batch 50/600 loss 0.099403 acc 0.935618 lr 0.00022726 grad_norm 0.573084 rank 2
2025-01-10 13:05:10,153 DEBUG TRAIN Batch 50/600 loss 0.089440 acc 0.930456 lr 0.00022726 grad_norm 0.573084 rank 0
2025-01-10 13:05:34,669 DEBUG TRAIN Batch 50/700 loss 0.134801 acc 0.900000 lr 0.00022714 grad_norm 0.556918 rank 0
2025-01-10 13:05:34,669 DEBUG TRAIN Batch 50/700 loss 0.123709 acc 0.905610 lr 0.00022714 grad_norm 0.556918 rank 1
2025-01-10 13:05:34,669 DEBUG TRAIN Batch 50/700 loss 0.109599 acc 0.923800 lr 0.00022714 grad_norm 0.556918 rank 2
2025-01-10 13:05:58,976 DEBUG TRAIN Batch 50/800 loss 0.133833 acc 0.914468 lr 0.00022702 grad_norm 0.593671 rank 1
2025-01-10 13:05:58,977 DEBUG TRAIN Batch 50/800 loss 0.151268 acc 0.894591 lr 0.00022702 grad_norm 0.593671 rank 0
2025-01-10 13:05:58,977 DEBUG TRAIN Batch 50/800 loss 0.114790 acc 0.911546 lr 0.00022702 grad_norm 0.593671 rank 2
2025-01-10 13:06:23,117 DEBUG TRAIN Batch 50/900 loss 0.121525 acc 0.916509 lr 0.00022691 grad_norm 0.569622 rank 2
2025-01-10 13:06:23,117 DEBUG TRAIN Batch 50/900 loss 0.113797 acc 0.925551 lr 0.00022691 grad_norm 0.569622 rank 0
2025-01-10 13:06:23,117 DEBUG TRAIN Batch 50/900 loss 0.118414 acc 0.922877 lr 0.00022691 grad_norm 0.569622 rank 1
2025-01-10 13:06:46,619 DEBUG TRAIN Batch 50/1000 loss 0.143328 acc 0.903066 lr 0.00022679 grad_norm 0.578771 rank 1
2025-01-10 13:06:46,619 DEBUG TRAIN Batch 50/1000 loss 0.146882 acc 0.891635 lr 0.00022679 grad_norm 0.578771 rank 2
2025-01-10 13:06:46,619 DEBUG TRAIN Batch 50/1000 loss 0.129812 acc 0.908326 lr 0.00022679 grad_norm 0.578771 rank 0
2025-01-10 13:07:10,732 DEBUG TRAIN Batch 50/1100 loss 0.166978 acc 0.871595 lr 0.00022667 grad_norm 0.625879 rank 1
2025-01-10 13:07:10,732 DEBUG TRAIN Batch 50/1100 loss 0.112087 acc 0.922686 lr 0.00022667 grad_norm 0.625879 rank 2
2025-01-10 13:07:10,732 DEBUG TRAIN Batch 50/1100 loss 0.108787 acc 0.923469 lr 0.00022667 grad_norm 0.625879 rank 0
2025-01-10 13:07:35,171 DEBUG TRAIN Batch 50/1200 loss 0.151842 acc 0.891032 lr 0.00022656 grad_norm 0.612075 rank 1
2025-01-10 13:07:35,171 DEBUG TRAIN Batch 50/1200 loss 0.082938 acc 0.944828 lr 0.00022656 grad_norm 0.612075 rank 2
2025-01-10 13:07:35,171 DEBUG TRAIN Batch 50/1200 loss 0.127247 acc 0.917895 lr 0.00022656 grad_norm 0.612075 rank 0
2025-01-10 13:07:59,570 DEBUG TRAIN Batch 50/1300 loss 0.159907 acc 0.886990 lr 0.00022644 grad_norm 0.620701 rank 2
2025-01-10 13:07:59,570 DEBUG TRAIN Batch 50/1300 loss 0.129778 acc 0.920039 lr 0.00022644 grad_norm 0.620701 rank 0
2025-01-10 13:07:59,570 DEBUG TRAIN Batch 50/1300 loss 0.120369 acc 0.907741 lr 0.00022644 grad_norm 0.620701 rank 1
2025-01-10 13:08:23,674 DEBUG TRAIN Batch 50/1400 loss 0.124806 acc 0.918348 lr 0.00022633 grad_norm 0.561316 rank 1
2025-01-10 13:08:23,674 DEBUG TRAIN Batch 50/1400 loss 0.121417 acc 0.906883 lr 0.00022633 grad_norm 0.561316 rank 0
2025-01-10 13:08:23,674 DEBUG TRAIN Batch 50/1400 loss 0.119779 acc 0.913366 lr 0.00022633 grad_norm 0.561316 rank 2
2025-01-10 13:08:47,978 DEBUG TRAIN Batch 50/1500 loss 0.140556 acc 0.899202 lr 0.00022621 grad_norm 0.551167 rank 1
2025-01-10 13:08:47,978 DEBUG TRAIN Batch 50/1500 loss 0.082601 acc 0.948845 lr 0.00022621 grad_norm 0.551167 rank 2
2025-01-10 13:08:47,979 DEBUG TRAIN Batch 50/1500 loss 0.114309 acc 0.924198 lr 0.00022621 grad_norm 0.551167 rank 0
2025-01-10 13:09:13,145 DEBUG TRAIN Batch 50/1600 loss 0.120313 acc 0.911132 lr 0.00022609 grad_norm 0.558967 rank 2
2025-01-10 13:09:13,145 DEBUG TRAIN Batch 50/1600 loss 0.127820 acc 0.910419 lr 0.00022609 grad_norm 0.558967 rank 0
2025-01-10 13:09:13,146 DEBUG TRAIN Batch 50/1600 loss 0.074650 acc 0.940984 lr 0.00022609 grad_norm 0.558967 rank 1
2025-01-10 13:09:36,821 DEBUG TRAIN Batch 50/1700 loss 0.084509 acc 0.941975 lr 0.00022598 grad_norm 0.571112 rank 2
2025-01-10 13:09:36,822 DEBUG TRAIN Batch 50/1700 loss 0.161768 acc 0.893596 lr 0.00022598 grad_norm 0.571112 rank 0
2025-01-10 13:09:36,822 DEBUG TRAIN Batch 50/1700 loss 0.150156 acc 0.895614 lr 0.00022598 grad_norm 0.571112 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 13:10:52,715 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 13:10:52,723 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 13:10:53,194 INFO Epoch 50 Step 48989 on_batch_end True CV rank 2
2025-01-10 13:10:53,194 INFO Epoch 50 Step 48989 on_batch_end True CV rank 0
2025-01-10 13:10:53,194 INFO Epoch 50 Step 48989 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 13:11:02,448 DEBUG CV Batch 50/100 loss 0.044227 acc 0.983278  rank 0
2025-01-10 13:11:02,545 DEBUG CV Batch 50/100 loss 0.044227 acc 0.983278  rank 2
2025-01-10 13:11:02,978 INFO Epoch 50 Step 48989 CV info lr 0.00022590233353391123 0 rank loss_1.9236945537931955 acc_0.7753652517209974
2025-01-10 13:11:03,068 INFO Epoch 50 Step 48989 CV info lr 0.00022590233353391123 2 rank loss_1.9236945537931955 acc_0.7753652517209974
2025-01-10 13:11:03,219 DEBUG CV Batch 50/100 loss 0.044227 acc 0.983278  rank 1
2025-01-10 13:11:03,756 INFO Epoch 50 Step 48989 CV info lr 0.00022590233353391123 1 rank loss_1.9236945537931955 acc_0.7753652517209974
2025-01-10 13:11:04,287 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_50_whole.pt
2025-01-10 13:11:04,309 INFO Added key: store_based_barrier_key:53 to store for rank: 0
2025-01-10 13:11:04,309 INFO Added key: store_based_barrier_key:53 to store for rank: 1
2025-01-10 13:11:04,309 INFO Added key: store_based_barrier_key:53 to store for rank: 2
2025-01-10 13:11:04,309 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:53 with 3 nodes.
2025-01-10 13:11:04,319 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:53 with 3 nodes.
2025-01-10 13:11:04,319 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:53 with 3 nodes.
2025-01-10 13:11:04,319 INFO Epoch 51 TRAIN info lr 0.00022590233353391123 rank 2
2025-01-10 13:11:04,319 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 13:11:04,320 INFO Epoch 51 TRAIN info lr 0.00022590233353391123 rank 1
2025-01-10 13:11:04,320 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 13:11:04,327 INFO Epoch 51 TRAIN info lr 0.00022590233353391123 rank 0
2025-01-10 13:11:04,328 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 13:11:35,252 DEBUG TRAIN Batch 51/100 loss 0.096387 acc 0.936575 lr 0.00022579 grad_norm 0.534211 rank 2
2025-01-10 13:11:35,252 DEBUG TRAIN Batch 51/100 loss 0.116987 acc 0.922675 lr 0.00022579 grad_norm 0.534211 rank 0
2025-01-10 13:11:35,253 DEBUG TRAIN Batch 51/100 loss 0.088293 acc 0.936853 lr 0.00022579 grad_norm 0.534211 rank 1
2025-01-10 13:11:58,946 DEBUG TRAIN Batch 51/200 loss 0.097678 acc 0.921120 lr 0.00022567 grad_norm 0.531838 rank 0
2025-01-10 13:11:58,947 DEBUG TRAIN Batch 51/200 loss 0.069298 acc 0.953431 lr 0.00022567 grad_norm 0.531838 rank 2
2025-01-10 13:11:58,947 DEBUG TRAIN Batch 51/200 loss 0.127338 acc 0.911504 lr 0.00022567 grad_norm 0.531838 rank 1
2025-01-10 13:12:22,399 DEBUG TRAIN Batch 51/300 loss 0.127280 acc 0.918683 lr 0.00022556 grad_norm 0.577217 rank 1
2025-01-10 13:12:22,400 DEBUG TRAIN Batch 51/300 loss 0.120598 acc 0.915157 lr 0.00022556 grad_norm 0.577217 rank 2
2025-01-10 13:12:22,400 DEBUG TRAIN Batch 51/300 loss 0.145189 acc 0.896552 lr 0.00022556 grad_norm 0.577217 rank 0
2025-01-10 13:12:45,931 DEBUG TRAIN Batch 51/400 loss 0.096691 acc 0.931507 lr 0.00022544 grad_norm 0.564828 rank 1
2025-01-10 13:12:45,931 DEBUG TRAIN Batch 51/400 loss 0.124691 acc 0.916129 lr 0.00022544 grad_norm 0.564828 rank 0
2025-01-10 13:12:45,932 DEBUG TRAIN Batch 51/400 loss 0.108759 acc 0.932000 lr 0.00022544 grad_norm 0.564828 rank 2
2025-01-10 13:13:10,036 DEBUG TRAIN Batch 51/500 loss 0.130592 acc 0.903525 lr 0.00022533 grad_norm 0.536498 rank 2
2025-01-10 13:13:10,037 DEBUG TRAIN Batch 51/500 loss 0.137703 acc 0.906726 lr 0.00022533 grad_norm 0.536498 rank 1
2025-01-10 13:13:10,038 DEBUG TRAIN Batch 51/500 loss 0.124544 acc 0.908333 lr 0.00022533 grad_norm 0.536498 rank 0
2025-01-10 13:13:33,592 DEBUG TRAIN Batch 51/600 loss 0.123415 acc 0.909935 lr 0.00022521 grad_norm 0.561549 rank 1
2025-01-10 13:13:33,592 DEBUG TRAIN Batch 51/600 loss 0.147563 acc 0.896396 lr 0.00022521 grad_norm 0.561549 rank 0
2025-01-10 13:13:33,592 DEBUG TRAIN Batch 51/600 loss 0.110268 acc 0.931567 lr 0.00022521 grad_norm 0.561549 rank 2
2025-01-10 13:13:57,996 DEBUG TRAIN Batch 51/700 loss 0.088075 acc 0.939297 lr 0.00022510 grad_norm 0.532053 rank 1
2025-01-10 13:13:57,997 DEBUG TRAIN Batch 51/700 loss 0.134715 acc 0.900350 lr 0.00022510 grad_norm 0.532053 rank 0
2025-01-10 13:13:57,997 DEBUG TRAIN Batch 51/700 loss 0.137445 acc 0.914259 lr 0.00022510 grad_norm 0.532053 rank 2
2025-01-10 13:14:21,793 DEBUG TRAIN Batch 51/800 loss 0.140822 acc 0.906087 lr 0.00022499 grad_norm 0.542147 rank 1
2025-01-10 13:14:21,794 DEBUG TRAIN Batch 51/800 loss 0.133052 acc 0.914110 lr 0.00022499 grad_norm 0.542147 rank 2
2025-01-10 13:14:21,795 DEBUG TRAIN Batch 51/800 loss 0.120649 acc 0.918675 lr 0.00022499 grad_norm 0.542147 rank 0
2025-01-10 13:14:45,961 DEBUG TRAIN Batch 51/900 loss 0.105251 acc 0.925791 lr 0.00022487 grad_norm 0.560523 rank 0
2025-01-10 13:14:45,962 DEBUG TRAIN Batch 51/900 loss 0.129239 acc 0.902878 lr 0.00022487 grad_norm 0.560523 rank 1
2025-01-10 13:14:45,962 DEBUG TRAIN Batch 51/900 loss 0.111247 acc 0.914914 lr 0.00022487 grad_norm 0.560523 rank 2
2025-01-10 13:15:09,790 DEBUG TRAIN Batch 51/1000 loss 0.107290 acc 0.932803 lr 0.00022476 grad_norm 0.549806 rank 2
2025-01-10 13:15:09,791 DEBUG TRAIN Batch 51/1000 loss 0.124942 acc 0.927412 lr 0.00022476 grad_norm 0.549806 rank 1
2025-01-10 13:15:09,791 DEBUG TRAIN Batch 51/1000 loss 0.132406 acc 0.913371 lr 0.00022476 grad_norm 0.549806 rank 0
2025-01-10 13:15:33,843 DEBUG TRAIN Batch 51/1100 loss 0.118671 acc 0.909091 lr 0.00022464 grad_norm 0.552479 rank 2
2025-01-10 13:15:33,843 DEBUG TRAIN Batch 51/1100 loss 0.105461 acc 0.925727 lr 0.00022464 grad_norm 0.552479 rank 1
2025-01-10 13:15:33,843 DEBUG TRAIN Batch 51/1100 loss 0.138412 acc 0.894737 lr 0.00022464 grad_norm 0.552479 rank 0
2025-01-10 13:15:58,519 DEBUG TRAIN Batch 51/1200 loss 0.152083 acc 0.892764 lr 0.00022453 grad_norm 0.560518 rank 1
2025-01-10 13:15:58,519 DEBUG TRAIN Batch 51/1200 loss 0.154850 acc 0.893911 lr 0.00022453 grad_norm 0.560518 rank 0
2025-01-10 13:15:58,519 DEBUG TRAIN Batch 51/1200 loss 0.085879 acc 0.936170 lr 0.00022453 grad_norm 0.560518 rank 2
2025-01-10 13:16:22,243 DEBUG TRAIN Batch 51/1300 loss 0.109577 acc 0.925852 lr 0.00022442 grad_norm 0.554195 rank 1
2025-01-10 13:16:22,243 DEBUG TRAIN Batch 51/1300 loss 0.076996 acc 0.947166 lr 0.00022442 grad_norm 0.554195 rank 2
2025-01-10 13:16:22,243 DEBUG TRAIN Batch 51/1300 loss 0.143054 acc 0.901257 lr 0.00022442 grad_norm 0.554195 rank 0
2025-01-10 13:16:46,522 DEBUG TRAIN Batch 51/1400 loss 0.138211 acc 0.906034 lr 0.00022431 grad_norm 0.565180 rank 1
2025-01-10 13:16:46,522 DEBUG TRAIN Batch 51/1400 loss 0.126517 acc 0.919828 lr 0.00022431 grad_norm 0.565180 rank 0
2025-01-10 13:16:46,523 DEBUG TRAIN Batch 51/1400 loss 0.146911 acc 0.893655 lr 0.00022431 grad_norm 0.565180 rank 2
2025-01-10 13:17:11,250 DEBUG TRAIN Batch 51/1500 loss 0.098122 acc 0.925638 lr 0.00022419 grad_norm 0.538259 rank 2
2025-01-10 13:17:11,250 DEBUG TRAIN Batch 51/1500 loss 0.111007 acc 0.931748 lr 0.00022419 grad_norm 0.538259 rank 0
2025-01-10 13:17:11,251 DEBUG TRAIN Batch 51/1500 loss 0.121405 acc 0.914401 lr 0.00022419 grad_norm 0.538259 rank 1
2025-01-10 13:17:35,938 DEBUG TRAIN Batch 51/1600 loss 0.128966 acc 0.907439 lr 0.00022408 grad_norm 0.542479 rank 1
2025-01-10 13:17:35,938 DEBUG TRAIN Batch 51/1600 loss 0.113992 acc 0.923144 lr 0.00022408 grad_norm 0.542479 rank 2
2025-01-10 13:17:35,940 DEBUG TRAIN Batch 51/1600 loss 0.110404 acc 0.926653 lr 0.00022408 grad_norm 0.542479 rank 0
2025-01-10 13:18:00,102 DEBUG TRAIN Batch 51/1700 loss 0.128372 acc 0.919060 lr 0.00022397 grad_norm 0.569408 rank 1
2025-01-10 13:18:00,102 DEBUG TRAIN Batch 51/1700 loss 0.117525 acc 0.916427 lr 0.00022397 grad_norm 0.569408 rank 2
2025-01-10 13:18:00,102 DEBUG TRAIN Batch 51/1700 loss 0.136747 acc 0.906250 lr 0.00022397 grad_norm 0.569408 rank 0
2025-01-10 13:18:24,779 DEBUG TRAIN Batch 51/1800 loss 0.142871 acc 0.910615 lr 0.00022386 grad_norm 0.551079 rank 1
2025-01-10 13:18:24,779 DEBUG TRAIN Batch 51/1800 loss 0.094980 acc 0.932417 lr 0.00022386 grad_norm 0.551079 rank 2
2025-01-10 13:18:24,779 DEBUG TRAIN Batch 51/1800 loss 0.100903 acc 0.918605 lr 0.00022386 grad_norm 0.551079 rank 0
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 13:19:34,883 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 13:19:34,884 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 13:19:35,343 INFO Epoch 51 Step 49910 on_batch_end True CV rank 2
2025-01-10 13:19:35,343 INFO Epoch 51 Step 49910 on_batch_end True CV rank 0
2025-01-10 13:19:35,343 INFO Epoch 51 Step 49910 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 13:19:44,361 DEBUG CV Batch 51/100 loss 0.039575 acc 0.986622  rank 0
2025-01-10 13:19:44,596 DEBUG CV Batch 51/100 loss 0.039575 acc 0.986622  rank 2
2025-01-10 13:19:44,894 INFO Epoch 51 Step 49910 CV info lr 0.0002238083159583795 0 rank loss_1.9406503664836157 acc_0.776757995810425
2025-01-10 13:19:45,136 INFO Epoch 51 Step 49910 CV info lr 0.0002238083159583795 2 rank loss_1.9406503664836157 acc_0.776757995810425
2025-01-10 13:19:45,446 DEBUG CV Batch 51/100 loss 0.039575 acc 0.986622  rank 1
2025-01-10 13:19:46,002 INFO Epoch 51 Step 49910 CV info lr 0.0002238083159583795 1 rank loss_1.9406503664836157 acc_0.776757995810425
2025-01-10 13:19:46,192 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_51_whole.pt
2025-01-10 13:19:46,204 INFO Added key: store_based_barrier_key:54 to store for rank: 0
2025-01-10 13:19:46,214 INFO Added key: store_based_barrier_key:54 to store for rank: 2
2025-01-10 13:19:46,214 INFO Added key: store_based_barrier_key:54 to store for rank: 1
2025-01-10 13:19:46,214 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:54 with 3 nodes.
2025-01-10 13:19:46,214 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:54 with 3 nodes.
2025-01-10 13:19:46,216 INFO Epoch 52 TRAIN info lr 0.0002238083159583795 rank 1
2025-01-10 13:19:46,216 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 13:19:46,219 INFO Epoch 52 TRAIN info lr 0.0002238083159583795 rank 2
2025-01-10 13:19:46,219 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 13:19:46,224 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:54 with 3 nodes.
2025-01-10 13:19:46,227 INFO Epoch 52 TRAIN info lr 0.0002238083159583795 rank 0
2025-01-10 13:19:46,227 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 13:20:17,013 DEBUG TRAIN Batch 52/100 loss 0.098691 acc 0.936906 lr 0.00022370 grad_norm 0.507190 rank 1
2025-01-10 13:20:17,013 DEBUG TRAIN Batch 52/100 loss 0.106529 acc 0.930740 lr 0.00022370 grad_norm 0.507190 rank 0
2025-01-10 13:20:17,013 DEBUG TRAIN Batch 52/100 loss 0.107844 acc 0.919624 lr 0.00022370 grad_norm 0.507190 rank 2
2025-01-10 13:20:41,059 DEBUG TRAIN Batch 52/200 loss 0.065194 acc 0.962085 lr 0.00022358 grad_norm 0.523093 rank 1
2025-01-10 13:20:41,059 DEBUG TRAIN Batch 52/200 loss 0.131664 acc 0.907180 lr 0.00022358 grad_norm 0.523093 rank 2
2025-01-10 13:20:41,059 DEBUG TRAIN Batch 52/200 loss 0.106232 acc 0.926199 lr 0.00022358 grad_norm 0.523093 rank 0
2025-01-10 13:21:04,966 DEBUG TRAIN Batch 52/300 loss 0.102885 acc 0.924354 lr 0.00022347 grad_norm 0.535504 rank 1
2025-01-10 13:21:04,967 DEBUG TRAIN Batch 52/300 loss 0.128075 acc 0.910420 lr 0.00022347 grad_norm 0.535504 rank 0
2025-01-10 13:21:04,968 DEBUG TRAIN Batch 52/300 loss 0.112614 acc 0.917423 lr 0.00022347 grad_norm 0.535504 rank 2
2025-01-10 13:21:28,572 DEBUG TRAIN Batch 52/400 loss 0.127576 acc 0.917850 lr 0.00022336 grad_norm 0.549246 rank 0
2025-01-10 13:21:28,572 DEBUG TRAIN Batch 52/400 loss 0.081683 acc 0.935992 lr 0.00022336 grad_norm 0.549246 rank 2
2025-01-10 13:21:28,572 DEBUG TRAIN Batch 52/400 loss 0.100244 acc 0.942857 lr 0.00022336 grad_norm 0.549246 rank 1
2025-01-10 13:21:52,639 DEBUG TRAIN Batch 52/500 loss 0.096582 acc 0.929510 lr 0.00022325 grad_norm 0.547189 rank 0
2025-01-10 13:21:52,640 DEBUG TRAIN Batch 52/500 loss 0.110540 acc 0.921447 lr 0.00022325 grad_norm 0.547189 rank 2
2025-01-10 13:21:52,640 DEBUG TRAIN Batch 52/500 loss 0.130733 acc 0.911792 lr 0.00022325 grad_norm 0.547189 rank 1
2025-01-10 13:22:16,634 DEBUG TRAIN Batch 52/600 loss 0.111518 acc 0.920677 lr 0.00022314 grad_norm 0.589594 rank 0
2025-01-10 13:22:16,634 DEBUG TRAIN Batch 52/600 loss 0.132922 acc 0.910268 lr 0.00022314 grad_norm 0.589594 rank 2
2025-01-10 13:22:16,634 DEBUG TRAIN Batch 52/600 loss 0.125432 acc 0.910319 lr 0.00022314 grad_norm 0.589594 rank 1
2025-01-10 13:22:41,719 DEBUG TRAIN Batch 52/700 loss 0.063395 acc 0.965116 lr 0.00022303 grad_norm 0.550825 rank 1
2025-01-10 13:22:41,720 DEBUG TRAIN Batch 52/700 loss 0.135687 acc 0.902852 lr 0.00022303 grad_norm 0.550825 rank 0
2025-01-10 13:22:41,720 DEBUG TRAIN Batch 52/700 loss 0.122329 acc 0.914370 lr 0.00022303 grad_norm 0.550825 rank 2
2025-01-10 13:23:06,627 DEBUG TRAIN Batch 52/800 loss 0.174819 acc 0.881533 lr 0.00022292 grad_norm 0.576735 rank 1
2025-01-10 13:23:06,627 DEBUG TRAIN Batch 52/800 loss 0.118870 acc 0.914056 lr 0.00022292 grad_norm 0.576735 rank 2
2025-01-10 13:23:06,628 DEBUG TRAIN Batch 52/800 loss 0.109789 acc 0.931574 lr 0.00022292 grad_norm 0.576735 rank 0
2025-01-10 13:23:30,778 DEBUG TRAIN Batch 52/900 loss 0.122477 acc 0.917012 lr 0.00022281 grad_norm 0.542489 rank 0
2025-01-10 13:23:30,779 DEBUG TRAIN Batch 52/900 loss 0.107464 acc 0.922613 lr 0.00022281 grad_norm 0.542489 rank 1
2025-01-10 13:23:30,779 DEBUG TRAIN Batch 52/900 loss 0.125992 acc 0.912150 lr 0.00022281 grad_norm 0.542489 rank 2
2025-01-10 13:23:55,365 DEBUG TRAIN Batch 52/1000 loss 0.116660 acc 0.921105 lr 0.00022270 grad_norm 0.577233 rank 0
2025-01-10 13:23:55,365 DEBUG TRAIN Batch 52/1000 loss 0.115770 acc 0.923163 lr 0.00022270 grad_norm 0.577233 rank 1
2025-01-10 13:23:55,365 DEBUG TRAIN Batch 52/1000 loss 0.154927 acc 0.894170 lr 0.00022270 grad_norm 0.577233 rank 2
2025-01-10 13:24:20,946 DEBUG TRAIN Batch 52/1100 loss 0.082264 acc 0.942197 lr 0.00022259 grad_norm 0.558997 rank 1
2025-01-10 13:24:20,946 DEBUG TRAIN Batch 52/1100 loss 0.103515 acc 0.926807 lr 0.00022259 grad_norm 0.558997 rank 2
2025-01-10 13:24:20,946 DEBUG TRAIN Batch 52/1100 loss 0.124534 acc 0.918310 lr 0.00022259 grad_norm 0.558997 rank 0
2025-01-10 13:24:45,746 DEBUG TRAIN Batch 52/1200 loss 0.140476 acc 0.897849 lr 0.00022248 grad_norm 0.536742 rank 2
2025-01-10 13:24:45,746 DEBUG TRAIN Batch 52/1200 loss 0.041422 acc 0.979522 lr 0.00022248 grad_norm 0.536742 rank 0
2025-01-10 13:24:45,746 DEBUG TRAIN Batch 52/1200 loss 0.099335 acc 0.933535 lr 0.00022248 grad_norm 0.536742 rank 1
2025-01-10 13:25:09,851 DEBUG TRAIN Batch 52/1300 loss 0.116553 acc 0.927991 lr 0.00022237 grad_norm 0.562273 rank 2
2025-01-10 13:25:09,851 DEBUG TRAIN Batch 52/1300 loss 0.085099 acc 0.944944 lr 0.00022237 grad_norm 0.562273 rank 1
2025-01-10 13:25:09,852 DEBUG TRAIN Batch 52/1300 loss 0.119574 acc 0.918165 lr 0.00022237 grad_norm 0.562273 rank 0
2025-01-10 13:25:35,434 DEBUG TRAIN Batch 52/1400 loss 0.110631 acc 0.918443 lr 0.00022226 grad_norm 0.547233 rank 1
2025-01-10 13:25:35,434 DEBUG TRAIN Batch 52/1400 loss 0.094262 acc 0.944376 lr 0.00022226 grad_norm 0.547233 rank 0
2025-01-10 13:25:35,434 DEBUG TRAIN Batch 52/1400 loss 0.112678 acc 0.918239 lr 0.00022226 grad_norm 0.547233 rank 2
2025-01-10 13:25:59,405 DEBUG TRAIN Batch 52/1500 loss 0.096022 acc 0.923954 lr 0.00022215 grad_norm 0.569770 rank 2
2025-01-10 13:25:59,405 DEBUG TRAIN Batch 52/1500 loss 0.116677 acc 0.915747 lr 0.00022215 grad_norm 0.569770 rank 1
2025-01-10 13:25:59,405 DEBUG TRAIN Batch 52/1500 loss 0.132026 acc 0.908503 lr 0.00022215 grad_norm 0.569770 rank 0
2025-01-10 13:26:23,893 DEBUG TRAIN Batch 52/1600 loss 0.093061 acc 0.946650 lr 0.00022204 grad_norm 0.586940 rank 0
2025-01-10 13:26:23,893 DEBUG TRAIN Batch 52/1600 loss 0.107607 acc 0.919858 lr 0.00022204 grad_norm 0.586940 rank 1
2025-01-10 13:26:23,893 DEBUG TRAIN Batch 52/1600 loss 0.154668 acc 0.886916 lr 0.00022204 grad_norm 0.586940 rank 2
2025-01-10 13:26:48,326 DEBUG TRAIN Batch 52/1700 loss 0.115786 acc 0.927291 lr 0.00022193 grad_norm 0.570803 rank 2
2025-01-10 13:26:48,327 DEBUG TRAIN Batch 52/1700 loss 0.095897 acc 0.935157 lr 0.00022193 grad_norm 0.570803 rank 0
2025-01-10 13:26:48,327 DEBUG TRAIN Batch 52/1700 loss 0.142671 acc 0.905354 lr 0.00022193 grad_norm 0.570803 rank 1
2025-01-10 13:27:12,014 DEBUG TRAIN Batch 52/1800 loss 0.098731 acc 0.929878 lr 0.00022182 grad_norm 0.590408 rank 2
2025-01-10 13:27:12,014 DEBUG TRAIN Batch 52/1800 loss 0.106777 acc 0.927022 lr 0.00022182 grad_norm 0.590408 rank 0
2025-01-10 13:27:12,014 DEBUG TRAIN Batch 52/1800 loss 0.138030 acc 0.910856 lr 0.00022182 grad_norm 0.590408 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 13:28:14,455 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 13:28:14,460 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 13:28:14,860 INFO Epoch 52 Step 50815 on_batch_end True CV rank 1
2025-01-10 13:28:14,860 INFO Epoch 52 Step 50815 on_batch_end True CV rank 2
2025-01-10 13:28:14,860 INFO Epoch 52 Step 50815 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 13:28:24,162 DEBUG CV Batch 52/100 loss 0.035084 acc 0.989967  rank 0
2025-01-10 13:28:24,384 DEBUG CV Batch 52/100 loss 0.035084 acc 0.989967  rank 2
2025-01-10 13:28:24,620 DEBUG CV Batch 52/100 loss 0.035084 acc 0.989967  rank 1
2025-01-10 13:28:24,685 INFO Epoch 52 Step 50815 CV info lr 0.0002218063827656899 0 rank loss_1.9601825460987656 acc_0.7763567773396509
2025-01-10 13:28:24,934 INFO Epoch 52 Step 50815 CV info lr 0.0002218063827656899 2 rank loss_1.9601825460987656 acc_0.7763567773396509
2025-01-10 13:28:25,183 INFO Epoch 52 Step 50815 CV info lr 0.0002218063827656899 1 rank loss_1.9601825460987656 acc_0.7763567773396509
2025-01-10 13:28:25,971 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_52_whole.pt
2025-01-10 13:28:25,982 INFO Added key: store_based_barrier_key:55 to store for rank: 0
2025-01-10 13:28:25,993 INFO Added key: store_based_barrier_key:55 to store for rank: 2
2025-01-10 13:28:25,993 INFO Added key: store_based_barrier_key:55 to store for rank: 1
2025-01-10 13:28:25,993 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:55 with 3 nodes.
2025-01-10 13:28:25,993 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:55 with 3 nodes.
2025-01-10 13:28:25,995 INFO Epoch 53 TRAIN info lr 0.0002218063827656899 rank 2
2025-01-10 13:28:25,995 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 13:28:26,000 INFO Epoch 53 TRAIN info lr 0.0002218063827656899 rank 1
2025-01-10 13:28:26,000 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 13:28:26,003 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:55 with 3 nodes.
2025-01-10 13:28:26,005 INFO Epoch 53 TRAIN info lr 0.0002218063827656899 rank 0
2025-01-10 13:28:26,005 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 13:28:56,929 DEBUG TRAIN Batch 53/100 loss 0.077137 acc 0.950749 lr 0.00022170 grad_norm 0.531694 rank 0
2025-01-10 13:28:56,929 DEBUG TRAIN Batch 53/100 loss 0.151649 acc 0.908463 lr 0.00022170 grad_norm 0.531694 rank 1
2025-01-10 13:28:56,929 DEBUG TRAIN Batch 53/100 loss 0.113521 acc 0.925926 lr 0.00022170 grad_norm 0.531694 rank 2
2025-01-10 13:29:20,699 DEBUG TRAIN Batch 53/200 loss 0.101608 acc 0.919610 lr 0.00022159 grad_norm 0.569194 rank 1
2025-01-10 13:29:20,699 DEBUG TRAIN Batch 53/200 loss 0.098837 acc 0.923172 lr 0.00022159 grad_norm 0.569194 rank 2
2025-01-10 13:29:20,699 DEBUG TRAIN Batch 53/200 loss 0.081149 acc 0.941397 lr 0.00022159 grad_norm 0.569194 rank 0
2025-01-10 13:29:44,371 DEBUG TRAIN Batch 53/300 loss 0.122132 acc 0.922929 lr 0.00022148 grad_norm 0.544764 rank 1
2025-01-10 13:29:44,372 DEBUG TRAIN Batch 53/300 loss 0.097991 acc 0.925926 lr 0.00022148 grad_norm 0.544764 rank 0
2025-01-10 13:29:44,372 DEBUG TRAIN Batch 53/300 loss 0.131890 acc 0.911321 lr 0.00022148 grad_norm 0.544764 rank 2
2025-01-10 13:30:07,872 DEBUG TRAIN Batch 53/400 loss 0.110292 acc 0.922542 lr 0.00022137 grad_norm 0.555882 rank 2
2025-01-10 13:30:07,873 DEBUG TRAIN Batch 53/400 loss 0.119751 acc 0.923623 lr 0.00022137 grad_norm 0.555882 rank 0
2025-01-10 13:30:07,873 DEBUG TRAIN Batch 53/400 loss 0.097925 acc 0.940355 lr 0.00022137 grad_norm 0.555882 rank 1
2025-01-10 13:30:31,725 DEBUG TRAIN Batch 53/500 loss 0.103137 acc 0.928161 lr 0.00022126 grad_norm 0.548369 rank 1
2025-01-10 13:30:31,725 DEBUG TRAIN Batch 53/500 loss 0.108129 acc 0.926230 lr 0.00022126 grad_norm 0.548369 rank 0
2025-01-10 13:30:31,725 DEBUG TRAIN Batch 53/500 loss 0.097745 acc 0.933809 lr 0.00022126 grad_norm 0.548369 rank 2
2025-01-10 13:30:55,198 DEBUG TRAIN Batch 53/600 loss 0.094834 acc 0.938259 lr 0.00022115 grad_norm 0.527062 rank 0
2025-01-10 13:30:55,198 DEBUG TRAIN Batch 53/600 loss 0.096878 acc 0.931223 lr 0.00022115 grad_norm 0.527062 rank 2
2025-01-10 13:30:55,198 DEBUG TRAIN Batch 53/600 loss 0.106567 acc 0.922941 lr 0.00022115 grad_norm 0.527062 rank 1
2025-01-10 13:31:19,248 DEBUG TRAIN Batch 53/700 loss 0.119360 acc 0.927273 lr 0.00022105 grad_norm 0.536913 rank 0
2025-01-10 13:31:19,248 DEBUG TRAIN Batch 53/700 loss 0.080299 acc 0.944963 lr 0.00022105 grad_norm 0.536913 rank 1
2025-01-10 13:31:19,249 DEBUG TRAIN Batch 53/700 loss 0.125606 acc 0.912343 lr 0.00022105 grad_norm 0.536913 rank 2
2025-01-10 13:31:42,820 DEBUG TRAIN Batch 53/800 loss 0.115682 acc 0.926527 lr 0.00022094 grad_norm 0.537528 rank 2
2025-01-10 13:31:42,820 DEBUG TRAIN Batch 53/800 loss 0.129671 acc 0.924051 lr 0.00022094 grad_norm 0.537528 rank 0
2025-01-10 13:31:42,820 DEBUG TRAIN Batch 53/800 loss 0.110130 acc 0.926431 lr 0.00022094 grad_norm 0.537528 rank 1
2025-01-10 13:32:06,750 DEBUG TRAIN Batch 53/900 loss 0.135843 acc 0.908847 lr 0.00022083 grad_norm 0.561439 rank 1
2025-01-10 13:32:06,751 DEBUG TRAIN Batch 53/900 loss 0.094113 acc 0.933921 lr 0.00022083 grad_norm 0.561439 rank 0
2025-01-10 13:32:06,751 DEBUG TRAIN Batch 53/900 loss 0.128454 acc 0.905363 lr 0.00022083 grad_norm 0.561439 rank 2
2025-01-10 13:32:31,034 DEBUG TRAIN Batch 53/1000 loss 0.129490 acc 0.907149 lr 0.00022072 grad_norm 0.548203 rank 2
2025-01-10 13:32:31,034 DEBUG TRAIN Batch 53/1000 loss 0.133271 acc 0.913215 lr 0.00022072 grad_norm 0.548203 rank 1
2025-01-10 13:32:31,034 DEBUG TRAIN Batch 53/1000 loss 0.110267 acc 0.925628 lr 0.00022072 grad_norm 0.548203 rank 0
2025-01-10 13:32:54,743 DEBUG TRAIN Batch 53/1100 loss 0.103661 acc 0.923077 lr 0.00022062 grad_norm 0.552303 rank 1
2025-01-10 13:32:54,743 DEBUG TRAIN Batch 53/1100 loss 0.097093 acc 0.923463 lr 0.00022062 grad_norm 0.552303 rank 2
2025-01-10 13:32:54,743 DEBUG TRAIN Batch 53/1100 loss 0.109645 acc 0.931227 lr 0.00022062 grad_norm 0.552303 rank 0
2025-01-10 13:33:18,804 DEBUG TRAIN Batch 53/1200 loss 0.097496 acc 0.926966 lr 0.00022051 grad_norm 0.562525 rank 0
2025-01-10 13:33:18,804 DEBUG TRAIN Batch 53/1200 loss 0.120314 acc 0.912377 lr 0.00022051 grad_norm 0.562525 rank 1
2025-01-10 13:33:18,805 DEBUG TRAIN Batch 53/1200 loss 0.137036 acc 0.894687 lr 0.00022051 grad_norm 0.562525 rank 2
2025-01-10 13:33:42,996 DEBUG TRAIN Batch 53/1300 loss 0.108857 acc 0.928128 lr 0.00022040 grad_norm 0.554263 rank 1
2025-01-10 13:33:42,996 DEBUG TRAIN Batch 53/1300 loss 0.122911 acc 0.918123 lr 0.00022040 grad_norm 0.554263 rank 2
2025-01-10 13:33:42,996 DEBUG TRAIN Batch 53/1300 loss 0.100572 acc 0.938796 lr 0.00022040 grad_norm 0.554263 rank 0
2025-01-10 13:34:07,874 DEBUG TRAIN Batch 53/1400 loss 0.136615 acc 0.903710 lr 0.00022029 grad_norm 0.571902 rank 1
2025-01-10 13:34:07,875 DEBUG TRAIN Batch 53/1400 loss 0.118943 acc 0.902510 lr 0.00022029 grad_norm 0.571902 rank 0
2025-01-10 13:34:07,875 DEBUG TRAIN Batch 53/1400 loss 0.096821 acc 0.930467 lr 0.00022029 grad_norm 0.571902 rank 2
2025-01-10 13:34:32,531 DEBUG TRAIN Batch 53/1500 loss 0.132876 acc 0.919171 lr 0.00022019 grad_norm 0.592277 rank 0
2025-01-10 13:34:32,531 DEBUG TRAIN Batch 53/1500 loss 0.107847 acc 0.924184 lr 0.00022019 grad_norm 0.592277 rank 1
2025-01-10 13:34:32,531 DEBUG TRAIN Batch 53/1500 loss 0.125033 acc 0.900990 lr 0.00022019 grad_norm 0.592277 rank 2
2025-01-10 13:34:58,142 DEBUG TRAIN Batch 53/1600 loss 0.081108 acc 0.947627 lr 0.00022008 grad_norm 0.631250 rank 2
2025-01-10 13:34:58,142 DEBUG TRAIN Batch 53/1600 loss 0.079999 acc 0.945763 lr 0.00022008 grad_norm 0.631250 rank 0
2025-01-10 13:34:58,142 DEBUG TRAIN Batch 53/1600 loss 0.101935 acc 0.924976 lr 0.00022008 grad_norm 0.631250 rank 1
2025-01-10 13:35:23,103 DEBUG TRAIN Batch 53/1700 loss 0.111415 acc 0.923507 lr 0.00021997 grad_norm 0.557055 rank 0
2025-01-10 13:35:23,103 DEBUG TRAIN Batch 53/1700 loss 0.095005 acc 0.934152 lr 0.00021997 grad_norm 0.557055 rank 1
2025-01-10 13:35:23,103 DEBUG TRAIN Batch 53/1700 loss 0.069093 acc 0.953869 lr 0.00021997 grad_norm 0.557055 rank 2
2025-01-10 13:35:48,272 DEBUG TRAIN Batch 53/1800 loss 0.135584 acc 0.905357 lr 0.00021987 grad_norm 0.561438 rank 1
2025-01-10 13:35:48,272 DEBUG TRAIN Batch 53/1800 loss 0.108929 acc 0.928505 lr 0.00021987 grad_norm 0.561438 rank 0
2025-01-10 13:35:48,273 DEBUG TRAIN Batch 53/1800 loss 0.103705 acc 0.939744 lr 0.00021987 grad_norm 0.561438 rank 2
2025-01-10 13:36:13,943 DEBUG TRAIN Batch 53/1900 loss 0.111709 acc 0.922348 lr 0.00021976 grad_norm 0.547818 rank 0
2025-01-10 13:36:13,943 DEBUG TRAIN Batch 53/1900 loss 0.127749 acc 0.914657 lr 0.00021976 grad_norm 0.547818 rank 1
2025-01-10 13:36:13,943 DEBUG TRAIN Batch 53/1900 loss 0.131550 acc 0.909672 lr 0.00021976 grad_norm 0.547818 rank 2
2025-01-10 13:36:37,375 DEBUG TRAIN Batch 53/2000 loss 0.102296 acc 0.927551 lr 0.00021966 grad_norm 0.553492 rank 0
2025-01-10 13:36:37,375 DEBUG TRAIN Batch 53/2000 loss 0.121266 acc 0.933090 lr 0.00021966 grad_norm 0.553492 rank 2
2025-01-10 13:36:37,375 DEBUG TRAIN Batch 53/2000 loss 0.127537 acc 0.903442 lr 0.00021966 grad_norm 0.553492 rank 1
2025-01-10 13:37:01,837 DEBUG TRAIN Batch 53/2100 loss 0.091628 acc 0.930036 lr 0.00021955 grad_norm 0.563225 rank 0
2025-01-10 13:37:01,838 DEBUG TRAIN Batch 53/2100 loss 0.110165 acc 0.923077 lr 0.00021955 grad_norm 0.563225 rank 1
2025-01-10 13:37:01,838 DEBUG TRAIN Batch 53/2100 loss 0.155702 acc 0.885368 lr 0.00021955 grad_norm 0.563225 rank 2
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 13:38:05,522 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 13:38:05,540 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 13:38:06,085 INFO Epoch 53 Step 51872 on_batch_end True CV rank 2
2025-01-10 13:38:06,085 INFO Epoch 53 Step 51872 on_batch_end True CV rank 1
2025-01-10 13:38:06,085 INFO Epoch 53 Step 51872 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 13:38:15,598 DEBUG CV Batch 53/100 loss 0.030509 acc 0.987737  rank 0
2025-01-10 13:38:15,629 DEBUG CV Batch 53/100 loss 0.030509 acc 0.987737  rank 2
2025-01-10 13:38:15,879 DEBUG CV Batch 53/100 loss 0.030509 acc 0.987737  rank 1
2025-01-10 13:38:16,122 INFO Epoch 53 Step 51872 CV info lr 0.0002195348680673467 0 rank loss_1.951642973389346 acc_0.7766309738682028
2025-01-10 13:38:16,131 INFO Epoch 53 Step 51872 CV info lr 0.0002195348680673467 2 rank loss_1.951642973389346 acc_0.7766309738682028
2025-01-10 13:38:16,417 INFO Epoch 53 Step 51872 CV info lr 0.0002195348680673467 1 rank loss_1.951642973389346 acc_0.7766309738682028
2025-01-10 13:38:17,389 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_53_whole.pt
2025-01-10 13:38:17,411 INFO Added key: store_based_barrier_key:56 to store for rank: 0
2025-01-10 13:38:17,421 INFO Added key: store_based_barrier_key:56 to store for rank: 2
2025-01-10 13:38:17,422 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:56 with 3 nodes.
2025-01-10 13:38:17,421 INFO Added key: store_based_barrier_key:56 to store for rank: 1
2025-01-10 13:38:17,422 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:56 with 3 nodes.
2025-01-10 13:38:17,425 INFO Epoch 54 TRAIN info lr 0.0002195348680673467 rank 2
2025-01-10 13:38:17,425 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 13:38:17,430 INFO Epoch 54 TRAIN info lr 0.0002195348680673467 rank 1
2025-01-10 13:38:17,430 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 13:38:17,431 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:56 with 3 nodes.
2025-01-10 13:38:17,433 INFO Epoch 54 TRAIN info lr 0.0002195348680673467 rank 0
2025-01-10 13:38:17,433 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 13:38:48,571 DEBUG TRAIN Batch 54/100 loss 0.096952 acc 0.930818 lr 0.00021943 grad_norm 0.542669 rank 1
2025-01-10 13:38:48,571 DEBUG TRAIN Batch 54/100 loss 0.109601 acc 0.929240 lr 0.00021943 grad_norm 0.542669 rank 2
2025-01-10 13:38:48,571 DEBUG TRAIN Batch 54/100 loss 0.109458 acc 0.924607 lr 0.00021943 grad_norm 0.542669 rank 0
2025-01-10 13:39:12,672 DEBUG TRAIN Batch 54/200 loss 0.100034 acc 0.924359 lr 0.00021932 grad_norm 0.533201 rank 2
2025-01-10 13:39:12,672 DEBUG TRAIN Batch 54/200 loss 0.079062 acc 0.943325 lr 0.00021932 grad_norm 0.533201 rank 1
2025-01-10 13:39:12,672 DEBUG TRAIN Batch 54/200 loss 0.083055 acc 0.946835 lr 0.00021932 grad_norm 0.533201 rank 0
2025-01-10 13:39:36,451 DEBUG TRAIN Batch 54/300 loss 0.103303 acc 0.928030 lr 0.00021922 grad_norm 0.524009 rank 1
2025-01-10 13:39:36,451 DEBUG TRAIN Batch 54/300 loss 0.131343 acc 0.909004 lr 0.00021922 grad_norm 0.524009 rank 2
2025-01-10 13:39:36,452 DEBUG TRAIN Batch 54/300 loss 0.126339 acc 0.917987 lr 0.00021922 grad_norm 0.524009 rank 0
2025-01-10 13:40:00,046 DEBUG TRAIN Batch 54/400 loss 0.103361 acc 0.927673 lr 0.00021911 grad_norm 0.533323 rank 2
2025-01-10 13:40:00,046 DEBUG TRAIN Batch 54/400 loss 0.104185 acc 0.938776 lr 0.00021911 grad_norm 0.533323 rank 1
2025-01-10 13:40:00,046 DEBUG TRAIN Batch 54/400 loss 0.135634 acc 0.914807 lr 0.00021911 grad_norm 0.533323 rank 0
2025-01-10 13:40:23,994 DEBUG TRAIN Batch 54/500 loss 0.126614 acc 0.909565 lr 0.00021901 grad_norm 0.518900 rank 2
2025-01-10 13:40:23,995 DEBUG TRAIN Batch 54/500 loss 0.099660 acc 0.933206 lr 0.00021901 grad_norm 0.518900 rank 0
2025-01-10 13:40:23,995 DEBUG TRAIN Batch 54/500 loss 0.114596 acc 0.924348 lr 0.00021901 grad_norm 0.518900 rank 1
2025-01-10 13:40:47,723 DEBUG TRAIN Batch 54/600 loss 0.131884 acc 0.903139 lr 0.00021890 grad_norm 0.548450 rank 1
2025-01-10 13:40:47,723 DEBUG TRAIN Batch 54/600 loss 0.130037 acc 0.909091 lr 0.00021890 grad_norm 0.548450 rank 2
2025-01-10 13:40:47,724 DEBUG TRAIN Batch 54/600 loss 0.109617 acc 0.922797 lr 0.00021890 grad_norm 0.548450 rank 0
2025-01-10 13:41:12,134 DEBUG TRAIN Batch 54/700 loss 0.141298 acc 0.904470 lr 0.00021880 grad_norm 0.541435 rank 1
2025-01-10 13:41:12,134 DEBUG TRAIN Batch 54/700 loss 0.099199 acc 0.935354 lr 0.00021880 grad_norm 0.541435 rank 0
2025-01-10 13:41:12,134 DEBUG TRAIN Batch 54/700 loss 0.120421 acc 0.914835 lr 0.00021880 grad_norm 0.541435 rank 2
2025-01-10 13:41:36,390 DEBUG TRAIN Batch 54/800 loss 0.134496 acc 0.917457 lr 0.00021869 grad_norm 0.562643 rank 1
2025-01-10 13:41:36,390 DEBUG TRAIN Batch 54/800 loss 0.099866 acc 0.929376 lr 0.00021869 grad_norm 0.562643 rank 2
2025-01-10 13:41:36,390 DEBUG TRAIN Batch 54/800 loss 0.124216 acc 0.920419 lr 0.00021869 grad_norm 0.562643 rank 0
2025-01-10 13:42:00,284 DEBUG TRAIN Batch 54/900 loss 0.128564 acc 0.909360 lr 0.00021859 grad_norm 0.561636 rank 0
2025-01-10 13:42:00,285 DEBUG TRAIN Batch 54/900 loss 0.128146 acc 0.910160 lr 0.00021859 grad_norm 0.561636 rank 1
2025-01-10 13:42:00,285 DEBUG TRAIN Batch 54/900 loss 0.078597 acc 0.950000 lr 0.00021859 grad_norm 0.561636 rank 2
2025-01-10 13:42:24,247 DEBUG TRAIN Batch 54/1000 loss 0.100146 acc 0.928736 lr 0.00021848 grad_norm 0.539495 rank 1
2025-01-10 13:42:24,247 DEBUG TRAIN Batch 54/1000 loss 0.079402 acc 0.944385 lr 0.00021848 grad_norm 0.539495 rank 2
2025-01-10 13:42:24,248 DEBUG TRAIN Batch 54/1000 loss 0.109193 acc 0.922931 lr 0.00021848 grad_norm 0.539495 rank 0
2025-01-10 13:42:48,690 DEBUG TRAIN Batch 54/1100 loss 0.127374 acc 0.920607 lr 0.00021838 grad_norm 0.539616 rank 2
2025-01-10 13:42:48,690 DEBUG TRAIN Batch 54/1100 loss 0.086606 acc 0.937773 lr 0.00021838 grad_norm 0.539616 rank 0
2025-01-10 13:42:48,690 DEBUG TRAIN Batch 54/1100 loss 0.073338 acc 0.955272 lr 0.00021838 grad_norm 0.539616 rank 1
2025-01-10 13:43:13,658 DEBUG TRAIN Batch 54/1200 loss 0.085436 acc 0.936842 lr 0.00021828 grad_norm 0.530792 rank 0
2025-01-10 13:43:13,658 DEBUG TRAIN Batch 54/1200 loss 0.108634 acc 0.927688 lr 0.00021828 grad_norm 0.530792 rank 2
2025-01-10 13:43:13,659 DEBUG TRAIN Batch 54/1200 loss 0.082763 acc 0.938071 lr 0.00021828 grad_norm 0.530792 rank 1
2025-01-10 13:43:38,661 DEBUG TRAIN Batch 54/1300 loss 0.088541 acc 0.930528 lr 0.00021817 grad_norm 0.572954 rank 2
2025-01-10 13:43:38,662 DEBUG TRAIN Batch 54/1300 loss 0.111589 acc 0.923529 lr 0.00021817 grad_norm 0.572954 rank 1
2025-01-10 13:43:38,662 DEBUG TRAIN Batch 54/1300 loss 0.097428 acc 0.924020 lr 0.00021817 grad_norm 0.572954 rank 0
2025-01-10 13:44:03,540 DEBUG TRAIN Batch 54/1400 loss 0.118518 acc 0.923611 lr 0.00021807 grad_norm 0.570949 rank 2
2025-01-10 13:44:03,540 DEBUG TRAIN Batch 54/1400 loss 0.129623 acc 0.908759 lr 0.00021807 grad_norm 0.570949 rank 1
2025-01-10 13:44:03,541 DEBUG TRAIN Batch 54/1400 loss 0.103464 acc 0.923913 lr 0.00021807 grad_norm 0.570949 rank 0
2025-01-10 13:44:28,219 DEBUG TRAIN Batch 54/1500 loss 0.086434 acc 0.938095 lr 0.00021796 grad_norm 0.560443 rank 1
2025-01-10 13:44:28,219 DEBUG TRAIN Batch 54/1500 loss 0.103218 acc 0.915612 lr 0.00021796 grad_norm 0.560443 rank 2
2025-01-10 13:44:28,226 DEBUG TRAIN Batch 54/1500 loss 0.084421 acc 0.945187 lr 0.00021796 grad_norm 0.560443 rank 0
2025-01-10 13:44:52,987 DEBUG TRAIN Batch 54/1600 loss 0.084443 acc 0.944915 lr 0.00021786 grad_norm 0.563662 rank 1
2025-01-10 13:44:52,987 DEBUG TRAIN Batch 54/1600 loss 0.108736 acc 0.918264 lr 0.00021786 grad_norm 0.563662 rank 0
2025-01-10 13:44:52,987 DEBUG TRAIN Batch 54/1600 loss 0.123838 acc 0.913082 lr 0.00021786 grad_norm 0.563662 rank 2
2025-01-10 13:45:17,824 DEBUG TRAIN Batch 54/1700 loss 0.093481 acc 0.943646 lr 0.00021776 grad_norm 0.577152 rank 1
2025-01-10 13:45:17,825 DEBUG TRAIN Batch 54/1700 loss 0.159316 acc 0.894128 lr 0.00021776 grad_norm 0.577152 rank 2
2025-01-10 13:45:17,825 DEBUG TRAIN Batch 54/1700 loss 0.111139 acc 0.920746 lr 0.00021776 grad_norm 0.577152 rank 0
2025-01-10 13:45:42,756 DEBUG TRAIN Batch 54/1800 loss 0.091028 acc 0.937441 lr 0.00021765 grad_norm 0.552065 rank 0
2025-01-10 13:45:42,756 DEBUG TRAIN Batch 54/1800 loss 0.102277 acc 0.927320 lr 0.00021765 grad_norm 0.552065 rank 2
2025-01-10 13:45:42,756 DEBUG TRAIN Batch 54/1800 loss 0.129231 acc 0.918656 lr 0.00021765 grad_norm 0.552065 rank 1
2025-01-10 13:46:07,193 DEBUG TRAIN Batch 54/1900 loss 0.142090 acc 0.894265 lr 0.00021755 grad_norm 0.588247 rank 2
2025-01-10 13:46:07,194 DEBUG TRAIN Batch 54/1900 loss 0.113359 acc 0.921371 lr 0.00021755 grad_norm 0.588247 rank 1
2025-01-10 13:46:07,194 DEBUG TRAIN Batch 54/1900 loss 0.078457 acc 0.942647 lr 0.00021755 grad_norm 0.588247 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 13:47:13,148 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 13:47:13,150 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 13:47:13,573 INFO Epoch 54 Step 52834 on_batch_end True CV rank 1
2025-01-10 13:47:13,574 INFO Epoch 54 Step 52834 on_batch_end True CV rank 0
2025-01-10 13:47:13,574 INFO Epoch 54 Step 52834 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 13:47:22,895 DEBUG CV Batch 54/100 loss 0.035000 acc 0.989967  rank 0
2025-01-10 13:47:22,920 DEBUG CV Batch 54/100 loss 0.035000 acc 0.989967  rank 2
2025-01-10 13:47:23,247 DEBUG CV Batch 54/100 loss 0.035000 acc 0.989967  rank 1
2025-01-10 13:47:23,413 INFO Epoch 54 Step 52834 CV info lr 0.00021752704409943674 0 rank loss_1.963418168081134 acc_0.7762543467576044
2025-01-10 13:47:23,457 INFO Epoch 54 Step 52834 CV info lr 0.00021752704409943674 2 rank loss_1.963418168081134 acc_0.7762543467576044
2025-01-10 13:47:23,802 INFO Epoch 54 Step 52834 CV info lr 0.00021752704409943674 1 rank loss_1.963418168081134 acc_0.7762543467576044
2025-01-10 13:47:24,697 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_54_whole.pt
2025-01-10 13:47:24,709 INFO Added key: store_based_barrier_key:57 to store for rank: 0
2025-01-10 13:47:24,719 INFO Added key: store_based_barrier_key:57 to store for rank: 1
2025-01-10 13:47:24,719 INFO Added key: store_based_barrier_key:57 to store for rank: 2
2025-01-10 13:47:24,719 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:57 with 3 nodes.
2025-01-10 13:47:24,719 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:57 with 3 nodes.
2025-01-10 13:47:24,727 INFO Epoch 55 TRAIN info lr 0.00021752704409943674 rank 1
2025-01-10 13:47:24,728 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 13:47:24,729 INFO Epoch 55 TRAIN info lr 0.00021752704409943674 rank 2
2025-01-10 13:47:24,729 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 13:47:24,729 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:57 with 3 nodes.
2025-01-10 13:47:24,736 INFO Epoch 55 TRAIN info lr 0.00021752704409943674 rank 0
2025-01-10 13:47:24,736 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 13:47:55,650 DEBUG TRAIN Batch 55/100 loss 0.103215 acc 0.923225 lr 0.00021742 grad_norm 0.535586 rank 2
2025-01-10 13:47:55,650 DEBUG TRAIN Batch 55/100 loss 0.100670 acc 0.923400 lr 0.00021742 grad_norm 0.535586 rank 0
2025-01-10 13:47:55,651 DEBUG TRAIN Batch 55/100 loss 0.119846 acc 0.906475 lr 0.00021742 grad_norm 0.535586 rank 1
2025-01-10 13:48:19,409 DEBUG TRAIN Batch 55/200 loss 0.115315 acc 0.910900 lr 0.00021732 grad_norm 0.528423 rank 1
2025-01-10 13:48:19,409 DEBUG TRAIN Batch 55/200 loss 0.096990 acc 0.925926 lr 0.00021732 grad_norm 0.528423 rank 0
2025-01-10 13:48:19,410 DEBUG TRAIN Batch 55/200 loss 0.124255 acc 0.922043 lr 0.00021732 grad_norm 0.528423 rank 2
2025-01-10 13:48:43,162 DEBUG TRAIN Batch 55/300 loss 0.110061 acc 0.926805 lr 0.00021722 grad_norm 0.546682 rank 1
2025-01-10 13:48:43,163 DEBUG TRAIN Batch 55/300 loss 0.133856 acc 0.919227 lr 0.00021722 grad_norm 0.546682 rank 2
2025-01-10 13:48:43,163 DEBUG TRAIN Batch 55/300 loss 0.121406 acc 0.914622 lr 0.00021722 grad_norm 0.546682 rank 0
2025-01-10 13:49:06,816 DEBUG TRAIN Batch 55/400 loss 0.115290 acc 0.913871 lr 0.00021712 grad_norm 0.523249 rank 2
2025-01-10 13:49:06,816 DEBUG TRAIN Batch 55/400 loss 0.089292 acc 0.943262 lr 0.00021712 grad_norm 0.523249 rank 1
2025-01-10 13:49:06,816 DEBUG TRAIN Batch 55/400 loss 0.085814 acc 0.940877 lr 0.00021712 grad_norm 0.523249 rank 0
2025-01-10 13:49:31,094 DEBUG TRAIN Batch 55/500 loss 0.093509 acc 0.933265 lr 0.00021701 grad_norm 0.543413 rank 0
2025-01-10 13:49:31,094 DEBUG TRAIN Batch 55/500 loss 0.087299 acc 0.934325 lr 0.00021701 grad_norm 0.543413 rank 1
2025-01-10 13:49:31,095 DEBUG TRAIN Batch 55/500 loss 0.082404 acc 0.938776 lr 0.00021701 grad_norm 0.543413 rank 2
2025-01-10 13:49:54,928 DEBUG TRAIN Batch 55/600 loss 0.114121 acc 0.928702 lr 0.00021691 grad_norm 0.502596 rank 1
2025-01-10 13:49:54,928 DEBUG TRAIN Batch 55/600 loss 0.106881 acc 0.927593 lr 0.00021691 grad_norm 0.502596 rank 2
2025-01-10 13:49:54,928 DEBUG TRAIN Batch 55/600 loss 0.078046 acc 0.947964 lr 0.00021691 grad_norm 0.502596 rank 0
2025-01-10 13:50:19,034 DEBUG TRAIN Batch 55/700 loss 0.127633 acc 0.902550 lr 0.00021681 grad_norm 0.543081 rank 2
2025-01-10 13:50:19,035 DEBUG TRAIN Batch 55/700 loss 0.098801 acc 0.935897 lr 0.00021681 grad_norm 0.543081 rank 1
2025-01-10 13:50:19,035 DEBUG TRAIN Batch 55/700 loss 0.118767 acc 0.919282 lr 0.00021681 grad_norm 0.543081 rank 0
2025-01-10 13:50:43,586 DEBUG TRAIN Batch 55/800 loss 0.132408 acc 0.896392 lr 0.00021671 grad_norm 0.565698 rank 0
2025-01-10 13:50:43,587 DEBUG TRAIN Batch 55/800 loss 0.077648 acc 0.947826 lr 0.00021671 grad_norm 0.565698 rank 1
2025-01-10 13:50:43,587 DEBUG TRAIN Batch 55/800 loss 0.091342 acc 0.932324 lr 0.00021671 grad_norm 0.565698 rank 2
2025-01-10 13:51:07,826 DEBUG TRAIN Batch 55/900 loss 0.095907 acc 0.936491 lr 0.00021661 grad_norm 0.511349 rank 2
2025-01-10 13:51:07,826 DEBUG TRAIN Batch 55/900 loss 0.089339 acc 0.945802 lr 0.00021661 grad_norm 0.511349 rank 0
2025-01-10 13:51:07,826 DEBUG TRAIN Batch 55/900 loss 0.081861 acc 0.937620 lr 0.00021661 grad_norm 0.511349 rank 1
2025-01-10 13:51:31,956 DEBUG TRAIN Batch 55/1000 loss 0.098908 acc 0.933393 lr 0.00021650 grad_norm 0.542410 rank 1
2025-01-10 13:51:31,956 DEBUG TRAIN Batch 55/1000 loss 0.102948 acc 0.926036 lr 0.00021650 grad_norm 0.542410 rank 0
2025-01-10 13:51:31,957 DEBUG TRAIN Batch 55/1000 loss 0.081503 acc 0.942723 lr 0.00021650 grad_norm 0.542410 rank 2
2025-01-10 13:51:55,717 DEBUG TRAIN Batch 55/1100 loss 0.115976 acc 0.913858 lr 0.00021640 grad_norm 0.545796 rank 0
2025-01-10 13:51:55,717 DEBUG TRAIN Batch 55/1100 loss 0.092145 acc 0.936634 lr 0.00021640 grad_norm 0.545796 rank 1
2025-01-10 13:51:55,717 DEBUG TRAIN Batch 55/1100 loss 0.101704 acc 0.926195 lr 0.00021640 grad_norm 0.545796 rank 2
2025-01-10 13:52:20,111 DEBUG TRAIN Batch 55/1200 loss 0.133931 acc 0.909170 lr 0.00021630 grad_norm 0.569671 rank 0
2025-01-10 13:52:20,111 DEBUG TRAIN Batch 55/1200 loss 0.121902 acc 0.910476 lr 0.00021630 grad_norm 0.569671 rank 1
2025-01-10 13:52:20,111 DEBUG TRAIN Batch 55/1200 loss 0.088754 acc 0.927273 lr 0.00021630 grad_norm 0.569671 rank 2
2025-01-10 13:52:44,873 DEBUG TRAIN Batch 55/1300 loss 0.113343 acc 0.913171 lr 0.00021620 grad_norm 0.558074 rank 1
2025-01-10 13:52:44,873 DEBUG TRAIN Batch 55/1300 loss 0.121903 acc 0.922547 lr 0.00021620 grad_norm 0.558074 rank 2
2025-01-10 13:52:44,873 DEBUG TRAIN Batch 55/1300 loss 0.123840 acc 0.917577 lr 0.00021620 grad_norm 0.558074 rank 0
2025-01-10 13:53:09,634 DEBUG TRAIN Batch 55/1400 loss 0.129867 acc 0.913126 lr 0.00021610 grad_norm 0.567493 rank 1
2025-01-10 13:53:09,634 DEBUG TRAIN Batch 55/1400 loss 0.100451 acc 0.936871 lr 0.00021610 grad_norm 0.567493 rank 2
2025-01-10 13:53:09,651 DEBUG TRAIN Batch 55/1400 loss 0.103529 acc 0.933333 lr 0.00021610 grad_norm 0.567493 rank 0
2025-01-10 13:53:34,593 DEBUG TRAIN Batch 55/1500 loss 0.070242 acc 0.952218 lr 0.00021600 grad_norm 0.556201 rank 1
2025-01-10 13:53:34,593 DEBUG TRAIN Batch 55/1500 loss 0.115887 acc 0.928215 lr 0.00021600 grad_norm 0.556201 rank 2
2025-01-10 13:53:34,594 DEBUG TRAIN Batch 55/1500 loss 0.063884 acc 0.962712 lr 0.00021600 grad_norm 0.556201 rank 0
2025-01-10 13:53:59,134 DEBUG TRAIN Batch 55/1600 loss 0.092184 acc 0.936285 lr 0.00021590 grad_norm 0.563165 rank 2
2025-01-10 13:53:59,134 DEBUG TRAIN Batch 55/1600 loss 0.117919 acc 0.915631 lr 0.00021590 grad_norm 0.563165 rank 0
2025-01-10 13:53:59,135 DEBUG TRAIN Batch 55/1600 loss 0.127415 acc 0.918777 lr 0.00021590 grad_norm 0.563165 rank 1
2025-01-10 13:54:23,142 DEBUG TRAIN Batch 55/1700 loss 0.105456 acc 0.924528 lr 0.00021580 grad_norm 0.545118 rank 1
2025-01-10 13:54:23,142 DEBUG TRAIN Batch 55/1700 loss 0.106973 acc 0.927405 lr 0.00021580 grad_norm 0.545118 rank 2
2025-01-10 13:54:23,142 DEBUG TRAIN Batch 55/1700 loss 0.132573 acc 0.907958 lr 0.00021580 grad_norm 0.545118 rank 0
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 13:55:35,335 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 13:55:35,337 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 13:55:35,756 INFO Epoch 55 Step 53709 on_batch_end True CV rank 2
2025-01-10 13:55:35,756 INFO Epoch 55 Step 53709 on_batch_end True CV rank 0
2025-01-10 13:55:35,756 INFO Epoch 55 Step 53709 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 13:55:44,886 DEBUG CV Batch 55/100 loss 0.043160 acc 0.987737  rank 0
2025-01-10 13:55:45,155 DEBUG CV Batch 55/100 loss 0.043160 acc 0.987737  rank 2
2025-01-10 13:55:45,420 INFO Epoch 55 Step 53709 CV info lr 0.00021574784732995885 0 rank loss_2.001807577483225 acc_0.7773677457058639
2025-01-10 13:55:45,499 DEBUG CV Batch 55/100 loss 0.043160 acc 0.987737  rank 1
2025-01-10 13:55:45,710 INFO Epoch 55 Step 53709 CV info lr 0.00021574784732995885 2 rank loss_2.001807577483225 acc_0.7773677457058639
2025-01-10 13:55:46,047 INFO Epoch 55 Step 53709 CV info lr 0.00021574784732995885 1 rank loss_2.001807577483225 acc_0.7773677457058639
2025-01-10 13:55:46,724 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_55_whole.pt
2025-01-10 13:55:46,736 INFO Added key: store_based_barrier_key:58 to store for rank: 0
2025-01-10 13:55:46,746 INFO Added key: store_based_barrier_key:58 to store for rank: 2
2025-01-10 13:55:46,746 INFO Added key: store_based_barrier_key:58 to store for rank: 1
2025-01-10 13:55:46,746 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:58 with 3 nodes.
2025-01-10 13:55:46,746 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:58 with 3 nodes.
2025-01-10 13:55:46,752 INFO Epoch 56 TRAIN info lr 0.00021574784732995885 rank 1
2025-01-10 13:55:46,752 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 13:55:46,752 INFO Epoch 56 TRAIN info lr 0.00021574784732995885 rank 2
2025-01-10 13:55:46,752 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 13:55:46,756 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:58 with 3 nodes.
2025-01-10 13:55:46,760 INFO Epoch 56 TRAIN info lr 0.00021574784732995885 rank 0
2025-01-10 13:55:46,760 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 13:56:18,466 DEBUG TRAIN Batch 56/100 loss 0.065483 acc 0.949843 lr 0.00021565 grad_norm 0.517063 rank 1
2025-01-10 13:56:18,466 DEBUG TRAIN Batch 56/100 loss 0.102074 acc 0.933809 lr 0.00021565 grad_norm 0.517063 rank 2
2025-01-10 13:56:18,466 DEBUG TRAIN Batch 56/100 loss 0.100601 acc 0.936214 lr 0.00021565 grad_norm 0.517063 rank 0
2025-01-10 13:56:42,567 DEBUG TRAIN Batch 56/200 loss 0.080420 acc 0.956778 lr 0.00021555 grad_norm 0.542931 rank 1
2025-01-10 13:56:42,567 DEBUG TRAIN Batch 56/200 loss 0.074675 acc 0.944834 lr 0.00021555 grad_norm 0.542931 rank 2
2025-01-10 13:56:42,567 DEBUG TRAIN Batch 56/200 loss 0.093175 acc 0.933998 lr 0.00021555 grad_norm 0.542931 rank 0
2025-01-10 13:57:07,508 DEBUG TRAIN Batch 56/300 loss 0.076713 acc 0.941480 lr 0.00021545 grad_norm 0.511999 rank 1
2025-01-10 13:57:07,509 DEBUG TRAIN Batch 56/300 loss 0.102992 acc 0.931452 lr 0.00021545 grad_norm 0.511999 rank 0
2025-01-10 13:57:07,509 DEBUG TRAIN Batch 56/300 loss 0.081520 acc 0.942403 lr 0.00021545 grad_norm 0.511999 rank 2
2025-01-10 13:57:31,410 DEBUG TRAIN Batch 56/400 loss 0.080327 acc 0.943377 lr 0.00021535 grad_norm 0.513788 rank 2
2025-01-10 13:57:31,411 DEBUG TRAIN Batch 56/400 loss 0.117455 acc 0.921533 lr 0.00021535 grad_norm 0.513788 rank 1
2025-01-10 13:57:31,411 DEBUG TRAIN Batch 56/400 loss 0.093754 acc 0.931373 lr 0.00021535 grad_norm 0.513788 rank 0
2025-01-10 13:57:55,671 DEBUG TRAIN Batch 56/500 loss 0.088316 acc 0.937669 lr 0.00021525 grad_norm 0.510217 rank 0
2025-01-10 13:57:55,671 DEBUG TRAIN Batch 56/500 loss 0.083900 acc 0.947743 lr 0.00021525 grad_norm 0.510217 rank 1
2025-01-10 13:57:55,671 DEBUG TRAIN Batch 56/500 loss 0.112376 acc 0.922397 lr 0.00021525 grad_norm 0.510217 rank 2
2025-01-10 13:58:20,102 DEBUG TRAIN Batch 56/600 loss 0.101650 acc 0.929954 lr 0.00021515 grad_norm 0.503218 rank 2
2025-01-10 13:58:20,102 DEBUG TRAIN Batch 56/600 loss 0.090481 acc 0.940865 lr 0.00021515 grad_norm 0.503218 rank 1
2025-01-10 13:58:20,102 DEBUG TRAIN Batch 56/600 loss 0.083853 acc 0.938697 lr 0.00021515 grad_norm 0.503218 rank 0
2025-01-10 13:58:44,028 DEBUG TRAIN Batch 56/700 loss 0.102119 acc 0.931477 lr 0.00021505 grad_norm 0.533255 rank 1
2025-01-10 13:58:44,028 DEBUG TRAIN Batch 56/700 loss 0.112401 acc 0.914522 lr 0.00021505 grad_norm 0.533255 rank 0
2025-01-10 13:58:44,028 DEBUG TRAIN Batch 56/700 loss 0.081256 acc 0.936989 lr 0.00021505 grad_norm 0.533255 rank 2
2025-01-10 13:59:08,428 DEBUG TRAIN Batch 56/800 loss 0.095554 acc 0.928988 lr 0.00021495 grad_norm 0.540537 rank 1
2025-01-10 13:59:08,428 DEBUG TRAIN Batch 56/800 loss 0.122471 acc 0.906278 lr 0.00021495 grad_norm 0.540537 rank 2
2025-01-10 13:59:08,429 DEBUG TRAIN Batch 56/800 loss 0.090365 acc 0.938197 lr 0.00021495 grad_norm 0.540537 rank 0
2025-01-10 13:59:32,646 DEBUG TRAIN Batch 56/900 loss 0.120721 acc 0.908384 lr 0.00021485 grad_norm 0.517709 rank 1
2025-01-10 13:59:32,646 DEBUG TRAIN Batch 56/900 loss 0.108251 acc 0.931532 lr 0.00021485 grad_norm 0.517709 rank 0
2025-01-10 13:59:32,646 DEBUG TRAIN Batch 56/900 loss 0.107465 acc 0.922852 lr 0.00021485 grad_norm 0.517709 rank 2
2025-01-10 13:59:57,115 DEBUG TRAIN Batch 56/1000 loss 0.147306 acc 0.901280 lr 0.00021475 grad_norm 0.547428 rank 2
2025-01-10 13:59:57,115 DEBUG TRAIN Batch 56/1000 loss 0.094112 acc 0.933121 lr 0.00021475 grad_norm 0.547428 rank 0
2025-01-10 13:59:57,116 DEBUG TRAIN Batch 56/1000 loss 0.144707 acc 0.902309 lr 0.00021475 grad_norm 0.547428 rank 1
2025-01-10 14:00:21,644 DEBUG TRAIN Batch 56/1100 loss 0.132110 acc 0.911429 lr 0.00021465 grad_norm 0.555201 rank 2
2025-01-10 14:00:21,644 DEBUG TRAIN Batch 56/1100 loss 0.102987 acc 0.933619 lr 0.00021465 grad_norm 0.555201 rank 0
2025-01-10 14:00:21,644 DEBUG TRAIN Batch 56/1100 loss 0.100991 acc 0.933196 lr 0.00021465 grad_norm 0.555201 rank 1
2025-01-10 14:00:46,305 DEBUG TRAIN Batch 56/1200 loss 0.114217 acc 0.912889 lr 0.00021455 grad_norm 0.578523 rank 0
2025-01-10 14:00:46,305 DEBUG TRAIN Batch 56/1200 loss 0.105706 acc 0.923547 lr 0.00021455 grad_norm 0.578523 rank 1
2025-01-10 14:00:46,305 DEBUG TRAIN Batch 56/1200 loss 0.127548 acc 0.916667 lr 0.00021455 grad_norm 0.578523 rank 2
2025-01-10 14:01:10,440 DEBUG TRAIN Batch 56/1300 loss 0.126938 acc 0.914763 lr 0.00021445 grad_norm 0.569427 rank 0
2025-01-10 14:01:10,440 DEBUG TRAIN Batch 56/1300 loss 0.077133 acc 0.948905 lr 0.00021445 grad_norm 0.569427 rank 1
2025-01-10 14:01:10,440 DEBUG TRAIN Batch 56/1300 loss 0.123620 acc 0.922009 lr 0.00021445 grad_norm 0.569427 rank 2
2025-01-10 14:01:34,659 DEBUG TRAIN Batch 56/1400 loss 0.119856 acc 0.915385 lr 0.00021436 grad_norm 0.631601 rank 1
2025-01-10 14:01:34,659 DEBUG TRAIN Batch 56/1400 loss 0.105142 acc 0.926736 lr 0.00021436 grad_norm 0.631601 rank 0
2025-01-10 14:01:34,659 DEBUG TRAIN Batch 56/1400 loss 0.101633 acc 0.929124 lr 0.00021436 grad_norm 0.631601 rank 2
2025-01-10 14:01:58,966 DEBUG TRAIN Batch 56/1500 loss 0.068426 acc 0.949861 lr 0.00021426 grad_norm 0.574052 rank 1
2025-01-10 14:01:58,966 DEBUG TRAIN Batch 56/1500 loss 0.144476 acc 0.900483 lr 0.00021426 grad_norm 0.574052 rank 2
2025-01-10 14:01:58,966 DEBUG TRAIN Batch 56/1500 loss 0.097430 acc 0.942752 lr 0.00021426 grad_norm 0.574052 rank 0
2025-01-10 14:02:22,857 DEBUG TRAIN Batch 56/1600 loss 0.077155 acc 0.943376 lr 0.00021416 grad_norm 0.556808 rank 1
2025-01-10 14:02:22,857 DEBUG TRAIN Batch 56/1600 loss 0.096199 acc 0.933839 lr 0.00021416 grad_norm 0.556808 rank 2
2025-01-10 14:02:22,857 DEBUG TRAIN Batch 56/1600 loss 0.120110 acc 0.915066 lr 0.00021416 grad_norm 0.556808 rank 0
2025-01-10 14:02:46,864 DEBUG TRAIN Batch 56/1700 loss 0.122579 acc 0.915974 lr 0.00021406 grad_norm 0.549767 rank 0
2025-01-10 14:02:46,865 DEBUG TRAIN Batch 56/1700 loss 0.079179 acc 0.935252 lr 0.00021406 grad_norm 0.549767 rank 1
2025-01-10 14:02:46,865 DEBUG TRAIN Batch 56/1700 loss 0.111517 acc 0.920039 lr 0.00021406 grad_norm 0.549767 rank 2
2025-01-10 14:03:10,906 DEBUG TRAIN Batch 56/1800 loss 0.095801 acc 0.929469 lr 0.00021396 grad_norm 0.564578 rank 1
2025-01-10 14:03:10,906 DEBUG TRAIN Batch 56/1800 loss 0.126265 acc 0.912727 lr 0.00021396 grad_norm 0.564578 rank 2
2025-01-10 14:03:10,906 DEBUG TRAIN Batch 56/1800 loss 0.115160 acc 0.927495 lr 0.00021396 grad_norm 0.564578 rank 0
2025-01-10 14:03:35,585 DEBUG TRAIN Batch 56/1900 loss 0.123237 acc 0.914522 lr 0.00021386 grad_norm 0.576075 rank 1
2025-01-10 14:03:35,585 DEBUG TRAIN Batch 56/1900 loss 0.104445 acc 0.929451 lr 0.00021386 grad_norm 0.576075 rank 2
2025-01-10 14:03:35,586 DEBUG TRAIN Batch 56/1900 loss 0.101769 acc 0.932648 lr 0.00021386 grad_norm 0.576075 rank 0
2025-01-10 14:03:59,132 DEBUG TRAIN Batch 56/2000 loss 0.111175 acc 0.919922 lr 0.00021377 grad_norm 0.541972 rank 1
2025-01-10 14:03:59,132 DEBUG TRAIN Batch 56/2000 loss 0.121145 acc 0.916667 lr 0.00021377 grad_norm 0.541972 rank 0
2025-01-10 14:03:59,132 DEBUG TRAIN Batch 56/2000 loss 0.112213 acc 0.922145 lr 0.00021377 grad_norm 0.541972 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 14:05:05,273 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 14:05:05,275 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 14:05:05,700 INFO Epoch 56 Step 54722 on_batch_end True CV rank 2
2025-01-10 14:05:05,700 INFO Epoch 56 Step 54722 on_batch_end True CV rank 0
2025-01-10 14:05:05,700 INFO Epoch 56 Step 54722 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 14:05:14,752 DEBUG CV Batch 56/100 loss 0.034258 acc 0.986622  rank 0
2025-01-10 14:05:15,122 DEBUG CV Batch 56/100 loss 0.034258 acc 0.986622  rank 2
2025-01-10 14:05:15,248 INFO Epoch 56 Step 54722 CV info lr 0.0002137415839572334 0 rank loss_1.9948375776589833 acc_0.7768703395860237
2025-01-10 14:05:15,440 DEBUG CV Batch 56/100 loss 0.034258 acc 0.986622  rank 1
2025-01-10 14:05:15,671 INFO Epoch 56 Step 54722 CV info lr 0.0002137415839572334 2 rank loss_1.9948375776589833 acc_0.7768703395860237
2025-01-10 14:05:15,988 INFO Epoch 56 Step 54722 CV info lr 0.0002137415839572334 1 rank loss_1.9948375776589833 acc_0.7768703395860237
2025-01-10 14:05:16,535 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_56_whole.pt
2025-01-10 14:05:16,556 INFO Added key: store_based_barrier_key:59 to store for rank: 0
2025-01-10 14:05:16,567 INFO Added key: store_based_barrier_key:59 to store for rank: 2
2025-01-10 14:05:16,567 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:59 with 3 nodes.
2025-01-10 14:05:16,567 INFO Added key: store_based_barrier_key:59 to store for rank: 1
2025-01-10 14:05:16,567 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:59 with 3 nodes.
2025-01-10 14:05:16,569 INFO Epoch 57 TRAIN info lr 0.0002137415839572334 rank 2
2025-01-10 14:05:16,569 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 14:05:16,569 INFO Epoch 57 TRAIN info lr 0.0002137415839572334 rank 1
2025-01-10 14:05:16,569 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 14:05:16,577 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:59 with 3 nodes.
2025-01-10 14:05:16,579 INFO Epoch 57 TRAIN info lr 0.0002137415839572334 rank 0
2025-01-10 14:05:16,579 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 14:05:52,296 DEBUG TRAIN Batch 57/100 loss 0.108746 acc 0.921315 lr 0.00021364 grad_norm 0.505104 rank 1
2025-01-10 14:05:52,296 DEBUG TRAIN Batch 57/100 loss 0.079291 acc 0.945283 lr 0.00021364 grad_norm 0.505104 rank 2
2025-01-10 14:05:52,297 DEBUG TRAIN Batch 57/100 loss 0.053947 acc 0.959132 lr 0.00021364 grad_norm 0.505104 rank 0
2025-01-10 14:06:16,449 DEBUG TRAIN Batch 57/200 loss 0.114547 acc 0.913998 lr 0.00021355 grad_norm 0.512356 rank 1
2025-01-10 14:06:16,449 DEBUG TRAIN Batch 57/200 loss 0.095363 acc 0.935238 lr 0.00021355 grad_norm 0.512356 rank 2
2025-01-10 14:06:16,449 DEBUG TRAIN Batch 57/200 loss 0.096922 acc 0.931373 lr 0.00021355 grad_norm 0.512356 rank 0
2025-01-10 14:06:41,569 DEBUG TRAIN Batch 57/300 loss 0.050872 acc 0.960784 lr 0.00021345 grad_norm 0.506855 rank 0
2025-01-10 14:06:41,569 DEBUG TRAIN Batch 57/300 loss 0.083620 acc 0.951098 lr 0.00021345 grad_norm 0.506855 rank 1
2025-01-10 14:06:41,569 DEBUG TRAIN Batch 57/300 loss 0.110588 acc 0.930314 lr 0.00021345 grad_norm 0.506855 rank 2
2025-01-10 14:07:05,905 DEBUG TRAIN Batch 57/400 loss 0.106015 acc 0.924184 lr 0.00021335 grad_norm 0.550984 rank 1
2025-01-10 14:07:05,906 DEBUG TRAIN Batch 57/400 loss 0.074786 acc 0.945892 lr 0.00021335 grad_norm 0.550984 rank 2
2025-01-10 14:07:05,906 DEBUG TRAIN Batch 57/400 loss 0.086313 acc 0.933616 lr 0.00021335 grad_norm 0.550984 rank 0
2025-01-10 14:07:30,662 DEBUG TRAIN Batch 57/500 loss 0.104914 acc 0.931250 lr 0.00021326 grad_norm 0.530833 rank 2
2025-01-10 14:07:30,662 DEBUG TRAIN Batch 57/500 loss 0.128406 acc 0.911188 lr 0.00021326 grad_norm 0.530833 rank 0
2025-01-10 14:07:30,662 DEBUG TRAIN Batch 57/500 loss 0.092478 acc 0.929105 lr 0.00021326 grad_norm 0.530833 rank 1
2025-01-10 14:07:55,204 DEBUG TRAIN Batch 57/600 loss 0.070260 acc 0.946322 lr 0.00021316 grad_norm 0.492094 rank 0
2025-01-10 14:07:55,205 DEBUG TRAIN Batch 57/600 loss 0.082168 acc 0.950980 lr 0.00021316 grad_norm 0.492094 rank 2
2025-01-10 14:07:55,205 DEBUG TRAIN Batch 57/600 loss 0.100245 acc 0.931099 lr 0.00021316 grad_norm 0.492094 rank 1
2025-01-10 14:08:19,662 DEBUG TRAIN Batch 57/700 loss 0.101827 acc 0.927593 lr 0.00021306 grad_norm 0.529847 rank 1
2025-01-10 14:08:19,662 DEBUG TRAIN Batch 57/700 loss 0.113246 acc 0.922840 lr 0.00021306 grad_norm 0.529847 rank 0
2025-01-10 14:08:19,663 DEBUG TRAIN Batch 57/700 loss 0.092868 acc 0.939012 lr 0.00021306 grad_norm 0.529847 rank 2
2025-01-10 14:08:44,818 DEBUG TRAIN Batch 57/800 loss 0.129512 acc 0.911243 lr 0.00021296 grad_norm 0.579097 rank 1
2025-01-10 14:08:44,818 DEBUG TRAIN Batch 57/800 loss 0.093077 acc 0.928505 lr 0.00021296 grad_norm 0.579097 rank 2
2025-01-10 14:08:44,819 DEBUG TRAIN Batch 57/800 loss 0.064455 acc 0.951261 lr 0.00021296 grad_norm 0.579097 rank 0
2025-01-10 14:09:09,010 DEBUG TRAIN Batch 57/900 loss 0.103111 acc 0.924883 lr 0.00021287 grad_norm 0.538818 rank 2
2025-01-10 14:09:09,010 DEBUG TRAIN Batch 57/900 loss 0.114177 acc 0.916519 lr 0.00021287 grad_norm 0.538818 rank 1
2025-01-10 14:09:09,011 DEBUG TRAIN Batch 57/900 loss 0.082848 acc 0.940298 lr 0.00021287 grad_norm 0.538818 rank 0
2025-01-10 14:09:33,392 DEBUG TRAIN Batch 57/1000 loss 0.083558 acc 0.944223 lr 0.00021277 grad_norm 0.515629 rank 0
2025-01-10 14:09:33,392 DEBUG TRAIN Batch 57/1000 loss 0.095101 acc 0.940391 lr 0.00021277 grad_norm 0.515629 rank 1
2025-01-10 14:09:33,392 DEBUG TRAIN Batch 57/1000 loss 0.090630 acc 0.932735 lr 0.00021277 grad_norm 0.515629 rank 2
2025-01-10 14:09:59,395 DEBUG TRAIN Batch 57/1100 loss 0.111968 acc 0.927273 lr 0.00021268 grad_norm 0.533491 rank 2
2025-01-10 14:09:59,395 DEBUG TRAIN Batch 57/1100 loss 0.114767 acc 0.915638 lr 0.00021268 grad_norm 0.533491 rank 0
2025-01-10 14:09:59,395 DEBUG TRAIN Batch 57/1100 loss 0.089628 acc 0.939000 lr 0.00021268 grad_norm 0.533491 rank 1
2025-01-10 14:10:23,266 DEBUG TRAIN Batch 57/1200 loss 0.120585 acc 0.915780 lr 0.00021258 grad_norm 0.539251 rank 0
2025-01-10 14:10:23,266 DEBUG TRAIN Batch 57/1200 loss 0.103891 acc 0.927723 lr 0.00021258 grad_norm 0.539251 rank 1
2025-01-10 14:10:23,266 DEBUG TRAIN Batch 57/1200 loss 0.106060 acc 0.933468 lr 0.00021258 grad_norm 0.539251 rank 2
2025-01-10 14:10:47,405 DEBUG TRAIN Batch 57/1300 loss 0.099660 acc 0.934718 lr 0.00021248 grad_norm 0.547579 rank 2
2025-01-10 14:10:47,406 DEBUG TRAIN Batch 57/1300 loss 0.086580 acc 0.945916 lr 0.00021248 grad_norm 0.547579 rank 0
2025-01-10 14:10:47,406 DEBUG TRAIN Batch 57/1300 loss 0.092687 acc 0.934741 lr 0.00021248 grad_norm 0.547579 rank 1
2025-01-10 14:11:12,547 DEBUG TRAIN Batch 57/1400 loss 0.085033 acc 0.938126 lr 0.00021239 grad_norm 0.544919 rank 1
2025-01-10 14:11:12,548 DEBUG TRAIN Batch 57/1400 loss 0.093730 acc 0.938069 lr 0.00021239 grad_norm 0.544919 rank 0
2025-01-10 14:11:12,548 DEBUG TRAIN Batch 57/1400 loss 0.098538 acc 0.936384 lr 0.00021239 grad_norm 0.544919 rank 2
2025-01-10 14:11:37,406 DEBUG TRAIN Batch 57/1500 loss 0.118063 acc 0.907332 lr 0.00021229 grad_norm 0.529947 rank 1
2025-01-10 14:11:37,406 DEBUG TRAIN Batch 57/1500 loss 0.076076 acc 0.946507 lr 0.00021229 grad_norm 0.529947 rank 0
2025-01-10 14:11:37,407 DEBUG TRAIN Batch 57/1500 loss 0.094025 acc 0.937313 lr 0.00021229 grad_norm 0.529947 rank 2
2025-01-10 14:12:01,561 DEBUG TRAIN Batch 57/1600 loss 0.117524 acc 0.909804 lr 0.00021220 grad_norm 0.553231 rank 0
2025-01-10 14:12:01,561 DEBUG TRAIN Batch 57/1600 loss 0.093808 acc 0.925472 lr 0.00021220 grad_norm 0.553231 rank 1
2025-01-10 14:12:01,562 DEBUG TRAIN Batch 57/1600 loss 0.127545 acc 0.911608 lr 0.00021220 grad_norm 0.553231 rank 2
2025-01-10 14:12:26,133 DEBUG TRAIN Batch 57/1700 loss 0.097616 acc 0.936382 lr 0.00021210 grad_norm 0.544626 rank 1
2025-01-10 14:12:26,133 DEBUG TRAIN Batch 57/1700 loss 0.139874 acc 0.914360 lr 0.00021210 grad_norm 0.544626 rank 2
2025-01-10 14:12:26,134 DEBUG TRAIN Batch 57/1700 loss 0.125886 acc 0.913242 lr 0.00021210 grad_norm 0.544626 rank 0
2025-01-10 14:12:49,691 DEBUG TRAIN Batch 57/1800 loss 0.140075 acc 0.900850 lr 0.00021201 grad_norm 0.543897 rank 2
2025-01-10 14:12:49,691 DEBUG TRAIN Batch 57/1800 loss 0.140996 acc 0.901257 lr 0.00021201 grad_norm 0.543897 rank 1
2025-01-10 14:12:49,692 DEBUG TRAIN Batch 57/1800 loss 0.105116 acc 0.919231 lr 0.00021201 grad_norm 0.543897 rank 0
2025-01-10 14:13:13,288 DEBUG TRAIN Batch 57/1900 loss 0.113004 acc 0.917068 lr 0.00021191 grad_norm 0.562958 rank 1
2025-01-10 14:13:13,288 DEBUG TRAIN Batch 57/1900 loss 0.117750 acc 0.924449 lr 0.00021191 grad_norm 0.562958 rank 2
2025-01-10 14:13:13,288 DEBUG TRAIN Batch 57/1900 loss 0.123337 acc 0.918134 lr 0.00021191 grad_norm 0.562958 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 14:14:21,485 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 14:14:21,487 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 14:14:21,944 INFO Epoch 57 Step 55689 on_batch_end True CV rank 2
2025-01-10 14:14:21,944 INFO Epoch 57 Step 55689 on_batch_end True CV rank 0
2025-01-10 14:14:21,944 INFO Epoch 57 Step 55689 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 14:14:30,990 DEBUG CV Batch 57/100 loss 0.030105 acc 0.988852  rank 0
2025-01-10 14:14:31,373 DEBUG CV Batch 57/100 loss 0.030105 acc 0.988852  rank 2
2025-01-10 14:14:31,523 INFO Epoch 57 Step 55689 CV info lr 0.0002118777218351139 0 rank loss_2.0203607808104143 acc_0.7774267834529542
2025-01-10 14:14:31,914 INFO Epoch 57 Step 55689 CV info lr 0.0002118777218351139 2 rank loss_2.0203607808104143 acc_0.7774267834529542
2025-01-10 14:14:31,955 DEBUG CV Batch 57/100 loss 0.030105 acc 0.988852  rank 1
2025-01-10 14:14:32,511 INFO Epoch 57 Step 55689 CV info lr 0.0002118777218351139 1 rank loss_2.0203607808104143 acc_0.7774267834529542
2025-01-10 14:14:32,832 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_57_whole.pt
2025-01-10 14:14:32,853 INFO Added key: store_based_barrier_key:60 to store for rank: 0
2025-01-10 14:14:32,863 INFO Added key: store_based_barrier_key:60 to store for rank: 2
2025-01-10 14:14:32,863 INFO Added key: store_based_barrier_key:60 to store for rank: 1
2025-01-10 14:14:32,864 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:60 with 3 nodes.
2025-01-10 14:14:32,864 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:60 with 3 nodes.
2025-01-10 14:14:32,866 INFO Epoch 58 TRAIN info lr 0.0002118777218351139 rank 1
2025-01-10 14:14:32,866 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 14:14:32,873 INFO Epoch 58 TRAIN info lr 0.0002118777218351139 rank 2
2025-01-10 14:14:32,873 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 14:14:32,874 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:60 with 3 nodes.
2025-01-10 14:14:32,883 INFO Epoch 58 TRAIN info lr 0.0002118777218351139 rank 0
2025-01-10 14:14:32,883 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 14:15:09,744 DEBUG TRAIN Batch 58/100 loss 0.063964 acc 0.957801 lr 0.00021178 grad_norm 0.509932 rank 1
2025-01-10 14:15:09,745 DEBUG TRAIN Batch 58/100 loss 0.089034 acc 0.936392 lr 0.00021178 grad_norm 0.509932 rank 0
2025-01-10 14:15:09,745 DEBUG TRAIN Batch 58/100 loss 0.084402 acc 0.940913 lr 0.00021178 grad_norm 0.509932 rank 2
2025-01-10 14:15:34,058 DEBUG TRAIN Batch 58/200 loss 0.082506 acc 0.941463 lr 0.00021169 grad_norm 0.538176 rank 2
2025-01-10 14:15:34,059 DEBUG TRAIN Batch 58/200 loss 0.129113 acc 0.909253 lr 0.00021169 grad_norm 0.538176 rank 0
2025-01-10 14:15:34,059 DEBUG TRAIN Batch 58/200 loss 0.103689 acc 0.922156 lr 0.00021169 grad_norm 0.538176 rank 1
2025-01-10 14:15:59,215 DEBUG TRAIN Batch 58/300 loss 0.126209 acc 0.918367 lr 0.00021159 grad_norm 0.522184 rank 0
2025-01-10 14:15:59,216 DEBUG TRAIN Batch 58/300 loss 0.090101 acc 0.943978 lr 0.00021159 grad_norm 0.522184 rank 2
2025-01-10 14:15:59,216 DEBUG TRAIN Batch 58/300 loss 0.076841 acc 0.937908 lr 0.00021159 grad_norm 0.522184 rank 1
2025-01-10 14:16:23,432 DEBUG TRAIN Batch 58/400 loss 0.106055 acc 0.923617 lr 0.00021150 grad_norm 0.532255 rank 2
2025-01-10 14:16:23,432 DEBUG TRAIN Batch 58/400 loss 0.102800 acc 0.935417 lr 0.00021150 grad_norm 0.532255 rank 0
2025-01-10 14:16:23,433 DEBUG TRAIN Batch 58/400 loss 0.056963 acc 0.962963 lr 0.00021150 grad_norm 0.532255 rank 1
2025-01-10 14:16:48,505 DEBUG TRAIN Batch 58/500 loss 0.101918 acc 0.931519 lr 0.00021140 grad_norm 0.525507 rank 2
2025-01-10 14:16:48,505 DEBUG TRAIN Batch 58/500 loss 0.109637 acc 0.933140 lr 0.00021140 grad_norm 0.525507 rank 0
2025-01-10 14:16:48,505 DEBUG TRAIN Batch 58/500 loss 0.102164 acc 0.933107 lr 0.00021140 grad_norm 0.525507 rank 1
2025-01-10 14:17:13,517 DEBUG TRAIN Batch 58/600 loss 0.110693 acc 0.922043 lr 0.00021131 grad_norm 0.531627 rank 0
2025-01-10 14:17:13,517 DEBUG TRAIN Batch 58/600 loss 0.098228 acc 0.937628 lr 0.00021131 grad_norm 0.531627 rank 1
2025-01-10 14:17:13,518 DEBUG TRAIN Batch 58/600 loss 0.104374 acc 0.923903 lr 0.00021131 grad_norm 0.531627 rank 2
2025-01-10 14:17:38,326 DEBUG TRAIN Batch 58/700 loss 0.104848 acc 0.934570 lr 0.00021122 grad_norm 0.514795 rank 2
2025-01-10 14:17:38,326 DEBUG TRAIN Batch 58/700 loss 0.096596 acc 0.930029 lr 0.00021122 grad_norm 0.514795 rank 0
2025-01-10 14:17:38,327 DEBUG TRAIN Batch 58/700 loss 0.076778 acc 0.942827 lr 0.00021122 grad_norm 0.514795 rank 1
2025-01-10 14:18:03,559 DEBUG TRAIN Batch 58/800 loss 0.084294 acc 0.937938 lr 0.00021112 grad_norm 0.588715 rank 0
2025-01-10 14:18:03,559 DEBUG TRAIN Batch 58/800 loss 0.109329 acc 0.927487 lr 0.00021112 grad_norm 0.588715 rank 1
2025-01-10 14:18:03,559 DEBUG TRAIN Batch 58/800 loss 0.111706 acc 0.917965 lr 0.00021112 grad_norm 0.588715 rank 2
2025-01-10 14:18:27,650 DEBUG TRAIN Batch 58/900 loss 0.074364 acc 0.957704 lr 0.00021103 grad_norm 0.540811 rank 1
2025-01-10 14:18:27,651 DEBUG TRAIN Batch 58/900 loss 0.081319 acc 0.948276 lr 0.00021103 grad_norm 0.540811 rank 0
2025-01-10 14:18:27,651 DEBUG TRAIN Batch 58/900 loss 0.135321 acc 0.911978 lr 0.00021103 grad_norm 0.540811 rank 2
2025-01-10 14:18:51,979 DEBUG TRAIN Batch 58/1000 loss 0.102554 acc 0.930332 lr 0.00021093 grad_norm 0.574221 rank 0
2025-01-10 14:18:51,980 DEBUG TRAIN Batch 58/1000 loss 0.114453 acc 0.935245 lr 0.00021093 grad_norm 0.574221 rank 2
2025-01-10 14:18:51,980 DEBUG TRAIN Batch 58/1000 loss 0.132098 acc 0.913747 lr 0.00021093 grad_norm 0.574221 rank 1
2025-01-10 14:19:17,632 DEBUG TRAIN Batch 58/1100 loss 0.091900 acc 0.942937 lr 0.00021084 grad_norm 0.536974 rank 0
2025-01-10 14:19:17,632 DEBUG TRAIN Batch 58/1100 loss 0.102983 acc 0.929725 lr 0.00021084 grad_norm 0.536974 rank 2
2025-01-10 14:19:17,633 DEBUG TRAIN Batch 58/1100 loss 0.127700 acc 0.917404 lr 0.00021084 grad_norm 0.536974 rank 1
2025-01-10 14:19:41,545 DEBUG TRAIN Batch 58/1200 loss 0.112460 acc 0.920263 lr 0.00021075 grad_norm 0.525449 rank 0
2025-01-10 14:19:41,545 DEBUG TRAIN Batch 58/1200 loss 0.111533 acc 0.924512 lr 0.00021075 grad_norm 0.525449 rank 2
2025-01-10 14:19:41,546 DEBUG TRAIN Batch 58/1200 loss 0.099833 acc 0.930568 lr 0.00021075 grad_norm 0.525449 rank 1
2025-01-10 14:20:05,558 DEBUG TRAIN Batch 58/1300 loss 0.096862 acc 0.925850 lr 0.00021065 grad_norm 0.555821 rank 2
2025-01-10 14:20:05,558 DEBUG TRAIN Batch 58/1300 loss 0.101319 acc 0.932136 lr 0.00021065 grad_norm 0.555821 rank 0
2025-01-10 14:20:05,558 DEBUG TRAIN Batch 58/1300 loss 0.097046 acc 0.932331 lr 0.00021065 grad_norm 0.555821 rank 1
2025-01-10 14:20:30,348 DEBUG TRAIN Batch 58/1400 loss 0.106380 acc 0.920930 lr 0.00021056 grad_norm 0.520879 rank 2
2025-01-10 14:20:30,349 DEBUG TRAIN Batch 58/1400 loss 0.094415 acc 0.932532 lr 0.00021056 grad_norm 0.520879 rank 0
2025-01-10 14:20:30,349 DEBUG TRAIN Batch 58/1400 loss 0.113009 acc 0.929954 lr 0.00021056 grad_norm 0.520879 rank 1
2025-01-10 14:20:53,711 DEBUG TRAIN Batch 58/1500 loss 0.092196 acc 0.926855 lr 0.00021047 grad_norm 0.537350 rank 2
2025-01-10 14:20:53,711 DEBUG TRAIN Batch 58/1500 loss 0.083875 acc 0.945080 lr 0.00021047 grad_norm 0.537350 rank 0
2025-01-10 14:20:53,712 DEBUG TRAIN Batch 58/1500 loss 0.117941 acc 0.916981 lr 0.00021047 grad_norm 0.537350 rank 1
2025-01-10 14:21:18,265 DEBUG TRAIN Batch 58/1600 loss 0.089642 acc 0.935606 lr 0.00021037 grad_norm 0.503408 rank 0
2025-01-10 14:21:18,265 DEBUG TRAIN Batch 58/1600 loss 0.110364 acc 0.918459 lr 0.00021037 grad_norm 0.503408 rank 1
2025-01-10 14:21:18,265 DEBUG TRAIN Batch 58/1600 loss 0.117348 acc 0.917319 lr 0.00021037 grad_norm 0.503408 rank 2
2025-01-10 14:21:41,905 DEBUG TRAIN Batch 58/1700 loss 0.094301 acc 0.939394 lr 0.00021028 grad_norm 0.507879 rank 2
2025-01-10 14:21:41,906 DEBUG TRAIN Batch 58/1700 loss 0.083921 acc 0.947982 lr 0.00021028 grad_norm 0.507879 rank 0
2025-01-10 14:21:41,906 DEBUG TRAIN Batch 58/1700 loss 0.088967 acc 0.927461 lr 0.00021028 grad_norm 0.507879 rank 1
2025-01-10 14:22:05,892 DEBUG TRAIN Batch 58/1800 loss 0.119604 acc 0.916971 lr 0.00021019 grad_norm 0.568098 rank 0
2025-01-10 14:22:05,892 DEBUG TRAIN Batch 58/1800 loss 0.102168 acc 0.933462 lr 0.00021019 grad_norm 0.568098 rank 2
2025-01-10 14:22:05,892 DEBUG TRAIN Batch 58/1800 loss 0.098548 acc 0.937440 lr 0.00021019 grad_norm 0.568098 rank 1
2025-01-10 14:22:30,504 DEBUG TRAIN Batch 58/1900 loss 0.121812 acc 0.919070 lr 0.00021009 grad_norm 0.541354 rank 2
2025-01-10 14:22:30,504 DEBUG TRAIN Batch 58/1900 loss 0.084685 acc 0.938669 lr 0.00021009 grad_norm 0.541354 rank 0
2025-01-10 14:22:30,505 DEBUG TRAIN Batch 58/1900 loss 0.095853 acc 0.929501 lr 0.00021009 grad_norm 0.541354 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 14:23:30,999 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 14:23:31,000 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 14:23:31,500 INFO Epoch 58 Step 56640 on_batch_end True CV rank 2
2025-01-10 14:23:31,500 INFO Epoch 58 Step 56640 on_batch_end True CV rank 0
2025-01-10 14:23:31,501 INFO Epoch 58 Step 56640 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 14:23:41,010 DEBUG CV Batch 58/100 loss 0.025959 acc 0.991081  rank 2
2025-01-10 14:23:41,054 DEBUG CV Batch 58/100 loss 0.025959 acc 0.991081  rank 0
2025-01-10 14:23:41,514 INFO Epoch 58 Step 56640 CV info lr 0.00021009145170400447 2 rank loss_2.042227797596225 acc_0.7757855368810788
2025-01-10 14:23:41,536 DEBUG CV Batch 58/100 loss 0.025959 acc 0.991081  rank 1
2025-01-10 14:23:41,583 INFO Epoch 58 Step 56640 CV info lr 0.00021009145170400447 0 rank loss_2.042227797596225 acc_0.7757855368810788
2025-01-10 14:23:42,083 INFO Epoch 58 Step 56640 CV info lr 0.00021009145170400447 1 rank loss_2.042227797596225 acc_0.7757855368810788
2025-01-10 14:23:42,872 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_58_whole.pt
2025-01-10 14:23:42,894 INFO Added key: store_based_barrier_key:61 to store for rank: 0
2025-01-10 14:23:42,894 INFO Added key: store_based_barrier_key:61 to store for rank: 1
2025-01-10 14:23:42,895 INFO Added key: store_based_barrier_key:61 to store for rank: 2
2025-01-10 14:23:42,895 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:61 with 3 nodes.
2025-01-10 14:23:42,899 INFO Epoch 59 TRAIN info lr 0.00021009145170400447 rank 2
2025-01-10 14:23:42,900 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 14:23:42,905 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:61 with 3 nodes.
2025-01-10 14:23:42,905 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:61 with 3 nodes.
2025-01-10 14:23:42,909 INFO Epoch 59 TRAIN info lr 0.00021009145170400447 rank 0
2025-01-10 14:23:42,909 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 14:23:42,911 INFO Epoch 59 TRAIN info lr 0.00021009145170400447 rank 1
2025-01-10 14:23:42,911 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 14:24:19,994 DEBUG TRAIN Batch 59/100 loss 0.091217 acc 0.935118 lr 0.00021000 grad_norm 0.499045 rank 0
2025-01-10 14:24:19,994 DEBUG TRAIN Batch 59/100 loss 0.075733 acc 0.947817 lr 0.00021000 grad_norm 0.499045 rank 1
2025-01-10 14:24:19,994 DEBUG TRAIN Batch 59/100 loss 0.089071 acc 0.939130 lr 0.00021000 grad_norm 0.499045 rank 2
2025-01-10 14:24:44,276 DEBUG TRAIN Batch 59/200 loss 0.102171 acc 0.921903 lr 0.00020991 grad_norm 0.510195 rank 1
2025-01-10 14:24:44,276 DEBUG TRAIN Batch 59/200 loss 0.098652 acc 0.928133 lr 0.00020991 grad_norm 0.510195 rank 0
2025-01-10 14:24:44,276 DEBUG TRAIN Batch 59/200 loss 0.093528 acc 0.930528 lr 0.00020991 grad_norm 0.510195 rank 2
2025-01-10 14:25:09,348 DEBUG TRAIN Batch 59/300 loss 0.123325 acc 0.916283 lr 0.00020981 grad_norm 0.530146 rank 1
2025-01-10 14:25:09,348 DEBUG TRAIN Batch 59/300 loss 0.062867 acc 0.953226 lr 0.00020981 grad_norm 0.530146 rank 2
2025-01-10 14:25:09,348 DEBUG TRAIN Batch 59/300 loss 0.108152 acc 0.919811 lr 0.00020981 grad_norm 0.530146 rank 0
2025-01-10 14:25:32,948 DEBUG TRAIN Batch 59/400 loss 0.081582 acc 0.945676 lr 0.00020972 grad_norm 0.509017 rank 0
2025-01-10 14:25:32,948 DEBUG TRAIN Batch 59/400 loss 0.089886 acc 0.940574 lr 0.00020972 grad_norm 0.509017 rank 1
2025-01-10 14:25:32,948 DEBUG TRAIN Batch 59/400 loss 0.050897 acc 0.968706 lr 0.00020972 grad_norm 0.509017 rank 2
2025-01-10 14:25:57,984 DEBUG TRAIN Batch 59/500 loss 0.110811 acc 0.920748 lr 0.00020963 grad_norm 0.528986 rank 0
2025-01-10 14:25:57,983 DEBUG TRAIN Batch 59/500 loss 0.087537 acc 0.945433 lr 0.00020963 grad_norm 0.528986 rank 2
2025-01-10 14:25:57,984 DEBUG TRAIN Batch 59/500 loss 0.085407 acc 0.942366 lr 0.00020963 grad_norm 0.528986 rank 1
2025-01-10 14:26:23,694 DEBUG TRAIN Batch 59/600 loss 0.098763 acc 0.937089 lr 0.00020954 grad_norm 0.525835 rank 0
2025-01-10 14:26:23,694 DEBUG TRAIN Batch 59/600 loss 0.089125 acc 0.944974 lr 0.00020954 grad_norm 0.525835 rank 1
2025-01-10 14:26:23,695 DEBUG TRAIN Batch 59/600 loss 0.088246 acc 0.944128 lr 0.00020954 grad_norm 0.525835 rank 2
2025-01-10 14:26:47,653 DEBUG TRAIN Batch 59/700 loss 0.084290 acc 0.943540 lr 0.00020945 grad_norm 0.535771 rank 2
2025-01-10 14:26:47,653 DEBUG TRAIN Batch 59/700 loss 0.104917 acc 0.928105 lr 0.00020945 grad_norm 0.535771 rank 0
2025-01-10 14:26:47,653 DEBUG TRAIN Batch 59/700 loss 0.095375 acc 0.944223 lr 0.00020945 grad_norm 0.535771 rank 1
2025-01-10 14:27:13,284 DEBUG TRAIN Batch 59/800 loss 0.108598 acc 0.918047 lr 0.00020935 grad_norm 0.524241 rank 2
2025-01-10 14:27:13,284 DEBUG TRAIN Batch 59/800 loss 0.077219 acc 0.948090 lr 0.00020935 grad_norm 0.524241 rank 0
2025-01-10 14:27:13,284 DEBUG TRAIN Batch 59/800 loss 0.110844 acc 0.922941 lr 0.00020935 grad_norm 0.524241 rank 1
2025-01-10 14:27:37,520 DEBUG TRAIN Batch 59/900 loss 0.095390 acc 0.934622 lr 0.00020926 grad_norm 0.516219 rank 0
2025-01-10 14:27:37,520 DEBUG TRAIN Batch 59/900 loss 0.067754 acc 0.964778 lr 0.00020926 grad_norm 0.516219 rank 2
2025-01-10 14:27:37,521 DEBUG TRAIN Batch 59/900 loss 0.079641 acc 0.946101 lr 0.00020926 grad_norm 0.516219 rank 1
2025-01-10 14:28:01,896 DEBUG TRAIN Batch 59/1000 loss 0.071184 acc 0.946977 lr 0.00020917 grad_norm 0.508404 rank 1
2025-01-10 14:28:01,897 DEBUG TRAIN Batch 59/1000 loss 0.066678 acc 0.958449 lr 0.00020917 grad_norm 0.508404 rank 2
2025-01-10 14:28:01,897 DEBUG TRAIN Batch 59/1000 loss 0.093160 acc 0.924762 lr 0.00020917 grad_norm 0.508404 rank 0
2025-01-10 14:28:27,178 DEBUG TRAIN Batch 59/1100 loss 0.105061 acc 0.929012 lr 0.00020908 grad_norm 0.547965 rank 0
2025-01-10 14:28:27,178 DEBUG TRAIN Batch 59/1100 loss 0.099307 acc 0.927984 lr 0.00020908 grad_norm 0.547965 rank 2
2025-01-10 14:28:27,178 DEBUG TRAIN Batch 59/1100 loss 0.080349 acc 0.942857 lr 0.00020908 grad_norm 0.547965 rank 1
2025-01-10 14:28:51,602 DEBUG TRAIN Batch 59/1200 loss 0.076978 acc 0.946514 lr 0.00020899 grad_norm 0.530817 rank 0
2025-01-10 14:28:51,602 DEBUG TRAIN Batch 59/1200 loss 0.088996 acc 0.938117 lr 0.00020899 grad_norm 0.530817 rank 1
2025-01-10 14:28:51,602 DEBUG TRAIN Batch 59/1200 loss 0.084132 acc 0.940298 lr 0.00020899 grad_norm 0.530817 rank 2
2025-01-10 14:29:15,409 DEBUG TRAIN Batch 59/1300 loss 0.067278 acc 0.954430 lr 0.00020890 grad_norm 0.541524 rank 1
2025-01-10 14:29:15,410 DEBUG TRAIN Batch 59/1300 loss 0.089418 acc 0.937500 lr 0.00020890 grad_norm 0.541524 rank 2
2025-01-10 14:29:15,410 DEBUG TRAIN Batch 59/1300 loss 0.099044 acc 0.932458 lr 0.00020890 grad_norm 0.541524 rank 0
2025-01-10 14:29:39,047 DEBUG TRAIN Batch 59/1400 loss 0.077962 acc 0.941685 lr 0.00020881 grad_norm 0.543510 rank 0
2025-01-10 14:29:39,047 DEBUG TRAIN Batch 59/1400 loss 0.133667 acc 0.910357 lr 0.00020881 grad_norm 0.543510 rank 1
2025-01-10 14:29:39,048 DEBUG TRAIN Batch 59/1400 loss 0.077725 acc 0.947257 lr 0.00020881 grad_norm 0.543510 rank 2
2025-01-10 14:30:03,199 DEBUG TRAIN Batch 59/1500 loss 0.119931 acc 0.917782 lr 0.00020871 grad_norm 0.533642 rank 0
2025-01-10 14:30:03,200 DEBUG TRAIN Batch 59/1500 loss 0.093258 acc 0.936445 lr 0.00020871 grad_norm 0.533642 rank 2
2025-01-10 14:30:03,200 DEBUG TRAIN Batch 59/1500 loss 0.080339 acc 0.942029 lr 0.00020871 grad_norm 0.533642 rank 1
2025-01-10 14:30:27,362 DEBUG TRAIN Batch 59/1600 loss 0.124353 acc 0.912961 lr 0.00020862 grad_norm 0.536343 rank 0
2025-01-10 14:30:27,363 DEBUG TRAIN Batch 59/1600 loss 0.061586 acc 0.958472 lr 0.00020862 grad_norm 0.536343 rank 1
2025-01-10 14:30:27,363 DEBUG TRAIN Batch 59/1600 loss 0.092812 acc 0.933455 lr 0.00020862 grad_norm 0.536343 rank 2
2025-01-10 14:30:51,783 DEBUG TRAIN Batch 59/1700 loss 0.071886 acc 0.951311 lr 0.00020853 grad_norm 0.557637 rank 0
2025-01-10 14:30:51,783 DEBUG TRAIN Batch 59/1700 loss 0.127479 acc 0.924581 lr 0.00020853 grad_norm 0.557637 rank 1
2025-01-10 14:30:51,783 DEBUG TRAIN Batch 59/1700 loss 0.091861 acc 0.930460 lr 0.00020853 grad_norm 0.557637 rank 2
2025-01-10 14:31:15,451 DEBUG TRAIN Batch 59/1800 loss 0.121577 acc 0.918206 lr 0.00020844 grad_norm 0.538591 rank 2
2025-01-10 14:31:15,451 DEBUG TRAIN Batch 59/1800 loss 0.103219 acc 0.931776 lr 0.00020844 grad_norm 0.538591 rank 0
2025-01-10 14:31:15,452 DEBUG TRAIN Batch 59/1800 loss 0.113085 acc 0.929448 lr 0.00020844 grad_norm 0.538591 rank 1
2025-01-10 14:31:39,323 DEBUG TRAIN Batch 59/1900 loss 0.094051 acc 0.936660 lr 0.00020835 grad_norm 0.527896 rank 0
2025-01-10 14:31:39,323 DEBUG TRAIN Batch 59/1900 loss 0.105967 acc 0.927254 lr 0.00020835 grad_norm 0.527896 rank 1
2025-01-10 14:31:39,323 DEBUG TRAIN Batch 59/1900 loss 0.117078 acc 0.920981 lr 0.00020835 grad_norm 0.527896 rank 2
2025-01-10 14:32:03,595 DEBUG TRAIN Batch 59/2000 loss 0.126653 acc 0.913160 lr 0.00020826 grad_norm 0.558863 rank 2
2025-01-10 14:32:03,595 DEBUG TRAIN Batch 59/2000 loss 0.085848 acc 0.947075 lr 0.00020826 grad_norm 0.558863 rank 1
2025-01-10 14:32:03,596 DEBUG TRAIN Batch 59/2000 loss 0.127592 acc 0.911211 lr 0.00020826 grad_norm 0.558863 rank 0
2025-01-10 14:32:27,879 DEBUG TRAIN Batch 59/2100 loss 0.100229 acc 0.928274 lr 0.00020817 grad_norm 0.567508 rank 0
2025-01-10 14:32:27,880 DEBUG TRAIN Batch 59/2100 loss 0.085453 acc 0.943050 lr 0.00020817 grad_norm 0.567508 rank 1
2025-01-10 14:32:27,880 DEBUG TRAIN Batch 59/2100 loss 0.087735 acc 0.943538 lr 0.00020817 grad_norm 0.567508 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 14:33:30,286 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 14:33:30,286 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 14:33:30,684 INFO Epoch 59 Step 57695 on_batch_end True CV rank 0
2025-01-10 14:33:30,684 INFO Epoch 59 Step 57695 on_batch_end True CV rank 1
2025-01-10 14:33:30,684 INFO Epoch 59 Step 57695 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 14:33:40,008 DEBUG CV Batch 59/100 loss 0.024614 acc 0.992196  rank 0
2025-01-10 14:33:40,258 DEBUG CV Batch 59/100 loss 0.024614 acc 0.992196  rank 2
2025-01-10 14:33:40,487 INFO Epoch 59 Step 57695 CV info lr 0.00020816174289594398 0 rank loss_2.036916772432609 acc_0.7779186167999318
2025-01-10 14:33:40,525 DEBUG CV Batch 59/100 loss 0.024614 acc 0.992196  rank 1
2025-01-10 14:33:40,803 INFO Epoch 59 Step 57695 CV info lr 0.00020816174289594398 2 rank loss_2.036916772432609 acc_0.7779186167999318
2025-01-10 14:33:41,070 INFO Epoch 59 Step 57695 CV info lr 0.00020816174289594398 1 rank loss_2.036916772432609 acc_0.7779186167999318
2025-01-10 14:33:41,772 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_59_whole.pt
2025-01-10 14:33:41,783 INFO Added key: store_based_barrier_key:62 to store for rank: 0
2025-01-10 14:33:41,794 INFO Added key: store_based_barrier_key:62 to store for rank: 2
2025-01-10 14:33:41,794 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:62 with 3 nodes.
2025-01-10 14:33:41,794 INFO Added key: store_based_barrier_key:62 to store for rank: 1
2025-01-10 14:33:41,794 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:62 with 3 nodes.
2025-01-10 14:33:41,802 INFO Epoch 60 TRAIN info lr 0.00020816174289594398 rank 2
2025-01-10 14:33:41,802 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 14:33:41,804 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:62 with 3 nodes.
2025-01-10 14:33:41,804 INFO Epoch 60 TRAIN info lr 0.00020816174289594398 rank 1
2025-01-10 14:33:41,804 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 14:33:41,805 INFO Epoch 60 TRAIN info lr 0.00020816174289594398 rank 0
2025-01-10 14:33:41,805 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 14:34:12,969 DEBUG TRAIN Batch 60/100 loss 0.075028 acc 0.946597 lr 0.00020807 grad_norm 0.512032 rank 1
2025-01-10 14:34:12,969 DEBUG TRAIN Batch 60/100 loss 0.080747 acc 0.945297 lr 0.00020807 grad_norm 0.512032 rank 0
2025-01-10 14:34:12,970 DEBUG TRAIN Batch 60/100 loss 0.093890 acc 0.934968 lr 0.00020807 grad_norm 0.512032 rank 2
2025-01-10 14:34:37,250 DEBUG TRAIN Batch 60/200 loss 0.096105 acc 0.929434 lr 0.00020798 grad_norm 0.484931 rank 0
2025-01-10 14:34:37,250 DEBUG TRAIN Batch 60/200 loss 0.060903 acc 0.955414 lr 0.00020798 grad_norm 0.484931 rank 2
2025-01-10 14:34:37,251 DEBUG TRAIN Batch 60/200 loss 0.088177 acc 0.945095 lr 0.00020798 grad_norm 0.484931 rank 1
2025-01-10 14:35:01,033 DEBUG TRAIN Batch 60/300 loss 0.068968 acc 0.953368 lr 0.00020789 grad_norm 0.483657 rank 0
2025-01-10 14:35:01,033 DEBUG TRAIN Batch 60/300 loss 0.109792 acc 0.928842 lr 0.00020789 grad_norm 0.483657 rank 2
2025-01-10 14:35:01,036 DEBUG TRAIN Batch 60/300 loss 0.081062 acc 0.943571 lr 0.00020789 grad_norm 0.483657 rank 1
2025-01-10 14:35:25,048 DEBUG TRAIN Batch 60/400 loss 0.082323 acc 0.936262 lr 0.00020780 grad_norm 0.522497 rank 0
2025-01-10 14:35:25,049 DEBUG TRAIN Batch 60/400 loss 0.092332 acc 0.938090 lr 0.00020780 grad_norm 0.522497 rank 2
2025-01-10 14:35:25,049 DEBUG TRAIN Batch 60/400 loss 0.076420 acc 0.946588 lr 0.00020780 grad_norm 0.522497 rank 1
2025-01-10 14:35:49,890 DEBUG TRAIN Batch 60/500 loss 0.080363 acc 0.943348 lr 0.00020771 grad_norm 0.507631 rank 0
2025-01-10 14:35:49,890 DEBUG TRAIN Batch 60/500 loss 0.109179 acc 0.926829 lr 0.00020771 grad_norm 0.507631 rank 1
2025-01-10 14:35:49,890 DEBUG TRAIN Batch 60/500 loss 0.090435 acc 0.933028 lr 0.00020771 grad_norm 0.507631 rank 2
2025-01-10 14:36:14,197 DEBUG TRAIN Batch 60/600 loss 0.117177 acc 0.915521 lr 0.00020762 grad_norm 0.537271 rank 0
2025-01-10 14:36:14,197 DEBUG TRAIN Batch 60/600 loss 0.106876 acc 0.912358 lr 0.00020762 grad_norm 0.537271 rank 1
2025-01-10 14:36:14,197 DEBUG TRAIN Batch 60/600 loss 0.104915 acc 0.924731 lr 0.00020762 grad_norm 0.537271 rank 2
2025-01-10 14:36:38,732 DEBUG TRAIN Batch 60/700 loss 0.117031 acc 0.926263 lr 0.00020753 grad_norm 0.546883 rank 1
2025-01-10 14:36:38,732 DEBUG TRAIN Batch 60/700 loss 0.093199 acc 0.933187 lr 0.00020753 grad_norm 0.546883 rank 0
2025-01-10 14:36:38,733 DEBUG TRAIN Batch 60/700 loss 0.092308 acc 0.931035 lr 0.00020753 grad_norm 0.546883 rank 2
2025-01-10 14:37:03,266 DEBUG TRAIN Batch 60/800 loss 0.089126 acc 0.944223 lr 0.00020744 grad_norm 0.508896 rank 0
2025-01-10 14:37:03,266 DEBUG TRAIN Batch 60/800 loss 0.098328 acc 0.935115 lr 0.00020744 grad_norm 0.508896 rank 1
2025-01-10 14:37:03,267 DEBUG TRAIN Batch 60/800 loss 0.102618 acc 0.928866 lr 0.00020744 grad_norm 0.508896 rank 2
2025-01-10 14:37:28,638 DEBUG TRAIN Batch 60/900 loss 0.113110 acc 0.923077 lr 0.00020735 grad_norm 0.549442 rank 0
2025-01-10 14:37:28,639 DEBUG TRAIN Batch 60/900 loss 0.064318 acc 0.948052 lr 0.00020735 grad_norm 0.549442 rank 2
2025-01-10 14:37:28,639 DEBUG TRAIN Batch 60/900 loss 0.118981 acc 0.914155 lr 0.00020735 grad_norm 0.549442 rank 1
2025-01-10 14:37:53,168 DEBUG TRAIN Batch 60/1000 loss 0.081543 acc 0.937639 lr 0.00020727 grad_norm 0.525811 rank 0
2025-01-10 14:37:53,169 DEBUG TRAIN Batch 60/1000 loss 0.103549 acc 0.924759 lr 0.00020727 grad_norm 0.525811 rank 2
2025-01-10 14:37:53,169 DEBUG TRAIN Batch 60/1000 loss 0.089155 acc 0.942748 lr 0.00020727 grad_norm 0.525811 rank 1
2025-01-10 14:38:17,824 DEBUG TRAIN Batch 60/1100 loss 0.111747 acc 0.911312 lr 0.00020718 grad_norm 0.528132 rank 0
2025-01-10 14:38:17,824 DEBUG TRAIN Batch 60/1100 loss 0.104802 acc 0.930596 lr 0.00020718 grad_norm 0.528132 rank 1
2025-01-10 14:38:17,824 DEBUG TRAIN Batch 60/1100 loss 0.061253 acc 0.951515 lr 0.00020718 grad_norm 0.528132 rank 2
2025-01-10 14:38:42,182 DEBUG TRAIN Batch 60/1200 loss 0.098555 acc 0.932048 lr 0.00020709 grad_norm 0.533273 rank 2
2025-01-10 14:38:42,182 DEBUG TRAIN Batch 60/1200 loss 0.112685 acc 0.923767 lr 0.00020709 grad_norm 0.533273 rank 0
2025-01-10 14:38:42,182 DEBUG TRAIN Batch 60/1200 loss 0.086963 acc 0.941176 lr 0.00020709 grad_norm 0.533273 rank 1
2025-01-10 14:39:06,105 DEBUG TRAIN Batch 60/1300 loss 0.105863 acc 0.925682 lr 0.00020700 grad_norm 0.530292 rank 1
2025-01-10 14:39:06,105 DEBUG TRAIN Batch 60/1300 loss 0.115277 acc 0.918018 lr 0.00020700 grad_norm 0.530292 rank 0
2025-01-10 14:39:06,105 DEBUG TRAIN Batch 60/1300 loss 0.094813 acc 0.928247 lr 0.00020700 grad_norm 0.530292 rank 2
2025-01-10 14:39:30,334 DEBUG TRAIN Batch 60/1400 loss 0.102696 acc 0.936317 lr 0.00020691 grad_norm 0.538934 rank 2
2025-01-10 14:39:30,334 DEBUG TRAIN Batch 60/1400 loss 0.086940 acc 0.930960 lr 0.00020691 grad_norm 0.538934 rank 1
2025-01-10 14:39:30,335 DEBUG TRAIN Batch 60/1400 loss 0.118295 acc 0.919635 lr 0.00020691 grad_norm 0.538934 rank 0
2025-01-10 14:39:54,262 DEBUG TRAIN Batch 60/1500 loss 0.099959 acc 0.932617 lr 0.00020682 grad_norm 0.539440 rank 2
2025-01-10 14:39:54,263 DEBUG TRAIN Batch 60/1500 loss 0.106632 acc 0.926606 lr 0.00020682 grad_norm 0.539440 rank 0
2025-01-10 14:39:54,263 DEBUG TRAIN Batch 60/1500 loss 0.081189 acc 0.938476 lr 0.00020682 grad_norm 0.539440 rank 1
2025-01-10 14:40:18,311 DEBUG TRAIN Batch 60/1600 loss 0.099818 acc 0.928750 lr 0.00020673 grad_norm 0.548701 rank 0
2025-01-10 14:40:18,311 DEBUG TRAIN Batch 60/1600 loss 0.082162 acc 0.940901 lr 0.00020673 grad_norm 0.548701 rank 1
2025-01-10 14:40:18,311 DEBUG TRAIN Batch 60/1600 loss 0.105481 acc 0.929791 lr 0.00020673 grad_norm 0.548701 rank 2
2025-01-10 14:40:42,338 DEBUG TRAIN Batch 60/1700 loss 0.087651 acc 0.946322 lr 0.00020665 grad_norm 0.508174 rank 0
2025-01-10 14:40:42,338 DEBUG TRAIN Batch 60/1700 loss 0.089966 acc 0.932302 lr 0.00020665 grad_norm 0.508174 rank 1
2025-01-10 14:40:42,338 DEBUG TRAIN Batch 60/1700 loss 0.114762 acc 0.908036 lr 0.00020665 grad_norm 0.508174 rank 2
2025-01-10 14:41:07,090 DEBUG TRAIN Batch 60/1800 loss 0.087478 acc 0.932976 lr 0.00020656 grad_norm 0.529258 rank 1
2025-01-10 14:41:07,090 DEBUG TRAIN Batch 60/1800 loss 0.093799 acc 0.942158 lr 0.00020656 grad_norm 0.529258 rank 0
2025-01-10 14:41:07,090 DEBUG TRAIN Batch 60/1800 loss 0.085546 acc 0.932597 lr 0.00020656 grad_norm 0.529258 rank 2
2025-01-10 14:41:30,806 DEBUG TRAIN Batch 60/1900 loss 0.073486 acc 0.953347 lr 0.00020647 grad_norm 0.533849 rank 0
2025-01-10 14:41:30,806 DEBUG TRAIN Batch 60/1900 loss 0.113432 acc 0.914315 lr 0.00020647 grad_norm 0.533849 rank 1
2025-01-10 14:41:30,807 DEBUG TRAIN Batch 60/1900 loss 0.094966 acc 0.931174 lr 0.00020647 grad_norm 0.533849 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 14:42:31,398 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 14:42:31,400 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 14:42:31,854 INFO Epoch 60 Step 58646 on_batch_end True CV rank 0
2025-01-10 14:42:31,854 INFO Epoch 60 Step 58646 on_batch_end True CV rank 2
2025-01-10 14:42:31,854 INFO Epoch 60 Step 58646 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 14:42:41,131 DEBUG CV Batch 60/100 loss 0.022864 acc 0.994426  rank 0
2025-01-10 14:42:41,329 DEBUG CV Batch 60/100 loss 0.022864 acc 0.994426  rank 2
2025-01-10 14:42:41,613 DEBUG CV Batch 60/100 loss 0.022864 acc 0.994426  rank 1
2025-01-10 14:42:41,647 INFO Epoch 60 Step 58646 CV info lr 0.00020646707552436955 0 rank loss_2.0773544615469546 acc_0.778259207151438
2025-01-10 14:42:41,859 INFO Epoch 60 Step 58646 CV info lr 0.00020646707552436955 2 rank loss_2.0773544615469546 acc_0.778259207151438
2025-01-10 14:42:42,158 INFO Epoch 60 Step 58646 CV info lr 0.00020646707552436955 1 rank loss_2.0773544615469546 acc_0.778259207151438
2025-01-10 14:42:42,953 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_60_whole.pt
2025-01-10 14:42:42,965 INFO Added key: store_based_barrier_key:63 to store for rank: 0
2025-01-10 14:42:42,975 INFO Added key: store_based_barrier_key:63 to store for rank: 1
2025-01-10 14:42:42,975 INFO Added key: store_based_barrier_key:63 to store for rank: 2
2025-01-10 14:42:42,975 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:63 with 3 nodes.
2025-01-10 14:42:42,983 INFO Epoch 61 TRAIN info lr 0.00020646707552436955 rank 2
2025-01-10 14:42:42,984 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 14:42:42,985 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:63 with 3 nodes.
2025-01-10 14:42:42,985 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:63 with 3 nodes.
2025-01-10 14:42:42,987 INFO Epoch 61 TRAIN info lr 0.00020646707552436955 rank 1
2025-01-10 14:42:42,987 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 14:42:42,995 INFO Epoch 61 TRAIN info lr 0.00020646707552436955 rank 0
2025-01-10 14:42:42,995 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 14:43:19,837 DEBUG TRAIN Batch 61/100 loss 0.093226 acc 0.945032 lr 0.00020638 grad_norm 0.518168 rank 1
2025-01-10 14:43:19,837 DEBUG TRAIN Batch 61/100 loss 0.084285 acc 0.945148 lr 0.00020638 grad_norm 0.518168 rank 2
2025-01-10 14:43:19,837 DEBUG TRAIN Batch 61/100 loss 0.102419 acc 0.931035 lr 0.00020638 grad_norm 0.518168 rank 0
2025-01-10 14:43:44,160 DEBUG TRAIN Batch 61/200 loss 0.071419 acc 0.945612 lr 0.00020629 grad_norm 0.515505 rank 1
2025-01-10 14:43:44,160 DEBUG TRAIN Batch 61/200 loss 0.107376 acc 0.924429 lr 0.00020629 grad_norm 0.515505 rank 0
2025-01-10 14:43:44,160 DEBUG TRAIN Batch 61/200 loss 0.055334 acc 0.965021 lr 0.00020629 grad_norm 0.515505 rank 2
2025-01-10 14:44:08,895 DEBUG TRAIN Batch 61/300 loss 0.110235 acc 0.921705 lr 0.00020620 grad_norm 0.514015 rank 0
2025-01-10 14:44:08,895 DEBUG TRAIN Batch 61/300 loss 0.104274 acc 0.924424 lr 0.00020620 grad_norm 0.514015 rank 1
2025-01-10 14:44:08,896 DEBUG TRAIN Batch 61/300 loss 0.089193 acc 0.941176 lr 0.00020620 grad_norm 0.514015 rank 2
2025-01-10 14:44:33,097 DEBUG TRAIN Batch 61/400 loss 0.107103 acc 0.925891 lr 0.00020612 grad_norm 0.544292 rank 1
2025-01-10 14:44:33,097 DEBUG TRAIN Batch 61/400 loss 0.093860 acc 0.931795 lr 0.00020612 grad_norm 0.544292 rank 0
2025-01-10 14:44:33,098 DEBUG TRAIN Batch 61/400 loss 0.112241 acc 0.928885 lr 0.00020612 grad_norm 0.544292 rank 2
2025-01-10 14:44:57,923 DEBUG TRAIN Batch 61/500 loss 0.103772 acc 0.928298 lr 0.00020603 grad_norm 0.514466 rank 1
2025-01-10 14:44:57,923 DEBUG TRAIN Batch 61/500 loss 0.062552 acc 0.952381 lr 0.00020603 grad_norm 0.514466 rank 2
2025-01-10 14:44:57,924 DEBUG TRAIN Batch 61/500 loss 0.117221 acc 0.919014 lr 0.00020603 grad_norm 0.514466 rank 0
2025-01-10 14:45:22,704 DEBUG TRAIN Batch 61/600 loss 0.079453 acc 0.946789 lr 0.00020594 grad_norm 0.509488 rank 1
2025-01-10 14:45:22,704 DEBUG TRAIN Batch 61/600 loss 0.085015 acc 0.936073 lr 0.00020594 grad_norm 0.509488 rank 2
2025-01-10 14:45:22,704 DEBUG TRAIN Batch 61/600 loss 0.075327 acc 0.951960 lr 0.00020594 grad_norm 0.509488 rank 0
2025-01-10 14:45:46,584 DEBUG TRAIN Batch 61/700 loss 0.082398 acc 0.940855 lr 0.00020585 grad_norm 0.528749 rank 1
2025-01-10 14:45:46,585 DEBUG TRAIN Batch 61/700 loss 0.104897 acc 0.921358 lr 0.00020585 grad_norm 0.528749 rank 0
2025-01-10 14:45:46,585 DEBUG TRAIN Batch 61/700 loss 0.108351 acc 0.926471 lr 0.00020585 grad_norm 0.528749 rank 2
2025-01-10 14:46:11,417 DEBUG TRAIN Batch 61/800 loss 0.087854 acc 0.941509 lr 0.00020577 grad_norm 0.480014 rank 1
2025-01-10 14:46:11,418 DEBUG TRAIN Batch 61/800 loss 0.083531 acc 0.938735 lr 0.00020577 grad_norm 0.480014 rank 0
2025-01-10 14:46:11,418 DEBUG TRAIN Batch 61/800 loss 0.083838 acc 0.938931 lr 0.00020577 grad_norm 0.480014 rank 2
2025-01-10 14:46:35,661 DEBUG TRAIN Batch 61/900 loss 0.077935 acc 0.954802 lr 0.00020568 grad_norm 0.538235 rank 1
2025-01-10 14:46:35,662 DEBUG TRAIN Batch 61/900 loss 0.114250 acc 0.924805 lr 0.00020568 grad_norm 0.538235 rank 2
2025-01-10 14:46:35,662 DEBUG TRAIN Batch 61/900 loss 0.101103 acc 0.919574 lr 0.00020568 grad_norm 0.538235 rank 0
2025-01-10 14:47:00,190 DEBUG TRAIN Batch 61/1000 loss 0.091391 acc 0.939640 lr 0.00020559 grad_norm 0.496924 rank 0
2025-01-10 14:47:00,190 DEBUG TRAIN Batch 61/1000 loss 0.072244 acc 0.952236 lr 0.00020559 grad_norm 0.496924 rank 1
2025-01-10 14:47:00,190 DEBUG TRAIN Batch 61/1000 loss 0.106336 acc 0.926267 lr 0.00020559 grad_norm 0.496924 rank 2
2025-01-10 14:47:26,399 DEBUG TRAIN Batch 61/1100 loss 0.106277 acc 0.925234 lr 0.00020551 grad_norm 0.534157 rank 0
2025-01-10 14:47:26,400 DEBUG TRAIN Batch 61/1100 loss 0.101247 acc 0.937273 lr 0.00020551 grad_norm 0.534157 rank 1
2025-01-10 14:47:26,400 DEBUG TRAIN Batch 61/1100 loss 0.056415 acc 0.956897 lr 0.00020551 grad_norm 0.534157 rank 2
2025-01-10 14:47:50,223 DEBUG TRAIN Batch 61/1200 loss 0.108519 acc 0.922516 lr 0.00020542 grad_norm 0.557250 rank 0
2025-01-10 14:47:50,223 DEBUG TRAIN Batch 61/1200 loss 0.118700 acc 0.926393 lr 0.00020542 grad_norm 0.557250 rank 1
2025-01-10 14:47:50,224 DEBUG TRAIN Batch 61/1200 loss 0.081442 acc 0.946154 lr 0.00020542 grad_norm 0.557250 rank 2
2025-01-10 14:48:14,341 DEBUG TRAIN Batch 61/1300 loss 0.109537 acc 0.922481 lr 0.00020533 grad_norm 0.545531 rank 0
2025-01-10 14:48:14,341 DEBUG TRAIN Batch 61/1300 loss 0.093822 acc 0.930070 lr 0.00020533 grad_norm 0.545531 rank 1
2025-01-10 14:48:14,342 DEBUG TRAIN Batch 61/1300 loss 0.090034 acc 0.925840 lr 0.00020533 grad_norm 0.545531 rank 2
2025-01-10 14:48:38,715 DEBUG TRAIN Batch 61/1400 loss 0.122271 acc 0.909524 lr 0.00020525 grad_norm 0.552695 rank 0
2025-01-10 14:48:38,715 DEBUG TRAIN Batch 61/1400 loss 0.103081 acc 0.930417 lr 0.00020525 grad_norm 0.552695 rank 1
2025-01-10 14:48:38,715 DEBUG TRAIN Batch 61/1400 loss 0.065509 acc 0.953895 lr 0.00020525 grad_norm 0.552695 rank 2
2025-01-10 14:49:04,074 DEBUG TRAIN Batch 61/1500 loss 0.091505 acc 0.940371 lr 0.00020516 grad_norm 0.557310 rank 1
2025-01-10 14:49:04,074 DEBUG TRAIN Batch 61/1500 loss 0.111886 acc 0.929626 lr 0.00020516 grad_norm 0.557310 rank 0
2025-01-10 14:49:04,075 DEBUG TRAIN Batch 61/1500 loss 0.137912 acc 0.910244 lr 0.00020516 grad_norm 0.557310 rank 2
2025-01-10 14:49:28,442 DEBUG TRAIN Batch 61/1600 loss 0.096397 acc 0.932811 lr 0.00020507 grad_norm 0.551052 rank 1
2025-01-10 14:49:28,442 DEBUG TRAIN Batch 61/1600 loss 0.115755 acc 0.918822 lr 0.00020507 grad_norm 0.551052 rank 0
2025-01-10 14:49:28,443 DEBUG TRAIN Batch 61/1600 loss 0.111520 acc 0.928298 lr 0.00020507 grad_norm 0.551052 rank 2
2025-01-10 14:49:52,687 DEBUG TRAIN Batch 61/1700 loss 0.101568 acc 0.932802 lr 0.00020499 grad_norm 0.561417 rank 1
2025-01-10 14:49:52,688 DEBUG TRAIN Batch 61/1700 loss 0.093760 acc 0.933610 lr 0.00020499 grad_norm 0.561417 rank 0
2025-01-10 14:49:52,688 DEBUG TRAIN Batch 61/1700 loss 0.102721 acc 0.923313 lr 0.00020499 grad_norm 0.561417 rank 2
2025-01-10 14:50:17,649 DEBUG TRAIN Batch 61/1800 loss 0.111483 acc 0.922862 lr 0.00020490 grad_norm 0.562042 rank 1
2025-01-10 14:50:17,650 DEBUG TRAIN Batch 61/1800 loss 0.067636 acc 0.950752 lr 0.00020490 grad_norm 0.562042 rank 2
2025-01-10 14:50:17,650 DEBUG TRAIN Batch 61/1800 loss 0.074906 acc 0.953224 lr 0.00020490 grad_norm 0.562042 rank 0
2025-01-10 14:50:42,075 DEBUG TRAIN Batch 61/1900 loss 0.083427 acc 0.943965 lr 0.00020481 grad_norm 0.533513 rank 1
2025-01-10 14:50:42,075 DEBUG TRAIN Batch 61/1900 loss 0.120788 acc 0.916090 lr 0.00020481 grad_norm 0.533513 rank 0
2025-01-10 14:50:42,076 DEBUG TRAIN Batch 61/1900 loss 0.107515 acc 0.921397 lr 0.00020481 grad_norm 0.533513 rank 2
2025-01-10 14:51:05,959 DEBUG TRAIN Batch 61/2000 loss 0.088798 acc 0.943137 lr 0.00020473 grad_norm 0.529345 rank 1
2025-01-10 14:51:05,959 DEBUG TRAIN Batch 61/2000 loss 0.102717 acc 0.922027 lr 0.00020473 grad_norm 0.529345 rank 0
2025-01-10 14:51:05,959 DEBUG TRAIN Batch 61/2000 loss 0.082453 acc 0.941788 lr 0.00020473 grad_norm 0.529345 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 14:52:20,880 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 14:52:20,884 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 14:52:21,255 INFO Epoch 61 Step 59677 on_batch_end True CV rank 0
2025-01-10 14:52:21,255 INFO Epoch 61 Step 59677 on_batch_end True CV rank 2
2025-01-10 14:52:21,255 INFO Epoch 61 Step 59677 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 14:52:30,560 DEBUG CV Batch 61/100 loss 0.030370 acc 0.988852  rank 2
2025-01-10 14:52:30,611 DEBUG CV Batch 61/100 loss 0.030370 acc 0.988852  rank 0
2025-01-10 14:52:31,093 DEBUG CV Batch 61/100 loss 0.030370 acc 0.988852  rank 1
2025-01-10 14:52:31,107 INFO Epoch 61 Step 59677 CV info lr 0.00020467580772875194 0 rank loss_2.074483722043959 acc_0.7780451600750288
2025-01-10 14:52:31,107 INFO Epoch 61 Step 59677 CV info lr 0.00020467580772875194 2 rank loss_2.074483722043959 acc_0.7780451600750288
2025-01-10 14:52:31,655 INFO Epoch 61 Step 59677 CV info lr 0.00020467580772875194 1 rank loss_2.074483722043959 acc_0.7780451600750288
2025-01-10 14:52:32,415 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_61_whole.pt
2025-01-10 14:52:32,436 INFO Added key: store_based_barrier_key:64 to store for rank: 0
2025-01-10 14:52:32,447 INFO Added key: store_based_barrier_key:64 to store for rank: 2
2025-01-10 14:52:32,447 INFO Added key: store_based_barrier_key:64 to store for rank: 1
2025-01-10 14:52:32,447 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:64 with 3 nodes.
2025-01-10 14:52:32,447 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:64 with 3 nodes.
2025-01-10 14:52:32,455 INFO Epoch 62 TRAIN info lr 0.00020467580772875194 rank 1
2025-01-10 14:52:32,455 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 14:52:32,457 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:64 with 3 nodes.
2025-01-10 14:52:32,457 INFO Epoch 62 TRAIN info lr 0.00020467580772875194 rank 2
2025-01-10 14:52:32,457 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 14:52:32,467 INFO Epoch 62 TRAIN info lr 0.00020467580772875194 rank 0
2025-01-10 14:52:32,467 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 14:53:02,912 DEBUG TRAIN Batch 62/100 loss 0.096204 acc 0.936396 lr 0.00020459 grad_norm 0.503803 rank 1
2025-01-10 14:53:02,913 DEBUG TRAIN Batch 62/100 loss 0.108482 acc 0.927020 lr 0.00020459 grad_norm 0.503803 rank 0
2025-01-10 14:53:02,913 DEBUG TRAIN Batch 62/100 loss 0.097136 acc 0.930233 lr 0.00020459 grad_norm 0.503803 rank 2
2025-01-10 14:53:27,093 DEBUG TRAIN Batch 62/200 loss 0.060241 acc 0.959950 lr 0.00020450 grad_norm 0.520268 rank 0
2025-01-10 14:53:27,093 DEBUG TRAIN Batch 62/200 loss 0.098146 acc 0.937186 lr 0.00020450 grad_norm 0.520268 rank 1
2025-01-10 14:53:27,093 DEBUG TRAIN Batch 62/200 loss 0.090354 acc 0.940171 lr 0.00020450 grad_norm 0.520268 rank 2
2025-01-10 14:53:50,587 DEBUG TRAIN Batch 62/300 loss 0.087695 acc 0.946378 lr 0.00020442 grad_norm 0.511524 rank 0
2025-01-10 14:53:50,587 DEBUG TRAIN Batch 62/300 loss 0.087821 acc 0.936251 lr 0.00020442 grad_norm 0.511524 rank 1
2025-01-10 14:53:50,587 DEBUG TRAIN Batch 62/300 loss 0.099192 acc 0.932515 lr 0.00020442 grad_norm 0.511524 rank 2
2025-01-10 14:54:14,358 DEBUG TRAIN Batch 62/400 loss 0.116525 acc 0.915695 lr 0.00020433 grad_norm 0.549322 rank 1
2025-01-10 14:54:14,358 DEBUG TRAIN Batch 62/400 loss 0.093675 acc 0.937273 lr 0.00020433 grad_norm 0.549322 rank 0
2025-01-10 14:54:14,359 DEBUG TRAIN Batch 62/400 loss 0.100334 acc 0.930253 lr 0.00020433 grad_norm 0.549322 rank 2
2025-01-10 14:54:38,570 DEBUG TRAIN Batch 62/500 loss 0.094011 acc 0.937859 lr 0.00020425 grad_norm 0.559542 rank 1
2025-01-10 14:54:38,571 DEBUG TRAIN Batch 62/500 loss 0.066130 acc 0.957255 lr 0.00020425 grad_norm 0.559542 rank 2
2025-01-10 14:54:38,571 DEBUG TRAIN Batch 62/500 loss 0.090012 acc 0.943432 lr 0.00020425 grad_norm 0.559542 rank 0
2025-01-10 14:55:02,641 DEBUG TRAIN Batch 62/600 loss 0.065965 acc 0.957569 lr 0.00020416 grad_norm 0.516380 rank 1
2025-01-10 14:55:02,642 DEBUG TRAIN Batch 62/600 loss 0.088526 acc 0.933598 lr 0.00020416 grad_norm 0.516380 rank 2
2025-01-10 14:55:02,642 DEBUG TRAIN Batch 62/600 loss 0.064153 acc 0.957130 lr 0.00020416 grad_norm 0.516380 rank 0
2025-01-10 14:55:28,089 DEBUG TRAIN Batch 62/700 loss 0.092572 acc 0.934198 lr 0.00020408 grad_norm 0.512688 rank 1
2025-01-10 14:55:28,090 DEBUG TRAIN Batch 62/700 loss 0.085766 acc 0.946572 lr 0.00020408 grad_norm 0.512688 rank 0
2025-01-10 14:55:28,090 DEBUG TRAIN Batch 62/700 loss 0.069270 acc 0.948630 lr 0.00020408 grad_norm 0.512688 rank 2
2025-01-10 14:55:51,959 DEBUG TRAIN Batch 62/800 loss 0.070569 acc 0.953342 lr 0.00020399 grad_norm 0.536343 rank 0
2025-01-10 14:55:51,960 DEBUG TRAIN Batch 62/800 loss 0.074347 acc 0.949267 lr 0.00020399 grad_norm 0.536343 rank 1
2025-01-10 14:55:51,960 DEBUG TRAIN Batch 62/800 loss 0.133261 acc 0.918140 lr 0.00020399 grad_norm 0.536343 rank 2
2025-01-10 14:56:16,351 DEBUG TRAIN Batch 62/900 loss 0.097585 acc 0.924771 lr 0.00020391 grad_norm 0.553134 rank 0
2025-01-10 14:56:16,351 DEBUG TRAIN Batch 62/900 loss 0.093040 acc 0.932515 lr 0.00020391 grad_norm 0.553134 rank 1
2025-01-10 14:56:16,351 DEBUG TRAIN Batch 62/900 loss 0.131424 acc 0.908999 lr 0.00020391 grad_norm 0.553134 rank 2
2025-01-10 14:56:42,611 DEBUG TRAIN Batch 62/1000 loss 0.096582 acc 0.934005 lr 0.00020382 grad_norm 0.559310 rank 1
2025-01-10 14:56:42,612 DEBUG TRAIN Batch 62/1000 loss 0.108943 acc 0.929552 lr 0.00020382 grad_norm 0.559310 rank 0
2025-01-10 14:56:42,612 DEBUG TRAIN Batch 62/1000 loss 0.090941 acc 0.935680 lr 0.00020382 grad_norm 0.559310 rank 2
2025-01-10 14:57:07,335 DEBUG TRAIN Batch 62/1100 loss 0.095843 acc 0.938134 lr 0.00020374 grad_norm 0.534134 rank 0
2025-01-10 14:57:07,336 DEBUG TRAIN Batch 62/1100 loss 0.082113 acc 0.937561 lr 0.00020374 grad_norm 0.534134 rank 1
2025-01-10 14:57:07,336 DEBUG TRAIN Batch 62/1100 loss 0.150562 acc 0.894504 lr 0.00020374 grad_norm 0.534134 rank 2
2025-01-10 14:57:31,650 DEBUG TRAIN Batch 62/1200 loss 0.074515 acc 0.947132 lr 0.00020365 grad_norm 0.529417 rank 0
2025-01-10 14:57:31,651 DEBUG TRAIN Batch 62/1200 loss 0.073237 acc 0.949367 lr 0.00020365 grad_norm 0.529417 rank 1
2025-01-10 14:57:31,651 DEBUG TRAIN Batch 62/1200 loss 0.137506 acc 0.901222 lr 0.00020365 grad_norm 0.529417 rank 2
2025-01-10 14:57:56,725 DEBUG TRAIN Batch 62/1300 loss 0.109664 acc 0.919786 lr 0.00020357 grad_norm 0.523055 rank 1
2025-01-10 14:57:56,726 DEBUG TRAIN Batch 62/1300 loss 0.098179 acc 0.939539 lr 0.00020357 grad_norm 0.523055 rank 0
2025-01-10 14:57:56,726 DEBUG TRAIN Batch 62/1300 loss 0.081043 acc 0.944112 lr 0.00020357 grad_norm 0.523055 rank 2
2025-01-10 14:58:20,824 DEBUG TRAIN Batch 62/1400 loss 0.060178 acc 0.951577 lr 0.00020349 grad_norm 0.521962 rank 2
2025-01-10 14:58:20,824 DEBUG TRAIN Batch 62/1400 loss 0.106436 acc 0.933892 lr 0.00020349 grad_norm 0.521962 rank 0
2025-01-10 14:58:20,824 DEBUG TRAIN Batch 62/1400 loss 0.083678 acc 0.944954 lr 0.00020349 grad_norm 0.521962 rank 1
2025-01-10 14:58:45,455 DEBUG TRAIN Batch 62/1500 loss 0.094562 acc 0.928092 lr 0.00020340 grad_norm 0.551805 rank 1
2025-01-10 14:58:45,456 DEBUG TRAIN Batch 62/1500 loss 0.114415 acc 0.919431 lr 0.00020340 grad_norm 0.551805 rank 0
2025-01-10 14:58:45,456 DEBUG TRAIN Batch 62/1500 loss 0.095375 acc 0.931590 lr 0.00020340 grad_norm 0.551805 rank 2
2025-01-10 14:59:10,655 DEBUG TRAIN Batch 62/1600 loss 0.073887 acc 0.953409 lr 0.00020332 grad_norm 0.508142 rank 2
2025-01-10 14:59:10,655 DEBUG TRAIN Batch 62/1600 loss 0.096031 acc 0.933263 lr 0.00020332 grad_norm 0.508142 rank 0
2025-01-10 14:59:10,656 DEBUG TRAIN Batch 62/1600 loss 0.114960 acc 0.922813 lr 0.00020332 grad_norm 0.508142 rank 1
2025-01-10 14:59:34,640 DEBUG TRAIN Batch 62/1700 loss 0.079599 acc 0.942821 lr 0.00020323 grad_norm 0.522105 rank 0
2025-01-10 14:59:34,640 DEBUG TRAIN Batch 62/1700 loss 0.103093 acc 0.922541 lr 0.00020323 grad_norm 0.522105 rank 2
2025-01-10 14:59:34,640 DEBUG TRAIN Batch 62/1700 loss 0.090500 acc 0.940891 lr 0.00020323 grad_norm 0.522105 rank 1
2025-01-10 14:59:59,653 DEBUG TRAIN Batch 62/1800 loss 0.099114 acc 0.932456 lr 0.00020315 grad_norm 0.523885 rank 1
2025-01-10 14:59:59,654 DEBUG TRAIN Batch 62/1800 loss 0.097012 acc 0.928092 lr 0.00020315 grad_norm 0.523885 rank 0
2025-01-10 14:59:59,654 DEBUG TRAIN Batch 62/1800 loss 0.052747 acc 0.964103 lr 0.00020315 grad_norm 0.523885 rank 2
2025-01-10 15:00:23,781 DEBUG TRAIN Batch 62/1900 loss 0.122703 acc 0.916129 lr 0.00020307 grad_norm 0.532994 rank 0
2025-01-10 15:00:23,782 DEBUG TRAIN Batch 62/1900 loss 0.086985 acc 0.945513 lr 0.00020307 grad_norm 0.532994 rank 1
2025-01-10 15:00:23,782 DEBUG TRAIN Batch 62/1900 loss 0.088228 acc 0.933333 lr 0.00020307 grad_norm 0.532994 rank 2
2025-01-10 15:00:48,331 DEBUG TRAIN Batch 62/2000 loss 0.057397 acc 0.958159 lr 0.00020298 grad_norm 0.523251 rank 2
2025-01-10 15:00:48,331 DEBUG TRAIN Batch 62/2000 loss 0.106475 acc 0.915730 lr 0.00020298 grad_norm 0.523251 rank 0
2025-01-10 15:00:48,332 DEBUG TRAIN Batch 62/2000 loss 0.091735 acc 0.938034 lr 0.00020298 grad_norm 0.523251 rank 1
2025-01-10 15:01:12,781 DEBUG TRAIN Batch 62/2100 loss 0.096666 acc 0.934153 lr 0.00020290 grad_norm 0.572174 rank 1
2025-01-10 15:01:12,782 DEBUG TRAIN Batch 62/2100 loss 0.118996 acc 0.917989 lr 0.00020290 grad_norm 0.572174 rank 0
2025-01-10 15:01:12,782 DEBUG TRAIN Batch 62/2100 loss 0.060973 acc 0.961538 lr 0.00020290 grad_norm 0.572174 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 15:02:32,968 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 15:02:32,999 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 15:02:33,317 INFO Epoch 62 Step 60768 on_batch_end True CV rank 0
2025-01-10 15:02:33,317 INFO Epoch 62 Step 60768 on_batch_end True CV rank 2
2025-01-10 15:02:33,317 INFO Epoch 62 Step 60768 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 15:02:42,386 DEBUG CV Batch 62/100 loss 0.026025 acc 0.994426  rank 0
2025-01-10 15:02:42,740 DEBUG CV Batch 62/100 loss 0.026025 acc 0.994426  rank 2
2025-01-10 15:02:42,921 INFO Epoch 62 Step 60768 CV info lr 0.00020283015979634812 0 rank loss_2.0790086271437374 acc_0.7780471819273213
2025-01-10 15:02:43,030 DEBUG CV Batch 62/100 loss 0.026025 acc 0.994426  rank 1
2025-01-10 15:02:43,276 INFO Epoch 62 Step 60768 CV info lr 0.00020283015979634812 2 rank loss_2.0790086271437374 acc_0.7780471819273213
2025-01-10 15:02:43,576 INFO Epoch 62 Step 60768 CV info lr 0.00020283015979634812 1 rank loss_2.0790086271437374 acc_0.7780471819273213
2025-01-10 15:02:44,209 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_62_whole.pt
2025-01-10 15:02:44,231 INFO Added key: store_based_barrier_key:65 to store for rank: 0
2025-01-10 15:02:44,231 INFO Added key: store_based_barrier_key:65 to store for rank: 1
2025-01-10 15:02:44,231 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:65 with 3 nodes.
2025-01-10 15:02:44,231 INFO Added key: store_based_barrier_key:65 to store for rank: 2
2025-01-10 15:02:44,232 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:65 with 3 nodes.
2025-01-10 15:02:44,233 INFO Epoch 63 TRAIN info lr 0.00020283015979634812 rank 1
2025-01-10 15:02:44,234 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 15:02:44,240 INFO Epoch 63 TRAIN info lr 0.00020283015979634812 rank 2
2025-01-10 15:02:44,240 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 15:02:44,241 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:65 with 3 nodes.
2025-01-10 15:02:44,249 INFO Epoch 63 TRAIN info lr 0.00020283015979634812 rank 0
2025-01-10 15:02:44,249 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 15:03:17,760 DEBUG TRAIN Batch 63/100 loss 0.077593 acc 0.944849 lr 0.00020275 grad_norm 0.499579 rank 2
2025-01-10 15:03:17,760 DEBUG TRAIN Batch 63/100 loss 0.086912 acc 0.939734 lr 0.00020275 grad_norm 0.499579 rank 0
2025-01-10 15:03:17,760 DEBUG TRAIN Batch 63/100 loss 0.085410 acc 0.939815 lr 0.00020275 grad_norm 0.499579 rank 1
2025-01-10 15:03:42,113 DEBUG TRAIN Batch 63/200 loss 0.097644 acc 0.934901 lr 0.00020266 grad_norm 0.527209 rank 0
2025-01-10 15:03:42,114 DEBUG TRAIN Batch 63/200 loss 0.078958 acc 0.941281 lr 0.00020266 grad_norm 0.527209 rank 1
2025-01-10 15:03:42,114 DEBUG TRAIN Batch 63/200 loss 0.103592 acc 0.919861 lr 0.00020266 grad_norm 0.527209 rank 2
2025-01-10 15:04:06,506 DEBUG TRAIN Batch 63/300 loss 0.066381 acc 0.954641 lr 0.00020258 grad_norm 0.489137 rank 1
2025-01-10 15:04:06,506 DEBUG TRAIN Batch 63/300 loss 0.081007 acc 0.945152 lr 0.00020258 grad_norm 0.489137 rank 0
2025-01-10 15:04:06,507 DEBUG TRAIN Batch 63/300 loss 0.083014 acc 0.947266 lr 0.00020258 grad_norm 0.489137 rank 2
2025-01-10 15:04:31,264 DEBUG TRAIN Batch 63/400 loss 0.082972 acc 0.938224 lr 0.00020250 grad_norm 0.527780 rank 1
2025-01-10 15:04:31,265 DEBUG TRAIN Batch 63/400 loss 0.086293 acc 0.943961 lr 0.00020250 grad_norm 0.527780 rank 0
2025-01-10 15:04:31,265 DEBUG TRAIN Batch 63/400 loss 0.085294 acc 0.940021 lr 0.00020250 grad_norm 0.527780 rank 2
2025-01-10 15:04:55,440 DEBUG TRAIN Batch 63/500 loss 0.099261 acc 0.932856 lr 0.00020241 grad_norm 0.490621 rank 1
2025-01-10 15:04:55,441 DEBUG TRAIN Batch 63/500 loss 0.092883 acc 0.945191 lr 0.00020241 grad_norm 0.490621 rank 0
2025-01-10 15:04:55,441 DEBUG TRAIN Batch 63/500 loss 0.078521 acc 0.944746 lr 0.00020241 grad_norm 0.490621 rank 2
2025-01-10 15:05:19,928 DEBUG TRAIN Batch 63/600 loss 0.086139 acc 0.938154 lr 0.00020233 grad_norm 0.500710 rank 1
2025-01-10 15:05:19,928 DEBUG TRAIN Batch 63/600 loss 0.092248 acc 0.931102 lr 0.00020233 grad_norm 0.500710 rank 0
2025-01-10 15:05:19,929 DEBUG TRAIN Batch 63/600 loss 0.075032 acc 0.945516 lr 0.00020233 grad_norm 0.500710 rank 2
2025-01-10 15:05:45,288 DEBUG TRAIN Batch 63/700 loss 0.086663 acc 0.936681 lr 0.00020225 grad_norm 0.523730 rank 0
2025-01-10 15:05:45,288 DEBUG TRAIN Batch 63/700 loss 0.106304 acc 0.930233 lr 0.00020225 grad_norm 0.523730 rank 1
2025-01-10 15:05:45,289 DEBUG TRAIN Batch 63/700 loss 0.081663 acc 0.942134 lr 0.00020225 grad_norm 0.523730 rank 2
2025-01-10 15:06:09,416 DEBUG TRAIN Batch 63/800 loss 0.097383 acc 0.936300 lr 0.00020217 grad_norm 0.491620 rank 0
2025-01-10 15:06:09,416 DEBUG TRAIN Batch 63/800 loss 0.080697 acc 0.941873 lr 0.00020217 grad_norm 0.491620 rank 1
2025-01-10 15:06:09,416 DEBUG TRAIN Batch 63/800 loss 0.067197 acc 0.949239 lr 0.00020217 grad_norm 0.491620 rank 2
2025-01-10 15:06:33,676 DEBUG TRAIN Batch 63/900 loss 0.094166 acc 0.934928 lr 0.00020208 grad_norm 0.492959 rank 0
2025-01-10 15:06:33,676 DEBUG TRAIN Batch 63/900 loss 0.093494 acc 0.942827 lr 0.00020208 grad_norm 0.492959 rank 1
2025-01-10 15:06:33,676 DEBUG TRAIN Batch 63/900 loss 0.067342 acc 0.955556 lr 0.00020208 grad_norm 0.492959 rank 2
2025-01-10 15:06:58,974 DEBUG TRAIN Batch 63/1000 loss 0.105076 acc 0.930097 lr 0.00020200 grad_norm 0.543199 rank 0
2025-01-10 15:06:58,974 DEBUG TRAIN Batch 63/1000 loss 0.134811 acc 0.911170 lr 0.00020200 grad_norm 0.543199 rank 1
2025-01-10 15:06:58,974 DEBUG TRAIN Batch 63/1000 loss 0.081689 acc 0.950000 lr 0.00020200 grad_norm 0.543199 rank 2
2025-01-10 15:07:22,721 DEBUG TRAIN Batch 63/1100 loss 0.089565 acc 0.938338 lr 0.00020192 grad_norm 0.508835 rank 0
2025-01-10 15:07:22,721 DEBUG TRAIN Batch 63/1100 loss 0.104365 acc 0.925963 lr 0.00020192 grad_norm 0.508835 rank 1
2025-01-10 15:07:22,722 DEBUG TRAIN Batch 63/1100 loss 0.075866 acc 0.947534 lr 0.00020192 grad_norm 0.508835 rank 2
2025-01-10 15:07:47,019 DEBUG TRAIN Batch 63/1200 loss 0.081074 acc 0.943925 lr 0.00020184 grad_norm 0.514547 rank 2
2025-01-10 15:07:47,019 DEBUG TRAIN Batch 63/1200 loss 0.106710 acc 0.914494 lr 0.00020184 grad_norm 0.514547 rank 1
2025-01-10 15:07:47,019 DEBUG TRAIN Batch 63/1200 loss 0.104856 acc 0.930083 lr 0.00020184 grad_norm 0.514547 rank 0
2025-01-10 15:08:11,660 DEBUG TRAIN Batch 63/1300 loss 0.091194 acc 0.938517 lr 0.00020175 grad_norm 0.485318 rank 0
2025-01-10 15:08:11,660 DEBUG TRAIN Batch 63/1300 loss 0.081104 acc 0.946585 lr 0.00020175 grad_norm 0.485318 rank 1
2025-01-10 15:08:11,660 DEBUG TRAIN Batch 63/1300 loss 0.064932 acc 0.952591 lr 0.00020175 grad_norm 0.485318 rank 2
2025-01-10 15:08:35,594 DEBUG TRAIN Batch 63/1400 loss 0.096071 acc 0.935814 lr 0.00020167 grad_norm 0.522051 rank 1
2025-01-10 15:08:35,594 DEBUG TRAIN Batch 63/1400 loss 0.067422 acc 0.944570 lr 0.00020167 grad_norm 0.522051 rank 0
2025-01-10 15:08:35,595 DEBUG TRAIN Batch 63/1400 loss 0.093423 acc 0.931641 lr 0.00020167 grad_norm 0.522051 rank 2
2025-01-10 15:09:00,407 DEBUG TRAIN Batch 63/1500 loss 0.119074 acc 0.912029 lr 0.00020159 grad_norm inf rank 1
2025-01-10 15:09:00,408 DEBUG TRAIN Batch 63/1500 loss 0.089158 acc 0.937622 lr 0.00020159 grad_norm inf rank 2
2025-01-10 15:09:00,408 DEBUG TRAIN Batch 63/1500 loss 0.077419 acc 0.944279 lr 0.00020159 grad_norm inf rank 0
2025-01-10 15:09:25,015 DEBUG TRAIN Batch 63/1600 loss 0.092985 acc 0.933945 lr 0.00020151 grad_norm 0.504960 rank 0
2025-01-10 15:09:25,015 DEBUG TRAIN Batch 63/1600 loss 0.098584 acc 0.930337 lr 0.00020151 grad_norm 0.504960 rank 1
2025-01-10 15:09:25,017 DEBUG TRAIN Batch 63/1600 loss 0.091186 acc 0.939694 lr 0.00020151 grad_norm 0.504960 rank 2
2025-01-10 15:09:49,528 DEBUG TRAIN Batch 63/1700 loss 0.110095 acc 0.912088 lr 0.00020143 grad_norm 0.534964 rank 1
2025-01-10 15:09:49,529 DEBUG TRAIN Batch 63/1700 loss 0.086946 acc 0.935722 lr 0.00020143 grad_norm 0.534964 rank 2
2025-01-10 15:09:49,529 DEBUG TRAIN Batch 63/1700 loss 0.111173 acc 0.923818 lr 0.00020143 grad_norm 0.534964 rank 0
2025-01-10 15:10:13,255 DEBUG TRAIN Batch 63/1800 loss 0.116537 acc 0.922936 lr 0.00020134 grad_norm 0.596146 rank 0
2025-01-10 15:10:13,255 DEBUG TRAIN Batch 63/1800 loss 0.107994 acc 0.920408 lr 0.00020134 grad_norm 0.596146 rank 1
2025-01-10 15:10:13,256 DEBUG TRAIN Batch 63/1800 loss 0.079024 acc 0.939880 lr 0.00020134 grad_norm 0.596146 rank 2
2025-01-10 15:10:37,737 DEBUG TRAIN Batch 63/1900 loss 0.106627 acc 0.914758 lr 0.00020126 grad_norm 0.575339 rank 1
2025-01-10 15:10:37,737 DEBUG TRAIN Batch 63/1900 loss 0.102310 acc 0.935176 lr 0.00020126 grad_norm 0.575339 rank 0
2025-01-10 15:10:37,738 DEBUG TRAIN Batch 63/1900 loss 0.125048 acc 0.914019 lr 0.00020126 grad_norm 0.575339 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 15:11:44,659 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 15:11:44,661 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 15:11:45,101 INFO Epoch 63 Step 61732 on_batch_end True CV rank 0
2025-01-10 15:11:45,101 INFO Epoch 63 Step 61732 on_batch_end True CV rank 1
2025-01-10 15:11:45,101 INFO Epoch 63 Step 61732 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 15:11:54,159 DEBUG CV Batch 63/100 loss 0.033937 acc 0.989967  rank 0
2025-01-10 15:11:54,513 DEBUG CV Batch 63/100 loss 0.033937 acc 0.989967  rank 2
2025-01-10 15:11:54,639 INFO Epoch 63 Step 61732 CV info lr 0.0002012402418457094 0 rank loss_2.0771996710661864 acc_0.7778905445807859
2025-01-10 15:11:54,696 DEBUG CV Batch 63/100 loss 0.033937 acc 0.989967  rank 1
2025-01-10 15:11:55,051 INFO Epoch 63 Step 61732 CV info lr 0.0002012402418457094 2 rank loss_2.0771996710661864 acc_0.7778905445807859
2025-01-10 15:11:55,239 INFO Epoch 63 Step 61732 CV info lr 0.0002012402418457094 1 rank loss_2.0771996710661864 acc_0.7778905445807859
2025-01-10 15:11:55,942 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_63_whole.pt
2025-01-10 15:11:55,964 INFO Added key: store_based_barrier_key:66 to store for rank: 0
2025-01-10 15:11:55,974 INFO Added key: store_based_barrier_key:66 to store for rank: 1
2025-01-10 15:11:55,974 INFO Added key: store_based_barrier_key:66 to store for rank: 2
2025-01-10 15:11:55,974 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:66 with 3 nodes.
2025-01-10 15:11:55,974 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:66 with 3 nodes.
2025-01-10 15:11:55,978 INFO Epoch 64 TRAIN info lr 0.0002012402418457094 rank 1
2025-01-10 15:11:55,978 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 15:11:55,983 INFO Epoch 64 TRAIN info lr 0.0002012402418457094 rank 2
2025-01-10 15:11:55,983 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 15:11:55,984 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:66 with 3 nodes.
2025-01-10 15:11:55,994 INFO Epoch 64 TRAIN info lr 0.0002012402418457094 rank 0
2025-01-10 15:11:55,994 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 15:12:27,771 DEBUG TRAIN Batch 64/100 loss 0.078350 acc 0.944395 lr 0.00020116 grad_norm 0.454487 rank 0
2025-01-10 15:12:27,771 DEBUG TRAIN Batch 64/100 loss 0.070280 acc 0.948718 lr 0.00020116 grad_norm 0.454487 rank 1
2025-01-10 15:12:27,771 DEBUG TRAIN Batch 64/100 loss 0.049934 acc 0.969377 lr 0.00020116 grad_norm 0.454487 rank 2
2025-01-10 15:12:51,802 DEBUG TRAIN Batch 64/200 loss 0.081754 acc 0.939591 lr 0.00020108 grad_norm 0.483952 rank 1
2025-01-10 15:12:51,802 DEBUG TRAIN Batch 64/200 loss 0.053663 acc 0.963992 lr 0.00020108 grad_norm 0.483952 rank 2
2025-01-10 15:12:51,802 DEBUG TRAIN Batch 64/200 loss 0.090010 acc 0.939713 lr 0.00020108 grad_norm 0.483952 rank 0
2025-01-10 15:13:16,421 DEBUG TRAIN Batch 64/300 loss 0.069107 acc 0.958333 lr 0.00020100 grad_norm 0.502528 rank 2
2025-01-10 15:13:16,421 DEBUG TRAIN Batch 64/300 loss 0.088072 acc 0.942000 lr 0.00020100 grad_norm 0.502528 rank 0
2025-01-10 15:13:16,422 DEBUG TRAIN Batch 64/300 loss 0.104571 acc 0.927346 lr 0.00020100 grad_norm 0.502528 rank 1
2025-01-10 15:13:40,547 DEBUG TRAIN Batch 64/400 loss 0.071844 acc 0.953564 lr 0.00020092 grad_norm 0.543199 rank 0
2025-01-10 15:13:40,547 DEBUG TRAIN Batch 64/400 loss 0.100212 acc 0.932725 lr 0.00020092 grad_norm 0.543199 rank 1
2025-01-10 15:13:40,547 DEBUG TRAIN Batch 64/400 loss 0.101611 acc 0.929537 lr 0.00020092 grad_norm 0.543199 rank 2
2025-01-10 15:14:04,969 DEBUG TRAIN Batch 64/500 loss 0.071025 acc 0.959184 lr 0.00020083 grad_norm 0.493552 rank 0
2025-01-10 15:14:04,969 DEBUG TRAIN Batch 64/500 loss 0.063370 acc 0.957198 lr 0.00020083 grad_norm 0.493552 rank 1
2025-01-10 15:14:04,970 DEBUG TRAIN Batch 64/500 loss 0.092625 acc 0.937500 lr 0.00020083 grad_norm 0.493552 rank 2
2025-01-10 15:14:29,948 DEBUG TRAIN Batch 64/600 loss 0.068608 acc 0.945707 lr 0.00020075 grad_norm 0.501633 rank 2
2025-01-10 15:14:29,948 DEBUG TRAIN Batch 64/600 loss 0.063054 acc 0.945783 lr 0.00020075 grad_norm 0.501633 rank 0
2025-01-10 15:14:29,948 DEBUG TRAIN Batch 64/600 loss 0.054575 acc 0.964461 lr 0.00020075 grad_norm 0.501633 rank 1
2025-01-10 15:14:55,005 DEBUG TRAIN Batch 64/700 loss 0.092276 acc 0.936954 lr 0.00020067 grad_norm 0.529563 rank 1
2025-01-10 15:14:55,006 DEBUG TRAIN Batch 64/700 loss 0.072560 acc 0.954808 lr 0.00020067 grad_norm 0.529563 rank 2
2025-01-10 15:14:55,006 DEBUG TRAIN Batch 64/700 loss 0.090703 acc 0.936015 lr 0.00020067 grad_norm 0.529563 rank 0
2025-01-10 15:15:19,601 DEBUG TRAIN Batch 64/800 loss 0.096774 acc 0.931244 lr 0.00020059 grad_norm 0.513099 rank 2
2025-01-10 15:15:19,601 DEBUG TRAIN Batch 64/800 loss 0.085833 acc 0.943978 lr 0.00020059 grad_norm 0.513099 rank 0
2025-01-10 15:15:19,602 DEBUG TRAIN Batch 64/800 loss 0.041861 acc 0.970588 lr 0.00020059 grad_norm 0.513099 rank 1
2025-01-10 15:15:43,614 DEBUG TRAIN Batch 64/900 loss 0.096736 acc 0.929044 lr 0.00020051 grad_norm 0.524425 rank 2
2025-01-10 15:15:43,614 DEBUG TRAIN Batch 64/900 loss 0.078967 acc 0.945783 lr 0.00020051 grad_norm 0.524425 rank 0
2025-01-10 15:15:43,615 DEBUG TRAIN Batch 64/900 loss 0.056856 acc 0.954481 lr 0.00020051 grad_norm 0.524425 rank 1
2025-01-10 15:16:08,772 DEBUG TRAIN Batch 64/1000 loss 0.098460 acc 0.932544 lr 0.00020043 grad_norm 0.556452 rank 1
2025-01-10 15:16:08,773 DEBUG TRAIN Batch 64/1000 loss 0.054291 acc 0.971311 lr 0.00020043 grad_norm 0.556452 rank 0
2025-01-10 15:16:08,773 DEBUG TRAIN Batch 64/1000 loss 0.106803 acc 0.927845 lr 0.00020043 grad_norm 0.556452 rank 2
2025-01-10 15:16:33,848 DEBUG TRAIN Batch 64/1100 loss 0.106870 acc 0.923415 lr 0.00020035 grad_norm 0.521990 rank 0
2025-01-10 15:16:33,848 DEBUG TRAIN Batch 64/1100 loss 0.087136 acc 0.930091 lr 0.00020035 grad_norm 0.521990 rank 1
2025-01-10 15:16:33,848 DEBUG TRAIN Batch 64/1100 loss 0.099118 acc 0.929924 lr 0.00020035 grad_norm 0.521990 rank 2
2025-01-10 15:16:57,662 DEBUG TRAIN Batch 64/1200 loss 0.099819 acc 0.926733 lr 0.00020027 grad_norm 0.527747 rank 0
2025-01-10 15:16:57,662 DEBUG TRAIN Batch 64/1200 loss 0.098528 acc 0.931818 lr 0.00020027 grad_norm 0.527747 rank 2
2025-01-10 15:16:57,662 DEBUG TRAIN Batch 64/1200 loss 0.058996 acc 0.961216 lr 0.00020027 grad_norm 0.527747 rank 1
2025-01-10 15:17:22,705 DEBUG TRAIN Batch 64/1300 loss 0.119695 acc 0.925023 lr 0.00020019 grad_norm 0.520970 rank 0
2025-01-10 15:17:22,705 DEBUG TRAIN Batch 64/1300 loss 0.094384 acc 0.934307 lr 0.00020019 grad_norm 0.520970 rank 2
2025-01-10 15:17:22,706 DEBUG TRAIN Batch 64/1300 loss 0.049196 acc 0.968491 lr 0.00020019 grad_norm 0.520970 rank 1
2025-01-10 15:17:46,339 DEBUG TRAIN Batch 64/1400 loss 0.128692 acc 0.911607 lr 0.00020011 grad_norm 0.527787 rank 0
2025-01-10 15:17:46,340 DEBUG TRAIN Batch 64/1400 loss 0.102774 acc 0.935455 lr 0.00020011 grad_norm 0.527787 rank 2
2025-01-10 15:17:46,340 DEBUG TRAIN Batch 64/1400 loss 0.066178 acc 0.953869 lr 0.00020011 grad_norm 0.527787 rank 1
2025-01-10 15:18:10,438 DEBUG TRAIN Batch 64/1500 loss 0.069328 acc 0.952444 lr 0.00020003 grad_norm 0.528448 rank 1
2025-01-10 15:18:10,438 DEBUG TRAIN Batch 64/1500 loss 0.093378 acc 0.928571 lr 0.00020003 grad_norm 0.528448 rank 2
2025-01-10 15:18:10,439 DEBUG TRAIN Batch 64/1500 loss 0.088291 acc 0.939891 lr 0.00020003 grad_norm 0.528448 rank 0
2025-01-10 15:18:36,702 DEBUG TRAIN Batch 64/1600 loss 0.082268 acc 0.946535 lr 0.00019995 grad_norm 0.526396 rank 1
2025-01-10 15:18:36,702 DEBUG TRAIN Batch 64/1600 loss 0.112381 acc 0.927481 lr 0.00019995 grad_norm 0.526396 rank 0
2025-01-10 15:18:36,702 DEBUG TRAIN Batch 64/1600 loss 0.087670 acc 0.939885 lr 0.00019995 grad_norm 0.526396 rank 2
2025-01-10 15:19:00,170 DEBUG TRAIN Batch 64/1700 loss 0.097184 acc 0.933333 lr 0.00019987 grad_norm 0.516442 rank 0
2025-01-10 15:19:00,170 DEBUG TRAIN Batch 64/1700 loss 0.105975 acc 0.933996 lr 0.00019987 grad_norm 0.516442 rank 2
2025-01-10 15:19:00,171 DEBUG TRAIN Batch 64/1700 loss 0.099889 acc 0.925729 lr 0.00019987 grad_norm 0.516442 rank 1
2025-01-10 15:19:24,114 DEBUG TRAIN Batch 64/1800 loss 0.106679 acc 0.924184 lr 0.00019979 grad_norm 0.526673 rank 2
2025-01-10 15:19:24,114 DEBUG TRAIN Batch 64/1800 loss 0.098854 acc 0.932868 lr 0.00019979 grad_norm 0.526673 rank 0
2025-01-10 15:19:24,115 DEBUG TRAIN Batch 64/1800 loss 0.082453 acc 0.942529 lr 0.00019979 grad_norm 0.526673 rank 1
2025-01-10 15:19:47,948 DEBUG TRAIN Batch 64/1900 loss 0.099023 acc 0.939455 lr 0.00019971 grad_norm 0.525103 rank 2
2025-01-10 15:19:47,948 DEBUG TRAIN Batch 64/1900 loss 0.088000 acc 0.931567 lr 0.00019971 grad_norm 0.525103 rank 0
2025-01-10 15:19:47,949 DEBUG TRAIN Batch 64/1900 loss 0.098006 acc 0.934037 lr 0.00019971 grad_norm 0.525103 rank 1
2025-01-10 15:20:12,682 DEBUG TRAIN Batch 64/2000 loss 0.084185 acc 0.938725 lr 0.00019963 grad_norm 0.523903 rank 2
2025-01-10 15:20:12,683 DEBUG TRAIN Batch 64/2000 loss 0.095870 acc 0.937177 lr 0.00019963 grad_norm 0.523903 rank 0
2025-01-10 15:20:12,683 DEBUG TRAIN Batch 64/2000 loss 0.086652 acc 0.937819 lr 0.00019963 grad_norm 0.523903 rank 1
2025-01-10 15:20:36,243 DEBUG TRAIN Batch 64/2100 loss 0.100339 acc 0.932822 lr 0.00019955 grad_norm 0.523147 rank 2
2025-01-10 15:20:36,243 DEBUG TRAIN Batch 64/2100 loss 0.083327 acc 0.944182 lr 0.00019955 grad_norm 0.523147 rank 0
2025-01-10 15:20:36,244 DEBUG TRAIN Batch 64/2100 loss 0.081087 acc 0.945335 lr 0.00019955 grad_norm 0.523147 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 15:21:42,419 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 15:21:42,420 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 15:21:42,789 INFO Epoch 64 Step 62795 on_batch_end True CV rank 2
2025-01-10 15:21:42,789 INFO Epoch 64 Step 62795 on_batch_end True CV rank 0
2025-01-10 15:21:42,790 INFO Epoch 64 Step 62795 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 15:21:51,980 DEBUG CV Batch 64/100 loss 0.025923 acc 0.992196  rank 2
2025-01-10 15:21:52,106 DEBUG CV Batch 64/100 loss 0.025923 acc 0.992196  rank 0
2025-01-10 15:21:52,500 INFO Epoch 64 Step 62795 CV info lr 0.0001995296643349001 2 rank loss_2.0954899845742867 acc_0.7778229857223076
2025-01-10 15:21:52,591 INFO Epoch 64 Step 62795 CV info lr 0.0001995296643349001 0 rank loss_2.0954899845742867 acc_0.7778229857223076
2025-01-10 15:21:52,669 DEBUG CV Batch 64/100 loss 0.025923 acc 0.992196  rank 1
2025-01-10 15:21:53,230 INFO Epoch 64 Step 62795 CV info lr 0.0001995296643349001 1 rank loss_2.0954899845742867 acc_0.7778229857223076
2025-01-10 15:21:53,882 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_64_whole.pt
2025-01-10 15:21:53,904 INFO Added key: store_based_barrier_key:67 to store for rank: 0
2025-01-10 15:21:53,915 INFO Added key: store_based_barrier_key:67 to store for rank: 1
2025-01-10 15:21:53,915 INFO Added key: store_based_barrier_key:67 to store for rank: 2
2025-01-10 15:21:53,915 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:67 with 3 nodes.
2025-01-10 15:21:53,915 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:67 with 3 nodes.
2025-01-10 15:21:53,916 INFO Epoch 65 TRAIN info lr 0.0001995296643349001 rank 2
2025-01-10 15:21:53,916 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 15:21:53,925 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:67 with 3 nodes.
2025-01-10 15:21:53,925 INFO Epoch 65 TRAIN info lr 0.0001995296643349001 rank 1
2025-01-10 15:21:53,925 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 15:21:53,930 INFO Epoch 65 TRAIN info lr 0.0001995296643349001 rank 0
2025-01-10 15:21:53,930 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 15:22:24,828 DEBUG TRAIN Batch 65/100 loss 0.073029 acc 0.945435 lr 0.00019945 grad_norm 0.482753 rank 0
2025-01-10 15:22:24,828 DEBUG TRAIN Batch 65/100 loss 0.065448 acc 0.958932 lr 0.00019945 grad_norm 0.482753 rank 2
2025-01-10 15:22:24,828 DEBUG TRAIN Batch 65/100 loss 0.084866 acc 0.945554 lr 0.00019945 grad_norm 0.482753 rank 1
2025-01-10 15:22:48,755 DEBUG TRAIN Batch 65/200 loss 0.059326 acc 0.951282 lr 0.00019937 grad_norm 0.474342 rank 0
2025-01-10 15:22:48,755 DEBUG TRAIN Batch 65/200 loss 0.057563 acc 0.956419 lr 0.00019937 grad_norm 0.474342 rank 1
2025-01-10 15:22:48,755 DEBUG TRAIN Batch 65/200 loss 0.081080 acc 0.943132 lr 0.00019937 grad_norm 0.474342 rank 2
2025-01-10 15:23:12,343 DEBUG TRAIN Batch 65/300 loss 0.072745 acc 0.945622 lr 0.00019929 grad_norm 0.488422 rank 0
2025-01-10 15:23:12,343 DEBUG TRAIN Batch 65/300 loss 0.082374 acc 0.943324 lr 0.00019929 grad_norm 0.488422 rank 2
2025-01-10 15:23:12,344 DEBUG TRAIN Batch 65/300 loss 0.087018 acc 0.946266 lr 0.00019929 grad_norm 0.488422 rank 1
2025-01-10 15:23:36,428 DEBUG TRAIN Batch 65/400 loss 0.076128 acc 0.943605 lr 0.00019921 grad_norm 0.518013 rank 0
2025-01-10 15:23:36,429 DEBUG TRAIN Batch 65/400 loss 0.082213 acc 0.940476 lr 0.00019921 grad_norm 0.518013 rank 2
2025-01-10 15:23:36,429 DEBUG TRAIN Batch 65/400 loss 0.083150 acc 0.946619 lr 0.00019921 grad_norm 0.518013 rank 1
2025-01-10 15:24:00,541 DEBUG TRAIN Batch 65/500 loss 0.082692 acc 0.940125 lr 0.00019913 grad_norm 0.503472 rank 0
2025-01-10 15:24:00,542 DEBUG TRAIN Batch 65/500 loss 0.080261 acc 0.945423 lr 0.00019913 grad_norm 0.503472 rank 2
2025-01-10 15:24:00,542 DEBUG TRAIN Batch 65/500 loss 0.085202 acc 0.944149 lr 0.00019913 grad_norm 0.503472 rank 1
2025-01-10 15:24:24,453 DEBUG TRAIN Batch 65/600 loss 0.091708 acc 0.931579 lr 0.00019905 grad_norm 0.518607 rank 1
2025-01-10 15:24:24,454 DEBUG TRAIN Batch 65/600 loss 0.078378 acc 0.950523 lr 0.00019905 grad_norm 0.518607 rank 0
2025-01-10 15:24:24,454 DEBUG TRAIN Batch 65/600 loss 0.091961 acc 0.934866 lr 0.00019905 grad_norm 0.518607 rank 2
2025-01-10 15:24:48,686 DEBUG TRAIN Batch 65/700 loss 0.070517 acc 0.951002 lr 0.00019898 grad_norm 0.512890 rank 2
2025-01-10 15:24:48,686 DEBUG TRAIN Batch 65/700 loss 0.109816 acc 0.922406 lr 0.00019898 grad_norm 0.512890 rank 0
2025-01-10 15:24:48,686 DEBUG TRAIN Batch 65/700 loss 0.076881 acc 0.943580 lr 0.00019898 grad_norm 0.512890 rank 1
2025-01-10 15:25:13,158 DEBUG TRAIN Batch 65/800 loss 0.084099 acc 0.953439 lr 0.00019890 grad_norm 0.538155 rank 1
2025-01-10 15:25:13,158 DEBUG TRAIN Batch 65/800 loss 0.102773 acc 0.926186 lr 0.00019890 grad_norm 0.538155 rank 2
2025-01-10 15:25:13,159 DEBUG TRAIN Batch 65/800 loss 0.105665 acc 0.925373 lr 0.00019890 grad_norm 0.538155 rank 0
2025-01-10 15:25:37,330 DEBUG TRAIN Batch 65/900 loss 0.061530 acc 0.956647 lr 0.00019882 grad_norm 0.516007 rank 2
2025-01-10 15:25:37,330 DEBUG TRAIN Batch 65/900 loss 0.088082 acc 0.946970 lr 0.00019882 grad_norm 0.516007 rank 0
2025-01-10 15:25:37,330 DEBUG TRAIN Batch 65/900 loss 0.119609 acc 0.910369 lr 0.00019882 grad_norm 0.516007 rank 1
2025-01-10 15:26:00,969 DEBUG TRAIN Batch 65/1000 loss 0.091925 acc 0.933913 lr 0.00019874 grad_norm 0.500921 rank 0
2025-01-10 15:26:00,970 DEBUG TRAIN Batch 65/1000 loss 0.092243 acc 0.937380 lr 0.00019874 grad_norm 0.500921 rank 2
2025-01-10 15:26:00,970 DEBUG TRAIN Batch 65/1000 loss 0.105116 acc 0.920108 lr 0.00019874 grad_norm 0.500921 rank 1
2025-01-10 15:26:25,064 DEBUG TRAIN Batch 65/1100 loss 0.097793 acc 0.932727 lr 0.00019866 grad_norm 0.521847 rank 1
2025-01-10 15:26:25,065 DEBUG TRAIN Batch 65/1100 loss 0.087335 acc 0.941675 lr 0.00019866 grad_norm 0.521847 rank 0
2025-01-10 15:26:25,065 DEBUG TRAIN Batch 65/1100 loss 0.080573 acc 0.945882 lr 0.00019866 grad_norm 0.521847 rank 2
2025-01-10 15:26:49,381 DEBUG TRAIN Batch 65/1200 loss 0.083007 acc 0.948949 lr 0.00019858 grad_norm 0.494824 rank 0
2025-01-10 15:26:49,381 DEBUG TRAIN Batch 65/1200 loss 0.081870 acc 0.943950 lr 0.00019858 grad_norm 0.494824 rank 1
2025-01-10 15:26:49,381 DEBUG TRAIN Batch 65/1200 loss 0.085336 acc 0.940037 lr 0.00019858 grad_norm 0.494824 rank 2
2025-01-10 15:27:13,767 DEBUG TRAIN Batch 65/1300 loss 0.083332 acc 0.948634 lr 0.00019850 grad_norm 0.539148 rank 0
2025-01-10 15:27:13,768 DEBUG TRAIN Batch 65/1300 loss 0.127528 acc 0.914634 lr 0.00019850 grad_norm 0.539148 rank 2
2025-01-10 15:27:13,768 DEBUG TRAIN Batch 65/1300 loss 0.100625 acc 0.921053 lr 0.00019850 grad_norm 0.539148 rank 1
2025-01-10 15:27:37,240 DEBUG TRAIN Batch 65/1400 loss 0.097417 acc 0.930792 lr 0.00019843 grad_norm 0.536361 rank 1
2025-01-10 15:27:37,240 DEBUG TRAIN Batch 65/1400 loss 0.095779 acc 0.933134 lr 0.00019843 grad_norm 0.536361 rank 2
2025-01-10 15:27:37,240 DEBUG TRAIN Batch 65/1400 loss 0.086428 acc 0.939394 lr 0.00019843 grad_norm 0.536361 rank 0
2025-01-10 15:28:01,597 DEBUG TRAIN Batch 65/1500 loss 0.072781 acc 0.954219 lr 0.00019835 grad_norm 0.549935 rank 0
2025-01-10 15:28:01,598 DEBUG TRAIN Batch 65/1500 loss 0.104961 acc 0.930783 lr 0.00019835 grad_norm 0.549935 rank 1
2025-01-10 15:28:01,725 DEBUG TRAIN Batch 65/1500 loss 0.089522 acc 0.938300 lr 0.00019835 grad_norm 0.549935 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 15:29:25,536 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 15:29:25,539 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 15:29:25,943 INFO Epoch 65 Step 63594 on_batch_end True CV rank 0
2025-01-10 15:29:25,943 INFO Epoch 65 Step 63594 on_batch_end True CV rank 2
2025-01-10 15:29:25,944 INFO Epoch 65 Step 63594 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 15:29:34,967 DEBUG CV Batch 65/100 loss 0.029880 acc 0.988852  rank 0
2025-01-10 15:29:35,215 DEBUG CV Batch 65/100 loss 0.029880 acc 0.988852  rank 2
2025-01-10 15:29:35,490 INFO Epoch 65 Step 63594 CV info lr 0.00019827224911470433 0 rank loss_2.1219876582914017 acc_0.7784552384625402
2025-01-10 15:29:35,745 INFO Epoch 65 Step 63594 CV info lr 0.00019827224911470433 2 rank loss_2.1219876582914017 acc_0.7784552384625402
2025-01-10 15:29:35,981 DEBUG CV Batch 65/100 loss 0.029880 acc 0.988852  rank 1
2025-01-10 15:29:36,549 INFO Epoch 65 Step 63594 CV info lr 0.00019827224911470433 1 rank loss_2.1219876582914017 acc_0.7784552384625402
2025-01-10 15:29:36,771 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_65_whole.pt
2025-01-10 15:29:36,792 INFO Added key: store_based_barrier_key:68 to store for rank: 0
2025-01-10 15:29:36,792 INFO Added key: store_based_barrier_key:68 to store for rank: 1
2025-01-10 15:29:36,793 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:68 with 3 nodes.
2025-01-10 15:29:36,793 INFO Added key: store_based_barrier_key:68 to store for rank: 2
2025-01-10 15:29:36,793 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:68 with 3 nodes.
2025-01-10 15:29:36,796 INFO Epoch 66 TRAIN info lr 0.00019827224911470433 rank 1
2025-01-10 15:29:36,796 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 15:29:36,800 INFO Epoch 66 TRAIN info lr 0.00019827224911470433 rank 2
2025-01-10 15:29:36,800 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 15:29:36,803 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:68 with 3 nodes.
2025-01-10 15:29:36,803 INFO Epoch 66 TRAIN info lr 0.00019827224911470433 rank 0
2025-01-10 15:29:36,803 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 15:30:10,913 DEBUG TRAIN Batch 66/100 loss 0.090210 acc 0.939556 lr 0.00019819 grad_norm 0.457821 rank 2
2025-01-10 15:30:10,913 DEBUG TRAIN Batch 66/100 loss 0.065444 acc 0.953878 lr 0.00019819 grad_norm 0.457821 rank 0
2025-01-10 15:30:10,914 DEBUG TRAIN Batch 66/100 loss 0.067699 acc 0.952813 lr 0.00019819 grad_norm 0.457821 rank 1
2025-01-10 15:30:34,814 DEBUG TRAIN Batch 66/200 loss 0.059648 acc 0.957962 lr 0.00019812 grad_norm 0.469069 rank 0
2025-01-10 15:30:34,814 DEBUG TRAIN Batch 66/200 loss 0.088381 acc 0.937381 lr 0.00019812 grad_norm 0.469069 rank 2
2025-01-10 15:30:34,814 DEBUG TRAIN Batch 66/200 loss 0.076798 acc 0.951583 lr 0.00019812 grad_norm 0.469069 rank 1
2025-01-10 15:30:59,042 DEBUG TRAIN Batch 66/300 loss 0.089849 acc 0.935176 lr 0.00019804 grad_norm 0.482742 rank 0
2025-01-10 15:30:59,042 DEBUG TRAIN Batch 66/300 loss 0.083053 acc 0.937556 lr 0.00019804 grad_norm 0.482742 rank 2
2025-01-10 15:30:59,043 DEBUG TRAIN Batch 66/300 loss 0.073586 acc 0.952514 lr 0.00019804 grad_norm 0.482742 rank 1
2025-01-10 15:31:23,457 DEBUG TRAIN Batch 66/400 loss 0.084193 acc 0.940208 lr 0.00019796 grad_norm 0.468436 rank 2
2025-01-10 15:31:23,457 DEBUG TRAIN Batch 66/400 loss 0.079392 acc 0.940329 lr 0.00019796 grad_norm 0.468436 rank 0
2025-01-10 15:31:23,458 DEBUG TRAIN Batch 66/400 loss 0.067749 acc 0.960041 lr 0.00019796 grad_norm 0.468436 rank 1
2025-01-10 15:31:47,963 DEBUG TRAIN Batch 66/500 loss 0.084915 acc 0.941000 lr 0.00019788 grad_norm 0.485986 rank 0
2025-01-10 15:31:47,963 DEBUG TRAIN Batch 66/500 loss 0.064075 acc 0.960100 lr 0.00019788 grad_norm 0.485986 rank 2
2025-01-10 15:31:47,964 DEBUG TRAIN Batch 66/500 loss 0.077411 acc 0.945289 lr 0.00019788 grad_norm 0.485986 rank 1
2025-01-10 15:32:11,934 DEBUG TRAIN Batch 66/600 loss 0.090764 acc 0.930467 lr 0.00019781 grad_norm 0.505544 rank 2
2025-01-10 15:32:11,934 DEBUG TRAIN Batch 66/600 loss 0.094922 acc 0.944706 lr 0.00019781 grad_norm 0.505544 rank 0
2025-01-10 15:32:11,934 DEBUG TRAIN Batch 66/600 loss 0.062834 acc 0.956965 lr 0.00019781 grad_norm 0.505544 rank 1
2025-01-10 15:32:36,706 DEBUG TRAIN Batch 66/700 loss 0.115175 acc 0.924270 lr 0.00019773 grad_norm 0.512019 rank 0
2025-01-10 15:32:36,707 DEBUG TRAIN Batch 66/700 loss 0.099397 acc 0.933036 lr 0.00019773 grad_norm 0.512019 rank 2
2025-01-10 15:32:36,707 DEBUG TRAIN Batch 66/700 loss 0.061514 acc 0.958130 lr 0.00019773 grad_norm 0.512019 rank 1
2025-01-10 15:33:01,014 DEBUG TRAIN Batch 66/800 loss 0.089799 acc 0.933735 lr 0.00019765 grad_norm 0.502566 rank 1
2025-01-10 15:33:01,014 DEBUG TRAIN Batch 66/800 loss 0.050780 acc 0.960630 lr 0.00019765 grad_norm 0.502566 rank 0
2025-01-10 15:33:01,014 DEBUG TRAIN Batch 66/800 loss 0.089482 acc 0.934105 lr 0.00019765 grad_norm 0.502566 rank 2
2025-01-10 15:33:24,962 DEBUG TRAIN Batch 66/900 loss 0.080980 acc 0.951627 lr 0.00019757 grad_norm 0.506354 rank 1
2025-01-10 15:33:24,963 DEBUG TRAIN Batch 66/900 loss 0.076534 acc 0.945355 lr 0.00019757 grad_norm 0.506354 rank 0
2025-01-10 15:33:24,963 DEBUG TRAIN Batch 66/900 loss 0.065788 acc 0.961809 lr 0.00019757 grad_norm 0.506354 rank 2
2025-01-10 15:33:49,973 DEBUG TRAIN Batch 66/1000 loss 0.107213 acc 0.930256 lr 0.00019750 grad_norm 0.597827 rank 1
2025-01-10 15:33:49,973 DEBUG TRAIN Batch 66/1000 loss 0.244702 acc 0.841037 lr 0.00019750 grad_norm 0.597827 rank 0
2025-01-10 15:33:49,973 DEBUG TRAIN Batch 66/1000 loss 0.103599 acc 0.925612 lr 0.00019750 grad_norm 0.597827 rank 2
2025-01-10 15:34:14,286 DEBUG TRAIN Batch 66/1100 loss 0.076776 acc 0.940179 lr 0.00019742 grad_norm 0.496047 rank 2
2025-01-10 15:34:14,286 DEBUG TRAIN Batch 66/1100 loss 0.090846 acc 0.936889 lr 0.00019742 grad_norm 0.496047 rank 1
2025-01-10 15:34:14,287 DEBUG TRAIN Batch 66/1100 loss 0.079923 acc 0.946593 lr 0.00019742 grad_norm 0.496047 rank 0
2025-01-10 15:34:38,284 DEBUG TRAIN Batch 66/1200 loss 0.076277 acc 0.947422 lr 0.00019734 grad_norm 0.520839 rank 1
2025-01-10 15:34:38,285 DEBUG TRAIN Batch 66/1200 loss 0.096459 acc 0.929078 lr 0.00019734 grad_norm 0.520839 rank 0
2025-01-10 15:34:38,285 DEBUG TRAIN Batch 66/1200 loss 0.074139 acc 0.948259 lr 0.00019734 grad_norm 0.520839 rank 2
2025-01-10 15:35:03,502 DEBUG TRAIN Batch 66/1300 loss 0.069603 acc 0.954936 lr 0.00019727 grad_norm 0.539071 rank 2
2025-01-10 15:35:03,502 DEBUG TRAIN Batch 66/1300 loss 0.077211 acc 0.951505 lr 0.00019727 grad_norm 0.539071 rank 0
2025-01-10 15:35:03,503 DEBUG TRAIN Batch 66/1300 loss 0.087971 acc 0.942096 lr 0.00019727 grad_norm 0.539071 rank 1
2025-01-10 15:35:27,813 DEBUG TRAIN Batch 66/1400 loss 0.102513 acc 0.918261 lr 0.00019719 grad_norm 0.541011 rank 1
2025-01-10 15:35:27,813 DEBUG TRAIN Batch 66/1400 loss 0.104119 acc 0.922009 lr 0.00019719 grad_norm 0.541011 rank 2
2025-01-10 15:35:27,813 DEBUG TRAIN Batch 66/1400 loss 0.069216 acc 0.953869 lr 0.00019719 grad_norm 0.541011 rank 0
2025-01-10 15:35:51,958 DEBUG TRAIN Batch 66/1500 loss 0.059495 acc 0.953165 lr 0.00019711 grad_norm 0.536517 rank 0
2025-01-10 15:35:51,959 DEBUG TRAIN Batch 66/1500 loss 0.125272 acc 0.904627 lr 0.00019711 grad_norm 0.536517 rank 2
2025-01-10 15:35:51,960 DEBUG TRAIN Batch 66/1500 loss 0.103871 acc 0.932503 lr 0.00019711 grad_norm 0.536517 rank 1
2025-01-10 15:36:17,190 DEBUG TRAIN Batch 66/1600 loss 0.110475 acc 0.921986 lr 0.00019704 grad_norm 0.561815 rank 0
2025-01-10 15:36:17,191 DEBUG TRAIN Batch 66/1600 loss 0.107683 acc 0.927105 lr 0.00019704 grad_norm 0.561815 rank 2
2025-01-10 15:36:17,191 DEBUG TRAIN Batch 66/1600 loss 0.105215 acc 0.927111 lr 0.00019704 grad_norm 0.561815 rank 1
2025-01-10 15:36:41,475 DEBUG TRAIN Batch 66/1700 loss 0.109964 acc 0.920725 lr 0.00019696 grad_norm 0.575409 rank 2
2025-01-10 15:36:41,475 DEBUG TRAIN Batch 66/1700 loss 0.084796 acc 0.941066 lr 0.00019696 grad_norm 0.575409 rank 0
2025-01-10 15:36:41,476 DEBUG TRAIN Batch 66/1700 loss 0.114932 acc 0.930475 lr 0.00019696 grad_norm 0.575409 rank 1
2025-01-10 15:37:06,122 DEBUG TRAIN Batch 66/1800 loss 0.110050 acc 0.929302 lr 0.00019688 grad_norm 0.549036 rank 2
2025-01-10 15:37:06,122 DEBUG TRAIN Batch 66/1800 loss 0.097876 acc 0.931798 lr 0.00019688 grad_norm 0.549036 rank 0
2025-01-10 15:37:06,124 DEBUG TRAIN Batch 66/1800 loss 0.078936 acc 0.939937 lr 0.00019688 grad_norm 0.549036 rank 1
2025-01-10 15:37:30,593 DEBUG TRAIN Batch 66/1900 loss 0.095068 acc 0.928335 lr 0.00019681 grad_norm 0.529874 rank 2
2025-01-10 15:37:30,593 DEBUG TRAIN Batch 66/1900 loss 0.107735 acc 0.926126 lr 0.00019681 grad_norm 0.529874 rank 1
2025-01-10 15:37:30,594 DEBUG TRAIN Batch 66/1900 loss 0.072509 acc 0.954774 lr 0.00019681 grad_norm 0.529874 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 15:38:50,207 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 15:38:50,214 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 15:38:50,641 INFO Epoch 66 Step 64583 on_batch_end True CV rank 0
2025-01-10 15:38:50,641 INFO Epoch 66 Step 64583 on_batch_end True CV rank 1
2025-01-10 15:38:50,642 INFO Epoch 66 Step 64583 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 15:38:59,672 DEBUG CV Batch 66/100 loss 0.034959 acc 0.986622  rank 0
2025-01-10 15:39:00,139 DEBUG CV Batch 66/100 loss 0.034959 acc 0.986622  rank 2
2025-01-10 15:39:00,188 INFO Epoch 66 Step 64583 CV info lr 0.00019674825847328225 0 rank loss_2.1212163042387386 acc_0.7776216196647862
2025-01-10 15:39:00,488 DEBUG CV Batch 66/100 loss 0.034959 acc 0.986622  rank 1
2025-01-10 15:39:00,683 INFO Epoch 66 Step 64583 CV info lr 0.00019674825847328225 2 rank loss_2.1212163042387386 acc_0.7776216196647862
2025-01-10 15:39:01,010 INFO Epoch 66 Step 64583 CV info lr 0.00019674825847328225 1 rank loss_2.1212163042387386 acc_0.7776216196647862
2025-01-10 15:39:01,484 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_66_whole.pt
2025-01-10 15:39:01,506 INFO Added key: store_based_barrier_key:69 to store for rank: 0
2025-01-10 15:39:01,516 INFO Added key: store_based_barrier_key:69 to store for rank: 2
2025-01-10 15:39:01,516 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:69 with 3 nodes.
2025-01-10 15:39:01,516 INFO Added key: store_based_barrier_key:69 to store for rank: 1
2025-01-10 15:39:01,517 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:69 with 3 nodes.
2025-01-10 15:39:01,520 INFO Epoch 67 TRAIN info lr 0.00019674825847328225 rank 2
2025-01-10 15:39:01,520 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 15:39:01,526 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:69 with 3 nodes.
2025-01-10 15:39:01,527 INFO Epoch 67 TRAIN info lr 0.00019674825847328225 rank 1
2025-01-10 15:39:01,527 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 15:39:01,531 INFO Epoch 67 TRAIN info lr 0.00019674825847328225 rank 0
2025-01-10 15:39:01,531 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 15:39:34,619 DEBUG TRAIN Batch 67/100 loss 0.066742 acc 0.954846 lr 0.00019667 grad_norm 0.512946 rank 0
2025-01-10 15:39:34,620 DEBUG TRAIN Batch 67/100 loss 0.095809 acc 0.926023 lr 0.00019667 grad_norm 0.512946 rank 2
2025-01-10 15:39:34,621 DEBUG TRAIN Batch 67/100 loss 0.079984 acc 0.942289 lr 0.00019667 grad_norm 0.512946 rank 1
2025-01-10 15:39:58,641 DEBUG TRAIN Batch 67/200 loss 0.076758 acc 0.951190 lr 0.00019660 grad_norm 0.512980 rank 0
2025-01-10 15:39:58,641 DEBUG TRAIN Batch 67/200 loss 0.088952 acc 0.937828 lr 0.00019660 grad_norm 0.512980 rank 1
2025-01-10 15:39:58,641 DEBUG TRAIN Batch 67/200 loss 0.064077 acc 0.950122 lr 0.00019660 grad_norm 0.512980 rank 2
2025-01-10 15:40:22,703 DEBUG TRAIN Batch 67/300 loss 0.117376 acc 0.926104 lr 0.00019652 grad_norm 0.493219 rank 2
2025-01-10 15:40:22,703 DEBUG TRAIN Batch 67/300 loss 0.043386 acc 0.977528 lr 0.00019652 grad_norm 0.493219 rank 0
2025-01-10 15:40:22,703 DEBUG TRAIN Batch 67/300 loss 0.071986 acc 0.947316 lr 0.00019652 grad_norm 0.493219 rank 1
2025-01-10 15:40:46,803 DEBUG TRAIN Batch 67/400 loss 0.075589 acc 0.959413 lr 0.00019644 grad_norm 0.485138 rank 2
2025-01-10 15:40:46,803 DEBUG TRAIN Batch 67/400 loss 0.093218 acc 0.937376 lr 0.00019644 grad_norm 0.485138 rank 0
2025-01-10 15:40:46,804 DEBUG TRAIN Batch 67/400 loss 0.095564 acc 0.937828 lr 0.00019644 grad_norm 0.485138 rank 1
2025-01-10 15:41:10,621 DEBUG TRAIN Batch 67/500 loss 0.072518 acc 0.947835 lr 0.00019637 grad_norm 0.496570 rank 0
2025-01-10 15:41:10,621 DEBUG TRAIN Batch 67/500 loss 0.081632 acc 0.940855 lr 0.00019637 grad_norm 0.496570 rank 2
2025-01-10 15:41:10,622 DEBUG TRAIN Batch 67/500 loss 0.081736 acc 0.951613 lr 0.00019637 grad_norm 0.496570 rank 1
2025-01-10 15:41:34,641 DEBUG TRAIN Batch 67/600 loss 0.084129 acc 0.936041 lr 0.00019629 grad_norm 0.509032 rank 0
2025-01-10 15:41:34,641 DEBUG TRAIN Batch 67/600 loss 0.088662 acc 0.943599 lr 0.00019629 grad_norm 0.509032 rank 2
2025-01-10 15:41:34,642 DEBUG TRAIN Batch 67/600 loss 0.071907 acc 0.953020 lr 0.00019629 grad_norm 0.509032 rank 1
2025-01-10 15:41:58,392 DEBUG TRAIN Batch 67/700 loss 0.055896 acc 0.958165 lr 0.00019622 grad_norm 0.496202 rank 0
2025-01-10 15:41:58,393 DEBUG TRAIN Batch 67/700 loss 0.072239 acc 0.954158 lr 0.00019622 grad_norm 0.496202 rank 1
2025-01-10 15:41:58,393 DEBUG TRAIN Batch 67/700 loss 0.083678 acc 0.936670 lr 0.00019622 grad_norm 0.496202 rank 2
2025-01-10 15:42:22,714 DEBUG TRAIN Batch 67/800 loss 0.084525 acc 0.937848 lr 0.00019614 grad_norm 0.531200 rank 0
2025-01-10 15:42:22,714 DEBUG TRAIN Batch 67/800 loss 0.100814 acc 0.926884 lr 0.00019614 grad_norm 0.531200 rank 2
2025-01-10 15:42:22,715 DEBUG TRAIN Batch 67/800 loss 0.096154 acc 0.944598 lr 0.00019614 grad_norm 0.531200 rank 1
2025-01-10 15:42:46,232 DEBUG TRAIN Batch 67/900 loss 0.074129 acc 0.946058 lr 0.00019607 grad_norm 0.506613 rank 0
2025-01-10 15:42:46,232 DEBUG TRAIN Batch 67/900 loss 0.101180 acc 0.928070 lr 0.00019607 grad_norm 0.506613 rank 1
2025-01-10 15:42:46,232 DEBUG TRAIN Batch 67/900 loss 0.096283 acc 0.935630 lr 0.00019607 grad_norm 0.506613 rank 2
2025-01-10 15:43:10,186 DEBUG TRAIN Batch 67/1000 loss 0.078648 acc 0.948767 lr 0.00019599 grad_norm 0.536836 rank 0
2025-01-10 15:43:10,186 DEBUG TRAIN Batch 67/1000 loss 0.095297 acc 0.932765 lr 0.00019599 grad_norm 0.536836 rank 2
2025-01-10 15:43:10,186 DEBUG TRAIN Batch 67/1000 loss 0.074411 acc 0.942825 lr 0.00019599 grad_norm 0.536836 rank 1
2025-01-10 15:43:35,266 DEBUG TRAIN Batch 67/1100 loss 0.093143 acc 0.933579 lr 0.00019592 grad_norm 0.524723 rank 0
2025-01-10 15:43:35,266 DEBUG TRAIN Batch 67/1100 loss 0.094827 acc 0.932584 lr 0.00019592 grad_norm 0.524723 rank 1
2025-01-10 15:43:35,266 DEBUG TRAIN Batch 67/1100 loss 0.074102 acc 0.947191 lr 0.00019592 grad_norm 0.524723 rank 2
2025-01-10 15:43:59,195 DEBUG TRAIN Batch 67/1200 loss 0.086407 acc 0.937044 lr 0.00019584 grad_norm 0.471732 rank 2
2025-01-10 15:43:59,195 DEBUG TRAIN Batch 67/1200 loss 0.066052 acc 0.963554 lr 0.00019584 grad_norm 0.471732 rank 0
2025-01-10 15:43:59,196 DEBUG TRAIN Batch 67/1200 loss 0.068642 acc 0.951025 lr 0.00019584 grad_norm 0.471732 rank 1
2025-01-10 15:44:23,240 DEBUG TRAIN Batch 67/1300 loss 0.081038 acc 0.946375 lr 0.00019577 grad_norm 0.512059 rank 1
2025-01-10 15:44:23,240 DEBUG TRAIN Batch 67/1300 loss 0.116255 acc 0.921409 lr 0.00019577 grad_norm 0.512059 rank 0
2025-01-10 15:44:23,240 DEBUG TRAIN Batch 67/1300 loss 0.094062 acc 0.936477 lr 0.00019577 grad_norm 0.512059 rank 2
2025-01-10 15:44:47,756 DEBUG TRAIN Batch 67/1400 loss 0.098186 acc 0.931520 lr 0.00019569 grad_norm 0.523414 rank 0
2025-01-10 15:44:47,756 DEBUG TRAIN Batch 67/1400 loss 0.087888 acc 0.942529 lr 0.00019569 grad_norm 0.523414 rank 2
2025-01-10 15:44:47,757 DEBUG TRAIN Batch 67/1400 loss 0.103537 acc 0.923954 lr 0.00019569 grad_norm 0.523414 rank 1
2025-01-10 15:45:12,381 DEBUG TRAIN Batch 67/1500 loss 0.091740 acc 0.939834 lr 0.00019562 grad_norm 0.551168 rank 1
2025-01-10 15:45:12,381 DEBUG TRAIN Batch 67/1500 loss 0.096150 acc 0.940452 lr 0.00019562 grad_norm 0.551168 rank 0
2025-01-10 15:45:12,381 DEBUG TRAIN Batch 67/1500 loss 0.081134 acc 0.940252 lr 0.00019562 grad_norm 0.551168 rank 2
2025-01-10 15:45:36,607 DEBUG TRAIN Batch 67/1600 loss 0.086533 acc 0.931132 lr 0.00019554 grad_norm 0.549261 rank 2
2025-01-10 15:45:36,608 DEBUG TRAIN Batch 67/1600 loss 0.112144 acc 0.927752 lr 0.00019554 grad_norm 0.549261 rank 0
2025-01-10 15:45:36,608 DEBUG TRAIN Batch 67/1600 loss 0.058695 acc 0.972650 lr 0.00019554 grad_norm 0.549261 rank 1
2025-01-10 15:46:01,182 DEBUG TRAIN Batch 67/1700 loss 0.103296 acc 0.935169 lr 0.00019547 grad_norm 0.527112 rank 2
2025-01-10 15:46:01,182 DEBUG TRAIN Batch 67/1700 loss 0.078489 acc 0.947907 lr 0.00019547 grad_norm 0.527112 rank 1
2025-01-10 15:46:01,183 DEBUG TRAIN Batch 67/1700 loss 0.115396 acc 0.925401 lr 0.00019547 grad_norm 0.527112 rank 0
2025-01-10 15:46:25,351 DEBUG TRAIN Batch 67/1800 loss 0.081298 acc 0.949167 lr 0.00019539 grad_norm 0.465333 rank 1
2025-01-10 15:46:25,351 DEBUG TRAIN Batch 67/1800 loss 0.081224 acc 0.939770 lr 0.00019539 grad_norm 0.465333 rank 0
2025-01-10 15:46:25,352 DEBUG TRAIN Batch 67/1800 loss 0.073075 acc 0.950820 lr 0.00019539 grad_norm 0.465333 rank 2
2025-01-10 15:46:49,405 DEBUG TRAIN Batch 67/1900 loss 0.090059 acc 0.931166 lr 0.00019532 grad_norm 0.518210 rank 2
2025-01-10 15:46:49,405 DEBUG TRAIN Batch 67/1900 loss 0.089413 acc 0.935772 lr 0.00019532 grad_norm 0.518210 rank 0
2025-01-10 15:46:49,406 DEBUG TRAIN Batch 67/1900 loss 0.060669 acc 0.959581 lr 0.00019532 grad_norm 0.518210 rank 1
2025-01-10 15:47:15,068 DEBUG TRAIN Batch 67/2000 loss 0.107956 acc 0.924791 lr 0.00019524 grad_norm 0.548129 rank 1
2025-01-10 15:47:15,068 DEBUG TRAIN Batch 67/2000 loss 0.084712 acc 0.942771 lr 0.00019524 grad_norm 0.548129 rank 2
2025-01-10 15:47:15,068 DEBUG TRAIN Batch 67/2000 loss 0.107776 acc 0.921778 lr 0.00019524 grad_norm 0.548129 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 15:48:17,739 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59988ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 15:48:17,745 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 15:48:18,200 INFO Epoch 67 Step 65588 on_batch_end True CV rank 0
2025-01-10 15:48:18,200 INFO Epoch 67 Step 65588 on_batch_end True CV rank 1
2025-01-10 15:48:18,200 INFO Epoch 67 Step 65588 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 15:48:27,283 DEBUG CV Batch 67/100 loss 0.017931 acc 0.996656  rank 0
2025-01-10 15:48:27,543 DEBUG CV Batch 67/100 loss 0.017931 acc 0.996656  rank 2
2025-01-10 15:48:27,739 DEBUG CV Batch 67/100 loss 0.017931 acc 0.996656  rank 1
2025-01-10 15:48:27,797 INFO Epoch 67 Step 65588 CV info lr 0.00019523506004270506 0 rank loss_2.119842450001702 acc_0.7782057893642208
2025-01-10 15:48:28,027 INFO Epoch 67 Step 65588 CV info lr 0.00019523506004270506 2 rank loss_2.119842450001702 acc_0.7782057893642208
2025-01-10 15:48:28,275 INFO Epoch 67 Step 65588 CV info lr 0.00019523506004270506 1 rank loss_2.119842450001702 acc_0.7782057893642208
2025-01-10 15:48:29,061 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_67_whole.pt
2025-01-10 15:48:29,083 INFO Added key: store_based_barrier_key:70 to store for rank: 0
2025-01-10 15:48:29,093 INFO Added key: store_based_barrier_key:70 to store for rank: 2
2025-01-10 15:48:29,093 INFO Added key: store_based_barrier_key:70 to store for rank: 1
2025-01-10 15:48:29,093 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:70 with 3 nodes.
2025-01-10 15:48:29,100 INFO Epoch 68 TRAIN info lr 0.00019523506004270506 rank 1
2025-01-10 15:48:29,100 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 15:48:29,103 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:70 with 3 nodes.
2025-01-10 15:48:29,103 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:70 with 3 nodes.
2025-01-10 15:48:29,104 INFO Epoch 68 TRAIN info lr 0.00019523506004270506 rank 0
2025-01-10 15:48:29,104 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 15:48:29,111 INFO Epoch 68 TRAIN info lr 0.00019523506004270506 rank 2
2025-01-10 15:48:29,111 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 15:49:01,004 DEBUG TRAIN Batch 68/100 loss 0.069840 acc 0.946856 lr 0.00019516 grad_norm 0.484776 rank 0
2025-01-10 15:49:01,004 DEBUG TRAIN Batch 68/100 loss 0.104187 acc 0.926702 lr 0.00019516 grad_norm 0.484776 rank 2
2025-01-10 15:49:01,005 DEBUG TRAIN Batch 68/100 loss 0.076748 acc 0.946678 lr 0.00019516 grad_norm 0.484776 rank 1
2025-01-10 15:49:24,963 DEBUG TRAIN Batch 68/200 loss 0.059580 acc 0.965854 lr 0.00019509 grad_norm 0.479766 rank 0
2025-01-10 15:49:24,964 DEBUG TRAIN Batch 68/200 loss 0.064931 acc 0.955649 lr 0.00019509 grad_norm 0.479766 rank 2
2025-01-10 15:49:24,970 DEBUG TRAIN Batch 68/200 loss 0.070230 acc 0.954377 lr 0.00019509 grad_norm 0.479766 rank 1
2025-01-10 15:49:49,576 DEBUG TRAIN Batch 68/300 loss 0.102200 acc 0.934959 lr 0.00019501 grad_norm 0.510573 rank 1
2025-01-10 15:49:49,576 DEBUG TRAIN Batch 68/300 loss 0.069517 acc 0.953271 lr 0.00019501 grad_norm 0.510573 rank 2
2025-01-10 15:49:49,576 DEBUG TRAIN Batch 68/300 loss 0.100992 acc 0.933458 lr 0.00019501 grad_norm 0.510573 rank 0
2025-01-10 15:50:13,856 DEBUG TRAIN Batch 68/400 loss 0.084878 acc 0.946285 lr 0.00019494 grad_norm 0.502193 rank 0
2025-01-10 15:50:13,856 DEBUG TRAIN Batch 68/400 loss 0.077855 acc 0.950000 lr 0.00019494 grad_norm 0.502193 rank 2
2025-01-10 15:50:13,856 DEBUG TRAIN Batch 68/400 loss 0.076305 acc 0.949288 lr 0.00019494 grad_norm 0.502193 rank 1
2025-01-10 15:50:38,640 DEBUG TRAIN Batch 68/500 loss 0.075679 acc 0.940037 lr 0.00019486 grad_norm 0.500126 rank 1
2025-01-10 15:50:38,641 DEBUG TRAIN Batch 68/500 loss 0.047291 acc 0.969072 lr 0.00019486 grad_norm 0.500126 rank 2
2025-01-10 15:50:38,641 DEBUG TRAIN Batch 68/500 loss 0.075725 acc 0.945629 lr 0.00019486 grad_norm 0.500126 rank 0
2025-01-10 15:51:02,953 DEBUG TRAIN Batch 68/600 loss 0.093528 acc 0.931985 lr 0.00019479 grad_norm 0.506760 rank 0
2025-01-10 15:51:02,954 DEBUG TRAIN Batch 68/600 loss 0.066633 acc 0.953141 lr 0.00019479 grad_norm 0.506760 rank 1
2025-01-10 15:51:02,954 DEBUG TRAIN Batch 68/600 loss 0.108531 acc 0.933678 lr 0.00019479 grad_norm 0.506760 rank 2
2025-01-10 15:51:27,962 DEBUG TRAIN Batch 68/700 loss 0.065484 acc 0.962096 lr 0.00019472 grad_norm 0.504796 rank 0
2025-01-10 15:51:27,962 DEBUG TRAIN Batch 68/700 loss 0.087597 acc 0.936508 lr 0.00019472 grad_norm 0.504796 rank 2
2025-01-10 15:51:27,962 DEBUG TRAIN Batch 68/700 loss 0.074147 acc 0.945799 lr 0.00019472 grad_norm 0.504796 rank 1
2025-01-10 15:51:52,254 DEBUG TRAIN Batch 68/800 loss 0.081170 acc 0.944981 lr 0.00019464 grad_norm 0.507114 rank 0
2025-01-10 15:51:52,254 DEBUG TRAIN Batch 68/800 loss 0.057200 acc 0.956763 lr 0.00019464 grad_norm 0.507114 rank 1
2025-01-10 15:51:52,255 DEBUG TRAIN Batch 68/800 loss 0.083404 acc 0.945021 lr 0.00019464 grad_norm 0.507114 rank 2
2025-01-10 15:52:16,338 DEBUG TRAIN Batch 68/900 loss 0.089150 acc 0.938605 lr 0.00019457 grad_norm 0.514673 rank 1
2025-01-10 15:52:16,339 DEBUG TRAIN Batch 68/900 loss 0.082029 acc 0.949896 lr 0.00019457 grad_norm 0.514673 rank 0
2025-01-10 15:52:16,339 DEBUG TRAIN Batch 68/900 loss 0.078622 acc 0.945455 lr 0.00019457 grad_norm 0.514673 rank 2
2025-01-10 15:52:40,852 DEBUG TRAIN Batch 68/1000 loss 0.096132 acc 0.938061 lr 0.00019450 grad_norm 0.547102 rank 0
2025-01-10 15:52:40,852 DEBUG TRAIN Batch 68/1000 loss 0.098452 acc 0.933515 lr 0.00019450 grad_norm 0.547102 rank 2
2025-01-10 15:52:40,852 DEBUG TRAIN Batch 68/1000 loss 0.102191 acc 0.930281 lr 0.00019450 grad_norm 0.547102 rank 1
2025-01-10 15:53:04,715 DEBUG TRAIN Batch 68/1100 loss 0.075454 acc 0.949087 lr 0.00019442 grad_norm 0.501223 rank 2
2025-01-10 15:53:04,716 DEBUG TRAIN Batch 68/1100 loss 0.092516 acc 0.929539 lr 0.00019442 grad_norm 0.501223 rank 0
2025-01-10 15:53:04,716 DEBUG TRAIN Batch 68/1100 loss 0.092468 acc 0.934653 lr 0.00019442 grad_norm 0.501223 rank 1
2025-01-10 15:53:29,025 DEBUG TRAIN Batch 68/1200 loss 0.088590 acc 0.934252 lr 0.00019435 grad_norm 0.527209 rank 1
2025-01-10 15:53:29,025 DEBUG TRAIN Batch 68/1200 loss 0.090185 acc 0.932115 lr 0.00019435 grad_norm 0.527209 rank 0
2025-01-10 15:53:29,026 DEBUG TRAIN Batch 68/1200 loss 0.070130 acc 0.953998 lr 0.00019435 grad_norm 0.527209 rank 2
2025-01-10 15:53:54,464 DEBUG TRAIN Batch 68/1300 loss 0.080129 acc 0.946844 lr 0.00019427 grad_norm 0.495079 rank 1
2025-01-10 15:53:54,464 DEBUG TRAIN Batch 68/1300 loss 0.088368 acc 0.936492 lr 0.00019427 grad_norm 0.495079 rank 0
2025-01-10 15:53:54,464 DEBUG TRAIN Batch 68/1300 loss 0.065121 acc 0.954963 lr 0.00019427 grad_norm 0.495079 rank 2
2025-01-10 15:54:18,163 DEBUG TRAIN Batch 68/1400 loss 0.092728 acc 0.928571 lr 0.00019420 grad_norm 0.483999 rank 0
2025-01-10 15:54:18,163 DEBUG TRAIN Batch 68/1400 loss 0.087180 acc 0.944990 lr 0.00019420 grad_norm 0.483999 rank 2
2025-01-10 15:54:18,163 DEBUG TRAIN Batch 68/1400 loss 0.068816 acc 0.944245 lr 0.00019420 grad_norm 0.483999 rank 1
2025-01-10 15:54:42,184 DEBUG TRAIN Batch 68/1500 loss 0.041013 acc 0.973502 lr 0.00019413 grad_norm 0.467807 rank 1
2025-01-10 15:54:42,184 DEBUG TRAIN Batch 68/1500 loss 0.064248 acc 0.953086 lr 0.00019413 grad_norm 0.467807 rank 2
2025-01-10 15:54:42,184 DEBUG TRAIN Batch 68/1500 loss 0.083712 acc 0.941683 lr 0.00019413 grad_norm 0.467807 rank 0
2025-01-10 15:55:06,733 DEBUG TRAIN Batch 68/1600 loss 0.079442 acc 0.949515 lr 0.00019406 grad_norm 0.486506 rank 2
2025-01-10 15:55:06,733 DEBUG TRAIN Batch 68/1600 loss 0.074086 acc 0.948873 lr 0.00019406 grad_norm 0.486506 rank 1
2025-01-10 15:55:06,733 DEBUG TRAIN Batch 68/1600 loss 0.083562 acc 0.935111 lr 0.00019406 grad_norm 0.486506 rank 0
2025-01-10 15:55:30,955 DEBUG TRAIN Batch 68/1700 loss 0.063154 acc 0.955083 lr 0.00019398 grad_norm 0.522404 rank 1
2025-01-10 15:55:30,956 DEBUG TRAIN Batch 68/1700 loss 0.100971 acc 0.931495 lr 0.00019398 grad_norm 0.522404 rank 0
2025-01-10 15:55:30,956 DEBUG TRAIN Batch 68/1700 loss 0.072015 acc 0.953684 lr 0.00019398 grad_norm 0.522404 rank 2
2025-01-10 15:55:55,089 DEBUG TRAIN Batch 68/1800 loss 0.087812 acc 0.941799 lr 0.00019391 grad_norm 0.474741 rank 1
2025-01-10 15:55:55,090 DEBUG TRAIN Batch 68/1800 loss 0.086622 acc 0.944139 lr 0.00019391 grad_norm 0.474741 rank 0
2025-01-10 15:55:55,090 DEBUG TRAIN Batch 68/1800 loss 0.089997 acc 0.935226 lr 0.00019391 grad_norm 0.474741 rank 2
2025-01-10 15:56:19,068 DEBUG TRAIN Batch 68/1900 loss 0.065077 acc 0.950276 lr 0.00019384 grad_norm 0.503709 rank 2
2025-01-10 15:56:19,068 DEBUG TRAIN Batch 68/1900 loss 0.063986 acc 0.957360 lr 0.00019384 grad_norm 0.503709 rank 0
2025-01-10 15:56:19,068 DEBUG TRAIN Batch 68/1900 loss 0.087081 acc 0.930144 lr 0.00019384 grad_norm 0.503709 rank 1
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 15:57:22,932 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 15:57:22,946 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 15:57:23,343 INFO Epoch 68 Step 66546 on_batch_end True CV rank 1
2025-01-10 15:57:23,343 INFO Epoch 68 Step 66546 on_batch_end True CV rank 2
2025-01-10 15:57:23,343 INFO Epoch 68 Step 66546 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 15:57:32,692 DEBUG CV Batch 68/100 loss 0.026221 acc 0.993311  rank 2
2025-01-10 15:57:32,789 DEBUG CV Batch 68/100 loss 0.026221 acc 0.993311  rank 0
2025-01-10 15:57:33,028 DEBUG CV Batch 68/100 loss 0.026221 acc 0.993311  rank 1
2025-01-10 15:57:33,196 INFO Epoch 68 Step 66546 CV info lr 0.0001938246580714603 2 rank loss_2.1484013458411617 acc_0.7774391864475451
2025-01-10 15:57:33,305 INFO Epoch 68 Step 66546 CV info lr 0.0001938246580714603 0 rank loss_2.1484013458411617 acc_0.7774391864475451
2025-01-10 15:57:33,533 INFO Epoch 68 Step 66546 CV info lr 0.0001938246580714603 1 rank loss_2.1484013458411617 acc_0.7774391864475451
2025-01-10 15:57:34,580 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_68_whole.pt
2025-01-10 15:57:34,592 INFO Added key: store_based_barrier_key:71 to store for rank: 0
2025-01-10 15:57:34,602 INFO Added key: store_based_barrier_key:71 to store for rank: 2
2025-01-10 15:57:34,602 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:71 with 3 nodes.
2025-01-10 15:57:34,602 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:71 with 3 nodes.
2025-01-10 15:57:34,602 INFO Added key: store_based_barrier_key:71 to store for rank: 1
2025-01-10 15:57:34,602 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:71 with 3 nodes.
2025-01-10 15:57:34,606 INFO Epoch 69 TRAIN info lr 0.0001938246580714603 rank 2
2025-01-10 15:57:34,606 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 15:57:34,611 INFO Epoch 69 TRAIN info lr 0.0001938246580714603 rank 1
2025-01-10 15:57:34,611 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 15:57:34,612 INFO Epoch 69 TRAIN info lr 0.0001938246580714603 rank 0
2025-01-10 15:57:34,612 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 15:58:07,706 DEBUG TRAIN Batch 69/100 loss 0.085898 acc 0.940701 lr 0.00019375 grad_norm 0.465849 rank 0
2025-01-10 15:58:07,706 DEBUG TRAIN Batch 69/100 loss 0.063153 acc 0.962687 lr 0.00019375 grad_norm 0.465849 rank 1
2025-01-10 15:58:07,707 DEBUG TRAIN Batch 69/100 loss 0.078807 acc 0.944995 lr 0.00019375 grad_norm 0.465849 rank 2
2025-01-10 15:58:31,711 DEBUG TRAIN Batch 69/200 loss 0.068228 acc 0.955936 lr 0.00019368 grad_norm 0.469435 rank 0
2025-01-10 15:58:31,711 DEBUG TRAIN Batch 69/200 loss 0.074766 acc 0.948690 lr 0.00019368 grad_norm 0.469435 rank 2
2025-01-10 15:58:31,711 DEBUG TRAIN Batch 69/200 loss 0.062354 acc 0.953789 lr 0.00019368 grad_norm 0.469435 rank 1
2025-01-10 15:58:55,934 DEBUG TRAIN Batch 69/300 loss 0.079986 acc 0.949634 lr 0.00019361 grad_norm 0.465655 rank 2
2025-01-10 15:58:55,934 DEBUG TRAIN Batch 69/300 loss 0.061757 acc 0.957806 lr 0.00019361 grad_norm 0.465655 rank 1
2025-01-10 15:58:55,935 DEBUG TRAIN Batch 69/300 loss 0.062246 acc 0.968372 lr 0.00019361 grad_norm 0.465655 rank 0
2025-01-10 15:59:20,177 DEBUG TRAIN Batch 69/400 loss 0.070983 acc 0.955508 lr 0.00019353 grad_norm 0.477490 rank 1
2025-01-10 15:59:20,178 DEBUG TRAIN Batch 69/400 loss 0.055724 acc 0.965435 lr 0.00019353 grad_norm 0.477490 rank 2
2025-01-10 15:59:20,181 DEBUG TRAIN Batch 69/400 loss 0.081468 acc 0.944149 lr 0.00019353 grad_norm 0.477490 rank 0
2025-01-10 15:59:45,401 DEBUG TRAIN Batch 69/500 loss 0.094149 acc 0.934743 lr 0.00019346 grad_norm 0.510451 rank 2
2025-01-10 15:59:45,401 DEBUG TRAIN Batch 69/500 loss 0.077497 acc 0.940969 lr 0.00019346 grad_norm 0.510451 rank 0
2025-01-10 15:59:45,401 DEBUG TRAIN Batch 69/500 loss 0.037802 acc 0.974446 lr 0.00019346 grad_norm 0.510451 rank 1
2025-01-10 16:00:09,738 DEBUG TRAIN Batch 69/600 loss 0.072216 acc 0.950455 lr 0.00019339 grad_norm 0.530817 rank 0
2025-01-10 16:00:09,738 DEBUG TRAIN Batch 69/600 loss 0.121512 acc 0.916017 lr 0.00019339 grad_norm 0.530817 rank 2
2025-01-10 16:00:09,738 DEBUG TRAIN Batch 69/600 loss 0.050385 acc 0.959091 lr 0.00019339 grad_norm 0.530817 rank 1
2025-01-10 16:00:34,627 DEBUG TRAIN Batch 69/700 loss 0.069620 acc 0.955405 lr 0.00019332 grad_norm 0.504642 rank 1
2025-01-10 16:00:34,627 DEBUG TRAIN Batch 69/700 loss 0.093875 acc 0.929577 lr 0.00019332 grad_norm 0.504642 rank 2
2025-01-10 16:00:34,628 DEBUG TRAIN Batch 69/700 loss 0.078283 acc 0.949254 lr 0.00019332 grad_norm 0.504642 rank 0
2025-01-10 16:01:00,472 DEBUG TRAIN Batch 69/800 loss 0.068996 acc 0.953614 lr 0.00019324 grad_norm 0.486393 rank 1
2025-01-10 16:01:00,473 DEBUG TRAIN Batch 69/800 loss 0.075014 acc 0.955338 lr 0.00019324 grad_norm 0.486393 rank 0
2025-01-10 16:01:00,473 DEBUG TRAIN Batch 69/800 loss 0.074955 acc 0.940444 lr 0.00019324 grad_norm 0.486393 rank 2
2025-01-10 16:01:24,912 DEBUG TRAIN Batch 69/900 loss 0.073300 acc 0.947966 lr 0.00019317 grad_norm 0.530754 rank 2
2025-01-10 16:01:24,912 DEBUG TRAIN Batch 69/900 loss 0.095184 acc 0.937063 lr 0.00019317 grad_norm 0.530754 rank 0
2025-01-10 16:01:24,912 DEBUG TRAIN Batch 69/900 loss 0.079268 acc 0.945084 lr 0.00019317 grad_norm 0.530754 rank 1
2025-01-10 16:01:48,953 DEBUG TRAIN Batch 69/1000 loss 0.088914 acc 0.942366 lr 0.00019310 grad_norm 0.500148 rank 2
2025-01-10 16:01:48,953 DEBUG TRAIN Batch 69/1000 loss 0.091266 acc 0.937001 lr 0.00019310 grad_norm 0.500148 rank 0
2025-01-10 16:01:48,953 DEBUG TRAIN Batch 69/1000 loss 0.084048 acc 0.947959 lr 0.00019310 grad_norm 0.500148 rank 1
2025-01-10 16:02:14,567 DEBUG TRAIN Batch 69/1100 loss 0.043708 acc 0.973813 lr 0.00019303 grad_norm 0.482708 rank 1
2025-01-10 16:02:14,568 DEBUG TRAIN Batch 69/1100 loss 0.076318 acc 0.955117 lr 0.00019303 grad_norm 0.482708 rank 0
2025-01-10 16:02:14,568 DEBUG TRAIN Batch 69/1100 loss 0.056926 acc 0.965721 lr 0.00019303 grad_norm 0.482708 rank 2
2025-01-10 16:02:38,595 DEBUG TRAIN Batch 69/1200 loss 0.061131 acc 0.954942 lr 0.00019296 grad_norm 0.507691 rank 1
2025-01-10 16:02:38,596 DEBUG TRAIN Batch 69/1200 loss 0.106659 acc 0.924712 lr 0.00019296 grad_norm 0.507691 rank 2
2025-01-10 16:02:38,596 DEBUG TRAIN Batch 69/1200 loss 0.052281 acc 0.961421 lr 0.00019296 grad_norm 0.507691 rank 0
2025-01-10 16:03:03,240 DEBUG TRAIN Batch 69/1300 loss 0.052139 acc 0.962040 lr 0.00019288 grad_norm 0.512646 rank 1
2025-01-10 16:03:03,240 DEBUG TRAIN Batch 69/1300 loss 0.099071 acc 0.930937 lr 0.00019288 grad_norm 0.512646 rank 2
2025-01-10 16:03:03,240 DEBUG TRAIN Batch 69/1300 loss 0.090396 acc 0.936356 lr 0.00019288 grad_norm 0.512646 rank 0
2025-01-10 16:03:28,079 DEBUG TRAIN Batch 69/1400 loss 0.095595 acc 0.935484 lr 0.00019281 grad_norm 0.513131 rank 0
2025-01-10 16:03:28,079 DEBUG TRAIN Batch 69/1400 loss 0.105041 acc 0.923977 lr 0.00019281 grad_norm 0.513131 rank 1
2025-01-10 16:03:28,079 DEBUG TRAIN Batch 69/1400 loss 0.073872 acc 0.943888 lr 0.00019281 grad_norm 0.513131 rank 2
2025-01-10 16:03:52,538 DEBUG TRAIN Batch 69/1500 loss 0.093321 acc 0.932489 lr 0.00019274 grad_norm 0.522607 rank 1
2025-01-10 16:03:52,539 DEBUG TRAIN Batch 69/1500 loss 0.077114 acc 0.944134 lr 0.00019274 grad_norm 0.522607 rank 2
2025-01-10 16:03:52,539 DEBUG TRAIN Batch 69/1500 loss 0.064652 acc 0.953722 lr 0.00019274 grad_norm 0.522607 rank 0
2025-01-10 16:04:16,743 DEBUG TRAIN Batch 69/1600 loss 0.053330 acc 0.967960 lr 0.00019267 grad_norm 0.510543 rank 0
2025-01-10 16:04:16,743 DEBUG TRAIN Batch 69/1600 loss 0.095093 acc 0.935252 lr 0.00019267 grad_norm 0.510543 rank 1
2025-01-10 16:04:16,743 DEBUG TRAIN Batch 69/1600 loss 0.081036 acc 0.947988 lr 0.00019267 grad_norm 0.510543 rank 2
2025-01-10 16:04:40,435 DEBUG TRAIN Batch 69/1700 loss 0.076098 acc 0.954545 lr 0.00019260 grad_norm 0.530734 rank 1
2025-01-10 16:04:40,435 DEBUG TRAIN Batch 69/1700 loss 0.102671 acc 0.934506 lr 0.00019260 grad_norm 0.530734 rank 0
2025-01-10 16:04:40,435 DEBUG TRAIN Batch 69/1700 loss 0.098007 acc 0.937158 lr 0.00019260 grad_norm 0.530734 rank 2
2025-01-10 16:05:04,145 DEBUG TRAIN Batch 69/1800 loss 0.082971 acc 0.937905 lr 0.00019253 grad_norm 0.516117 rank 0
2025-01-10 16:05:04,146 DEBUG TRAIN Batch 69/1800 loss 0.093957 acc 0.932907 lr 0.00019253 grad_norm 0.516117 rank 2
2025-01-10 16:05:04,146 DEBUG TRAIN Batch 69/1800 loss 0.086213 acc 0.942073 lr 0.00019253 grad_norm 0.516117 rank 1
2025-01-10 16:05:28,291 DEBUG TRAIN Batch 69/1900 loss 0.041061 acc 0.967543 lr 0.00019246 grad_norm 0.513745 rank 0
2025-01-10 16:05:28,292 DEBUG TRAIN Batch 69/1900 loss 0.084123 acc 0.949911 lr 0.00019246 grad_norm 0.513745 rank 2
2025-01-10 16:05:28,292 DEBUG TRAIN Batch 69/1900 loss 0.083438 acc 0.945837 lr 0.00019246 grad_norm 0.513745 rank 1
2025-01-10 16:05:52,958 DEBUG TRAIN Batch 69/2000 loss 0.084546 acc 0.940382 lr 0.00019238 grad_norm 0.499650 rank 2
2025-01-10 16:05:52,958 DEBUG TRAIN Batch 69/2000 loss 0.091494 acc 0.935238 lr 0.00019238 grad_norm 0.499650 rank 1
2025-01-10 16:05:52,959 DEBUG TRAIN Batch 69/2000 loss 0.070972 acc 0.951070 lr 0.00019238 grad_norm 0.499650 rank 0
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 16:06:54,489 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 16:06:54,491 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 16:06:54,895 INFO Epoch 69 Step 67549 on_batch_end True CV rank 1
2025-01-10 16:06:54,895 INFO Epoch 69 Step 67549 on_batch_end True CV rank 0
2025-01-10 16:06:54,895 INFO Epoch 69 Step 67549 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 16:07:04,178 DEBUG CV Batch 69/100 loss 0.013431 acc 0.997770  rank 0
2025-01-10 16:07:04,317 DEBUG CV Batch 69/100 loss 0.013431 acc 0.997770  rank 2
2025-01-10 16:07:04,475 DEBUG CV Batch 69/100 loss 0.013431 acc 0.997770  rank 1
2025-01-10 16:07:04,713 INFO Epoch 69 Step 67549 CV info lr 0.00019238027548276488 0 rank loss_2.1489774296284865 acc_0.7784709901663295
2025-01-10 16:07:04,865 INFO Epoch 69 Step 67549 CV info lr 0.00019238027548276488 2 rank loss_2.1489774296284865 acc_0.7784709901663295
2025-01-10 16:07:04,986 INFO Epoch 69 Step 67549 CV info lr 0.00019238027548276488 1 rank loss_2.1489774296284865 acc_0.7784709901663295
2025-01-10 16:07:06,004 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_69_whole.pt
2025-01-10 16:07:06,015 INFO Added key: store_based_barrier_key:72 to store for rank: 0
2025-01-10 16:07:06,025 INFO Added key: store_based_barrier_key:72 to store for rank: 2
2025-01-10 16:07:06,026 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:72 with 3 nodes.
2025-01-10 16:07:06,026 INFO Added key: store_based_barrier_key:72 to store for rank: 1
2025-01-10 16:07:06,026 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:72 with 3 nodes.
2025-01-10 16:07:06,030 INFO Epoch 70 TRAIN info lr 0.00019238027548276488 rank 1
2025-01-10 16:07:06,030 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 16:07:06,034 INFO Epoch 70 TRAIN info lr 0.00019238027548276488 rank 2
2025-01-10 16:07:06,034 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 16:07:06,036 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:72 with 3 nodes.
2025-01-10 16:07:06,042 INFO Epoch 70 TRAIN info lr 0.00019238027548276488 rank 0
2025-01-10 16:07:06,042 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 16:07:43,344 DEBUG TRAIN Batch 70/100 loss 0.068231 acc 0.957256 lr 0.00019231 grad_norm 0.462220 rank 2
2025-01-10 16:07:43,344 DEBUG TRAIN Batch 70/100 loss 0.081567 acc 0.948745 lr 0.00019231 grad_norm 0.462220 rank 0
2025-01-10 16:07:43,345 DEBUG TRAIN Batch 70/100 loss 0.046495 acc 0.962217 lr 0.00019231 grad_norm 0.462220 rank 1
2025-01-10 16:08:07,692 DEBUG TRAIN Batch 70/200 loss 0.066471 acc 0.956876 lr 0.00019224 grad_norm 0.501363 rank 2
2025-01-10 16:08:07,692 DEBUG TRAIN Batch 70/200 loss 0.061312 acc 0.958228 lr 0.00019224 grad_norm 0.501363 rank 0
2025-01-10 16:08:07,692 DEBUG TRAIN Batch 70/200 loss 0.067693 acc 0.953033 lr 0.00019224 grad_norm 0.501363 rank 1
2025-01-10 16:08:33,651 DEBUG TRAIN Batch 70/300 loss 0.070160 acc 0.954894 lr 0.00019217 grad_norm 0.488572 rank 2
2025-01-10 16:08:33,651 DEBUG TRAIN Batch 70/300 loss 0.093792 acc 0.929283 lr 0.00019217 grad_norm 0.488572 rank 0
2025-01-10 16:08:33,652 DEBUG TRAIN Batch 70/300 loss 0.044789 acc 0.967585 lr 0.00019217 grad_norm 0.488572 rank 1
2025-01-10 16:08:57,993 DEBUG TRAIN Batch 70/400 loss 0.067393 acc 0.951456 lr 0.00019210 grad_norm 0.528095 rank 2
2025-01-10 16:08:57,993 DEBUG TRAIN Batch 70/400 loss 0.103095 acc 0.933623 lr 0.00019210 grad_norm 0.528095 rank 0
2025-01-10 16:08:57,993 DEBUG TRAIN Batch 70/400 loss 0.037818 acc 0.969697 lr 0.00019210 grad_norm 0.528095 rank 1
2025-01-10 16:09:23,033 DEBUG TRAIN Batch 70/500 loss 0.076955 acc 0.955422 lr 0.00019203 grad_norm 0.474831 rank 1
2025-01-10 16:09:23,033 DEBUG TRAIN Batch 70/500 loss 0.084337 acc 0.941712 lr 0.00019203 grad_norm 0.474831 rank 0
2025-01-10 16:09:23,033 DEBUG TRAIN Batch 70/500 loss 0.037107 acc 0.977083 lr 0.00019203 grad_norm 0.474831 rank 2
2025-01-10 16:09:48,345 DEBUG TRAIN Batch 70/600 loss 0.055048 acc 0.965368 lr 0.00019195 grad_norm 0.474559 rank 1
2025-01-10 16:09:48,346 DEBUG TRAIN Batch 70/600 loss 0.081302 acc 0.939306 lr 0.00019195 grad_norm 0.474559 rank 0
2025-01-10 16:09:48,346 DEBUG TRAIN Batch 70/600 loss 0.045694 acc 0.975460 lr 0.00019195 grad_norm 0.474559 rank 2
2025-01-10 16:10:12,305 DEBUG TRAIN Batch 70/700 loss 0.087735 acc 0.936323 lr 0.00019188 grad_norm 0.498119 rank 0
2025-01-10 16:10:12,305 DEBUG TRAIN Batch 70/700 loss 0.064138 acc 0.956243 lr 0.00019188 grad_norm 0.498119 rank 1
2025-01-10 16:10:12,305 DEBUG TRAIN Batch 70/700 loss 0.071102 acc 0.946154 lr 0.00019188 grad_norm 0.498119 rank 2
2025-01-10 16:10:37,525 DEBUG TRAIN Batch 70/800 loss 0.075642 acc 0.951797 lr 0.00019181 grad_norm 0.476281 rank 0
2025-01-10 16:10:37,525 DEBUG TRAIN Batch 70/800 loss 0.063308 acc 0.959712 lr 0.00019181 grad_norm 0.476281 rank 2
2025-01-10 16:10:37,525 DEBUG TRAIN Batch 70/800 loss 0.038462 acc 0.972881 lr 0.00019181 grad_norm 0.476281 rank 1
2025-01-10 16:11:01,062 DEBUG TRAIN Batch 70/900 loss 0.076831 acc 0.951294 lr 0.00019174 grad_norm 0.507545 rank 1
2025-01-10 16:11:01,063 DEBUG TRAIN Batch 70/900 loss 0.061464 acc 0.955208 lr 0.00019174 grad_norm 0.507545 rank 0
2025-01-10 16:11:01,063 DEBUG TRAIN Batch 70/900 loss 0.065623 acc 0.959162 lr 0.00019174 grad_norm 0.507545 rank 2
2025-01-10 16:11:24,852 DEBUG TRAIN Batch 70/1000 loss 0.091929 acc 0.944234 lr 0.00019167 grad_norm 0.496472 rank 2
2025-01-10 16:11:24,852 DEBUG TRAIN Batch 70/1000 loss 0.080879 acc 0.941176 lr 0.00019167 grad_norm 0.496472 rank 0
2025-01-10 16:11:24,853 DEBUG TRAIN Batch 70/1000 loss 0.067777 acc 0.954545 lr 0.00019167 grad_norm 0.496472 rank 1
2025-01-10 16:11:50,374 DEBUG TRAIN Batch 70/1100 loss 0.085002 acc 0.933884 lr 0.00019160 grad_norm 0.481186 rank 1
2025-01-10 16:11:50,375 DEBUG TRAIN Batch 70/1100 loss 0.075136 acc 0.947321 lr 0.00019160 grad_norm 0.481186 rank 2
2025-01-10 16:11:50,375 DEBUG TRAIN Batch 70/1100 loss 0.068049 acc 0.953833 lr 0.00019160 grad_norm 0.481186 rank 0
2025-01-10 16:12:13,672 DEBUG TRAIN Batch 70/1200 loss 0.072115 acc 0.952555 lr 0.00019153 grad_norm 0.508193 rank 0
2025-01-10 16:12:13,672 DEBUG TRAIN Batch 70/1200 loss 0.083136 acc 0.946654 lr 0.00019153 grad_norm 0.508193 rank 1
2025-01-10 16:12:13,672 DEBUG TRAIN Batch 70/1200 loss 0.068993 acc 0.951561 lr 0.00019153 grad_norm 0.508193 rank 2
2025-01-10 16:12:37,736 DEBUG TRAIN Batch 70/1300 loss 0.102776 acc 0.928312 lr 0.00019146 grad_norm 0.538274 rank 0
2025-01-10 16:12:37,736 DEBUG TRAIN Batch 70/1300 loss 0.086517 acc 0.938889 lr 0.00019146 grad_norm 0.538274 rank 2
2025-01-10 16:12:37,736 DEBUG TRAIN Batch 70/1300 loss 0.100807 acc 0.931900 lr 0.00019146 grad_norm 0.538274 rank 1
2025-01-10 16:13:00,938 DEBUG TRAIN Batch 70/1400 loss 0.076266 acc 0.953171 lr 0.00019139 grad_norm 0.492129 rank 1
2025-01-10 16:13:00,938 DEBUG TRAIN Batch 70/1400 loss 0.061363 acc 0.959835 lr 0.00019139 grad_norm 0.492129 rank 2
2025-01-10 16:13:00,938 DEBUG TRAIN Batch 70/1400 loss 0.080251 acc 0.940072 lr 0.00019139 grad_norm 0.492129 rank 0
2025-01-10 16:13:24,653 DEBUG TRAIN Batch 70/1500 loss 0.093358 acc 0.940298 lr 0.00019132 grad_norm 0.522064 rank 0
2025-01-10 16:13:24,653 DEBUG TRAIN Batch 70/1500 loss 0.078119 acc 0.944290 lr 0.00019132 grad_norm 0.522064 rank 1
2025-01-10 16:13:24,654 DEBUG TRAIN Batch 70/1500 loss 0.059983 acc 0.958376 lr 0.00019132 grad_norm 0.522064 rank 2
2025-01-10 16:13:48,086 DEBUG TRAIN Batch 70/1600 loss 0.099718 acc 0.936639 lr 0.00019125 grad_norm 0.501686 rank 0
2025-01-10 16:13:48,086 DEBUG TRAIN Batch 70/1600 loss 0.103335 acc 0.919858 lr 0.00019125 grad_norm 0.501686 rank 2
2025-01-10 16:13:48,086 DEBUG TRAIN Batch 70/1600 loss 0.077515 acc 0.950442 lr 0.00019125 grad_norm 0.501686 rank 1
2025-01-10 16:14:11,467 DEBUG TRAIN Batch 70/1700 loss 0.085617 acc 0.935630 lr 0.00019118 grad_norm 0.507724 rank 0
2025-01-10 16:14:11,468 DEBUG TRAIN Batch 70/1700 loss 0.049136 acc 0.967419 lr 0.00019118 grad_norm 0.507724 rank 2
2025-01-10 16:14:11,609 DEBUG TRAIN Batch 70/1700 loss 0.093936 acc 0.935931 lr 0.00019118 grad_norm 0.507724 rank 1
2025-01-10 16:14:35,060 DEBUG TRAIN Batch 70/1800 loss 0.079927 acc 0.949633 lr 0.00019111 grad_norm 0.510702 rank 2
2025-01-10 16:14:35,060 DEBUG TRAIN Batch 70/1800 loss 0.076775 acc 0.950334 lr 0.00019111 grad_norm 0.510702 rank 0
2025-01-10 16:14:35,060 DEBUG TRAIN Batch 70/1800 loss 0.088388 acc 0.944709 lr 0.00019111 grad_norm 0.510702 rank 1
2025-01-10 16:14:58,736 DEBUG TRAIN Batch 70/1900 loss 0.072779 acc 0.950690 lr 0.00019104 grad_norm 0.528242 rank 2
2025-01-10 16:14:58,736 DEBUG TRAIN Batch 70/1900 loss 0.093684 acc 0.936477 lr 0.00019104 grad_norm 0.528242 rank 0
2025-01-10 16:14:58,736 DEBUG TRAIN Batch 70/1900 loss 0.097059 acc 0.947844 lr 0.00019104 grad_norm 0.528242 rank 1
2025-01-10 16:15:23,104 DEBUG TRAIN Batch 70/2000 loss 0.076525 acc 0.954497 lr 0.00019097 grad_norm 0.498854 rank 2
2025-01-10 16:15:23,104 DEBUG TRAIN Batch 70/2000 loss 0.088983 acc 0.929878 lr 0.00019097 grad_norm 0.498854 rank 0
2025-01-10 16:15:23,104 DEBUG TRAIN Batch 70/2000 loss 0.064483 acc 0.951595 lr 0.00019097 grad_norm 0.498854 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 16:16:40,472 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 16:16:40,473 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 16:16:40,921 INFO Epoch 70 Step 68584 on_batch_end True CV rank 1
2025-01-10 16:16:40,921 INFO Epoch 70 Step 68584 on_batch_end True CV rank 2
2025-01-10 16:16:40,921 INFO Epoch 70 Step 68584 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 16:16:50,262 DEBUG CV Batch 70/100 loss 0.016282 acc 0.993311  rank 2
2025-01-10 16:16:50,341 DEBUG CV Batch 70/100 loss 0.016282 acc 0.993311  rank 0
2025-01-10 16:16:50,562 DEBUG CV Batch 70/100 loss 0.016282 acc 0.993311  rank 1
2025-01-10 16:16:50,793 INFO Epoch 70 Step 68584 CV info lr 0.0001909231534694942 2 rank loss_2.1601401454434126 acc_0.7782881974912527
2025-01-10 16:16:50,874 INFO Epoch 70 Step 68584 CV info lr 0.0001909231534694942 0 rank loss_2.1601401454434126 acc_0.7782881974912527
2025-01-10 16:16:51,107 INFO Epoch 70 Step 68584 CV info lr 0.0001909231534694942 1 rank loss_2.1601401454434126 acc_0.7782881974912527
2025-01-10 16:16:52,152 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_70_whole.pt
2025-01-10 16:16:52,163 INFO Added key: store_based_barrier_key:73 to store for rank: 0
2025-01-10 16:16:52,174 INFO Added key: store_based_barrier_key:73 to store for rank: 2
2025-01-10 16:16:52,174 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:73 with 3 nodes.
2025-01-10 16:16:52,174 INFO Added key: store_based_barrier_key:73 to store for rank: 1
2025-01-10 16:16:52,174 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:73 with 3 nodes.
2025-01-10 16:16:52,175 INFO Epoch 71 TRAIN info lr 0.0001909231534694942 rank 2
2025-01-10 16:16:52,175 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 16:16:52,182 INFO Epoch 71 TRAIN info lr 0.0001909231534694942 rank 1
2025-01-10 16:16:52,182 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 16:16:52,184 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:73 with 3 nodes.
2025-01-10 16:16:52,192 INFO Epoch 71 TRAIN info lr 0.0001909231534694942 rank 0
2025-01-10 16:16:52,192 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 16:17:23,220 DEBUG TRAIN Batch 71/100 loss 0.073478 acc 0.952865 lr 0.00019085 grad_norm 0.463318 rank 1
2025-01-10 16:17:23,221 DEBUG TRAIN Batch 71/100 loss 0.074075 acc 0.946729 lr 0.00019085 grad_norm 0.463318 rank 0
2025-01-10 16:17:23,221 DEBUG TRAIN Batch 71/100 loss 0.066153 acc 0.953846 lr 0.00019085 grad_norm 0.463318 rank 2
2025-01-10 16:17:47,037 DEBUG TRAIN Batch 71/200 loss 0.050252 acc 0.967172 lr 0.00019078 grad_norm 0.477193 rank 2
2025-01-10 16:17:47,038 DEBUG TRAIN Batch 71/200 loss 0.062940 acc 0.956075 lr 0.00019078 grad_norm 0.477193 rank 0
2025-01-10 16:17:47,038 DEBUG TRAIN Batch 71/200 loss 0.075818 acc 0.938249 lr 0.00019078 grad_norm 0.477193 rank 1
2025-01-10 16:18:10,645 DEBUG TRAIN Batch 71/300 loss 0.081907 acc 0.945998 lr 0.00019071 grad_norm 0.490965 rank 1
2025-01-10 16:18:10,645 DEBUG TRAIN Batch 71/300 loss 0.098595 acc 0.944802 lr 0.00019071 grad_norm 0.490965 rank 0
2025-01-10 16:18:10,645 DEBUG TRAIN Batch 71/300 loss 0.056380 acc 0.955969 lr 0.00019071 grad_norm 0.490965 rank 2
2025-01-10 16:18:34,396 DEBUG TRAIN Batch 71/400 loss 0.093844 acc 0.930140 lr 0.00019065 grad_norm 0.497971 rank 1
2025-01-10 16:18:34,396 DEBUG TRAIN Batch 71/400 loss 0.065443 acc 0.953540 lr 0.00019065 grad_norm 0.497971 rank 0
2025-01-10 16:18:34,397 DEBUG TRAIN Batch 71/400 loss 0.063592 acc 0.955836 lr 0.00019065 grad_norm 0.497971 rank 2
2025-01-10 16:18:58,091 DEBUG TRAIN Batch 71/500 loss 0.068064 acc 0.956434 lr 0.00019058 grad_norm 0.483309 rank 0
2025-01-10 16:18:58,091 DEBUG TRAIN Batch 71/500 loss 0.061385 acc 0.958371 lr 0.00019058 grad_norm 0.483309 rank 1
2025-01-10 16:18:58,091 DEBUG TRAIN Batch 71/500 loss 0.087762 acc 0.946226 lr 0.00019058 grad_norm 0.483309 rank 2
2025-01-10 16:19:21,794 DEBUG TRAIN Batch 71/600 loss 0.071729 acc 0.953092 lr 0.00019051 grad_norm 0.486952 rank 2
2025-01-10 16:19:21,794 DEBUG TRAIN Batch 71/600 loss 0.060315 acc 0.956685 lr 0.00019051 grad_norm 0.486952 rank 1
2025-01-10 16:19:21,795 DEBUG TRAIN Batch 71/600 loss 0.111253 acc 0.924348 lr 0.00019051 grad_norm 0.486952 rank 0
2025-01-10 16:19:46,059 DEBUG TRAIN Batch 71/700 loss 0.068404 acc 0.955865 lr 0.00019044 grad_norm 0.515385 rank 1
2025-01-10 16:19:46,060 DEBUG TRAIN Batch 71/700 loss 0.074049 acc 0.941527 lr 0.00019044 grad_norm 0.515385 rank 0
2025-01-10 16:19:46,060 DEBUG TRAIN Batch 71/700 loss 0.069890 acc 0.952941 lr 0.00019044 grad_norm 0.515385 rank 2
2025-01-10 16:20:10,588 DEBUG TRAIN Batch 71/800 loss 0.054540 acc 0.961118 lr 0.00019037 grad_norm 0.523891 rank 2
2025-01-10 16:20:10,588 DEBUG TRAIN Batch 71/800 loss 0.064079 acc 0.958472 lr 0.00019037 grad_norm 0.523891 rank 0
2025-01-10 16:20:10,589 DEBUG TRAIN Batch 71/800 loss 0.069096 acc 0.946429 lr 0.00019037 grad_norm 0.523891 rank 1
2025-01-10 16:20:35,300 DEBUG TRAIN Batch 71/900 loss 0.077897 acc 0.947166 lr 0.00019030 grad_norm 0.487511 rank 0
2025-01-10 16:20:35,301 DEBUG TRAIN Batch 71/900 loss 0.071337 acc 0.954984 lr 0.00019030 grad_norm 0.487511 rank 2
2025-01-10 16:20:35,301 DEBUG TRAIN Batch 71/900 loss 0.069676 acc 0.946303 lr 0.00019030 grad_norm 0.487511 rank 1
2025-01-10 16:20:59,006 DEBUG TRAIN Batch 71/1000 loss 0.103112 acc 0.919421 lr 0.00019023 grad_norm 0.502526 rank 0
2025-01-10 16:20:59,007 DEBUG TRAIN Batch 71/1000 loss 0.080947 acc 0.940747 lr 0.00019023 grad_norm 0.502526 rank 2
2025-01-10 16:20:59,007 DEBUG TRAIN Batch 71/1000 loss 0.049804 acc 0.967925 lr 0.00019023 grad_norm 0.502526 rank 1
2025-01-10 16:21:22,935 DEBUG TRAIN Batch 71/1100 loss 0.069166 acc 0.961749 lr 0.00019016 grad_norm 0.518085 rank 1
2025-01-10 16:21:22,936 DEBUG TRAIN Batch 71/1100 loss 0.085180 acc 0.939891 lr 0.00019016 grad_norm 0.518085 rank 0
2025-01-10 16:21:22,936 DEBUG TRAIN Batch 71/1100 loss 0.080983 acc 0.942991 lr 0.00019016 grad_norm 0.518085 rank 2
2025-01-10 16:21:48,120 DEBUG TRAIN Batch 71/1200 loss 0.067198 acc 0.951724 lr 0.00019009 grad_norm 0.546369 rank 0
2025-01-10 16:21:48,121 DEBUG TRAIN Batch 71/1200 loss 0.073341 acc 0.952083 lr 0.00019009 grad_norm 0.546369 rank 2
2025-01-10 16:21:48,121 DEBUG TRAIN Batch 71/1200 loss 0.103115 acc 0.926316 lr 0.00019009 grad_norm 0.546369 rank 1
2025-01-10 16:22:12,531 DEBUG TRAIN Batch 71/1300 loss 0.060444 acc 0.957747 lr 0.00019002 grad_norm 0.477013 rank 0
2025-01-10 16:22:12,531 DEBUG TRAIN Batch 71/1300 loss 0.049277 acc 0.970205 lr 0.00019002 grad_norm 0.477013 rank 1
2025-01-10 16:22:12,531 DEBUG TRAIN Batch 71/1300 loss 0.074193 acc 0.943359 lr 0.00019002 grad_norm 0.477013 rank 2
2025-01-10 16:22:36,226 DEBUG TRAIN Batch 71/1400 loss 0.079296 acc 0.944323 lr 0.00018996 grad_norm 0.519202 rank 0
2025-01-10 16:22:36,226 DEBUG TRAIN Batch 71/1400 loss 0.055351 acc 0.959509 lr 0.00018996 grad_norm 0.519202 rank 1
2025-01-10 16:22:36,226 DEBUG TRAIN Batch 71/1400 loss 0.062902 acc 0.951087 lr 0.00018996 grad_norm 0.519202 rank 2
2025-01-10 16:23:00,343 DEBUG TRAIN Batch 71/1500 loss 0.048017 acc 0.965160 lr 0.00018989 grad_norm 0.517015 rank 1
2025-01-10 16:23:00,344 DEBUG TRAIN Batch 71/1500 loss 0.093792 acc 0.940535 lr 0.00018989 grad_norm 0.517015 rank 0
2025-01-10 16:23:00,344 DEBUG TRAIN Batch 71/1500 loss 0.096488 acc 0.937113 lr 0.00018989 grad_norm 0.517015 rank 2
2025-01-10 16:23:24,729 DEBUG TRAIN Batch 71/1600 loss 0.044990 acc 0.963376 lr 0.00018982 grad_norm 0.503002 rank 1
2025-01-10 16:23:24,729 DEBUG TRAIN Batch 71/1600 loss 0.105345 acc 0.928030 lr 0.00018982 grad_norm 0.503002 rank 0
2025-01-10 16:23:24,729 DEBUG TRAIN Batch 71/1600 loss 0.063765 acc 0.956140 lr 0.00018982 grad_norm 0.503002 rank 2
2025-01-10 16:23:48,474 DEBUG TRAIN Batch 71/1700 loss 0.083773 acc 0.942708 lr 0.00018975 grad_norm 0.509438 rank 0
2025-01-10 16:23:48,474 DEBUG TRAIN Batch 71/1700 loss 0.105189 acc 0.921676 lr 0.00018975 grad_norm 0.509438 rank 2
2025-01-10 16:23:48,474 DEBUG TRAIN Batch 71/1700 loss 0.050783 acc 0.961702 lr 0.00018975 grad_norm 0.509438 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 16:25:08,251 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 16:25:08,252 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 16:25:08,732 INFO Epoch 71 Step 69474 on_batch_end True CV rank 1
2025-01-10 16:25:08,732 INFO Epoch 71 Step 69474 on_batch_end True CV rank 0
2025-01-10 16:25:08,732 INFO Epoch 71 Step 69474 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 16:25:17,921 DEBUG CV Batch 71/100 loss 0.013513 acc 0.997770  rank 0
2025-01-10 16:25:18,183 DEBUG CV Batch 71/100 loss 0.013513 acc 0.997770  rank 2
2025-01-10 16:25:18,359 DEBUG CV Batch 71/100 loss 0.013513 acc 0.997770  rank 1
2025-01-10 16:25:18,439 INFO Epoch 71 Step 69474 CV info lr 0.0001896962965323753 0 rank loss_2.1836273491611347 acc_0.7782199274291072
2025-01-10 16:25:18,713 INFO Epoch 71 Step 69474 CV info lr 0.0001896962965323753 2 rank loss_2.1836273491611347 acc_0.7782199274291072
2025-01-10 16:25:18,914 INFO Epoch 71 Step 69474 CV info lr 0.0001896962965323753 1 rank loss_2.1836273491611347 acc_0.7782199274291072
2025-01-10 16:25:19,750 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_71_whole.pt
2025-01-10 16:25:19,772 INFO Added key: store_based_barrier_key:74 to store for rank: 0
2025-01-10 16:25:19,782 INFO Added key: store_based_barrier_key:74 to store for rank: 2
2025-01-10 16:25:19,782 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:74 with 3 nodes.
2025-01-10 16:25:19,782 INFO Added key: store_based_barrier_key:74 to store for rank: 1
2025-01-10 16:25:19,782 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:74 with 3 nodes.
2025-01-10 16:25:19,786 INFO Epoch 72 TRAIN info lr 0.0001896962965323753 rank 2
2025-01-10 16:25:19,786 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 16:25:19,790 INFO Epoch 72 TRAIN info lr 0.0001896962965323753 rank 1
2025-01-10 16:25:19,790 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 16:25:19,792 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:74 with 3 nodes.
2025-01-10 16:25:19,793 INFO Epoch 72 TRAIN info lr 0.0001896962965323753 rank 0
2025-01-10 16:25:19,793 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 16:25:52,313 DEBUG TRAIN Batch 72/100 loss 0.052845 acc 0.966667 lr 0.00018963 grad_norm 0.439603 rank 0
2025-01-10 16:25:52,313 DEBUG TRAIN Batch 72/100 loss 0.074555 acc 0.955959 lr 0.00018963 grad_norm 0.439603 rank 1
2025-01-10 16:25:52,313 DEBUG TRAIN Batch 72/100 loss 0.080233 acc 0.950100 lr 0.00018963 grad_norm 0.439603 rank 2
2025-01-10 16:26:16,677 DEBUG TRAIN Batch 72/200 loss 0.062645 acc 0.959716 lr 0.00018956 grad_norm 0.456034 rank 0
2025-01-10 16:26:16,678 DEBUG TRAIN Batch 72/200 loss 0.072600 acc 0.953752 lr 0.00018956 grad_norm 0.456034 rank 2
2025-01-10 16:26:16,679 DEBUG TRAIN Batch 72/200 loss 0.060706 acc 0.958640 lr 0.00018956 grad_norm 0.456034 rank 1
2025-01-10 16:26:40,734 DEBUG TRAIN Batch 72/300 loss 0.059124 acc 0.966454 lr 0.00018949 grad_norm 0.475551 rank 0
2025-01-10 16:26:40,734 DEBUG TRAIN Batch 72/300 loss 0.063924 acc 0.956401 lr 0.00018949 grad_norm 0.475551 rank 1
2025-01-10 16:26:40,734 DEBUG TRAIN Batch 72/300 loss 0.072601 acc 0.954819 lr 0.00018949 grad_norm 0.475551 rank 2
2025-01-10 16:27:04,959 DEBUG TRAIN Batch 72/400 loss 0.089656 acc 0.937945 lr 0.00018942 grad_norm 0.509100 rank 0
2025-01-10 16:27:04,959 DEBUG TRAIN Batch 72/400 loss 0.082928 acc 0.945885 lr 0.00018942 grad_norm 0.509100 rank 2
2025-01-10 16:27:04,960 DEBUG TRAIN Batch 72/400 loss 0.052956 acc 0.963039 lr 0.00018942 grad_norm 0.509100 rank 1
2025-01-10 16:27:29,320 DEBUG TRAIN Batch 72/500 loss 0.065190 acc 0.955343 lr 0.00018936 grad_norm 0.504412 rank 2
2025-01-10 16:27:29,321 DEBUG TRAIN Batch 72/500 loss 0.106294 acc 0.920959 lr 0.00018936 grad_norm 0.504412 rank 1
2025-01-10 16:27:29,321 DEBUG TRAIN Batch 72/500 loss 0.044257 acc 0.971759 lr 0.00018936 grad_norm 0.504412 rank 0
2025-01-10 16:27:53,659 DEBUG TRAIN Batch 72/600 loss 0.079012 acc 0.945946 lr 0.00018929 grad_norm 0.517234 rank 2
2025-01-10 16:27:53,660 DEBUG TRAIN Batch 72/600 loss 0.090968 acc 0.930777 lr 0.00018929 grad_norm 0.517234 rank 1
2025-01-10 16:27:53,660 DEBUG TRAIN Batch 72/600 loss 0.060315 acc 0.962393 lr 0.00018929 grad_norm 0.517234 rank 0
2025-01-10 16:28:17,834 DEBUG TRAIN Batch 72/700 loss 0.094582 acc 0.926901 lr 0.00018922 grad_norm 0.501395 rank 1
2025-01-10 16:28:17,835 DEBUG TRAIN Batch 72/700 loss 0.056405 acc 0.956636 lr 0.00018922 grad_norm 0.501395 rank 0
2025-01-10 16:28:17,835 DEBUG TRAIN Batch 72/700 loss 0.082161 acc 0.947761 lr 0.00018922 grad_norm 0.501395 rank 2
2025-01-10 16:28:42,186 DEBUG TRAIN Batch 72/800 loss 0.083914 acc 0.944395 lr 0.00018915 grad_norm 0.490558 rank 2
2025-01-10 16:28:42,186 DEBUG TRAIN Batch 72/800 loss 0.070765 acc 0.951627 lr 0.00018915 grad_norm 0.490558 rank 0
2025-01-10 16:28:42,186 DEBUG TRAIN Batch 72/800 loss 0.084526 acc 0.949818 lr 0.00018915 grad_norm 0.490558 rank 1
2025-01-10 16:29:06,424 DEBUG TRAIN Batch 72/900 loss 0.074113 acc 0.953321 lr 0.00018908 grad_norm 0.489247 rank 0
2025-01-10 16:29:06,424 DEBUG TRAIN Batch 72/900 loss 0.091179 acc 0.938606 lr 0.00018908 grad_norm 0.489247 rank 2
2025-01-10 16:29:06,423 DEBUG TRAIN Batch 72/900 loss 0.074872 acc 0.949909 lr 0.00018908 grad_norm 0.489247 rank 1
2025-01-10 16:29:31,306 DEBUG TRAIN Batch 72/1000 loss 0.091202 acc 0.939713 lr 0.00018902 grad_norm 0.487173 rank 0
2025-01-10 16:29:31,306 DEBUG TRAIN Batch 72/1000 loss 0.097105 acc 0.938135 lr 0.00018902 grad_norm 0.487173 rank 2
2025-01-10 16:29:31,306 DEBUG TRAIN Batch 72/1000 loss 0.066190 acc 0.953398 lr 0.00018902 grad_norm 0.487173 rank 1
2025-01-10 16:29:54,809 DEBUG TRAIN Batch 72/1100 loss 0.093304 acc 0.935345 lr 0.00018895 grad_norm 0.489473 rank 1
2025-01-10 16:29:54,809 DEBUG TRAIN Batch 72/1100 loss 0.079148 acc 0.945566 lr 0.00018895 grad_norm 0.489473 rank 0
2025-01-10 16:29:54,810 DEBUG TRAIN Batch 72/1100 loss 0.095905 acc 0.934076 lr 0.00018895 grad_norm 0.489473 rank 2
2025-01-10 16:30:19,178 DEBUG TRAIN Batch 72/1200 loss 0.086764 acc 0.943956 lr 0.00018888 grad_norm 0.480632 rank 2
2025-01-10 16:30:19,178 DEBUG TRAIN Batch 72/1200 loss 0.067704 acc 0.950311 lr 0.00018888 grad_norm 0.480632 rank 0
2025-01-10 16:30:19,179 DEBUG TRAIN Batch 72/1200 loss 0.074420 acc 0.940114 lr 0.00018888 grad_norm 0.480632 rank 1
2025-01-10 16:30:44,311 DEBUG TRAIN Batch 72/1300 loss 0.057169 acc 0.957129 lr 0.00018882 grad_norm 0.472134 rank 0
2025-01-10 16:30:44,311 DEBUG TRAIN Batch 72/1300 loss 0.061952 acc 0.951677 lr 0.00018882 grad_norm 0.472134 rank 1
2025-01-10 16:30:44,311 DEBUG TRAIN Batch 72/1300 loss 0.070357 acc 0.948847 lr 0.00018882 grad_norm 0.472134 rank 2
2025-01-10 16:31:08,500 DEBUG TRAIN Batch 72/1400 loss 0.061948 acc 0.959707 lr 0.00018875 grad_norm 0.467754 rank 2
2025-01-10 16:31:08,500 DEBUG TRAIN Batch 72/1400 loss 0.083288 acc 0.949653 lr 0.00018875 grad_norm 0.467754 rank 0
2025-01-10 16:31:08,500 DEBUG TRAIN Batch 72/1400 loss 0.056553 acc 0.965035 lr 0.00018875 grad_norm 0.467754 rank 1
2025-01-10 16:31:33,965 DEBUG TRAIN Batch 72/1500 loss 0.060736 acc 0.964497 lr 0.00018868 grad_norm 0.520722 rank 0
2025-01-10 16:31:33,965 DEBUG TRAIN Batch 72/1500 loss 0.055479 acc 0.963979 lr 0.00018868 grad_norm 0.520722 rank 1
2025-01-10 16:31:33,965 DEBUG TRAIN Batch 72/1500 loss 0.069008 acc 0.953356 lr 0.00018868 grad_norm 0.520722 rank 2
2025-01-10 16:31:58,023 DEBUG TRAIN Batch 72/1600 loss 0.064517 acc 0.957854 lr 0.00018861 grad_norm 0.505332 rank 1
2025-01-10 16:31:58,024 DEBUG TRAIN Batch 72/1600 loss 0.104175 acc 0.933333 lr 0.00018861 grad_norm 0.505332 rank 2
2025-01-10 16:31:58,024 DEBUG TRAIN Batch 72/1600 loss 0.100886 acc 0.933211 lr 0.00018861 grad_norm 0.505332 rank 0
2025-01-10 16:32:22,162 DEBUG TRAIN Batch 72/1700 loss 0.109748 acc 0.921875 lr 0.00018855 grad_norm 0.550265 rank 2
2025-01-10 16:32:22,162 DEBUG TRAIN Batch 72/1700 loss 0.073209 acc 0.947993 lr 0.00018855 grad_norm 0.550265 rank 1
2025-01-10 16:32:22,162 DEBUG TRAIN Batch 72/1700 loss 0.096386 acc 0.944444 lr 0.00018855 grad_norm 0.550265 rank 0
2025-01-10 16:32:47,900 DEBUG TRAIN Batch 72/1800 loss 0.099696 acc 0.933267 lr 0.00018848 grad_norm 0.543873 rank 0
2025-01-10 16:32:47,901 DEBUG TRAIN Batch 72/1800 loss 0.097874 acc 0.925243 lr 0.00018848 grad_norm 0.543873 rank 2
2025-01-10 16:32:47,902 DEBUG TRAIN Batch 72/1800 loss 0.069690 acc 0.954649 lr 0.00018848 grad_norm 0.543873 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 16:34:12,964 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59997ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 16:34:12,970 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 16:34:13,416 INFO Epoch 72 Step 70423 on_batch_end True CV rank 0
2025-01-10 16:34:13,416 INFO Epoch 72 Step 70423 on_batch_end True CV rank 1
2025-01-10 16:34:13,416 INFO Epoch 72 Step 70423 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 16:34:22,394 DEBUG CV Batch 72/100 loss 0.022771 acc 0.992196  rank 0
2025-01-10 16:34:22,724 DEBUG CV Batch 72/100 loss 0.022771 acc 0.992196  rank 2
2025-01-10 16:34:22,901 INFO Epoch 72 Step 70423 CV info lr 0.000188413815049604 0 rank loss_2.186015816429924 acc_0.7785286313870496
2025-01-10 16:34:23,253 INFO Epoch 72 Step 70423 CV info lr 0.000188413815049604 2 rank loss_2.186015816429924 acc_0.7785286313870496
2025-01-10 16:34:23,496 DEBUG CV Batch 72/100 loss 0.022771 acc 0.992196  rank 1
2025-01-10 16:34:24,029 INFO Epoch 72 Step 70423 CV info lr 0.000188413815049604 1 rank loss_2.186015816429924 acc_0.7785286313870496
2025-01-10 16:34:24,198 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_72_whole.pt
2025-01-10 16:34:24,220 INFO Added key: store_based_barrier_key:75 to store for rank: 0
2025-01-10 16:34:24,230 INFO Added key: store_based_barrier_key:75 to store for rank: 2
2025-01-10 16:34:24,230 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:75 with 3 nodes.
2025-01-10 16:34:24,230 INFO Added key: store_based_barrier_key:75 to store for rank: 1
2025-01-10 16:34:24,230 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:75 with 3 nodes.
2025-01-10 16:34:24,232 INFO Epoch 73 TRAIN info lr 0.000188413815049604 rank 2
2025-01-10 16:34:24,232 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 16:34:24,237 INFO Epoch 73 TRAIN info lr 0.000188413815049604 rank 1
2025-01-10 16:34:24,237 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 16:34:24,240 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:75 with 3 nodes.
2025-01-10 16:34:24,249 INFO Epoch 73 TRAIN info lr 0.000188413815049604 rank 0
2025-01-10 16:34:24,249 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 16:34:54,765 DEBUG TRAIN Batch 73/100 loss 0.055142 acc 0.963726 lr 0.00018835 grad_norm 0.490894 rank 0
2025-01-10 16:34:54,766 DEBUG TRAIN Batch 73/100 loss 0.082215 acc 0.945802 lr 0.00018835 grad_norm 0.490894 rank 2
2025-01-10 16:34:54,766 DEBUG TRAIN Batch 73/100 loss 0.085160 acc 0.943010 lr 0.00018835 grad_norm 0.490894 rank 1
2025-01-10 16:35:18,298 DEBUG TRAIN Batch 73/200 loss 0.072569 acc 0.942982 lr 0.00018828 grad_norm 0.500541 rank 0
2025-01-10 16:35:18,298 DEBUG TRAIN Batch 73/200 loss 0.081432 acc 0.946679 lr 0.00018828 grad_norm 0.500541 rank 1
2025-01-10 16:35:18,298 DEBUG TRAIN Batch 73/200 loss 0.107793 acc 0.923216 lr 0.00018828 grad_norm 0.500541 rank 2
2025-01-10 16:35:41,690 DEBUG TRAIN Batch 73/300 loss 0.080931 acc 0.944640 lr 0.00018821 grad_norm 0.464364 rank 1
2025-01-10 16:35:41,691 DEBUG TRAIN Batch 73/300 loss 0.067295 acc 0.955348 lr 0.00018821 grad_norm 0.464364 rank 0
2025-01-10 16:35:41,691 DEBUG TRAIN Batch 73/300 loss 0.086845 acc 0.935829 lr 0.00018821 grad_norm 0.464364 rank 2
2025-01-10 16:36:05,427 DEBUG TRAIN Batch 73/400 loss 0.094601 acc 0.943020 lr 0.00018815 grad_norm 0.500999 rank 1
2025-01-10 16:36:05,427 DEBUG TRAIN Batch 73/400 loss 0.075656 acc 0.945283 lr 0.00018815 grad_norm 0.500999 rank 0
2025-01-10 16:36:05,428 DEBUG TRAIN Batch 73/400 loss 0.095774 acc 0.935391 lr 0.00018815 grad_norm 0.500999 rank 2
2025-01-10 16:36:29,580 DEBUG TRAIN Batch 73/500 loss 0.111787 acc 0.924820 lr 0.00018808 grad_norm 0.523315 rank 0
2025-01-10 16:36:29,580 DEBUG TRAIN Batch 73/500 loss 0.091373 acc 0.935231 lr 0.00018808 grad_norm 0.523315 rank 1
2025-01-10 16:36:29,580 DEBUG TRAIN Batch 73/500 loss 0.078146 acc 0.948529 lr 0.00018808 grad_norm 0.523315 rank 2
2025-01-10 16:36:53,058 DEBUG TRAIN Batch 73/600 loss 0.062158 acc 0.959799 lr 0.00018801 grad_norm 0.453976 rank 1
2025-01-10 16:36:53,058 DEBUG TRAIN Batch 73/600 loss 0.058661 acc 0.961226 lr 0.00018801 grad_norm 0.453976 rank 2
2025-01-10 16:36:53,058 DEBUG TRAIN Batch 73/600 loss 0.077179 acc 0.948310 lr 0.00018801 grad_norm 0.453976 rank 0
2025-01-10 16:37:17,116 DEBUG TRAIN Batch 73/700 loss 0.069779 acc 0.951170 lr 0.00018795 grad_norm 0.503404 rank 1
2025-01-10 16:37:17,116 DEBUG TRAIN Batch 73/700 loss 0.069096 acc 0.954447 lr 0.00018795 grad_norm 0.503404 rank 0
2025-01-10 16:37:17,116 DEBUG TRAIN Batch 73/700 loss 0.084248 acc 0.948353 lr 0.00018795 grad_norm 0.503404 rank 2
2025-01-10 16:37:41,243 DEBUG TRAIN Batch 73/800 loss 0.078718 acc 0.941924 lr 0.00018788 grad_norm 0.497042 rank 0
2025-01-10 16:37:41,243 DEBUG TRAIN Batch 73/800 loss 0.065750 acc 0.954751 lr 0.00018788 grad_norm 0.497042 rank 1
2025-01-10 16:37:41,244 DEBUG TRAIN Batch 73/800 loss 0.090605 acc 0.936675 lr 0.00018788 grad_norm 0.497042 rank 2
2025-01-10 16:38:04,971 DEBUG TRAIN Batch 73/900 loss 0.061414 acc 0.960265 lr 0.00018781 grad_norm 0.473391 rank 1
2025-01-10 16:38:04,972 DEBUG TRAIN Batch 73/900 loss 0.075292 acc 0.953321 lr 0.00018781 grad_norm 0.473391 rank 0
2025-01-10 16:38:04,972 DEBUG TRAIN Batch 73/900 loss 0.080166 acc 0.943231 lr 0.00018781 grad_norm 0.473391 rank 2
2025-01-10 16:38:28,804 DEBUG TRAIN Batch 73/1000 loss 0.084394 acc 0.935714 lr 0.00018775 grad_norm 0.475212 rank 2
2025-01-10 16:38:28,805 DEBUG TRAIN Batch 73/1000 loss 0.076005 acc 0.952470 lr 0.00018775 grad_norm 0.475212 rank 1
2025-01-10 16:38:28,805 DEBUG TRAIN Batch 73/1000 loss 0.085547 acc 0.935278 lr 0.00018775 grad_norm 0.475212 rank 0
2025-01-10 16:38:53,150 DEBUG TRAIN Batch 73/1100 loss 0.122714 acc 0.913871 lr 0.00018768 grad_norm 0.516133 rank 0
2025-01-10 16:38:53,150 DEBUG TRAIN Batch 73/1100 loss 0.071412 acc 0.950969 lr 0.00018768 grad_norm 0.516133 rank 2
2025-01-10 16:38:53,150 DEBUG TRAIN Batch 73/1100 loss 0.087390 acc 0.946894 lr 0.00018768 grad_norm 0.516133 rank 1
2025-01-10 16:39:17,115 DEBUG TRAIN Batch 73/1200 loss 0.101007 acc 0.928447 lr 0.00018762 grad_norm 0.500484 rank 0
2025-01-10 16:39:17,115 DEBUG TRAIN Batch 73/1200 loss 0.072071 acc 0.948553 lr 0.00018762 grad_norm 0.500484 rank 1
2025-01-10 16:39:17,115 DEBUG TRAIN Batch 73/1200 loss 0.089376 acc 0.940574 lr 0.00018762 grad_norm 0.500484 rank 2
2025-01-10 16:39:41,294 DEBUG TRAIN Batch 73/1300 loss 0.095943 acc 0.934542 lr 0.00018755 grad_norm 0.491394 rank 0
2025-01-10 16:39:41,294 DEBUG TRAIN Batch 73/1300 loss 0.071833 acc 0.953941 lr 0.00018755 grad_norm 0.491394 rank 2
2025-01-10 16:39:41,294 DEBUG TRAIN Batch 73/1300 loss 0.071493 acc 0.951087 lr 0.00018755 grad_norm 0.491394 rank 1
2025-01-10 16:40:06,635 DEBUG TRAIN Batch 73/1400 loss 0.050620 acc 0.962798 lr 0.00018748 grad_norm 0.498552 rank 1
2025-01-10 16:40:06,635 DEBUG TRAIN Batch 73/1400 loss 0.065533 acc 0.957627 lr 0.00018748 grad_norm 0.498552 rank 0
2025-01-10 16:40:06,636 DEBUG TRAIN Batch 73/1400 loss 0.072905 acc 0.950633 lr 0.00018748 grad_norm 0.498552 rank 2
2025-01-10 16:40:30,968 DEBUG TRAIN Batch 73/1500 loss 0.087243 acc 0.936170 lr 0.00018742 grad_norm 0.488392 rank 2
2025-01-10 16:40:30,968 DEBUG TRAIN Batch 73/1500 loss 0.070572 acc 0.956175 lr 0.00018742 grad_norm 0.488392 rank 0
2025-01-10 16:40:30,969 DEBUG TRAIN Batch 73/1500 loss 0.072446 acc 0.953763 lr 0.00018742 grad_norm 0.488392 rank 1
2025-01-10 16:40:55,044 DEBUG TRAIN Batch 73/1600 loss 0.099336 acc 0.933040 lr 0.00018735 grad_norm 0.547324 rank 1
2025-01-10 16:40:55,044 DEBUG TRAIN Batch 73/1600 loss 0.101619 acc 0.932057 lr 0.00018735 grad_norm 0.547324 rank 0
2025-01-10 16:40:55,044 DEBUG TRAIN Batch 73/1600 loss 0.089672 acc 0.941055 lr 0.00018735 grad_norm 0.547324 rank 2
2025-01-10 16:41:20,088 DEBUG TRAIN Batch 73/1700 loss 0.092151 acc 0.938117 lr 0.00018729 grad_norm 0.528111 rank 2
2025-01-10 16:41:20,088 DEBUG TRAIN Batch 73/1700 loss 0.059821 acc 0.958960 lr 0.00018729 grad_norm 0.528111 rank 1
2025-01-10 16:41:20,089 DEBUG TRAIN Batch 73/1700 loss 0.061982 acc 0.953582 lr 0.00018729 grad_norm 0.528111 rank 0
2025-01-10 16:41:45,319 DEBUG TRAIN Batch 73/1800 loss 0.073278 acc 0.945006 lr 0.00018722 grad_norm 0.513141 rank 2
2025-01-10 16:41:45,319 DEBUG TRAIN Batch 73/1800 loss 0.086014 acc 0.935922 lr 0.00018722 grad_norm 0.513141 rank 0
2025-01-10 16:41:45,320 DEBUG TRAIN Batch 73/1800 loss 0.049169 acc 0.966837 lr 0.00018722 grad_norm 0.513141 rank 1
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 16:43:07,792 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 16:43:07,793 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 16:43:08,190 INFO Epoch 73 Step 71370 on_batch_end True CV rank 0
2025-01-10 16:43:08,190 INFO Epoch 73 Step 71370 on_batch_end True CV rank 2
2025-01-10 16:43:08,190 INFO Epoch 73 Step 71370 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 16:43:17,171 DEBUG CV Batch 73/100 loss 0.021406 acc 0.994426  rank 0
2025-01-10 16:43:17,540 DEBUG CV Batch 73/100 loss 0.021406 acc 0.994426  rank 2
2025-01-10 16:43:17,638 INFO Epoch 73 Step 71370 CV info lr 0.00018715962052032946 0 rank loss_2.194302889469423 acc_0.7781351879239082
2025-01-10 16:43:17,895 DEBUG CV Batch 73/100 loss 0.021406 acc 0.994426  rank 1
2025-01-10 16:43:18,089 INFO Epoch 73 Step 71370 CV info lr 0.00018715962052032946 2 rank loss_2.194302889469423 acc_0.7781351879239082
2025-01-10 16:43:18,439 INFO Epoch 73 Step 71370 CV info lr 0.00018715962052032946 1 rank loss_2.194302889469423 acc_0.7781351879239082
2025-01-10 16:43:18,928 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_73_whole.pt
2025-01-10 16:43:18,950 INFO Added key: store_based_barrier_key:76 to store for rank: 0
2025-01-10 16:43:18,960 INFO Added key: store_based_barrier_key:76 to store for rank: 2
2025-01-10 16:43:18,960 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:76 with 3 nodes.
2025-01-10 16:43:18,960 INFO Added key: store_based_barrier_key:76 to store for rank: 1
2025-01-10 16:43:18,960 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:76 with 3 nodes.
2025-01-10 16:43:18,964 INFO Epoch 74 TRAIN info lr 0.00018715962052032946 rank 1
2025-01-10 16:43:18,964 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 16:43:18,967 INFO Epoch 74 TRAIN info lr 0.00018715962052032946 rank 2
2025-01-10 16:43:18,968 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 16:43:18,970 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:76 with 3 nodes.
2025-01-10 16:43:18,974 INFO Epoch 74 TRAIN info lr 0.00018715962052032946 rank 0
2025-01-10 16:43:18,974 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 16:43:49,035 DEBUG TRAIN Batch 74/100 loss 0.053188 acc 0.964668 lr 0.00018709 grad_norm 0.466782 rank 0
2025-01-10 16:43:49,035 DEBUG TRAIN Batch 74/100 loss 0.062982 acc 0.956612 lr 0.00018709 grad_norm 0.466782 rank 2
2025-01-10 16:43:49,036 DEBUG TRAIN Batch 74/100 loss 0.085442 acc 0.938650 lr 0.00018709 grad_norm 0.466782 rank 1
2025-01-10 16:44:12,955 DEBUG TRAIN Batch 74/200 loss 0.074240 acc 0.948885 lr 0.00018703 grad_norm 0.471898 rank 2
2025-01-10 16:44:12,956 DEBUG TRAIN Batch 74/200 loss 0.050424 acc 0.962309 lr 0.00018703 grad_norm 0.471898 rank 0
2025-01-10 16:44:12,956 DEBUG TRAIN Batch 74/200 loss 0.065683 acc 0.954386 lr 0.00018703 grad_norm 0.471898 rank 1
2025-01-10 16:44:36,235 DEBUG TRAIN Batch 74/300 loss 0.061524 acc 0.951219 lr 0.00018696 grad_norm 0.469009 rank 2
2025-01-10 16:44:36,235 DEBUG TRAIN Batch 74/300 loss 0.084283 acc 0.947222 lr 0.00018696 grad_norm 0.469009 rank 0
2025-01-10 16:44:36,235 DEBUG TRAIN Batch 74/300 loss 0.085834 acc 0.944598 lr 0.00018696 grad_norm 0.469009 rank 1
2025-01-10 16:44:59,819 DEBUG TRAIN Batch 74/400 loss 0.093354 acc 0.931004 lr 0.00018690 grad_norm 0.501199 rank 1
2025-01-10 16:44:59,819 DEBUG TRAIN Batch 74/400 loss 0.089702 acc 0.942238 lr 0.00018690 grad_norm 0.501199 rank 0
2025-01-10 16:44:59,820 DEBUG TRAIN Batch 74/400 loss 0.074934 acc 0.955761 lr 0.00018690 grad_norm 0.501199 rank 2
2025-01-10 16:45:23,867 DEBUG TRAIN Batch 74/500 loss 0.050247 acc 0.967433 lr 0.00018683 grad_norm 0.476763 rank 2
2025-01-10 16:45:23,867 DEBUG TRAIN Batch 74/500 loss 0.064063 acc 0.952085 lr 0.00018683 grad_norm 0.476763 rank 0
2025-01-10 16:45:23,867 DEBUG TRAIN Batch 74/500 loss 0.068930 acc 0.951000 lr 0.00018683 grad_norm 0.476763 rank 1
2025-01-10 16:45:48,257 DEBUG TRAIN Batch 74/600 loss 0.073773 acc 0.953876 lr 0.00018677 grad_norm 0.517995 rank 1
2025-01-10 16:45:48,259 DEBUG TRAIN Batch 74/600 loss 0.067557 acc 0.961934 lr 0.00018677 grad_norm 0.517995 rank 2
2025-01-10 16:45:48,259 DEBUG TRAIN Batch 74/600 loss 0.073872 acc 0.939077 lr 0.00018677 grad_norm 0.517995 rank 0
2025-01-10 16:46:11,965 DEBUG TRAIN Batch 74/700 loss 0.055671 acc 0.964753 lr 0.00018670 grad_norm 0.492008 rank 2
2025-01-10 16:46:11,965 DEBUG TRAIN Batch 74/700 loss 0.078584 acc 0.941941 lr 0.00018670 grad_norm 0.492008 rank 1
2025-01-10 16:46:11,966 DEBUG TRAIN Batch 74/700 loss 0.084963 acc 0.937563 lr 0.00018670 grad_norm 0.492008 rank 0
2025-01-10 16:46:35,920 DEBUG TRAIN Batch 74/800 loss 0.079204 acc 0.953629 lr 0.00018664 grad_norm 0.501077 rank 1
2025-01-10 16:46:35,920 DEBUG TRAIN Batch 74/800 loss 0.102725 acc 0.927207 lr 0.00018664 grad_norm 0.501077 rank 0
2025-01-10 16:46:35,920 DEBUG TRAIN Batch 74/800 loss 0.080685 acc 0.947070 lr 0.00018664 grad_norm 0.501077 rank 2
2025-01-10 16:47:00,670 DEBUG TRAIN Batch 74/900 loss 0.079576 acc 0.945014 lr 0.00018657 grad_norm 0.485805 rank 2
2025-01-10 16:47:00,670 DEBUG TRAIN Batch 74/900 loss 0.089271 acc 0.923218 lr 0.00018657 grad_norm 0.485805 rank 0
2025-01-10 16:47:00,671 DEBUG TRAIN Batch 74/900 loss 0.063961 acc 0.950450 lr 0.00018657 grad_norm 0.485805 rank 1
2025-01-10 16:47:24,427 DEBUG TRAIN Batch 74/1000 loss 0.077024 acc 0.948905 lr 0.00018651 grad_norm 0.494186 rank 0
2025-01-10 16:47:24,427 DEBUG TRAIN Batch 74/1000 loss 0.070054 acc 0.950685 lr 0.00018651 grad_norm 0.494186 rank 2
2025-01-10 16:47:24,428 DEBUG TRAIN Batch 74/1000 loss 0.049853 acc 0.969925 lr 0.00018651 grad_norm 0.494186 rank 1
2025-01-10 16:47:48,447 DEBUG TRAIN Batch 74/1100 loss 0.099120 acc 0.927456 lr 0.00018644 grad_norm 0.550686 rank 2
2025-01-10 16:47:48,447 DEBUG TRAIN Batch 74/1100 loss 0.089932 acc 0.934995 lr 0.00018644 grad_norm 0.550686 rank 0
2025-01-10 16:47:48,448 DEBUG TRAIN Batch 74/1100 loss 0.068688 acc 0.950104 lr 0.00018644 grad_norm 0.550686 rank 1
2025-01-10 16:48:13,125 DEBUG TRAIN Batch 74/1200 loss 0.078237 acc 0.947047 lr 0.00018638 grad_norm 0.491531 rank 2
2025-01-10 16:48:13,125 DEBUG TRAIN Batch 74/1200 loss 0.082133 acc 0.942932 lr 0.00018638 grad_norm 0.491531 rank 0
2025-01-10 16:48:13,126 DEBUG TRAIN Batch 74/1200 loss 0.033402 acc 0.980488 lr 0.00018638 grad_norm 0.491531 rank 1
2025-01-10 16:48:37,211 DEBUG TRAIN Batch 74/1300 loss 0.089197 acc 0.940000 lr 0.00018631 grad_norm 0.512887 rank 0
2025-01-10 16:48:37,212 DEBUG TRAIN Batch 74/1300 loss 0.100129 acc 0.941385 lr 0.00018631 grad_norm 0.512887 rank 2
2025-01-10 16:48:37,212 DEBUG TRAIN Batch 74/1300 loss 0.072655 acc 0.948837 lr 0.00018631 grad_norm 0.512887 rank 1
2025-01-10 16:49:01,555 DEBUG TRAIN Batch 74/1400 loss 0.064712 acc 0.960310 lr 0.00018625 grad_norm 0.489606 rank 0
2025-01-10 16:49:01,556 DEBUG TRAIN Batch 74/1400 loss 0.095211 acc 0.936953 lr 0.00018625 grad_norm 0.489606 rank 2
2025-01-10 16:49:01,556 DEBUG TRAIN Batch 74/1400 loss 0.072993 acc 0.946678 lr 0.00018625 grad_norm 0.489606 rank 1
2025-01-10 16:49:25,609 DEBUG TRAIN Batch 74/1500 loss 0.076134 acc 0.946681 lr 0.00018618 grad_norm 0.492366 rank 2
2025-01-10 16:49:25,609 DEBUG TRAIN Batch 74/1500 loss 0.071253 acc 0.947872 lr 0.00018618 grad_norm 0.492366 rank 0
2025-01-10 16:49:25,610 DEBUG TRAIN Batch 74/1500 loss 0.077253 acc 0.948913 lr 0.00018618 grad_norm 0.492366 rank 1
2025-01-10 16:49:50,466 DEBUG TRAIN Batch 74/1600 loss 0.070407 acc 0.950104 lr 0.00018612 grad_norm 0.504031 rank 2
2025-01-10 16:49:50,466 DEBUG TRAIN Batch 74/1600 loss 0.097630 acc 0.931532 lr 0.00018612 grad_norm 0.504031 rank 0
2025-01-10 16:49:50,466 DEBUG TRAIN Batch 74/1600 loss 0.037445 acc 0.970684 lr 0.00018612 grad_norm 0.504031 rank 1
2025-01-10 16:50:15,264 DEBUG TRAIN Batch 74/1700 loss 0.067511 acc 0.949000 lr 0.00018605 grad_norm 0.522421 rank 0
2025-01-10 16:50:15,265 DEBUG TRAIN Batch 74/1700 loss 0.073277 acc 0.946040 lr 0.00018605 grad_norm 0.522421 rank 2
2025-01-10 16:50:15,265 DEBUG TRAIN Batch 74/1700 loss 0.101779 acc 0.934726 lr 0.00018605 grad_norm 0.522421 rank 1
2025-01-10 16:50:39,497 DEBUG TRAIN Batch 74/1800 loss 0.075587 acc 0.942329 lr 0.00018599 grad_norm 0.544594 rank 1
2025-01-10 16:50:39,497 DEBUG TRAIN Batch 74/1800 loss 0.094623 acc 0.929841 lr 0.00018599 grad_norm 0.544594 rank 2
2025-01-10 16:50:39,498 DEBUG TRAIN Batch 74/1800 loss 0.069977 acc 0.952096 lr 0.00018599 grad_norm 0.544594 rank 0
2025-01-10 16:51:04,227 DEBUG TRAIN Batch 74/1900 loss 0.052966 acc 0.968553 lr 0.00018593 grad_norm 0.494323 rank 0
2025-01-10 16:51:04,227 DEBUG TRAIN Batch 74/1900 loss 0.086851 acc 0.942290 lr 0.00018593 grad_norm 0.494323 rank 1
2025-01-10 16:51:04,227 DEBUG TRAIN Batch 74/1900 loss 0.098387 acc 0.927856 lr 0.00018593 grad_norm 0.494323 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 16:52:21,777 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59994ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 16:52:21,784 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 16:52:22,204 INFO Epoch 74 Step 72356 on_batch_end True CV rank 0
2025-01-10 16:52:22,204 INFO Epoch 74 Step 72356 on_batch_end True CV rank 1
2025-01-10 16:52:22,205 INFO Epoch 74 Step 72356 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 16:52:31,429 DEBUG CV Batch 74/100 loss 0.017014 acc 0.995541  rank 0
2025-01-10 16:52:31,763 DEBUG CV Batch 74/100 loss 0.017014 acc 0.995541  rank 2
2025-01-10 16:52:31,940 INFO Epoch 74 Step 72356 CV info lr 0.00018588002802749835 0 rank loss_2.1940625403750396 acc_0.7783585002547816
2025-01-10 16:52:31,954 DEBUG CV Batch 74/100 loss 0.017014 acc 0.995541  rank 1
2025-01-10 16:52:32,316 INFO Epoch 74 Step 72356 CV info lr 0.00018588002802749835 2 rank loss_2.1940625403750396 acc_0.7783585002547816
2025-01-10 16:52:32,512 INFO Epoch 74 Step 72356 CV info lr 0.00018588002802749835 1 rank loss_2.1940625403750396 acc_0.7783585002547816
2025-01-10 16:52:33,238 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_74_whole.pt
2025-01-10 16:52:33,249 INFO Added key: store_based_barrier_key:77 to store for rank: 0
2025-01-10 16:52:33,259 INFO Added key: store_based_barrier_key:77 to store for rank: 2
2025-01-10 16:52:33,260 INFO Added key: store_based_barrier_key:77 to store for rank: 1
2025-01-10 16:52:33,260 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:77 with 3 nodes.
2025-01-10 16:52:33,260 INFO Epoch 75 TRAIN info lr 0.00018588002802749835 rank 1
2025-01-10 16:52:33,261 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 16:52:33,269 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:77 with 3 nodes.
2025-01-10 16:52:33,270 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:77 with 3 nodes.
2025-01-10 16:52:33,274 INFO Epoch 75 TRAIN info lr 0.00018588002802749835 rank 0
2025-01-10 16:52:33,274 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 16:52:33,279 INFO Epoch 75 TRAIN info lr 0.00018588002802749835 rank 2
2025-01-10 16:52:33,279 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 16:53:06,648 DEBUG TRAIN Batch 75/100 loss 0.058493 acc 0.956243 lr 0.00018582 grad_norm 0.457308 rank 1
2025-01-10 16:53:06,648 DEBUG TRAIN Batch 75/100 loss 0.051321 acc 0.966387 lr 0.00018582 grad_norm 0.457308 rank 2
2025-01-10 16:53:06,649 DEBUG TRAIN Batch 75/100 loss 0.060861 acc 0.962189 lr 0.00018582 grad_norm 0.457308 rank 0
2025-01-10 16:53:30,902 DEBUG TRAIN Batch 75/200 loss 0.080601 acc 0.937883 lr 0.00018575 grad_norm 0.485111 rank 0
2025-01-10 16:53:30,902 DEBUG TRAIN Batch 75/200 loss 0.058039 acc 0.957016 lr 0.00018575 grad_norm 0.485111 rank 2
2025-01-10 16:53:30,902 DEBUG TRAIN Batch 75/200 loss 0.075558 acc 0.949495 lr 0.00018575 grad_norm 0.485111 rank 1
2025-01-10 16:53:56,573 DEBUG TRAIN Batch 75/300 loss 0.068124 acc 0.950932 lr 0.00018569 grad_norm 0.483858 rank 0
2025-01-10 16:53:56,574 DEBUG TRAIN Batch 75/300 loss 0.071794 acc 0.950455 lr 0.00018569 grad_norm 0.483858 rank 2
2025-01-10 16:53:56,574 DEBUG TRAIN Batch 75/300 loss 0.075681 acc 0.954545 lr 0.00018569 grad_norm 0.483858 rank 1
2025-01-10 16:54:20,873 DEBUG TRAIN Batch 75/400 loss 0.057128 acc 0.968718 lr 0.00018562 grad_norm 0.477567 rank 1
2025-01-10 16:54:20,873 DEBUG TRAIN Batch 75/400 loss 0.082652 acc 0.947511 lr 0.00018562 grad_norm 0.477567 rank 0
2025-01-10 16:54:20,873 DEBUG TRAIN Batch 75/400 loss 0.062584 acc 0.955367 lr 0.00018562 grad_norm 0.477567 rank 2
2025-01-10 16:54:45,181 DEBUG TRAIN Batch 75/500 loss 0.069640 acc 0.954023 lr 0.00018556 grad_norm 0.482172 rank 2
2025-01-10 16:54:45,182 DEBUG TRAIN Batch 75/500 loss 0.070930 acc 0.948560 lr 0.00018556 grad_norm 0.482172 rank 0
2025-01-10 16:54:45,182 DEBUG TRAIN Batch 75/500 loss 0.062521 acc 0.955752 lr 0.00018556 grad_norm 0.482172 rank 1
2025-01-10 16:55:09,963 DEBUG TRAIN Batch 75/600 loss 0.065397 acc 0.948936 lr 0.00018550 grad_norm 0.465366 rank 1
2025-01-10 16:55:09,964 DEBUG TRAIN Batch 75/600 loss 0.068870 acc 0.953445 lr 0.00018550 grad_norm 0.465366 rank 2
2025-01-10 16:55:09,964 DEBUG TRAIN Batch 75/600 loss 0.079371 acc 0.936479 lr 0.00018550 grad_norm 0.465366 rank 0
2025-01-10 16:55:35,266 DEBUG TRAIN Batch 75/700 loss 0.073622 acc 0.960000 lr 0.00018543 grad_norm 0.467352 rank 0
2025-01-10 16:55:35,267 DEBUG TRAIN Batch 75/700 loss 0.054644 acc 0.962702 lr 0.00018543 grad_norm 0.467352 rank 2
2025-01-10 16:55:35,267 DEBUG TRAIN Batch 75/700 loss 0.051899 acc 0.972015 lr 0.00018543 grad_norm 0.467352 rank 1
2025-01-10 16:55:59,782 DEBUG TRAIN Batch 75/800 loss 0.081395 acc 0.946725 lr 0.00018537 grad_norm 0.478931 rank 2
2025-01-10 16:55:59,782 DEBUG TRAIN Batch 75/800 loss 0.086572 acc 0.941822 lr 0.00018537 grad_norm 0.478931 rank 0
2025-01-10 16:55:59,782 DEBUG TRAIN Batch 75/800 loss 0.081504 acc 0.946691 lr 0.00018537 grad_norm 0.478931 rank 1
2025-01-10 16:56:24,503 DEBUG TRAIN Batch 75/900 loss 0.082374 acc 0.949827 lr 0.00018530 grad_norm 0.500009 rank 2
2025-01-10 16:56:24,503 DEBUG TRAIN Batch 75/900 loss 0.061678 acc 0.954597 lr 0.00018530 grad_norm 0.500009 rank 1
2025-01-10 16:56:24,504 DEBUG TRAIN Batch 75/900 loss 0.100415 acc 0.931897 lr 0.00018530 grad_norm 0.500009 rank 0
2025-01-10 16:56:49,938 DEBUG TRAIN Batch 75/1000 loss 0.101124 acc 0.931095 lr 0.00018524 grad_norm 0.500668 rank 1
2025-01-10 16:56:49,938 DEBUG TRAIN Batch 75/1000 loss 0.070505 acc 0.949840 lr 0.00018524 grad_norm 0.500668 rank 2
2025-01-10 16:56:49,938 DEBUG TRAIN Batch 75/1000 loss 0.074956 acc 0.951160 lr 0.00018524 grad_norm 0.500668 rank 0
2025-01-10 16:57:13,746 DEBUG TRAIN Batch 75/1100 loss 0.098021 acc 0.931481 lr 0.00018518 grad_norm 0.504600 rank 1
2025-01-10 16:57:13,746 DEBUG TRAIN Batch 75/1100 loss 0.065515 acc 0.955375 lr 0.00018518 grad_norm 0.504600 rank 2
2025-01-10 16:57:13,747 DEBUG TRAIN Batch 75/1100 loss 0.075804 acc 0.946445 lr 0.00018518 grad_norm 0.504600 rank 0
2025-01-10 16:57:38,742 DEBUG TRAIN Batch 75/1200 loss 0.087811 acc 0.936021 lr 0.00018511 grad_norm 0.508707 rank 1
2025-01-10 16:57:38,743 DEBUG TRAIN Batch 75/1200 loss 0.090175 acc 0.936550 lr 0.00018511 grad_norm 0.508707 rank 2
2025-01-10 16:57:38,743 DEBUG TRAIN Batch 75/1200 loss 0.081239 acc 0.944241 lr 0.00018511 grad_norm 0.508707 rank 0
2025-01-10 16:58:03,514 DEBUG TRAIN Batch 75/1300 loss 0.065246 acc 0.955535 lr 0.00018505 grad_norm 0.489526 rank 0
2025-01-10 16:58:03,515 DEBUG TRAIN Batch 75/1300 loss 0.081975 acc 0.945491 lr 0.00018505 grad_norm 0.489526 rank 2
2025-01-10 16:58:03,515 DEBUG TRAIN Batch 75/1300 loss 0.085392 acc 0.938687 lr 0.00018505 grad_norm 0.489526 rank 1
2025-01-10 16:58:27,857 DEBUG TRAIN Batch 75/1400 loss 0.088409 acc 0.940647 lr 0.00018499 grad_norm 0.520467 rank 1
2025-01-10 16:58:27,857 DEBUG TRAIN Batch 75/1400 loss 0.073682 acc 0.955435 lr 0.00018499 grad_norm 0.520467 rank 2
2025-01-10 16:58:27,858 DEBUG TRAIN Batch 75/1400 loss 0.081248 acc 0.945545 lr 0.00018499 grad_norm 0.520467 rank 0
2025-01-10 16:58:52,924 DEBUG TRAIN Batch 75/1500 loss 0.096578 acc 0.935662 lr 0.00018492 grad_norm 0.697015 rank 1
2025-01-10 16:58:52,924 DEBUG TRAIN Batch 75/1500 loss 0.077683 acc 0.944865 lr 0.00018492 grad_norm 0.697015 rank 0
2025-01-10 16:58:52,925 DEBUG TRAIN Batch 75/1500 loss 0.101693 acc 0.936797 lr 0.00018492 grad_norm 0.697015 rank 2
2025-01-10 16:59:17,219 DEBUG TRAIN Batch 75/1600 loss 0.054216 acc 0.961364 lr 0.00018486 grad_norm 0.513142 rank 1
2025-01-10 16:59:17,220 DEBUG TRAIN Batch 75/1600 loss 0.093680 acc 0.934588 lr 0.00018486 grad_norm 0.513142 rank 0
2025-01-10 16:59:17,220 DEBUG TRAIN Batch 75/1600 loss 0.061373 acc 0.947781 lr 0.00018486 grad_norm 0.513142 rank 2
2025-01-10 16:59:40,996 DEBUG TRAIN Batch 75/1700 loss 0.085599 acc 0.939341 lr 0.00018480 grad_norm 0.500507 rank 2
2025-01-10 16:59:40,996 DEBUG TRAIN Batch 75/1700 loss 0.073011 acc 0.946485 lr 0.00018480 grad_norm 0.500507 rank 0
2025-01-10 16:59:40,996 DEBUG TRAIN Batch 75/1700 loss 0.081530 acc 0.940891 lr 0.00018480 grad_norm 0.500507 rank 1
2025-01-10 17:00:04,779 DEBUG TRAIN Batch 75/1800 loss 0.061760 acc 0.953461 lr 0.00018473 grad_norm 0.493733 rank 2
2025-01-10 17:00:04,779 DEBUG TRAIN Batch 75/1800 loss 0.089495 acc 0.940088 lr 0.00018473 grad_norm 0.493733 rank 1
2025-01-10 17:00:04,780 DEBUG TRAIN Batch 75/1800 loss 0.078247 acc 0.943343 lr 0.00018473 grad_norm 0.493733 rank 0
2025-01-10 17:00:27,711 DEBUG TRAIN Batch 75/1900 loss 0.080844 acc 0.936192 lr 0.00018467 grad_norm 0.530164 rank 1
2025-01-10 17:00:27,711 DEBUG TRAIN Batch 75/1900 loss 0.095636 acc 0.932233 lr 0.00018467 grad_norm 0.530164 rank 2
2025-01-10 17:00:27,712 DEBUG TRAIN Batch 75/1900 loss 0.076914 acc 0.945507 lr 0.00018467 grad_norm 0.530164 rank 0
2025-01-10 17:00:51,914 DEBUG TRAIN Batch 75/2000 loss 0.100570 acc 0.930748 lr 0.00018461 grad_norm 0.521177 rank 1
2025-01-10 17:00:51,915 DEBUG TRAIN Batch 75/2000 loss 0.075884 acc 0.955534 lr 0.00018461 grad_norm 0.521177 rank 0
2025-01-10 17:00:51,915 DEBUG TRAIN Batch 75/2000 loss 0.066752 acc 0.954639 lr 0.00018461 grad_norm 0.521177 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 17:02:14,780 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 17:02:14,780 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 17:02:15,178 INFO Epoch 75 Step 73404 on_batch_end True CV rank 2
2025-01-10 17:02:15,178 INFO Epoch 75 Step 73404 on_batch_end True CV rank 1
2025-01-10 17:02:15,178 INFO Epoch 75 Step 73404 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 17:02:24,294 DEBUG CV Batch 75/100 loss 0.011960 acc 0.993311  rank 0
2025-01-10 17:02:24,426 DEBUG CV Batch 75/100 loss 0.011960 acc 0.993311  rank 2
2025-01-10 17:02:24,828 DEBUG CV Batch 75/100 loss 0.011960 acc 0.993311  rank 1
2025-01-10 17:02:24,834 INFO Epoch 75 Step 73404 CV info lr 0.0001845483391347987 0 rank loss_2.203050826472974 acc_0.778122470174965
2025-01-10 17:02:24,970 INFO Epoch 75 Step 73404 CV info lr 0.0001845483391347987 2 rank loss_2.203050826472974 acc_0.778122470174965
2025-01-10 17:02:25,372 INFO Epoch 75 Step 73404 CV info lr 0.0001845483391347987 1 rank loss_2.203050826472974 acc_0.778122470174965
2025-01-10 17:02:26,132 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_75_whole.pt
2025-01-10 17:02:26,144 INFO Added key: store_based_barrier_key:78 to store for rank: 0
2025-01-10 17:02:26,154 INFO Added key: store_based_barrier_key:78 to store for rank: 1
2025-01-10 17:02:26,154 INFO Added key: store_based_barrier_key:78 to store for rank: 2
2025-01-10 17:02:26,154 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:78 with 3 nodes.
2025-01-10 17:02:26,154 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:78 with 3 nodes.
2025-01-10 17:02:26,157 INFO Epoch 76 TRAIN info lr 0.0001845483391347987 rank 2
2025-01-10 17:02:26,157 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 17:02:26,158 INFO Epoch 76 TRAIN info lr 0.0001845483391347987 rank 1
2025-01-10 17:02:26,158 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 17:02:26,164 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:78 with 3 nodes.
2025-01-10 17:02:26,168 INFO Epoch 76 TRAIN info lr 0.0001845483391347987 rank 0
2025-01-10 17:02:26,168 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 17:02:58,007 DEBUG TRAIN Batch 76/100 loss 0.060639 acc 0.960821 lr 0.00018449 grad_norm 0.464216 rank 1
2025-01-10 17:02:58,007 DEBUG TRAIN Batch 76/100 loss 0.080777 acc 0.947323 lr 0.00018449 grad_norm 0.464216 rank 2
2025-01-10 17:02:58,007 DEBUG TRAIN Batch 76/100 loss 0.071093 acc 0.955600 lr 0.00018449 grad_norm 0.464216 rank 0
2025-01-10 17:03:22,121 DEBUG TRAIN Batch 76/200 loss 0.064629 acc 0.957944 lr 0.00018442 grad_norm 0.472324 rank 1
2025-01-10 17:03:22,122 DEBUG TRAIN Batch 76/200 loss 0.072428 acc 0.946565 lr 0.00018442 grad_norm 0.472324 rank 2
2025-01-10 17:03:22,122 DEBUG TRAIN Batch 76/200 loss 0.070434 acc 0.946161 lr 0.00018442 grad_norm 0.472324 rank 0
2025-01-10 17:03:46,537 DEBUG TRAIN Batch 76/300 loss 0.070354 acc 0.948244 lr 0.00018436 grad_norm 0.459387 rank 1
2025-01-10 17:03:46,538 DEBUG TRAIN Batch 76/300 loss 0.052094 acc 0.961864 lr 0.00018436 grad_norm 0.459387 rank 0
2025-01-10 17:03:46,538 DEBUG TRAIN Batch 76/300 loss 0.074029 acc 0.948694 lr 0.00018436 grad_norm 0.459387 rank 2
2025-01-10 17:04:10,504 DEBUG TRAIN Batch 76/400 loss 0.075003 acc 0.948276 lr 0.00018430 grad_norm 0.467014 rank 2
2025-01-10 17:04:10,504 DEBUG TRAIN Batch 76/400 loss 0.050706 acc 0.969849 lr 0.00018430 grad_norm 0.467014 rank 1
2025-01-10 17:04:10,505 DEBUG TRAIN Batch 76/400 loss 0.064207 acc 0.946735 lr 0.00018430 grad_norm 0.467014 rank 0
2025-01-10 17:04:34,657 DEBUG TRAIN Batch 76/500 loss 0.064602 acc 0.955575 lr 0.00018423 grad_norm 0.471651 rank 2
2025-01-10 17:04:34,657 DEBUG TRAIN Batch 76/500 loss 0.054719 acc 0.964763 lr 0.00018423 grad_norm 0.471651 rank 1
2025-01-10 17:04:34,658 DEBUG TRAIN Batch 76/500 loss 0.052706 acc 0.959746 lr 0.00018423 grad_norm 0.471651 rank 0
2025-01-10 17:04:58,900 DEBUG TRAIN Batch 76/600 loss 0.084377 acc 0.936720 lr 0.00018417 grad_norm 0.464045 rank 2
2025-01-10 17:04:58,900 DEBUG TRAIN Batch 76/600 loss 0.077029 acc 0.944343 lr 0.00018417 grad_norm 0.464045 rank 1
2025-01-10 17:04:59,084 DEBUG TRAIN Batch 76/600 loss 0.081365 acc 0.941849 lr 0.00018417 grad_norm 0.464045 rank 0
2025-01-10 17:05:23,995 DEBUG TRAIN Batch 76/700 loss 0.069842 acc 0.954502 lr 0.00018411 grad_norm 0.469236 rank 1
2025-01-10 17:05:23,996 DEBUG TRAIN Batch 76/700 loss 0.073510 acc 0.953307 lr 0.00018411 grad_norm 0.469236 rank 2
2025-01-10 17:05:23,996 DEBUG TRAIN Batch 76/700 loss 0.080493 acc 0.946950 lr 0.00018411 grad_norm 0.469236 rank 0
2025-01-10 17:05:48,124 DEBUG TRAIN Batch 76/800 loss 0.060571 acc 0.957565 lr 0.00018405 grad_norm 0.464430 rank 0
2025-01-10 17:05:48,124 DEBUG TRAIN Batch 76/800 loss 0.082702 acc 0.950877 lr 0.00018405 grad_norm 0.464430 rank 1
2025-01-10 17:05:48,124 DEBUG TRAIN Batch 76/800 loss 0.072099 acc 0.944896 lr 0.00018405 grad_norm 0.464430 rank 2
2025-01-10 17:06:12,893 DEBUG TRAIN Batch 76/900 loss 0.039744 acc 0.967033 lr 0.00018399 grad_norm 0.463438 rank 0
2025-01-10 17:06:12,893 DEBUG TRAIN Batch 76/900 loss 0.070308 acc 0.956476 lr 0.00018399 grad_norm 0.463438 rank 2
2025-01-10 17:06:12,893 DEBUG TRAIN Batch 76/900 loss 0.069258 acc 0.952463 lr 0.00018399 grad_norm 0.463438 rank 1
2025-01-10 17:06:38,231 DEBUG TRAIN Batch 76/1000 loss 0.089470 acc 0.941298 lr 0.00018392 grad_norm 0.472975 rank 1
2025-01-10 17:06:38,231 DEBUG TRAIN Batch 76/1000 loss 0.060465 acc 0.954491 lr 0.00018392 grad_norm 0.472975 rank 2
2025-01-10 17:06:38,231 DEBUG TRAIN Batch 76/1000 loss 0.073248 acc 0.941495 lr 0.00018392 grad_norm 0.472975 rank 0
2025-01-10 17:07:01,873 DEBUG TRAIN Batch 76/1100 loss 0.072281 acc 0.957360 lr 0.00018386 grad_norm 0.464550 rank 1
2025-01-10 17:07:01,873 DEBUG TRAIN Batch 76/1100 loss 0.086401 acc 0.941541 lr 0.00018386 grad_norm 0.464550 rank 2
2025-01-10 17:07:01,874 DEBUG TRAIN Batch 76/1100 loss 0.059584 acc 0.958212 lr 0.00018386 grad_norm 0.464550 rank 0
2025-01-10 17:07:26,243 DEBUG TRAIN Batch 76/1200 loss 0.064666 acc 0.957627 lr 0.00018380 grad_norm 0.461416 rank 0
2025-01-10 17:07:26,243 DEBUG TRAIN Batch 76/1200 loss 0.076627 acc 0.950772 lr 0.00018380 grad_norm 0.461416 rank 2
2025-01-10 17:07:26,244 DEBUG TRAIN Batch 76/1200 loss 0.082306 acc 0.943688 lr 0.00018380 grad_norm 0.461416 rank 1
2025-01-10 17:07:51,533 DEBUG TRAIN Batch 76/1300 loss 0.065526 acc 0.954357 lr 0.00018374 grad_norm 0.499707 rank 0
2025-01-10 17:07:51,533 DEBUG TRAIN Batch 76/1300 loss 0.099762 acc 0.933746 lr 0.00018374 grad_norm 0.499707 rank 1
2025-01-10 17:07:51,533 DEBUG TRAIN Batch 76/1300 loss 0.069087 acc 0.955330 lr 0.00018374 grad_norm 0.499707 rank 2
2025-01-10 17:08:15,948 DEBUG TRAIN Batch 76/1400 loss 0.084312 acc 0.944194 lr 0.00018367 grad_norm 0.503158 rank 1
2025-01-10 17:08:15,948 DEBUG TRAIN Batch 76/1400 loss 0.079566 acc 0.937883 lr 0.00018367 grad_norm 0.503158 rank 0
2025-01-10 17:08:15,948 DEBUG TRAIN Batch 76/1400 loss 0.068423 acc 0.949299 lr 0.00018367 grad_norm 0.503158 rank 2
2025-01-10 17:08:41,233 DEBUG TRAIN Batch 76/1500 loss 0.091949 acc 0.947180 lr 0.00018361 grad_norm 0.481225 rank 2
2025-01-10 17:08:41,234 DEBUG TRAIN Batch 76/1500 loss 0.088642 acc 0.944692 lr 0.00018361 grad_norm 0.481225 rank 0
2025-01-10 17:08:41,234 DEBUG TRAIN Batch 76/1500 loss 0.074067 acc 0.951683 lr 0.00018361 grad_norm 0.481225 rank 1
2025-01-10 17:09:06,456 DEBUG TRAIN Batch 76/1600 loss 0.089292 acc 0.939819 lr 0.00018355 grad_norm 0.494234 rank 0
2025-01-10 17:09:06,456 DEBUG TRAIN Batch 76/1600 loss 0.059988 acc 0.952607 lr 0.00018355 grad_norm 0.494234 rank 2
2025-01-10 17:09:06,456 DEBUG TRAIN Batch 76/1600 loss 0.066802 acc 0.957214 lr 0.00018355 grad_norm 0.494234 rank 1
2025-01-10 17:09:29,866 DEBUG TRAIN Batch 76/1700 loss 0.069411 acc 0.957883 lr 0.00018349 grad_norm 0.491411 rank 1
2025-01-10 17:09:29,866 DEBUG TRAIN Batch 76/1700 loss 0.086055 acc 0.938532 lr 0.00018349 grad_norm 0.491411 rank 0
2025-01-10 17:09:29,866 DEBUG TRAIN Batch 76/1700 loss 0.062730 acc 0.953262 lr 0.00018349 grad_norm 0.491411 rank 2
2025-01-10 17:09:54,240 DEBUG TRAIN Batch 76/1800 loss 0.087168 acc 0.938261 lr 0.00018343 grad_norm 0.520076 rank 0
2025-01-10 17:09:54,240 DEBUG TRAIN Batch 76/1800 loss 0.074012 acc 0.948093 lr 0.00018343 grad_norm 0.520076 rank 1
2025-01-10 17:09:54,240 DEBUG TRAIN Batch 76/1800 loss 0.093231 acc 0.939479 lr 0.00018343 grad_norm 0.520076 rank 2
2025-01-10 17:10:19,228 DEBUG TRAIN Batch 76/1900 loss 0.066540 acc 0.948695 lr 0.00018337 grad_norm 0.489385 rank 1
2025-01-10 17:10:19,228 DEBUG TRAIN Batch 76/1900 loss 0.080990 acc 0.941281 lr 0.00018337 grad_norm 0.489385 rank 2
2025-01-10 17:10:19,228 DEBUG TRAIN Batch 76/1900 loss 0.074593 acc 0.947519 lr 0.00018337 grad_norm 0.489385 rank 0
2025-01-10 17:10:43,140 DEBUG TRAIN Batch 76/2000 loss 0.074428 acc 0.940284 lr 0.00018330 grad_norm 0.509688 rank 1
2025-01-10 17:10:43,140 DEBUG TRAIN Batch 76/2000 loss 0.098997 acc 0.928200 lr 0.00018330 grad_norm 0.509688 rank 0
2025-01-10 17:10:43,141 DEBUG TRAIN Batch 76/2000 loss 0.077366 acc 0.956811 lr 0.00018330 grad_norm 0.509688 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 17:11:43,624 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 17:11:43,634 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 17:11:44,054 INFO Epoch 76 Step 74405 on_batch_end True CV rank 1
2025-01-10 17:11:44,054 INFO Epoch 76 Step 74405 on_batch_end True CV rank 2
2025-01-10 17:11:44,055 INFO Epoch 76 Step 74405 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 17:11:53,219 DEBUG CV Batch 76/100 loss 0.016494 acc 0.995541  rank 0
2025-01-10 17:11:53,423 DEBUG CV Batch 76/100 loss 0.016494 acc 0.995541  rank 2
2025-01-10 17:11:53,680 DEBUG CV Batch 76/100 loss 0.016494 acc 0.995541  rank 1
2025-01-10 17:11:53,756 INFO Epoch 76 Step 74405 CV info lr 0.000183302734514093 0 rank loss_2.2108323294506 acc_0.7779978639201114
2025-01-10 17:11:53,950 INFO Epoch 76 Step 74405 CV info lr 0.000183302734514093 2 rank loss_2.2108323294506 acc_0.7779978639201114
2025-01-10 17:11:54,237 INFO Epoch 76 Step 74405 CV info lr 0.000183302734514093 1 rank loss_2.2108323294506 acc_0.7779978639201114
2025-01-10 17:11:55,043 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_76_whole.pt
2025-01-10 17:11:55,065 INFO Added key: store_based_barrier_key:79 to store for rank: 0
2025-01-10 17:11:55,065 INFO Added key: store_based_barrier_key:79 to store for rank: 1
2025-01-10 17:11:55,065 INFO Added key: store_based_barrier_key:79 to store for rank: 2
2025-01-10 17:11:55,066 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:79 with 3 nodes.
2025-01-10 17:11:55,074 INFO Epoch 77 TRAIN info lr 0.000183302734514093 rank 2
2025-01-10 17:11:55,074 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 17:11:55,075 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:79 with 3 nodes.
2025-01-10 17:11:55,075 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:79 with 3 nodes.
2025-01-10 17:11:55,078 INFO Epoch 77 TRAIN info lr 0.000183302734514093 rank 1
2025-01-10 17:11:55,078 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 17:11:55,083 INFO Epoch 77 TRAIN info lr 0.000183302734514093 rank 0
2025-01-10 17:11:55,083 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 17:12:29,363 DEBUG TRAIN Batch 77/100 loss 0.072576 acc 0.946678 lr 0.00018324 grad_norm 0.472983 rank 0
2025-01-10 17:12:29,364 DEBUG TRAIN Batch 77/100 loss 0.072950 acc 0.946612 lr 0.00018324 grad_norm 0.472983 rank 1
2025-01-10 17:12:29,364 DEBUG TRAIN Batch 77/100 loss 0.045474 acc 0.967146 lr 0.00018324 grad_norm 0.472983 rank 2
2025-01-10 17:12:53,504 DEBUG TRAIN Batch 77/200 loss 0.063129 acc 0.955172 lr 0.00018318 grad_norm 0.469469 rank 1
2025-01-10 17:12:53,505 DEBUG TRAIN Batch 77/200 loss 0.046798 acc 0.964706 lr 0.00018318 grad_norm 0.469469 rank 2
2025-01-10 17:12:53,505 DEBUG TRAIN Batch 77/200 loss 0.047149 acc 0.960621 lr 0.00018318 grad_norm 0.469469 rank 0
2025-01-10 17:13:17,867 DEBUG TRAIN Batch 77/300 loss 0.058938 acc 0.958494 lr 0.00018312 grad_norm 0.484640 rank 1
2025-01-10 17:13:17,867 DEBUG TRAIN Batch 77/300 loss 0.069380 acc 0.951243 lr 0.00018312 grad_norm 0.484640 rank 2
2025-01-10 17:13:17,867 DEBUG TRAIN Batch 77/300 loss 0.074843 acc 0.948556 lr 0.00018312 grad_norm 0.484640 rank 0
2025-01-10 17:13:42,241 DEBUG TRAIN Batch 77/400 loss 0.058756 acc 0.964661 lr 0.00018306 grad_norm 0.457990 rank 2
2025-01-10 17:13:42,241 DEBUG TRAIN Batch 77/400 loss 0.072369 acc 0.948135 lr 0.00018306 grad_norm 0.457990 rank 0
2025-01-10 17:13:42,241 DEBUG TRAIN Batch 77/400 loss 0.061542 acc 0.956871 lr 0.00018306 grad_norm 0.457990 rank 1
2025-01-10 17:14:06,900 DEBUG TRAIN Batch 77/500 loss 0.068897 acc 0.950748 lr 0.00018300 grad_norm 0.480912 rank 1
2025-01-10 17:14:06,901 DEBUG TRAIN Batch 77/500 loss 0.055238 acc 0.955736 lr 0.00018300 grad_norm 0.480912 rank 0
2025-01-10 17:14:06,901 DEBUG TRAIN Batch 77/500 loss 0.063549 acc 0.958084 lr 0.00018300 grad_norm 0.480912 rank 2
2025-01-10 17:14:30,589 DEBUG TRAIN Batch 77/600 loss 0.051498 acc 0.973684 lr 0.00018293 grad_norm 0.497435 rank 2
2025-01-10 17:14:30,589 DEBUG TRAIN Batch 77/600 loss 0.041508 acc 0.970726 lr 0.00018293 grad_norm 0.497435 rank 0
2025-01-10 17:14:30,589 DEBUG TRAIN Batch 77/600 loss 0.081636 acc 0.947977 lr 0.00018293 grad_norm 0.497435 rank 1
2025-01-10 17:14:55,223 DEBUG TRAIN Batch 77/700 loss 0.078789 acc 0.947090 lr 0.00018287 grad_norm 0.463511 rank 1
2025-01-10 17:14:55,223 DEBUG TRAIN Batch 77/700 loss 0.058700 acc 0.966173 lr 0.00018287 grad_norm 0.463511 rank 0
2025-01-10 17:14:55,223 DEBUG TRAIN Batch 77/700 loss 0.072182 acc 0.954887 lr 0.00018287 grad_norm 0.463511 rank 2
2025-01-10 17:15:19,446 DEBUG TRAIN Batch 77/800 loss 0.039646 acc 0.972500 lr 0.00018281 grad_norm 0.465124 rank 0
2025-01-10 17:15:19,447 DEBUG TRAIN Batch 77/800 loss 0.066964 acc 0.949099 lr 0.00018281 grad_norm 0.465124 rank 1
2025-01-10 17:15:19,447 DEBUG TRAIN Batch 77/800 loss 0.036507 acc 0.976608 lr 0.00018281 grad_norm 0.465124 rank 2
2025-01-10 17:15:43,519 DEBUG TRAIN Batch 77/900 loss 0.075213 acc 0.950086 lr 0.00018275 grad_norm 0.505241 rank 2
2025-01-10 17:15:43,519 DEBUG TRAIN Batch 77/900 loss 0.077302 acc 0.945766 lr 0.00018275 grad_norm 0.505241 rank 0
2025-01-10 17:15:43,520 DEBUG TRAIN Batch 77/900 loss 0.097536 acc 0.934629 lr 0.00018275 grad_norm 0.505241 rank 1
2025-01-10 17:16:07,577 DEBUG TRAIN Batch 77/1000 loss 0.072161 acc 0.953819 lr 0.00018269 grad_norm 0.464865 rank 2
2025-01-10 17:16:07,577 DEBUG TRAIN Batch 77/1000 loss 0.063426 acc 0.954545 lr 0.00018269 grad_norm 0.464865 rank 0
2025-01-10 17:16:07,577 DEBUG TRAIN Batch 77/1000 loss 0.062188 acc 0.962998 lr 0.00018269 grad_norm 0.464865 rank 1
2025-01-10 17:16:31,649 DEBUG TRAIN Batch 77/1100 loss 0.069451 acc 0.952696 lr 0.00018263 grad_norm 0.474737 rank 0
2025-01-10 17:16:31,649 DEBUG TRAIN Batch 77/1100 loss 0.064989 acc 0.962627 lr 0.00018263 grad_norm 0.474737 rank 2
2025-01-10 17:16:31,649 DEBUG TRAIN Batch 77/1100 loss 0.063404 acc 0.959375 lr 0.00018263 grad_norm 0.474737 rank 1
2025-01-10 17:16:55,882 DEBUG TRAIN Batch 77/1200 loss 0.054702 acc 0.965587 lr 0.00018257 grad_norm 0.497694 rank 1
2025-01-10 17:16:55,883 DEBUG TRAIN Batch 77/1200 loss 0.072335 acc 0.955366 lr 0.00018257 grad_norm 0.497694 rank 0
2025-01-10 17:16:55,883 DEBUG TRAIN Batch 77/1200 loss 0.082017 acc 0.944499 lr 0.00018257 grad_norm 0.497694 rank 2
2025-01-10 17:17:19,754 DEBUG TRAIN Batch 77/1300 loss 0.076364 acc 0.953155 lr 0.00018251 grad_norm 0.466038 rank 2
2025-01-10 17:17:19,754 DEBUG TRAIN Batch 77/1300 loss 0.030323 acc 0.985437 lr 0.00018251 grad_norm 0.466038 rank 1
2025-01-10 17:17:19,754 DEBUG TRAIN Batch 77/1300 loss 0.065245 acc 0.959064 lr 0.00018251 grad_norm 0.466038 rank 0
2025-01-10 17:17:43,548 DEBUG TRAIN Batch 77/1400 loss 0.072558 acc 0.947898 lr 0.00018245 grad_norm 0.499630 rank 0
2025-01-10 17:17:43,548 DEBUG TRAIN Batch 77/1400 loss 0.089824 acc 0.938338 lr 0.00018245 grad_norm 0.499630 rank 2
2025-01-10 17:17:43,548 DEBUG TRAIN Batch 77/1400 loss 0.076082 acc 0.942360 lr 0.00018245 grad_norm 0.499630 rank 1
2025-01-10 17:18:07,796 DEBUG TRAIN Batch 77/1500 loss 0.059062 acc 0.957078 lr 0.00018239 grad_norm 0.456789 rank 0
2025-01-10 17:18:07,796 DEBUG TRAIN Batch 77/1500 loss 0.055269 acc 0.962635 lr 0.00018239 grad_norm 0.456789 rank 1
2025-01-10 17:18:07,796 DEBUG TRAIN Batch 77/1500 loss 0.080880 acc 0.946459 lr 0.00018239 grad_norm 0.456789 rank 2
2025-01-10 17:18:32,328 DEBUG TRAIN Batch 77/1600 loss 0.074196 acc 0.948787 lr 0.00018233 grad_norm 0.472126 rank 1
2025-01-10 17:18:32,328 DEBUG TRAIN Batch 77/1600 loss 0.076467 acc 0.944105 lr 0.00018233 grad_norm 0.472126 rank 0
2025-01-10 17:18:32,328 DEBUG TRAIN Batch 77/1600 loss 0.081374 acc 0.945730 lr 0.00018233 grad_norm 0.472126 rank 2
2025-01-10 17:18:55,747 DEBUG TRAIN Batch 77/1700 loss 0.061320 acc 0.948768 lr 0.00018226 grad_norm 0.450908 rank 0
2025-01-10 17:18:55,747 DEBUG TRAIN Batch 77/1700 loss 0.045815 acc 0.960667 lr 0.00018226 grad_norm 0.450908 rank 1
2025-01-10 17:18:55,747 DEBUG TRAIN Batch 77/1700 loss 0.080207 acc 0.943434 lr 0.00018226 grad_norm 0.450908 rank 2
2025-01-10 17:19:20,300 DEBUG TRAIN Batch 77/1800 loss 0.057556 acc 0.962461 lr 0.00018220 grad_norm 0.475232 rank 1
2025-01-10 17:19:20,300 DEBUG TRAIN Batch 77/1800 loss 0.077479 acc 0.946757 lr 0.00018220 grad_norm 0.475232 rank 2
2025-01-10 17:19:20,300 DEBUG TRAIN Batch 77/1800 loss 0.054168 acc 0.961250 lr 0.00018220 grad_norm 0.475232 rank 0
2025-01-10 17:19:44,652 DEBUG TRAIN Batch 77/1900 loss 0.070121 acc 0.952239 lr 0.00018214 grad_norm 0.506634 rank 0
2025-01-10 17:19:44,652 DEBUG TRAIN Batch 77/1900 loss 0.071006 acc 0.942614 lr 0.00018214 grad_norm 0.506634 rank 2
2025-01-10 17:19:44,652 DEBUG TRAIN Batch 77/1900 loss 0.072021 acc 0.955333 lr 0.00018214 grad_norm 0.506634 rank 1
2025-01-10 17:20:08,606 DEBUG TRAIN Batch 77/2000 loss 0.094918 acc 0.933862 lr 0.00018208 grad_norm 0.543516 rank 2
2025-01-10 17:20:08,607 DEBUG TRAIN Batch 77/2000 loss 0.095106 acc 0.938813 lr 0.00018208 grad_norm 0.543516 rank 0
2025-01-10 17:20:08,607 DEBUG TRAIN Batch 77/2000 loss 0.097108 acc 0.935226 lr 0.00018208 grad_norm 0.543516 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 17:21:12,649 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59990ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 17:21:12,653 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 17:21:13,099 INFO Epoch 77 Step 75413 on_batch_end True CV rank 0
2025-01-10 17:21:13,099 INFO Epoch 77 Step 75413 on_batch_end True CV rank 1
2025-01-10 17:21:13,099 INFO Epoch 77 Step 75413 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 17:21:22,152 DEBUG CV Batch 77/100 loss 0.013725 acc 0.994426  rank 0
2025-01-10 17:21:22,496 DEBUG CV Batch 77/100 loss 0.013725 acc 0.994426  rank 2
2025-01-10 17:21:22,684 INFO Epoch 77 Step 75413 CV info lr 0.00018207356486182988 0 rank loss_2.219598646504445 acc_0.7780219426280574
2025-01-10 17:21:22,990 DEBUG CV Batch 77/100 loss 0.013725 acc 0.994426  rank 1
2025-01-10 17:21:23,045 INFO Epoch 77 Step 75413 CV info lr 0.00018207356486182988 2 rank loss_2.219598646504445 acc_0.7780219426280574
2025-01-10 17:21:23,541 INFO Epoch 77 Step 75413 CV info lr 0.00018207356486182988 1 rank loss_2.219598646504445 acc_0.7780219426280574
2025-01-10 17:21:23,976 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_77_whole.pt
2025-01-10 17:21:23,997 INFO Added key: store_based_barrier_key:80 to store for rank: 0
2025-01-10 17:21:23,998 INFO Added key: store_based_barrier_key:80 to store for rank: 1
2025-01-10 17:21:23,998 INFO Added key: store_based_barrier_key:80 to store for rank: 2
2025-01-10 17:21:23,998 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:80 with 3 nodes.
2025-01-10 17:21:23,998 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:80 with 3 nodes.
2025-01-10 17:21:24,000 INFO Epoch 78 TRAIN info lr 0.00018207356486182988 rank 2
2025-01-10 17:21:24,000 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 17:21:24,001 INFO Epoch 78 TRAIN info lr 0.00018207356486182988 rank 1
2025-01-10 17:21:24,001 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 17:21:24,008 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:80 with 3 nodes.
2025-01-10 17:21:24,010 INFO Epoch 78 TRAIN info lr 0.00018207356486182988 rank 0
2025-01-10 17:21:24,011 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 17:21:55,115 DEBUG TRAIN Batch 78/100 loss 0.082229 acc 0.947465 lr 0.00018201 grad_norm 0.471967 rank 2
2025-01-10 17:21:55,115 DEBUG TRAIN Batch 78/100 loss 0.053267 acc 0.964509 lr 0.00018201 grad_norm 0.471967 rank 0
2025-01-10 17:21:55,115 DEBUG TRAIN Batch 78/100 loss 0.064890 acc 0.958511 lr 0.00018201 grad_norm 0.471967 rank 1
2025-01-10 17:22:19,136 DEBUG TRAIN Batch 78/200 loss 0.057281 acc 0.957854 lr 0.00018195 grad_norm 0.482263 rank 1
2025-01-10 17:22:19,137 DEBUG TRAIN Batch 78/200 loss 0.065053 acc 0.953846 lr 0.00018195 grad_norm 0.482263 rank 2
2025-01-10 17:22:19,137 DEBUG TRAIN Batch 78/200 loss 0.080763 acc 0.948182 lr 0.00018195 grad_norm 0.482263 rank 0
2025-01-10 17:22:42,768 DEBUG TRAIN Batch 78/300 loss 0.067616 acc 0.953875 lr 0.00018189 grad_norm 0.497854 rank 0
2025-01-10 17:22:42,768 DEBUG TRAIN Batch 78/300 loss 0.091206 acc 0.939451 lr 0.00018189 grad_norm 0.497854 rank 1
2025-01-10 17:22:42,769 DEBUG TRAIN Batch 78/300 loss 0.056607 acc 0.954497 lr 0.00018189 grad_norm 0.497854 rank 2
2025-01-10 17:23:06,324 DEBUG TRAIN Batch 78/400 loss 0.074476 acc 0.945328 lr 0.00018183 grad_norm 0.499574 rank 1
2025-01-10 17:23:06,324 DEBUG TRAIN Batch 78/400 loss 0.062565 acc 0.960386 lr 0.00018183 grad_norm 0.499574 rank 0
2025-01-10 17:23:06,325 DEBUG TRAIN Batch 78/400 loss 0.085873 acc 0.941924 lr 0.00018183 grad_norm 0.499574 rank 2
2025-01-10 17:23:30,498 DEBUG TRAIN Batch 78/500 loss 0.087402 acc 0.937729 lr 0.00018177 grad_norm 0.469876 rank 2
2025-01-10 17:23:30,499 DEBUG TRAIN Batch 78/500 loss 0.065609 acc 0.951485 lr 0.00018177 grad_norm 0.469876 rank 1
2025-01-10 17:23:30,499 DEBUG TRAIN Batch 78/500 loss 0.064940 acc 0.959526 lr 0.00018177 grad_norm 0.469876 rank 0
2025-01-10 17:23:54,231 DEBUG TRAIN Batch 78/600 loss 0.086053 acc 0.940613 lr 0.00018171 grad_norm 0.460009 rank 1
2025-01-10 17:23:54,231 DEBUG TRAIN Batch 78/600 loss 0.074733 acc 0.948427 lr 0.00018171 grad_norm 0.460009 rank 2
2025-01-10 17:23:54,268 DEBUG TRAIN Batch 78/600 loss 0.054788 acc 0.961790 lr 0.00018171 grad_norm 0.460009 rank 0
2025-01-10 17:24:18,775 DEBUG TRAIN Batch 78/700 loss 0.076858 acc 0.944990 lr 0.00018165 grad_norm 0.481823 rank 0
2025-01-10 17:24:18,775 DEBUG TRAIN Batch 78/700 loss 0.080103 acc 0.942403 lr 0.00018165 grad_norm 0.481823 rank 2
2025-01-10 17:24:18,775 DEBUG TRAIN Batch 78/700 loss 0.071536 acc 0.956560 lr 0.00018165 grad_norm 0.481823 rank 1
2025-01-10 17:24:43,624 DEBUG TRAIN Batch 78/800 loss 0.069994 acc 0.955910 lr 0.00018159 grad_norm 0.467739 rank 0
2025-01-10 17:24:43,625 DEBUG TRAIN Batch 78/800 loss 0.058154 acc 0.961628 lr 0.00018159 grad_norm 0.467739 rank 2
2025-01-10 17:24:43,625 DEBUG TRAIN Batch 78/800 loss 0.063950 acc 0.954677 lr 0.00018159 grad_norm 0.467739 rank 1
2025-01-10 17:25:08,402 DEBUG TRAIN Batch 78/900 loss 0.049664 acc 0.966357 lr 0.00018153 grad_norm 0.477802 rank 0
2025-01-10 17:25:08,402 DEBUG TRAIN Batch 78/900 loss 0.090723 acc 0.927305 lr 0.00018153 grad_norm 0.477802 rank 1
2025-01-10 17:25:08,402 DEBUG TRAIN Batch 78/900 loss 0.091460 acc 0.943359 lr 0.00018153 grad_norm 0.477802 rank 2
2025-01-10 17:25:33,273 DEBUG TRAIN Batch 78/1000 loss 0.071158 acc 0.954894 lr 0.00018147 grad_norm 0.460239 rank 2
2025-01-10 17:25:33,273 DEBUG TRAIN Batch 78/1000 loss 0.060864 acc 0.963173 lr 0.00018147 grad_norm 0.460239 rank 0
2025-01-10 17:25:33,273 DEBUG TRAIN Batch 78/1000 loss 0.058732 acc 0.960680 lr 0.00018147 grad_norm 0.460239 rank 1
2025-01-10 17:25:58,373 DEBUG TRAIN Batch 78/1100 loss 0.058115 acc 0.963294 lr 0.00018141 grad_norm 0.482066 rank 1
2025-01-10 17:25:58,373 DEBUG TRAIN Batch 78/1100 loss 0.066118 acc 0.947276 lr 0.00018141 grad_norm 0.482066 rank 0
2025-01-10 17:25:58,373 DEBUG TRAIN Batch 78/1100 loss 0.083054 acc 0.942857 lr 0.00018141 grad_norm 0.482066 rank 2
2025-01-10 17:26:22,514 DEBUG TRAIN Batch 78/1200 loss 0.067203 acc 0.953721 lr 0.00018135 grad_norm 0.468150 rank 0
2025-01-10 17:26:22,514 DEBUG TRAIN Batch 78/1200 loss 0.078368 acc 0.943320 lr 0.00018135 grad_norm 0.468150 rank 2
2025-01-10 17:26:22,514 DEBUG TRAIN Batch 78/1200 loss 0.052216 acc 0.962925 lr 0.00018135 grad_norm 0.468150 rank 1
2025-01-10 17:26:47,693 DEBUG TRAIN Batch 78/1300 loss 0.052648 acc 0.966667 lr 0.00018129 grad_norm 0.497243 rank 0
2025-01-10 17:26:47,694 DEBUG TRAIN Batch 78/1300 loss 0.071742 acc 0.949009 lr 0.00018129 grad_norm 0.497243 rank 2
2025-01-10 17:26:47,694 DEBUG TRAIN Batch 78/1300 loss 0.093348 acc 0.933632 lr 0.00018129 grad_norm 0.497243 rank 1
2025-01-10 17:27:11,619 DEBUG TRAIN Batch 78/1400 loss 0.073833 acc 0.944954 lr 0.00018123 grad_norm 0.510244 rank 1
2025-01-10 17:27:11,620 DEBUG TRAIN Batch 78/1400 loss 0.085252 acc 0.937611 lr 0.00018123 grad_norm 0.510244 rank 2
2025-01-10 17:27:11,620 DEBUG TRAIN Batch 78/1400 loss 0.106324 acc 0.925926 lr 0.00018123 grad_norm 0.510244 rank 0
2025-01-10 17:27:36,256 DEBUG TRAIN Batch 78/1500 loss 0.096890 acc 0.932296 lr 0.00018117 grad_norm 0.527435 rank 0
2025-01-10 17:27:36,256 DEBUG TRAIN Batch 78/1500 loss 0.040668 acc 0.971140 lr 0.00018117 grad_norm 0.527435 rank 2
2025-01-10 17:27:36,257 DEBUG TRAIN Batch 78/1500 loss 0.077959 acc 0.943205 lr 0.00018117 grad_norm 0.527435 rank 1
2025-01-10 17:28:02,536 DEBUG TRAIN Batch 78/1600 loss 0.074185 acc 0.948745 lr 0.00018112 grad_norm 0.496230 rank 1
2025-01-10 17:28:02,536 DEBUG TRAIN Batch 78/1600 loss 0.090967 acc 0.938612 lr 0.00018112 grad_norm 0.496230 rank 0
2025-01-10 17:28:02,536 DEBUG TRAIN Batch 78/1600 loss 0.101147 acc 0.930909 lr 0.00018112 grad_norm 0.496230 rank 2
2025-01-10 17:28:27,155 DEBUG TRAIN Batch 78/1700 loss 0.067493 acc 0.953153 lr 0.00018106 grad_norm 0.468206 rank 1
2025-01-10 17:28:27,156 DEBUG TRAIN Batch 78/1700 loss 0.070904 acc 0.947569 lr 0.00018106 grad_norm 0.468206 rank 2
2025-01-10 17:28:27,156 DEBUG TRAIN Batch 78/1700 loss 0.060221 acc 0.962415 lr 0.00018106 grad_norm 0.468206 rank 0
2025-01-10 17:28:51,248 DEBUG TRAIN Batch 78/1800 loss 0.076249 acc 0.946494 lr 0.00018100 grad_norm 0.498059 rank 2
2025-01-10 17:28:51,248 DEBUG TRAIN Batch 78/1800 loss 0.082410 acc 0.946550 lr 0.00018100 grad_norm 0.498059 rank 0
2025-01-10 17:28:51,249 DEBUG TRAIN Batch 78/1800 loss 0.072651 acc 0.954737 lr 0.00018100 grad_norm 0.498059 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 17:30:11,721 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 17:30:11,724 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 17:30:12,205 INFO Epoch 78 Step 76356 on_batch_end True CV rank 0
2025-01-10 17:30:12,205 INFO Epoch 78 Step 76356 on_batch_end True CV rank 1
2025-01-10 17:30:12,205 INFO Epoch 78 Step 76356 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 17:30:21,233 DEBUG CV Batch 78/100 loss 0.008728 acc 0.998885  rank 0
2025-01-10 17:30:21,761 INFO Epoch 78 Step 76356 CV info lr 0.00018094576362831142 0 rank loss_2.22344044986663 acc_0.778008461129247
2025-01-10 17:30:21,766 DEBUG CV Batch 78/100 loss 0.008728 acc 0.998885  rank 2
2025-01-10 17:30:21,960 DEBUG CV Batch 78/100 loss 0.008728 acc 0.998885  rank 1
2025-01-10 17:30:22,311 INFO Epoch 78 Step 76356 CV info lr 0.00018094576362831142 2 rank loss_2.22344044986663 acc_0.778008461129247
2025-01-10 17:30:22,519 INFO Epoch 78 Step 76356 CV info lr 0.00018094576362831142 1 rank loss_2.22344044986663 acc_0.778008461129247
2025-01-10 17:30:23,057 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_78_whole.pt
2025-01-10 17:30:23,069 INFO Added key: store_based_barrier_key:81 to store for rank: 0
2025-01-10 17:30:23,079 INFO Added key: store_based_barrier_key:81 to store for rank: 1
2025-01-10 17:30:23,079 INFO Added key: store_based_barrier_key:81 to store for rank: 2
2025-01-10 17:30:23,079 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:81 with 3 nodes.
2025-01-10 17:30:23,083 INFO Epoch 79 TRAIN info lr 0.00018094576362831142 rank 2
2025-01-10 17:30:23,083 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 17:30:23,089 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:81 with 3 nodes.
2025-01-10 17:30:23,089 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:81 with 3 nodes.
2025-01-10 17:30:23,091 INFO Epoch 79 TRAIN info lr 0.00018094576362831142 rank 0
2025-01-10 17:30:23,091 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 17:30:23,096 INFO Epoch 79 TRAIN info lr 0.00018094576362831142 rank 1
2025-01-10 17:30:23,096 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 17:30:54,128 DEBUG TRAIN Batch 79/100 loss 0.054308 acc 0.963617 lr 0.00018089 grad_norm 0.473962 rank 1
2025-01-10 17:30:54,128 DEBUG TRAIN Batch 79/100 loss 0.059142 acc 0.957627 lr 0.00018089 grad_norm 0.473962 rank 2
2025-01-10 17:30:54,128 DEBUG TRAIN Batch 79/100 loss 0.085664 acc 0.941329 lr 0.00018089 grad_norm 0.473962 rank 0
2025-01-10 17:31:17,850 DEBUG TRAIN Batch 79/200 loss 0.048707 acc 0.969582 lr 0.00018083 grad_norm 0.512139 rank 0
2025-01-10 17:31:17,850 DEBUG TRAIN Batch 79/200 loss 0.076809 acc 0.946266 lr 0.00018083 grad_norm 0.512139 rank 1
2025-01-10 17:31:17,850 DEBUG TRAIN Batch 79/200 loss 0.063040 acc 0.951017 lr 0.00018083 grad_norm 0.512139 rank 2
2025-01-10 17:31:41,695 DEBUG TRAIN Batch 79/300 loss 0.058459 acc 0.961248 lr 0.00018077 grad_norm 0.480377 rank 1
2025-01-10 17:31:41,695 DEBUG TRAIN Batch 79/300 loss 0.075627 acc 0.947858 lr 0.00018077 grad_norm 0.480377 rank 2
2025-01-10 17:31:41,696 DEBUG TRAIN Batch 79/300 loss 0.075275 acc 0.949282 lr 0.00018077 grad_norm 0.480377 rank 0
2025-01-10 17:32:05,511 DEBUG TRAIN Batch 79/400 loss 0.055711 acc 0.963147 lr 0.00018071 grad_norm 0.464875 rank 1
2025-01-10 17:32:05,511 DEBUG TRAIN Batch 79/400 loss 0.079264 acc 0.948566 lr 0.00018071 grad_norm 0.464875 rank 0
2025-01-10 17:32:05,511 DEBUG TRAIN Batch 79/400 loss 0.056678 acc 0.963532 lr 0.00018071 grad_norm 0.464875 rank 2
2025-01-10 17:32:30,854 DEBUG TRAIN Batch 79/500 loss 0.063521 acc 0.952428 lr 0.00018065 grad_norm 0.493661 rank 0
2025-01-10 17:32:30,855 DEBUG TRAIN Batch 79/500 loss 0.033731 acc 0.972881 lr 0.00018065 grad_norm 0.493661 rank 1
2025-01-10 17:32:30,855 DEBUG TRAIN Batch 79/500 loss 0.064934 acc 0.957031 lr 0.00018065 grad_norm 0.493661 rank 2
2025-01-10 17:32:54,253 DEBUG TRAIN Batch 79/600 loss 0.044235 acc 0.971514 lr 0.00018059 grad_norm 0.449752 rank 1
2025-01-10 17:32:54,253 DEBUG TRAIN Batch 79/600 loss 0.048589 acc 0.966084 lr 0.00018059 grad_norm 0.449752 rank 2
2025-01-10 17:32:54,254 DEBUG TRAIN Batch 79/600 loss 0.049332 acc 0.967742 lr 0.00018059 grad_norm 0.449752 rank 0
2025-01-10 17:33:18,781 DEBUG TRAIN Batch 79/700 loss 0.039521 acc 0.968545 lr 0.00018053 grad_norm 0.467473 rank 1
2025-01-10 17:33:18,781 DEBUG TRAIN Batch 79/700 loss 0.069043 acc 0.943416 lr 0.00018053 grad_norm 0.467473 rank 0
2025-01-10 17:33:18,782 DEBUG TRAIN Batch 79/700 loss 0.082010 acc 0.948695 lr 0.00018053 grad_norm 0.467473 rank 2
2025-01-10 17:33:44,788 DEBUG TRAIN Batch 79/800 loss 0.056737 acc 0.962177 lr 0.00018047 grad_norm 0.489380 rank 1
2025-01-10 17:33:44,789 DEBUG TRAIN Batch 79/800 loss 0.056478 acc 0.957071 lr 0.00018047 grad_norm 0.489380 rank 0
2025-01-10 17:33:44,789 DEBUG TRAIN Batch 79/800 loss 0.071506 acc 0.951841 lr 0.00018047 grad_norm 0.489380 rank 2
2025-01-10 17:34:09,725 DEBUG TRAIN Batch 79/900 loss 0.040346 acc 0.976801 lr 0.00018041 grad_norm 0.468306 rank 1
2025-01-10 17:34:09,725 DEBUG TRAIN Batch 79/900 loss 0.075460 acc 0.950564 lr 0.00018041 grad_norm 0.468306 rank 0
2025-01-10 17:34:09,726 DEBUG TRAIN Batch 79/900 loss 0.059298 acc 0.952772 lr 0.00018041 grad_norm 0.468306 rank 2
2025-01-10 17:34:33,745 DEBUG TRAIN Batch 79/1000 loss 0.071337 acc 0.946544 lr 0.00018036 grad_norm 0.474573 rank 1
2025-01-10 17:34:33,745 DEBUG TRAIN Batch 79/1000 loss 0.058613 acc 0.952017 lr 0.00018036 grad_norm 0.474573 rank 2
2025-01-10 17:34:33,745 DEBUG TRAIN Batch 79/1000 loss 0.064609 acc 0.954152 lr 0.00018036 grad_norm 0.474573 rank 0
2025-01-10 17:34:58,629 DEBUG TRAIN Batch 79/1100 loss 0.069426 acc 0.950787 lr 0.00018030 grad_norm 0.505219 rank 0
2025-01-10 17:34:58,630 DEBUG TRAIN Batch 79/1100 loss 0.048846 acc 0.967033 lr 0.00018030 grad_norm 0.505219 rank 1
2025-01-10 17:34:58,630 DEBUG TRAIN Batch 79/1100 loss 0.094747 acc 0.933746 lr 0.00018030 grad_norm 0.505219 rank 2
2025-01-10 17:35:23,161 DEBUG TRAIN Batch 79/1200 loss 0.049495 acc 0.965374 lr 0.00018024 grad_norm 0.520977 rank 1
2025-01-10 17:35:23,162 DEBUG TRAIN Batch 79/1200 loss 0.062874 acc 0.960784 lr 0.00018024 grad_norm 0.520977 rank 2
2025-01-10 17:35:23,162 DEBUG TRAIN Batch 79/1200 loss 0.060549 acc 0.953125 lr 0.00018024 grad_norm 0.520977 rank 0
2025-01-10 17:35:48,438 DEBUG TRAIN Batch 79/1300 loss 0.057558 acc 0.956929 lr 0.00018018 grad_norm 0.457527 rank 0
2025-01-10 17:35:48,438 DEBUG TRAIN Batch 79/1300 loss 0.049335 acc 0.962719 lr 0.00018018 grad_norm 0.457527 rank 1
2025-01-10 17:35:48,439 DEBUG TRAIN Batch 79/1300 loss 0.070355 acc 0.949288 lr 0.00018018 grad_norm 0.457527 rank 2
2025-01-10 17:36:12,464 DEBUG TRAIN Batch 79/1400 loss 0.067279 acc 0.954254 lr 0.00018012 grad_norm 0.473661 rank 1
2025-01-10 17:36:12,464 DEBUG TRAIN Batch 79/1400 loss 0.050741 acc 0.961625 lr 0.00018012 grad_norm 0.473661 rank 0
2025-01-10 17:36:12,464 DEBUG TRAIN Batch 79/1400 loss 0.095733 acc 0.929021 lr 0.00018012 grad_norm 0.473661 rank 2
2025-01-10 17:36:36,543 DEBUG TRAIN Batch 79/1500 loss 0.069961 acc 0.946394 lr 0.00018006 grad_norm 0.474157 rank 0
2025-01-10 17:36:36,544 DEBUG TRAIN Batch 79/1500 loss 0.067051 acc 0.957360 lr 0.00018006 grad_norm 0.474157 rank 1
2025-01-10 17:36:36,544 DEBUG TRAIN Batch 79/1500 loss 0.073579 acc 0.950754 lr 0.00018006 grad_norm 0.474157 rank 2
2025-01-10 17:37:00,849 DEBUG TRAIN Batch 79/1600 loss 0.073758 acc 0.945946 lr 0.00018001 grad_norm 0.503850 rank 1
2025-01-10 17:37:00,849 DEBUG TRAIN Batch 79/1600 loss 0.081404 acc 0.940620 lr 0.00018001 grad_norm 0.503850 rank 2
2025-01-10 17:37:00,849 DEBUG TRAIN Batch 79/1600 loss 0.080088 acc 0.946147 lr 0.00018001 grad_norm 0.503850 rank 0
2025-01-10 17:37:25,389 DEBUG TRAIN Batch 79/1700 loss 0.039117 acc 0.974444 lr 0.00017995 grad_norm 0.461575 rank 1
2025-01-10 17:37:25,390 DEBUG TRAIN Batch 79/1700 loss 0.076550 acc 0.942675 lr 0.00017995 grad_norm 0.461575 rank 2
2025-01-10 17:37:25,389 DEBUG TRAIN Batch 79/1700 loss 0.079503 acc 0.948473 lr 0.00017995 grad_norm 0.461575 rank 0
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 17:38:40,849 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 17:38:40,854 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 17:38:41,321 INFO Epoch 79 Step 77238 on_batch_end True CV rank 1
2025-01-10 17:38:41,321 INFO Epoch 79 Step 77238 on_batch_end True CV rank 0
2025-01-10 17:38:41,322 INFO Epoch 79 Step 77238 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 17:38:50,472 DEBUG CV Batch 79/100 loss 0.018940 acc 0.993311  rank 0
2025-01-10 17:38:50,876 DEBUG CV Batch 79/100 loss 0.018940 acc 0.993311  rank 2
2025-01-10 17:38:51,006 INFO Epoch 79 Step 77238 CV info lr 0.00017990966484919543 0 rank loss_2.257075164912334 acc_0.7794841312264141
2025-01-10 17:38:51,062 DEBUG CV Batch 79/100 loss 0.018940 acc 0.993311  rank 1
2025-01-10 17:38:51,370 INFO Epoch 79 Step 77238 CV info lr 0.00017990966484919543 2 rank loss_2.257075164912334 acc_0.7794841312264141
2025-01-10 17:38:51,621 INFO Epoch 79 Step 77238 CV info lr 0.00017990966484919543 1 rank loss_2.257075164912334 acc_0.7794841312264141
2025-01-10 17:38:52,312 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_79_whole.pt
2025-01-10 17:38:52,333 INFO Added key: store_based_barrier_key:82 to store for rank: 0
2025-01-10 17:38:52,334 INFO Added key: store_based_barrier_key:82 to store for rank: 1
2025-01-10 17:38:52,334 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:82 with 3 nodes.
2025-01-10 17:38:52,334 INFO Added key: store_based_barrier_key:82 to store for rank: 2
2025-01-10 17:38:52,334 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:82 with 3 nodes.
2025-01-10 17:38:52,338 INFO Epoch 80 TRAIN info lr 0.00017990966484919543 rank 1
2025-01-10 17:38:52,338 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 17:38:52,339 INFO Epoch 80 TRAIN info lr 0.00017990966484919543 rank 2
2025-01-10 17:38:52,339 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 17:38:52,344 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:82 with 3 nodes.
2025-01-10 17:38:52,353 INFO Epoch 80 TRAIN info lr 0.00017990966484919543 rank 0
2025-01-10 17:38:52,353 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 17:39:23,933 DEBUG TRAIN Batch 80/100 loss 0.068328 acc 0.955856 lr 0.00017985 grad_norm 0.468616 rank 1
2025-01-10 17:39:23,933 DEBUG TRAIN Batch 80/100 loss 0.056759 acc 0.955461 lr 0.00017985 grad_norm 0.468616 rank 2
2025-01-10 17:39:23,934 DEBUG TRAIN Batch 80/100 loss 0.072933 acc 0.948122 lr 0.00017985 grad_norm 0.468616 rank 0
2025-01-10 17:39:47,878 DEBUG TRAIN Batch 80/200 loss 0.051811 acc 0.972707 lr 0.00017979 grad_norm 0.458564 rank 1
2025-01-10 17:39:47,878 DEBUG TRAIN Batch 80/200 loss 0.031700 acc 0.973552 lr 0.00017979 grad_norm 0.458564 rank 0
2025-01-10 17:39:47,878 DEBUG TRAIN Batch 80/200 loss 0.058945 acc 0.959386 lr 0.00017979 grad_norm 0.458564 rank 2
2025-01-10 17:40:11,533 DEBUG TRAIN Batch 80/300 loss 0.079996 acc 0.943934 lr 0.00017974 grad_norm 0.485029 rank 1
2025-01-10 17:40:11,533 DEBUG TRAIN Batch 80/300 loss 0.094225 acc 0.933271 lr 0.00017974 grad_norm 0.485029 rank 0
2025-01-10 17:40:11,534 DEBUG TRAIN Batch 80/300 loss 0.065793 acc 0.949282 lr 0.00017974 grad_norm 0.485029 rank 2
2025-01-10 17:40:35,523 DEBUG TRAIN Batch 80/400 loss 0.080852 acc 0.942652 lr 0.00017968 grad_norm 0.471280 rank 0
2025-01-10 17:40:35,523 DEBUG TRAIN Batch 80/400 loss 0.052165 acc 0.965394 lr 0.00017968 grad_norm 0.471280 rank 1
2025-01-10 17:40:35,524 DEBUG TRAIN Batch 80/400 loss 0.053539 acc 0.964657 lr 0.00017968 grad_norm 0.471280 rank 2
2025-01-10 17:40:59,973 DEBUG TRAIN Batch 80/500 loss 0.066417 acc 0.952797 lr 0.00017962 grad_norm 0.452667 rank 0
2025-01-10 17:40:59,973 DEBUG TRAIN Batch 80/500 loss 0.067694 acc 0.949169 lr 0.00017962 grad_norm 0.452667 rank 2
2025-01-10 17:40:59,973 DEBUG TRAIN Batch 80/500 loss 0.055169 acc 0.965079 lr 0.00017962 grad_norm 0.452667 rank 1
2025-01-10 17:41:23,414 DEBUG TRAIN Batch 80/600 loss 0.060566 acc 0.959307 lr 0.00017956 grad_norm 0.458924 rank 1
2025-01-10 17:41:23,414 DEBUG TRAIN Batch 80/600 loss 0.066176 acc 0.956197 lr 0.00017956 grad_norm 0.458924 rank 2
2025-01-10 17:41:23,414 DEBUG TRAIN Batch 80/600 loss 0.057057 acc 0.959427 lr 0.00017956 grad_norm 0.458924 rank 0
2025-01-10 17:41:48,012 DEBUG TRAIN Batch 80/700 loss 0.098144 acc 0.936813 lr 0.00017950 grad_norm 0.493840 rank 2
2025-01-10 17:41:48,013 DEBUG TRAIN Batch 80/700 loss 0.034542 acc 0.975689 lr 0.00017950 grad_norm 0.493840 rank 0
2025-01-10 17:41:48,012 DEBUG TRAIN Batch 80/700 loss 0.062548 acc 0.950478 lr 0.00017950 grad_norm 0.493840 rank 1
2025-01-10 17:42:12,185 DEBUG TRAIN Batch 80/800 loss 0.060582 acc 0.961501 lr 0.00017945 grad_norm 0.481666 rank 1
2025-01-10 17:42:12,186 DEBUG TRAIN Batch 80/800 loss 0.069181 acc 0.950322 lr 0.00017945 grad_norm 0.481666 rank 0
2025-01-10 17:42:12,186 DEBUG TRAIN Batch 80/800 loss 0.092676 acc 0.937440 lr 0.00017945 grad_norm 0.481666 rank 2
2025-01-10 17:42:36,102 DEBUG TRAIN Batch 80/900 loss 0.067571 acc 0.955375 lr 0.00017939 grad_norm 0.494002 rank 0
2025-01-10 17:42:36,102 DEBUG TRAIN Batch 80/900 loss 0.063327 acc 0.955326 lr 0.00017939 grad_norm 0.494002 rank 2
2025-01-10 17:42:36,102 DEBUG TRAIN Batch 80/900 loss 0.069477 acc 0.950050 lr 0.00017939 grad_norm 0.494002 rank 1
2025-01-10 17:43:00,590 DEBUG TRAIN Batch 80/1000 loss 0.078749 acc 0.947059 lr 0.00017933 grad_norm 0.481717 rank 1
2025-01-10 17:43:00,590 DEBUG TRAIN Batch 80/1000 loss 0.069391 acc 0.953244 lr 0.00017933 grad_norm 0.481717 rank 2
2025-01-10 17:43:00,591 DEBUG TRAIN Batch 80/1000 loss 0.056982 acc 0.963415 lr 0.00017933 grad_norm 0.481717 rank 0
2025-01-10 17:43:26,266 DEBUG TRAIN Batch 80/1100 loss 0.076281 acc 0.946864 lr 0.00017927 grad_norm 0.504533 rank 2
2025-01-10 17:43:26,266 DEBUG TRAIN Batch 80/1100 loss 0.077513 acc 0.946074 lr 0.00017927 grad_norm 0.504533 rank 1
2025-01-10 17:43:26,266 DEBUG TRAIN Batch 80/1100 loss 0.040667 acc 0.973239 lr 0.00017927 grad_norm 0.504533 rank 0
2025-01-10 17:43:50,890 DEBUG TRAIN Batch 80/1200 loss 0.081755 acc 0.933472 lr 0.00017921 grad_norm 0.483149 rank 2
2025-01-10 17:43:50,890 DEBUG TRAIN Batch 80/1200 loss 0.076980 acc 0.949477 lr 0.00017921 grad_norm 0.483149 rank 0
2025-01-10 17:43:50,891 DEBUG TRAIN Batch 80/1200 loss 0.070456 acc 0.959032 lr 0.00017921 grad_norm 0.483149 rank 1
2025-01-10 17:44:14,987 DEBUG TRAIN Batch 80/1300 loss 0.095408 acc 0.935652 lr 0.00017916 grad_norm 0.486775 rank 1
2025-01-10 17:44:14,987 DEBUG TRAIN Batch 80/1300 loss 0.058286 acc 0.967809 lr 0.00017916 grad_norm 0.486775 rank 2
2025-01-10 17:44:14,987 DEBUG TRAIN Batch 80/1300 loss 0.062851 acc 0.956827 lr 0.00017916 grad_norm 0.486775 rank 0
2025-01-10 17:44:40,392 DEBUG TRAIN Batch 80/1400 loss 0.062613 acc 0.954590 lr 0.00017910 grad_norm 0.452337 rank 0
2025-01-10 17:44:40,392 DEBUG TRAIN Batch 80/1400 loss 0.049683 acc 0.964720 lr 0.00017910 grad_norm 0.452337 rank 1
2025-01-10 17:44:40,392 DEBUG TRAIN Batch 80/1400 loss 0.041611 acc 0.973494 lr 0.00017910 grad_norm 0.452337 rank 2
2025-01-10 17:45:04,373 DEBUG TRAIN Batch 80/1500 loss 0.067968 acc 0.956731 lr 0.00017904 grad_norm 0.499765 rank 2
2025-01-10 17:45:04,374 DEBUG TRAIN Batch 80/1500 loss 0.065191 acc 0.951796 lr 0.00017904 grad_norm 0.499765 rank 1
2025-01-10 17:45:04,374 DEBUG TRAIN Batch 80/1500 loss 0.058395 acc 0.952709 lr 0.00017904 grad_norm 0.499765 rank 0
2025-01-10 17:45:29,377 DEBUG TRAIN Batch 80/1600 loss 0.093679 acc 0.937445 lr 0.00017899 grad_norm 0.515529 rank 1
2025-01-10 17:45:29,377 DEBUG TRAIN Batch 80/1600 loss 0.076426 acc 0.954301 lr 0.00017899 grad_norm 0.515529 rank 0
2025-01-10 17:45:29,377 DEBUG TRAIN Batch 80/1600 loss 0.041450 acc 0.962687 lr 0.00017899 grad_norm 0.515529 rank 2
2025-01-10 17:45:53,482 DEBUG TRAIN Batch 80/1700 loss 0.058940 acc 0.954248 lr 0.00017893 grad_norm 0.493275 rank 2
2025-01-10 17:45:53,482 DEBUG TRAIN Batch 80/1700 loss 0.071837 acc 0.949715 lr 0.00017893 grad_norm 0.493275 rank 1
2025-01-10 17:45:53,483 DEBUG TRAIN Batch 80/1700 loss 0.060951 acc 0.955010 lr 0.00017893 grad_norm 0.493275 rank 0
2025-01-10 17:46:17,562 DEBUG TRAIN Batch 80/1800 loss 0.079192 acc 0.943756 lr 0.00017887 grad_norm 0.505364 rank 0
2025-01-10 17:46:17,562 DEBUG TRAIN Batch 80/1800 loss 0.069083 acc 0.957786 lr 0.00017887 grad_norm 0.505364 rank 1
2025-01-10 17:46:17,562 DEBUG TRAIN Batch 80/1800 loss 0.061725 acc 0.956683 lr 0.00017887 grad_norm 0.505364 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 17:47:41,804 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 17:47:41,811 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 17:47:42,280 INFO Epoch 80 Step 78186 on_batch_end True CV rank 2
2025-01-10 17:47:42,280 INFO Epoch 80 Step 78186 on_batch_end True CV rank 0
2025-01-10 17:47:42,280 INFO Epoch 80 Step 78186 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 17:47:51,685 DEBUG CV Batch 80/100 loss 0.013754 acc 0.994426  rank 0
2025-01-10 17:47:51,739 DEBUG CV Batch 80/100 loss 0.013754 acc 0.994426  rank 2
2025-01-10 17:47:52,087 DEBUG CV Batch 80/100 loss 0.013754 acc 0.994426  rank 1
2025-01-10 17:47:52,227 INFO Epoch 80 Step 78186 CV info lr 0.00017881564219479216 0 rank loss_2.2408076054579986 acc_0.7783080832215777
2025-01-10 17:47:52,245 INFO Epoch 80 Step 78186 CV info lr 0.00017881564219479216 2 rank loss_2.2408076054579986 acc_0.7783080832215777
2025-01-10 17:47:52,637 INFO Epoch 80 Step 78186 CV info lr 0.00017881564219479216 1 rank loss_2.2408076054579986 acc_0.7783080832215777
2025-01-10 17:47:53,524 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_80_whole.pt
2025-01-10 17:47:53,536 INFO Added key: store_based_barrier_key:83 to store for rank: 0
2025-01-10 17:47:53,546 INFO Added key: store_based_barrier_key:83 to store for rank: 1
2025-01-10 17:47:53,546 INFO Added key: store_based_barrier_key:83 to store for rank: 2
2025-01-10 17:47:53,546 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:83 with 3 nodes.
2025-01-10 17:47:53,546 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:83 with 3 nodes.
2025-01-10 17:47:53,548 INFO Epoch 81 TRAIN info lr 0.00017881564219479216 rank 1
2025-01-10 17:47:53,548 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 17:47:53,551 INFO Epoch 81 TRAIN info lr 0.00017881564219479216 rank 2
2025-01-10 17:47:53,551 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 17:47:53,556 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:83 with 3 nodes.
2025-01-10 17:47:53,557 INFO Epoch 81 TRAIN info lr 0.00017881564219479216 rank 0
2025-01-10 17:47:53,557 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 17:48:23,974 DEBUG TRAIN Batch 81/100 loss 0.084374 acc 0.942308 lr 0.00017876 grad_norm 0.489516 rank 2
2025-01-10 17:48:23,974 DEBUG TRAIN Batch 81/100 loss 0.061622 acc 0.955603 lr 0.00017876 grad_norm 0.489516 rank 0
2025-01-10 17:48:23,975 DEBUG TRAIN Batch 81/100 loss 0.070546 acc 0.947834 lr 0.00017876 grad_norm 0.489516 rank 1
2025-01-10 17:48:47,545 DEBUG TRAIN Batch 81/200 loss 0.052800 acc 0.961749 lr 0.00017870 grad_norm 0.466405 rank 2
2025-01-10 17:48:47,546 DEBUG TRAIN Batch 81/200 loss 0.077158 acc 0.944444 lr 0.00017870 grad_norm 0.466405 rank 1
2025-01-10 17:48:47,546 DEBUG TRAIN Batch 81/200 loss 0.087892 acc 0.942029 lr 0.00017870 grad_norm 0.466405 rank 0
2025-01-10 17:49:10,927 DEBUG TRAIN Batch 81/300 loss 0.065746 acc 0.950853 lr 0.00017864 grad_norm 0.466783 rank 0
2025-01-10 17:49:10,927 DEBUG TRAIN Batch 81/300 loss 0.089511 acc 0.936493 lr 0.00017864 grad_norm 0.466783 rank 1
2025-01-10 17:49:10,928 DEBUG TRAIN Batch 81/300 loss 0.052723 acc 0.968577 lr 0.00017864 grad_norm 0.466783 rank 2
2025-01-10 17:49:34,943 DEBUG TRAIN Batch 81/400 loss 0.058924 acc 0.956236 lr 0.00017859 grad_norm 0.470599 rank 0
2025-01-10 17:49:34,943 DEBUG TRAIN Batch 81/400 loss 0.041386 acc 0.971193 lr 0.00017859 grad_norm 0.470599 rank 2
2025-01-10 17:49:34,943 DEBUG TRAIN Batch 81/400 loss 0.065450 acc 0.959233 lr 0.00017859 grad_norm 0.470599 rank 1
2025-01-10 17:49:58,883 DEBUG TRAIN Batch 81/500 loss 0.075660 acc 0.943800 lr 0.00017853 grad_norm 0.466163 rank 1
2025-01-10 17:49:58,883 DEBUG TRAIN Batch 81/500 loss 0.055915 acc 0.960245 lr 0.00017853 grad_norm 0.466163 rank 2
2025-01-10 17:49:58,883 DEBUG TRAIN Batch 81/500 loss 0.078448 acc 0.940520 lr 0.00017853 grad_norm 0.466163 rank 0
2025-01-10 17:50:22,926 DEBUG TRAIN Batch 81/600 loss 0.077290 acc 0.953110 lr 0.00017847 grad_norm 0.485646 rank 1
2025-01-10 17:50:22,927 DEBUG TRAIN Batch 81/600 loss 0.073670 acc 0.950331 lr 0.00017847 grad_norm 0.485646 rank 2
2025-01-10 17:50:22,928 DEBUG TRAIN Batch 81/600 loss 0.065497 acc 0.961840 lr 0.00017847 grad_norm 0.485646 rank 0
2025-01-10 17:50:46,767 DEBUG TRAIN Batch 81/700 loss 0.053386 acc 0.964813 lr 0.00017842 grad_norm 0.470733 rank 0
2025-01-10 17:50:46,767 DEBUG TRAIN Batch 81/700 loss 0.070026 acc 0.949050 lr 0.00017842 grad_norm 0.470733 rank 1
2025-01-10 17:50:46,767 DEBUG TRAIN Batch 81/700 loss 0.063056 acc 0.959319 lr 0.00017842 grad_norm 0.470733 rank 2
2025-01-10 17:51:10,598 DEBUG TRAIN Batch 81/800 loss 0.051294 acc 0.966194 lr 0.00017836 grad_norm 0.461243 rank 1
2025-01-10 17:51:10,598 DEBUG TRAIN Batch 81/800 loss 0.072610 acc 0.942962 lr 0.00017836 grad_norm 0.461243 rank 2
2025-01-10 17:51:10,599 DEBUG TRAIN Batch 81/800 loss 0.077516 acc 0.947850 lr 0.00017836 grad_norm 0.461243 rank 0
2025-01-10 17:51:34,996 DEBUG TRAIN Batch 81/900 loss 0.049309 acc 0.969216 lr 0.00017830 grad_norm 0.441795 rank 1
2025-01-10 17:51:34,996 DEBUG TRAIN Batch 81/900 loss 0.083630 acc 0.942966 lr 0.00017830 grad_norm 0.441795 rank 0
2025-01-10 17:51:34,997 DEBUG TRAIN Batch 81/900 loss 0.065155 acc 0.958369 lr 0.00017830 grad_norm 0.441795 rank 2
2025-01-10 17:51:59,337 DEBUG TRAIN Batch 81/1000 loss 0.050849 acc 0.965729 lr 0.00017825 grad_norm 0.467345 rank 2
2025-01-10 17:51:59,337 DEBUG TRAIN Batch 81/1000 loss 0.065580 acc 0.957576 lr 0.00017825 grad_norm 0.467345 rank 1
2025-01-10 17:51:59,337 DEBUG TRAIN Batch 81/1000 loss 0.066134 acc 0.949902 lr 0.00017825 grad_norm 0.467345 rank 0
2025-01-10 17:52:24,122 DEBUG TRAIN Batch 81/1100 loss 0.064649 acc 0.958920 lr 0.00017819 grad_norm 0.486384 rank 1
2025-01-10 17:52:24,122 DEBUG TRAIN Batch 81/1100 loss 0.057438 acc 0.960685 lr 0.00017819 grad_norm 0.486384 rank 2
2025-01-10 17:52:24,122 DEBUG TRAIN Batch 81/1100 loss 0.065799 acc 0.953567 lr 0.00017819 grad_norm 0.486384 rank 0
2025-01-10 17:52:49,381 DEBUG TRAIN Batch 81/1200 loss 0.061581 acc 0.958289 lr 0.00017813 grad_norm 0.493097 rank 1
2025-01-10 17:52:49,381 DEBUG TRAIN Batch 81/1200 loss 0.028712 acc 0.975530 lr 0.00017813 grad_norm 0.493097 rank 2
2025-01-10 17:52:49,381 DEBUG TRAIN Batch 81/1200 loss 0.080701 acc 0.943132 lr 0.00017813 grad_norm 0.493097 rank 0
2025-01-10 17:53:14,213 DEBUG TRAIN Batch 81/1300 loss 0.044845 acc 0.969477 lr 0.00017808 grad_norm 0.500115 rank 2
2025-01-10 17:53:14,214 DEBUG TRAIN Batch 81/1300 loss 0.067688 acc 0.954764 lr 0.00017808 grad_norm 0.500115 rank 1
2025-01-10 17:53:14,215 DEBUG TRAIN Batch 81/1300 loss 0.089116 acc 0.943223 lr 0.00017808 grad_norm 0.500115 rank 0
2025-01-10 17:53:38,832 DEBUG TRAIN Batch 81/1400 loss 0.073194 acc 0.943993 lr 0.00017802 grad_norm 0.479714 rank 1
2025-01-10 17:53:38,833 DEBUG TRAIN Batch 81/1400 loss 0.065512 acc 0.955260 lr 0.00017802 grad_norm 0.479714 rank 2
2025-01-10 17:53:38,833 DEBUG TRAIN Batch 81/1400 loss 0.052288 acc 0.959794 lr 0.00017802 grad_norm 0.479714 rank 0
2025-01-10 17:54:03,782 DEBUG TRAIN Batch 81/1500 loss 0.072542 acc 0.950348 lr 0.00017796 grad_norm 0.482154 rank 1
2025-01-10 17:54:03,782 DEBUG TRAIN Batch 81/1500 loss 0.079618 acc 0.948798 lr 0.00017796 grad_norm 0.482154 rank 0
2025-01-10 17:54:03,783 DEBUG TRAIN Batch 81/1500 loss 0.045085 acc 0.969149 lr 0.00017796 grad_norm 0.482154 rank 2
2025-01-10 17:54:28,249 DEBUG TRAIN Batch 81/1600 loss 0.063937 acc 0.946597 lr 0.00017791 grad_norm 0.499833 rank 1
2025-01-10 17:54:28,250 DEBUG TRAIN Batch 81/1600 loss 0.053549 acc 0.961498 lr 0.00017791 grad_norm 0.499833 rank 2
2025-01-10 17:54:28,250 DEBUG TRAIN Batch 81/1600 loss 0.065040 acc 0.952509 lr 0.00017791 grad_norm 0.499833 rank 0
2025-01-10 17:54:53,833 DEBUG TRAIN Batch 81/1700 loss 0.086936 acc 0.942222 lr 0.00017785 grad_norm 0.491752 rank 1
2025-01-10 17:54:53,833 DEBUG TRAIN Batch 81/1700 loss 0.037962 acc 0.979661 lr 0.00017785 grad_norm 0.491752 rank 2
2025-01-10 17:54:53,833 DEBUG TRAIN Batch 81/1700 loss 0.061194 acc 0.961155 lr 0.00017785 grad_norm 0.491752 rank 0
2025-01-10 17:55:17,565 DEBUG TRAIN Batch 81/1800 loss 0.082096 acc 0.943739 lr 0.00017780 grad_norm 0.478352 rank 1
2025-01-10 17:55:17,566 DEBUG TRAIN Batch 81/1800 loss 0.049262 acc 0.966917 lr 0.00017780 grad_norm 0.478352 rank 2
2025-01-10 17:55:17,566 DEBUG TRAIN Batch 81/1800 loss 0.070068 acc 0.946644 lr 0.00017780 grad_norm 0.478352 rank 0
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 17:56:36,811 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 17:56:36,816 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 17:56:37,274 INFO Epoch 81 Step 79126 on_batch_end True CV rank 2
2025-01-10 17:56:37,274 INFO Epoch 81 Step 79126 on_batch_end True CV rank 0
2025-01-10 17:56:37,274 INFO Epoch 81 Step 79126 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 17:56:46,364 DEBUG CV Batch 81/100 loss 0.020637 acc 0.993311  rank 0
2025-01-10 17:56:46,554 DEBUG CV Batch 81/100 loss 0.020637 acc 0.993311  rank 2
2025-01-10 17:56:46,888 DEBUG CV Batch 81/100 loss 0.020637 acc 0.993311  rank 1
2025-01-10 17:56:46,895 INFO Epoch 81 Step 79126 CV info lr 0.00017775032295929894 0 rank loss_2.253822379445314 acc_0.7793995110612166
2025-01-10 17:56:47,083 INFO Epoch 81 Step 79126 CV info lr 0.00017775032295929894 2 rank loss_2.253822379445314 acc_0.7793995110612166
2025-01-10 17:56:47,450 INFO Epoch 81 Step 79126 CV info lr 0.00017775032295929894 1 rank loss_2.253822379445314 acc_0.7793995110612166
2025-01-10 17:56:48,271 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_81_whole.pt
2025-01-10 17:56:48,293 INFO Added key: store_based_barrier_key:84 to store for rank: 1
2025-01-10 17:56:48,293 INFO Added key: store_based_barrier_key:84 to store for rank: 0
2025-01-10 17:56:48,293 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:84 with 3 nodes.
2025-01-10 17:56:48,293 INFO Added key: store_based_barrier_key:84 to store for rank: 2
2025-01-10 17:56:48,293 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:84 with 3 nodes.
2025-01-10 17:56:48,297 INFO Epoch 82 TRAIN info lr 0.00017775032295929894 rank 2
2025-01-10 17:56:48,297 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 17:56:48,298 INFO Epoch 82 TRAIN info lr 0.00017775032295929894 rank 0
2025-01-10 17:56:48,298 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 17:56:48,303 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:84 with 3 nodes.
2025-01-10 17:56:48,308 INFO Epoch 82 TRAIN info lr 0.00017775032295929894 rank 1
2025-01-10 17:56:48,308 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 17:57:24,804 DEBUG TRAIN Batch 82/100 loss 0.056673 acc 0.960764 lr 0.00017769 grad_norm 0.471804 rank 1
2025-01-10 17:57:24,804 DEBUG TRAIN Batch 82/100 loss 0.037247 acc 0.977157 lr 0.00017769 grad_norm 0.471804 rank 2
2025-01-10 17:57:24,804 DEBUG TRAIN Batch 82/100 loss 0.069286 acc 0.944388 lr 0.00017769 grad_norm 0.471804 rank 0
2025-01-10 17:57:49,105 DEBUG TRAIN Batch 82/200 loss 0.071374 acc 0.950530 lr 0.00017764 grad_norm 0.483237 rank 0
2025-01-10 17:57:49,105 DEBUG TRAIN Batch 82/200 loss 0.061706 acc 0.962359 lr 0.00017764 grad_norm 0.483237 rank 1
2025-01-10 17:57:49,106 DEBUG TRAIN Batch 82/200 loss 0.062369 acc 0.957426 lr 0.00017764 grad_norm 0.483237 rank 2
2025-01-10 17:58:14,238 DEBUG TRAIN Batch 82/300 loss 0.066395 acc 0.953488 lr 0.00017758 grad_norm 0.457188 rank 1
2025-01-10 17:58:14,238 DEBUG TRAIN Batch 82/300 loss 0.022618 acc 0.982055 lr 0.00017758 grad_norm 0.457188 rank 2
2025-01-10 17:58:14,238 DEBUG TRAIN Batch 82/300 loss 0.079211 acc 0.946911 lr 0.00017758 grad_norm 0.457188 rank 0
2025-01-10 17:58:38,862 DEBUG TRAIN Batch 82/400 loss 0.046027 acc 0.969849 lr 0.00017753 grad_norm 0.464152 rank 1
2025-01-10 17:58:38,862 DEBUG TRAIN Batch 82/400 loss 0.040636 acc 0.965318 lr 0.00017753 grad_norm 0.464152 rank 2
2025-01-10 17:58:38,863 DEBUG TRAIN Batch 82/400 loss 0.063666 acc 0.954545 lr 0.00017753 grad_norm 0.464152 rank 0
2025-01-10 17:59:03,612 DEBUG TRAIN Batch 82/500 loss 0.085302 acc 0.952646 lr 0.00017747 grad_norm 0.469006 rank 1
2025-01-10 17:59:03,612 DEBUG TRAIN Batch 82/500 loss 0.055687 acc 0.963975 lr 0.00017747 grad_norm 0.469006 rank 2
2025-01-10 17:59:03,612 DEBUG TRAIN Batch 82/500 loss 0.074907 acc 0.948052 lr 0.00017747 grad_norm 0.469006 rank 0
2025-01-10 17:59:28,911 DEBUG TRAIN Batch 82/600 loss 0.072846 acc 0.948454 lr 0.00017741 grad_norm 0.497288 rank 1
2025-01-10 17:59:28,911 DEBUG TRAIN Batch 82/600 loss 0.082287 acc 0.942186 lr 0.00017741 grad_norm 0.497288 rank 2
2025-01-10 17:59:28,911 DEBUG TRAIN Batch 82/600 loss 0.070888 acc 0.953704 lr 0.00017741 grad_norm 0.497288 rank 0
2025-01-10 17:59:53,341 DEBUG TRAIN Batch 82/700 loss 0.052067 acc 0.960981 lr 0.00017736 grad_norm 0.487859 rank 2
2025-01-10 17:59:53,341 DEBUG TRAIN Batch 82/700 loss 0.084718 acc 0.950998 lr 0.00017736 grad_norm 0.487859 rank 1
2025-01-10 17:59:53,341 DEBUG TRAIN Batch 82/700 loss 0.059844 acc 0.953933 lr 0.00017736 grad_norm 0.487859 rank 0
2025-01-10 18:00:18,936 DEBUG TRAIN Batch 82/800 loss 0.061440 acc 0.959809 lr 0.00017730 grad_norm 0.471382 rank 1
2025-01-10 18:00:18,937 DEBUG TRAIN Batch 82/800 loss 0.071578 acc 0.957205 lr 0.00017730 grad_norm 0.471382 rank 2
2025-01-10 18:00:18,936 DEBUG TRAIN Batch 82/800 loss 0.086262 acc 0.935657 lr 0.00017730 grad_norm 0.471382 rank 0
2025-01-10 18:00:42,664 DEBUG TRAIN Batch 82/900 loss 0.076463 acc 0.951402 lr 0.00017725 grad_norm 0.479498 rank 0
2025-01-10 18:00:42,664 DEBUG TRAIN Batch 82/900 loss 0.084190 acc 0.941587 lr 0.00017725 grad_norm 0.479498 rank 1
2025-01-10 18:00:42,721 DEBUG TRAIN Batch 82/900 loss 0.031437 acc 0.973966 lr 0.00017725 grad_norm 0.479498 rank 2
2025-01-10 18:01:06,943 DEBUG TRAIN Batch 82/1000 loss 0.049489 acc 0.958556 lr 0.00017719 grad_norm 0.458141 rank 2
2025-01-10 18:01:06,942 DEBUG TRAIN Batch 82/1000 loss 0.059353 acc 0.960360 lr 0.00017719 grad_norm 0.458141 rank 1
2025-01-10 18:01:06,944 DEBUG TRAIN Batch 82/1000 loss 0.070122 acc 0.950607 lr 0.00017719 grad_norm 0.458141 rank 0
2025-01-10 18:01:32,110 DEBUG TRAIN Batch 82/1100 loss 0.076282 acc 0.950047 lr 0.00017714 grad_norm 0.467800 rank 1
2025-01-10 18:01:32,110 DEBUG TRAIN Batch 82/1100 loss 0.064716 acc 0.959685 lr 0.00017714 grad_norm 0.467800 rank 2
2025-01-10 18:01:32,111 DEBUG TRAIN Batch 82/1100 loss 0.068071 acc 0.953287 lr 0.00017714 grad_norm 0.467800 rank 0
2025-01-10 18:01:56,010 DEBUG TRAIN Batch 82/1200 loss 0.063699 acc 0.957831 lr 0.00017708 grad_norm 0.479769 rank 1
2025-01-10 18:01:56,010 DEBUG TRAIN Batch 82/1200 loss 0.057617 acc 0.962382 lr 0.00017708 grad_norm 0.479769 rank 2
2025-01-10 18:01:56,011 DEBUG TRAIN Batch 82/1200 loss 0.063293 acc 0.952611 lr 0.00017708 grad_norm 0.479769 rank 0
2025-01-10 18:02:20,258 DEBUG TRAIN Batch 82/1300 loss 0.058371 acc 0.958035 lr 0.00017702 grad_norm 0.494865 rank 1
2025-01-10 18:02:20,258 DEBUG TRAIN Batch 82/1300 loss 0.059725 acc 0.957597 lr 0.00017702 grad_norm 0.494865 rank 2
2025-01-10 18:02:20,258 DEBUG TRAIN Batch 82/1300 loss 0.080353 acc 0.942002 lr 0.00017702 grad_norm 0.494865 rank 0
2025-01-10 18:02:43,875 DEBUG TRAIN Batch 82/1400 loss 0.066734 acc 0.949485 lr 0.00017697 grad_norm 0.474228 rank 2
2025-01-10 18:02:43,875 DEBUG TRAIN Batch 82/1400 loss 0.078064 acc 0.947966 lr 0.00017697 grad_norm 0.474228 rank 0
2025-01-10 18:02:43,875 DEBUG TRAIN Batch 82/1400 loss 0.051931 acc 0.962693 lr 0.00017697 grad_norm 0.474228 rank 1
2025-01-10 18:03:07,916 DEBUG TRAIN Batch 82/1500 loss 0.071510 acc 0.947680 lr 0.00017691 grad_norm 0.489811 rank 1
2025-01-10 18:03:07,916 DEBUG TRAIN Batch 82/1500 loss 0.089427 acc 0.940822 lr 0.00017691 grad_norm 0.489811 rank 2
2025-01-10 18:03:07,916 DEBUG TRAIN Batch 82/1500 loss 0.068394 acc 0.956705 lr 0.00017691 grad_norm 0.489811 rank 0
2025-01-10 18:03:31,671 DEBUG TRAIN Batch 82/1600 loss 0.079864 acc 0.933908 lr 0.00017686 grad_norm 0.504451 rank 1
2025-01-10 18:03:31,671 DEBUG TRAIN Batch 82/1600 loss 0.065061 acc 0.957157 lr 0.00017686 grad_norm 0.504451 rank 2
2025-01-10 18:03:31,672 DEBUG TRAIN Batch 82/1600 loss 0.073864 acc 0.950159 lr 0.00017686 grad_norm 0.504451 rank 0
2025-01-10 18:03:56,331 DEBUG TRAIN Batch 82/1700 loss 0.071701 acc 0.952381 lr 0.00017680 grad_norm 0.505752 rank 2
2025-01-10 18:03:56,331 DEBUG TRAIN Batch 82/1700 loss 0.076316 acc 0.950153 lr 0.00017680 grad_norm 0.505752 rank 1
2025-01-10 18:03:56,332 DEBUG TRAIN Batch 82/1700 loss 0.103415 acc 0.924362 lr 0.00017680 grad_norm 0.505752 rank 0
2025-01-10 18:04:20,994 DEBUG TRAIN Batch 82/1800 loss 0.048627 acc 0.965480 lr 0.00017675 grad_norm 0.479930 rank 2
2025-01-10 18:04:20,994 DEBUG TRAIN Batch 82/1800 loss 0.067320 acc 0.957031 lr 0.00017675 grad_norm 0.479930 rank 1
2025-01-10 18:04:20,994 DEBUG TRAIN Batch 82/1800 loss 0.092435 acc 0.931434 lr 0.00017675 grad_norm 0.479930 rank 0
2025-01-10 18:04:45,223 DEBUG TRAIN Batch 82/1900 loss 0.052105 acc 0.966734 lr 0.00017669 grad_norm 0.469863 rank 2
2025-01-10 18:04:45,223 DEBUG TRAIN Batch 82/1900 loss 0.070773 acc 0.951397 lr 0.00017669 grad_norm 0.469863 rank 1
2025-01-10 18:04:45,224 DEBUG TRAIN Batch 82/1900 loss 0.082361 acc 0.953971 lr 0.00017669 grad_norm 0.469863 rank 0
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 18:05:59,440 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 18:05:59,440 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 18:05:59,889 INFO Epoch 82 Step 80103 on_batch_end True CV rank 2
2025-01-10 18:05:59,889 INFO Epoch 82 Step 80103 on_batch_end True CV rank 0
2025-01-10 18:05:59,890 INFO Epoch 82 Step 80103 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 18:06:09,245 DEBUG CV Batch 82/100 loss 0.020499 acc 0.993311  rank 0
2025-01-10 18:06:09,449 DEBUG CV Batch 82/100 loss 0.020499 acc 0.993311  rank 2
2025-01-10 18:06:09,793 INFO Epoch 82 Step 80103 CV info lr 0.00017666300506939423 0 rank loss_2.243318554812536 acc_0.7784233846162495
2025-01-10 18:06:09,990 INFO Epoch 82 Step 80103 CV info lr 0.00017666300506939423 2 rank loss_2.243318554812536 acc_0.7784233846162495
2025-01-10 18:06:10,002 DEBUG CV Batch 82/100 loss 0.020499 acc 0.993311  rank 1
2025-01-10 18:06:10,554 INFO Epoch 82 Step 80103 CV info lr 0.00017666300506939423 1 rank loss_2.243318554812536 acc_0.7784233846162495
2025-01-10 18:06:11,140 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_82_whole.pt
2025-01-10 18:06:11,162 INFO Added key: store_based_barrier_key:85 to store for rank: 0
2025-01-10 18:06:11,162 INFO Added key: store_based_barrier_key:85 to store for rank: 1
2025-01-10 18:06:11,162 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:85 with 3 nodes.
2025-01-10 18:06:11,162 INFO Added key: store_based_barrier_key:85 to store for rank: 2
2025-01-10 18:06:11,162 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:85 with 3 nodes.
2025-01-10 18:06:11,169 INFO Epoch 83 TRAIN info lr 0.00017666300506939423 rank 1
2025-01-10 18:06:11,169 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 18:06:11,170 INFO Epoch 83 TRAIN info lr 0.00017666300506939423 rank 2
2025-01-10 18:06:11,171 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 18:06:11,172 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:85 with 3 nodes.
2025-01-10 18:06:11,176 INFO Epoch 83 TRAIN info lr 0.00017666300506939423 rank 0
2025-01-10 18:06:11,176 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 18:06:42,454 DEBUG TRAIN Batch 83/100 loss 0.058734 acc 0.962232 lr 0.00017661 grad_norm 0.445888 rank 1
2025-01-10 18:06:42,454 DEBUG TRAIN Batch 83/100 loss 0.048048 acc 0.973604 lr 0.00017661 grad_norm 0.445888 rank 2
2025-01-10 18:06:42,454 DEBUG TRAIN Batch 83/100 loss 0.056079 acc 0.962129 lr 0.00017661 grad_norm 0.445888 rank 0
2025-01-10 18:07:06,676 DEBUG TRAIN Batch 83/200 loss 0.060738 acc 0.960908 lr 0.00017655 grad_norm 0.452367 rank 1
2025-01-10 18:07:06,676 DEBUG TRAIN Batch 83/200 loss 0.051635 acc 0.968028 lr 0.00017655 grad_norm 0.452367 rank 2
2025-01-10 18:07:06,676 DEBUG TRAIN Batch 83/200 loss 0.035702 acc 0.972257 lr 0.00017655 grad_norm 0.452367 rank 0
2025-01-10 18:07:30,263 DEBUG TRAIN Batch 83/300 loss 0.080249 acc 0.945973 lr 0.00017650 grad_norm 0.457010 rank 1
2025-01-10 18:07:30,264 DEBUG TRAIN Batch 83/300 loss 0.050808 acc 0.965517 lr 0.00017650 grad_norm 0.457010 rank 0
2025-01-10 18:07:30,266 DEBUG TRAIN Batch 83/300 loss 0.057840 acc 0.957384 lr 0.00017650 grad_norm 0.457010 rank 2
2025-01-10 18:07:53,918 DEBUG TRAIN Batch 83/400 loss 0.047884 acc 0.968539 lr 0.00017644 grad_norm 0.464878 rank 2
2025-01-10 18:07:53,918 DEBUG TRAIN Batch 83/400 loss 0.061651 acc 0.953941 lr 0.00017644 grad_norm 0.464878 rank 0
2025-01-10 18:07:53,919 DEBUG TRAIN Batch 83/400 loss 0.090950 acc 0.938737 lr 0.00017644 grad_norm 0.464878 rank 1
2025-01-10 18:08:18,226 DEBUG TRAIN Batch 83/500 loss 0.075881 acc 0.944705 lr 0.00017639 grad_norm 0.447227 rank 2
2025-01-10 18:08:18,226 DEBUG TRAIN Batch 83/500 loss 0.057153 acc 0.959502 lr 0.00017639 grad_norm 0.447227 rank 1
2025-01-10 18:08:18,226 DEBUG TRAIN Batch 83/500 loss 0.050162 acc 0.957635 lr 0.00017639 grad_norm 0.447227 rank 0
2025-01-10 18:08:41,916 DEBUG TRAIN Batch 83/600 loss 0.054797 acc 0.966538 lr 0.00017633 grad_norm 0.467498 rank 1
2025-01-10 18:08:41,916 DEBUG TRAIN Batch 83/600 loss 0.059472 acc 0.958855 lr 0.00017633 grad_norm 0.467498 rank 0
2025-01-10 18:08:41,916 DEBUG TRAIN Batch 83/600 loss 0.062800 acc 0.959414 lr 0.00017633 grad_norm 0.467498 rank 2
2025-01-10 18:09:06,496 DEBUG TRAIN Batch 83/700 loss 0.024967 acc 0.982877 lr 0.00017628 grad_norm 0.430806 rank 1
2025-01-10 18:09:06,496 DEBUG TRAIN Batch 83/700 loss 0.074804 acc 0.953769 lr 0.00017628 grad_norm 0.430806 rank 2
2025-01-10 18:09:06,497 DEBUG TRAIN Batch 83/700 loss 0.063868 acc 0.962896 lr 0.00017628 grad_norm 0.430806 rank 0
2025-01-10 18:09:32,054 DEBUG TRAIN Batch 83/800 loss 0.061796 acc 0.953795 lr 0.00017622 grad_norm 0.500015 rank 1
2025-01-10 18:09:32,054 DEBUG TRAIN Batch 83/800 loss 0.065218 acc 0.953582 lr 0.00017622 grad_norm 0.500015 rank 0
2025-01-10 18:09:32,054 DEBUG TRAIN Batch 83/800 loss 0.080389 acc 0.943105 lr 0.00017622 grad_norm 0.500015 rank 2
2025-01-10 18:09:56,250 DEBUG TRAIN Batch 83/900 loss 0.045465 acc 0.969988 lr 0.00017617 grad_norm 0.461522 rank 0
2025-01-10 18:09:56,250 DEBUG TRAIN Batch 83/900 loss 0.068858 acc 0.946429 lr 0.00017617 grad_norm 0.461522 rank 2
2025-01-10 18:09:56,251 DEBUG TRAIN Batch 83/900 loss 0.058888 acc 0.958050 lr 0.00017617 grad_norm 0.461522 rank 1
2025-01-10 18:10:20,625 DEBUG TRAIN Batch 83/1000 loss 0.077759 acc 0.944545 lr 0.00017611 grad_norm 0.457141 rank 0
2025-01-10 18:10:20,625 DEBUG TRAIN Batch 83/1000 loss 0.054972 acc 0.961722 lr 0.00017611 grad_norm 0.457141 rank 1
2025-01-10 18:10:20,626 DEBUG TRAIN Batch 83/1000 loss 0.077668 acc 0.954266 lr 0.00017611 grad_norm 0.457141 rank 2
2025-01-10 18:10:45,603 DEBUG TRAIN Batch 83/1100 loss 0.069511 acc 0.957011 lr 0.00017606 grad_norm 0.494188 rank 0
2025-01-10 18:10:45,604 DEBUG TRAIN Batch 83/1100 loss 0.072413 acc 0.951554 lr 0.00017606 grad_norm 0.494188 rank 2
2025-01-10 18:10:45,604 DEBUG TRAIN Batch 83/1100 loss 0.049066 acc 0.972447 lr 0.00017606 grad_norm 0.494188 rank 1
2025-01-10 18:11:10,965 DEBUG TRAIN Batch 83/1200 loss 0.052900 acc 0.963190 lr 0.00017601 grad_norm 0.455652 rank 0
2025-01-10 18:11:10,965 DEBUG TRAIN Batch 83/1200 loss 0.089086 acc 0.943111 lr 0.00017601 grad_norm 0.455652 rank 2
2025-01-10 18:11:10,965 DEBUG TRAIN Batch 83/1200 loss 0.075443 acc 0.952123 lr 0.00017601 grad_norm 0.455652 rank 1
2025-01-10 18:11:34,967 DEBUG TRAIN Batch 83/1300 loss 0.069972 acc 0.951336 lr 0.00017595 grad_norm 0.476976 rank 0
2025-01-10 18:11:34,967 DEBUG TRAIN Batch 83/1300 loss 0.087797 acc 0.944082 lr 0.00017595 grad_norm 0.476976 rank 2
2025-01-10 18:11:34,967 DEBUG TRAIN Batch 83/1300 loss 0.081837 acc 0.947556 lr 0.00017595 grad_norm 0.476976 rank 1
2025-01-10 18:11:58,353 DEBUG TRAIN Batch 83/1400 loss 0.092481 acc 0.939061 lr 0.00017590 grad_norm 0.496055 rank 2
2025-01-10 18:11:58,353 DEBUG TRAIN Batch 83/1400 loss 0.059184 acc 0.960405 lr 0.00017590 grad_norm 0.496055 rank 0
2025-01-10 18:11:58,353 DEBUG TRAIN Batch 83/1400 loss 0.088886 acc 0.942379 lr 0.00017590 grad_norm 0.496055 rank 1
2025-01-10 18:12:22,067 DEBUG TRAIN Batch 83/1500 loss 0.052967 acc 0.963104 lr 0.00017584 grad_norm 0.478044 rank 2
2025-01-10 18:12:22,067 DEBUG TRAIN Batch 83/1500 loss 0.042621 acc 0.972000 lr 0.00017584 grad_norm 0.478044 rank 0
2025-01-10 18:12:22,067 DEBUG TRAIN Batch 83/1500 loss 0.084751 acc 0.945024 lr 0.00017584 grad_norm 0.478044 rank 1
2025-01-10 18:12:45,836 DEBUG TRAIN Batch 83/1600 loss 0.070811 acc 0.953307 lr 0.00017579 grad_norm 0.521465 rank 2
2025-01-10 18:12:45,837 DEBUG TRAIN Batch 83/1600 loss 0.067256 acc 0.952703 lr 0.00017579 grad_norm 0.521465 rank 0
2025-01-10 18:12:45,837 DEBUG TRAIN Batch 83/1600 loss 0.090707 acc 0.934223 lr 0.00017579 grad_norm 0.521465 rank 1
2025-01-10 18:13:09,785 DEBUG TRAIN Batch 83/1700 loss 0.054653 acc 0.966725 lr 0.00017573 grad_norm 0.519366 rank 0
2025-01-10 18:13:09,786 DEBUG TRAIN Batch 83/1700 loss 0.078245 acc 0.944821 lr 0.00017573 grad_norm 0.519366 rank 1
2025-01-10 18:13:09,786 DEBUG TRAIN Batch 83/1700 loss 0.057845 acc 0.957265 lr 0.00017573 grad_norm 0.519366 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 18:14:19,980 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 18:14:19,984 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 18:14:20,397 INFO Epoch 83 Step 80974 on_batch_end True CV rank 2
2025-01-10 18:14:20,397 INFO Epoch 83 Step 80974 on_batch_end True CV rank 0
2025-01-10 18:14:20,397 INFO Epoch 83 Step 80974 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 18:14:29,520 DEBUG CV Batch 83/100 loss 0.018099 acc 0.995541  rank 0
2025-01-10 18:14:29,851 DEBUG CV Batch 83/100 loss 0.018099 acc 0.995541  rank 2
2025-01-10 18:14:30,040 INFO Epoch 83 Step 80974 CV info lr 0.0001757102949126384 0 rank loss_2.273202408549351 acc_0.7785448763977018
2025-01-10 18:14:30,126 DEBUG CV Batch 83/100 loss 0.018099 acc 0.995541  rank 1
2025-01-10 18:14:30,381 INFO Epoch 83 Step 80974 CV info lr 0.0001757102949126384 2 rank loss_2.273202408549351 acc_0.7785448763977018
2025-01-10 18:14:30,669 INFO Epoch 83 Step 80974 CV info lr 0.0001757102949126384 1 rank loss_2.273202408549351 acc_0.7785448763977018
2025-01-10 18:14:31,342 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_83_whole.pt
2025-01-10 18:14:31,364 INFO Added key: store_based_barrier_key:86 to store for rank: 0
2025-01-10 18:14:31,364 INFO Added key: store_based_barrier_key:86 to store for rank: 1
2025-01-10 18:14:31,364 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:86 with 3 nodes.
2025-01-10 18:14:31,364 INFO Added key: store_based_barrier_key:86 to store for rank: 2
2025-01-10 18:14:31,364 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:86 with 3 nodes.
2025-01-10 18:14:31,372 INFO Epoch 84 TRAIN info lr 0.0001757102949126384 rank 1
2025-01-10 18:14:31,372 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 18:14:31,373 INFO Epoch 84 TRAIN info lr 0.0001757102949126384 rank 2
2025-01-10 18:14:31,373 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 18:14:31,374 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:86 with 3 nodes.
2025-01-10 18:14:31,384 INFO Epoch 84 TRAIN info lr 0.0001757102949126384 rank 0
2025-01-10 18:14:31,384 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 18:15:08,285 DEBUG TRAIN Batch 84/100 loss 0.063311 acc 0.952569 lr 0.00017566 grad_norm 0.460220 rank 2
2025-01-10 18:15:08,286 DEBUG TRAIN Batch 84/100 loss 0.089983 acc 0.936283 lr 0.00017566 grad_norm 0.460220 rank 1
2025-01-10 18:15:08,286 DEBUG TRAIN Batch 84/100 loss 0.060173 acc 0.961039 lr 0.00017566 grad_norm 0.460220 rank 0
2025-01-10 18:15:32,970 DEBUG TRAIN Batch 84/200 loss 0.070505 acc 0.953082 lr 0.00017560 grad_norm 0.469064 rank 2
2025-01-10 18:15:32,971 DEBUG TRAIN Batch 84/200 loss 0.066723 acc 0.953863 lr 0.00017560 grad_norm 0.469064 rank 1
2025-01-10 18:15:32,971 DEBUG TRAIN Batch 84/200 loss 0.042566 acc 0.970588 lr 0.00017560 grad_norm 0.469064 rank 0
2025-01-10 18:15:58,344 DEBUG TRAIN Batch 84/300 loss 0.065373 acc 0.955621 lr 0.00017555 grad_norm 0.477083 rank 2
2025-01-10 18:15:58,345 DEBUG TRAIN Batch 84/300 loss 0.046521 acc 0.966346 lr 0.00017555 grad_norm 0.477083 rank 0
2025-01-10 18:15:58,345 DEBUG TRAIN Batch 84/300 loss 0.073238 acc 0.950239 lr 0.00017555 grad_norm 0.477083 rank 1
2025-01-10 18:16:22,575 DEBUG TRAIN Batch 84/400 loss 0.056247 acc 0.958491 lr 0.00017549 grad_norm 0.477554 rank 2
2025-01-10 18:16:22,575 DEBUG TRAIN Batch 84/400 loss 0.078555 acc 0.955032 lr 0.00017549 grad_norm 0.477554 rank 1
2025-01-10 18:16:22,575 DEBUG TRAIN Batch 84/400 loss 0.040957 acc 0.976879 lr 0.00017549 grad_norm 0.477554 rank 0
2025-01-10 18:16:47,593 DEBUG TRAIN Batch 84/500 loss 0.047886 acc 0.966222 lr 0.00017544 grad_norm 0.478048 rank 2
2025-01-10 18:16:47,593 DEBUG TRAIN Batch 84/500 loss 0.083291 acc 0.939870 lr 0.00017544 grad_norm 0.478048 rank 1
2025-01-10 18:16:47,593 DEBUG TRAIN Batch 84/500 loss 0.063934 acc 0.952532 lr 0.00017544 grad_norm 0.478048 rank 0
2025-01-10 18:17:13,762 DEBUG TRAIN Batch 84/600 loss 0.070175 acc 0.953079 lr 0.00017539 grad_norm 0.472885 rank 1
2025-01-10 18:17:13,762 DEBUG TRAIN Batch 84/600 loss 0.041142 acc 0.972906 lr 0.00017539 grad_norm 0.472885 rank 0
2025-01-10 18:17:13,762 DEBUG TRAIN Batch 84/600 loss 0.054420 acc 0.963138 lr 0.00017539 grad_norm 0.472885 rank 2
2025-01-10 18:17:37,988 DEBUG TRAIN Batch 84/700 loss 0.074340 acc 0.940433 lr 0.00017533 grad_norm 0.474550 rank 1
2025-01-10 18:17:37,989 DEBUG TRAIN Batch 84/700 loss 0.058906 acc 0.961538 lr 0.00017533 grad_norm 0.474550 rank 0
2025-01-10 18:17:37,990 DEBUG TRAIN Batch 84/700 loss 0.044288 acc 0.971613 lr 0.00017533 grad_norm 0.474550 rank 2
2025-01-10 18:18:03,169 DEBUG TRAIN Batch 84/800 loss 0.044308 acc 0.972464 lr 0.00017528 grad_norm 0.478072 rank 0
2025-01-10 18:18:03,170 DEBUG TRAIN Batch 84/800 loss 0.065121 acc 0.959402 lr 0.00017528 grad_norm 0.478072 rank 1
2025-01-10 18:18:03,170 DEBUG TRAIN Batch 84/800 loss 0.068342 acc 0.953571 lr 0.00017528 grad_norm 0.478072 rank 2
2025-01-10 18:18:27,319 DEBUG TRAIN Batch 84/900 loss 0.052832 acc 0.954832 lr 0.00017522 grad_norm 0.482882 rank 1
2025-01-10 18:18:27,320 DEBUG TRAIN Batch 84/900 loss 0.061082 acc 0.960577 lr 0.00017522 grad_norm 0.482882 rank 2
2025-01-10 18:18:27,320 DEBUG TRAIN Batch 84/900 loss 0.075027 acc 0.947124 lr 0.00017522 grad_norm 0.482882 rank 0
2025-01-10 18:18:51,527 DEBUG TRAIN Batch 84/1000 loss 0.065444 acc 0.957819 lr 0.00017517 grad_norm 0.452890 rank 2
2025-01-10 18:18:51,528 DEBUG TRAIN Batch 84/1000 loss 0.066735 acc 0.946227 lr 0.00017517 grad_norm 0.452890 rank 0
2025-01-10 18:18:51,528 DEBUG TRAIN Batch 84/1000 loss 0.080461 acc 0.939448 lr 0.00017517 grad_norm 0.452890 rank 1
2025-01-10 18:19:16,928 DEBUG TRAIN Batch 84/1100 loss 0.074736 acc 0.948365 lr 0.00017512 grad_norm 0.451368 rank 2
2025-01-10 18:19:16,928 DEBUG TRAIN Batch 84/1100 loss 0.058392 acc 0.962206 lr 0.00017512 grad_norm 0.451368 rank 0
2025-01-10 18:19:16,928 DEBUG TRAIN Batch 84/1100 loss 0.080408 acc 0.941599 lr 0.00017512 grad_norm 0.451368 rank 1
2025-01-10 18:19:40,759 DEBUG TRAIN Batch 84/1200 loss 0.069198 acc 0.950920 lr 0.00017506 grad_norm 0.497427 rank 2
2025-01-10 18:19:40,759 DEBUG TRAIN Batch 84/1200 loss 0.080775 acc 0.953721 lr 0.00017506 grad_norm 0.497427 rank 1
2025-01-10 18:19:40,760 DEBUG TRAIN Batch 84/1200 loss 0.075541 acc 0.944162 lr 0.00017506 grad_norm 0.497427 rank 0
2025-01-10 18:20:04,797 DEBUG TRAIN Batch 84/1300 loss 0.066395 acc 0.952724 lr 0.00017501 grad_norm 0.502751 rank 0
2025-01-10 18:20:04,797 DEBUG TRAIN Batch 84/1300 loss 0.074877 acc 0.950136 lr 0.00017501 grad_norm 0.502751 rank 1
2025-01-10 18:20:04,797 DEBUG TRAIN Batch 84/1300 loss 0.069282 acc 0.956522 lr 0.00017501 grad_norm 0.502751 rank 2
2025-01-10 18:20:29,159 DEBUG TRAIN Batch 84/1400 loss 0.069362 acc 0.950378 lr 0.00017496 grad_norm 0.467979 rank 0
2025-01-10 18:20:29,160 DEBUG TRAIN Batch 84/1400 loss 0.061369 acc 0.954721 lr 0.00017496 grad_norm 0.467979 rank 2
2025-01-10 18:20:29,160 DEBUG TRAIN Batch 84/1400 loss 0.060426 acc 0.963567 lr 0.00017496 grad_norm 0.467979 rank 1
2025-01-10 18:20:53,435 DEBUG TRAIN Batch 84/1500 loss 0.054485 acc 0.959308 lr 0.00017490 grad_norm 0.477113 rank 1
2025-01-10 18:20:53,435 DEBUG TRAIN Batch 84/1500 loss 0.067988 acc 0.961340 lr 0.00017490 grad_norm 0.477113 rank 0
2025-01-10 18:20:53,435 DEBUG TRAIN Batch 84/1500 loss 0.077197 acc 0.953000 lr 0.00017490 grad_norm 0.477113 rank 2
2025-01-10 18:21:17,172 DEBUG TRAIN Batch 84/1600 loss 0.058191 acc 0.957973 lr 0.00017485 grad_norm 0.487587 rank 2
2025-01-10 18:21:17,172 DEBUG TRAIN Batch 84/1600 loss 0.069376 acc 0.949541 lr 0.00017485 grad_norm 0.487587 rank 0
2025-01-10 18:21:17,172 DEBUG TRAIN Batch 84/1600 loss 0.055064 acc 0.968146 lr 0.00017485 grad_norm 0.487587 rank 1
2025-01-10 18:21:41,562 DEBUG TRAIN Batch 84/1700 loss 0.076162 acc 0.946032 lr 0.00017480 grad_norm 0.511944 rank 1
2025-01-10 18:21:41,562 DEBUG TRAIN Batch 84/1700 loss 0.066969 acc 0.942804 lr 0.00017480 grad_norm 0.511944 rank 2
2025-01-10 18:21:41,562 DEBUG TRAIN Batch 84/1700 loss 0.081033 acc 0.944284 lr 0.00017480 grad_norm 0.511944 rank 0
2025-01-10 18:22:05,732 DEBUG TRAIN Batch 84/1800 loss 0.061997 acc 0.956212 lr 0.00017474 grad_norm 0.492867 rank 2
2025-01-10 18:22:05,732 DEBUG TRAIN Batch 84/1800 loss 0.062187 acc 0.953927 lr 0.00017474 grad_norm 0.492867 rank 1
2025-01-10 18:22:05,733 DEBUG TRAIN Batch 84/1800 loss 0.046607 acc 0.967347 lr 0.00017474 grad_norm 0.492867 rank 0
2025-01-10 18:22:30,100 DEBUG TRAIN Batch 84/1900 loss 0.060370 acc 0.964088 lr 0.00017469 grad_norm 0.493220 rank 0
2025-01-10 18:22:30,100 DEBUG TRAIN Batch 84/1900 loss 0.085944 acc 0.933395 lr 0.00017469 grad_norm 0.493220 rank 1
2025-01-10 18:22:30,100 DEBUG TRAIN Batch 84/1900 loss 0.069294 acc 0.953560 lr 0.00017469 grad_norm 0.493220 rank 2
2025-01-10 18:22:53,895 DEBUG TRAIN Batch 84/2000 loss 0.051037 acc 0.962806 lr 0.00017464 grad_norm 0.465936 rank 0
2025-01-10 18:22:53,895 DEBUG TRAIN Batch 84/2000 loss 0.069802 acc 0.956386 lr 0.00017464 grad_norm 0.465936 rank 2
2025-01-10 18:22:53,896 DEBUG TRAIN Batch 84/2000 loss 0.061372 acc 0.957895 lr 0.00017464 grad_norm 0.465936 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 18:24:04,030 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 18:24:04,036 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 18:24:04,451 INFO Epoch 84 Step 81995 on_batch_end True CV rank 1
2025-01-10 18:24:04,451 INFO Epoch 84 Step 81995 on_batch_end True CV rank 0
2025-01-10 18:24:04,451 INFO Epoch 84 Step 81995 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 18:24:13,408 DEBUG CV Batch 84/100 loss 0.019032 acc 0.995541  rank 0
2025-01-10 18:24:13,916 INFO Epoch 84 Step 81995 CV info lr 0.00017461289758749976 0 rank loss_2.2914446815970893 acc_0.7780951022317535
2025-01-10 18:24:13,999 DEBUG CV Batch 84/100 loss 0.019032 acc 0.995541  rank 2
2025-01-10 18:24:14,162 DEBUG CV Batch 84/100 loss 0.019032 acc 0.995541  rank 1
2025-01-10 18:24:14,544 INFO Epoch 84 Step 81995 CV info lr 0.00017461289758749976 2 rank loss_2.2914446815970893 acc_0.7780951022317535
2025-01-10 18:24:14,695 INFO Epoch 84 Step 81995 CV info lr 0.00017461289758749976 1 rank loss_2.2914446815970893 acc_0.7780951022317535
2025-01-10 18:24:15,220 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_84_whole.pt
2025-01-10 18:24:15,231 INFO Added key: store_based_barrier_key:87 to store for rank: 0
2025-01-10 18:24:15,242 INFO Added key: store_based_barrier_key:87 to store for rank: 2
2025-01-10 18:24:15,242 INFO Added key: store_based_barrier_key:87 to store for rank: 1
2025-01-10 18:24:15,242 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:87 with 3 nodes.
2025-01-10 18:24:15,242 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:87 with 3 nodes.
2025-01-10 18:24:15,244 INFO Epoch 85 TRAIN info lr 0.00017461289758749976 rank 2
2025-01-10 18:24:15,244 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 18:24:15,245 INFO Epoch 85 TRAIN info lr 0.00017461289758749976 rank 1
2025-01-10 18:24:15,245 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 18:24:15,252 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:87 with 3 nodes.
2025-01-10 18:24:15,252 INFO Epoch 85 TRAIN info lr 0.00017461289758749976 rank 0
2025-01-10 18:24:15,252 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 18:24:46,480 DEBUG TRAIN Batch 85/100 loss 0.048484 acc 0.959016 lr 0.00017456 grad_norm 0.459093 rank 0
2025-01-10 18:24:46,480 DEBUG TRAIN Batch 85/100 loss 0.072542 acc 0.958135 lr 0.00017456 grad_norm 0.459093 rank 1
2025-01-10 18:24:46,480 DEBUG TRAIN Batch 85/100 loss 0.065828 acc 0.951241 lr 0.00017456 grad_norm 0.459093 rank 2
2025-01-10 18:25:10,438 DEBUG TRAIN Batch 85/200 loss 0.090131 acc 0.940767 lr 0.00017451 grad_norm 0.454111 rank 0
2025-01-10 18:25:10,438 DEBUG TRAIN Batch 85/200 loss 0.061727 acc 0.960711 lr 0.00017451 grad_norm 0.454111 rank 1
2025-01-10 18:25:10,438 DEBUG TRAIN Batch 85/200 loss 0.064004 acc 0.967822 lr 0.00017451 grad_norm 0.454111 rank 2
2025-01-10 18:25:34,392 DEBUG TRAIN Batch 85/300 loss 0.066449 acc 0.950298 lr 0.00017445 grad_norm 0.487483 rank 0
2025-01-10 18:25:34,392 DEBUG TRAIN Batch 85/300 loss 0.059551 acc 0.956645 lr 0.00017445 grad_norm 0.487483 rank 2
2025-01-10 18:25:34,392 DEBUG TRAIN Batch 85/300 loss 0.059942 acc 0.960375 lr 0.00017445 grad_norm 0.487483 rank 1
2025-01-10 18:25:58,129 DEBUG TRAIN Batch 85/400 loss 0.049266 acc 0.969729 lr 0.00017440 grad_norm 0.463977 rank 0
2025-01-10 18:25:58,130 DEBUG TRAIN Batch 85/400 loss 0.058604 acc 0.963057 lr 0.00017440 grad_norm 0.463977 rank 2
2025-01-10 18:25:58,130 DEBUG TRAIN Batch 85/400 loss 0.083552 acc 0.942171 lr 0.00017440 grad_norm 0.463977 rank 1
2025-01-10 18:26:21,996 DEBUG TRAIN Batch 85/500 loss 0.077032 acc 0.950538 lr 0.00017435 grad_norm 0.498103 rank 2
2025-01-10 18:26:21,996 DEBUG TRAIN Batch 85/500 loss 0.071702 acc 0.954802 lr 0.00017435 grad_norm 0.498103 rank 0
2025-01-10 18:26:21,996 DEBUG TRAIN Batch 85/500 loss 0.069855 acc 0.954635 lr 0.00017435 grad_norm 0.498103 rank 1
2025-01-10 18:26:46,722 DEBUG TRAIN Batch 85/600 loss 0.061894 acc 0.955459 lr 0.00017429 grad_norm 0.483629 rank 2
2025-01-10 18:26:46,722 DEBUG TRAIN Batch 85/600 loss 0.079438 acc 0.947628 lr 0.00017429 grad_norm 0.483629 rank 0
2025-01-10 18:26:46,723 DEBUG TRAIN Batch 85/600 loss 0.048302 acc 0.969745 lr 0.00017429 grad_norm 0.483629 rank 1
2025-01-10 18:27:12,066 DEBUG TRAIN Batch 85/700 loss 0.073235 acc 0.940524 lr 0.00017424 grad_norm 0.479425 rank 2
2025-01-10 18:27:12,066 DEBUG TRAIN Batch 85/700 loss 0.058717 acc 0.960442 lr 0.00017424 grad_norm 0.479425 rank 0
2025-01-10 18:27:12,067 DEBUG TRAIN Batch 85/700 loss 0.085976 acc 0.943160 lr 0.00017424 grad_norm 0.479425 rank 1
2025-01-10 18:27:36,093 DEBUG TRAIN Batch 85/800 loss 0.063964 acc 0.956476 lr 0.00017419 grad_norm 0.465574 rank 0
2025-01-10 18:27:36,093 DEBUG TRAIN Batch 85/800 loss 0.070597 acc 0.954743 lr 0.00017419 grad_norm 0.465574 rank 1
2025-01-10 18:27:36,094 DEBUG TRAIN Batch 85/800 loss 0.051855 acc 0.971647 lr 0.00017419 grad_norm 0.465574 rank 2
2025-01-10 18:28:00,944 DEBUG TRAIN Batch 85/900 loss 0.051848 acc 0.958702 lr 0.00017414 grad_norm 0.485771 rank 1
2025-01-10 18:28:00,944 DEBUG TRAIN Batch 85/900 loss 0.048870 acc 0.967431 lr 0.00017414 grad_norm 0.485771 rank 0
2025-01-10 18:28:00,944 DEBUG TRAIN Batch 85/900 loss 0.055043 acc 0.958095 lr 0.00017414 grad_norm 0.485771 rank 2
2025-01-10 18:28:26,565 DEBUG TRAIN Batch 85/1000 loss 0.074908 acc 0.947826 lr 0.00017408 grad_norm 0.453988 rank 0
2025-01-10 18:28:26,565 DEBUG TRAIN Batch 85/1000 loss 0.047872 acc 0.968854 lr 0.00017408 grad_norm 0.453988 rank 1
2025-01-10 18:28:26,565 DEBUG TRAIN Batch 85/1000 loss 0.055944 acc 0.956479 lr 0.00017408 grad_norm 0.453988 rank 2
2025-01-10 18:28:50,662 DEBUG TRAIN Batch 85/1100 loss 0.073510 acc 0.952107 lr 0.00017403 grad_norm 0.442762 rank 0
2025-01-10 18:28:50,663 DEBUG TRAIN Batch 85/1100 loss 0.074478 acc 0.952889 lr 0.00017403 grad_norm 0.442762 rank 2
2025-01-10 18:28:50,663 DEBUG TRAIN Batch 85/1100 loss 0.035766 acc 0.978803 lr 0.00017403 grad_norm 0.442762 rank 1
2025-01-10 18:29:15,576 DEBUG TRAIN Batch 85/1200 loss 0.052818 acc 0.964185 lr 0.00017398 grad_norm 0.508445 rank 2
2025-01-10 18:29:15,577 DEBUG TRAIN Batch 85/1200 loss 0.094623 acc 0.934673 lr 0.00017398 grad_norm 0.508445 rank 0
2025-01-10 18:29:15,577 DEBUG TRAIN Batch 85/1200 loss 0.056340 acc 0.953174 lr 0.00017398 grad_norm 0.508445 rank 1
2025-01-10 18:29:40,587 DEBUG TRAIN Batch 85/1300 loss 0.080872 acc 0.949000 lr 0.00017392 grad_norm 0.454933 rank 0
2025-01-10 18:29:40,588 DEBUG TRAIN Batch 85/1300 loss 0.066488 acc 0.952295 lr 0.00017392 grad_norm 0.454933 rank 2
2025-01-10 18:29:40,588 DEBUG TRAIN Batch 85/1300 loss 0.023428 acc 0.979430 lr 0.00017392 grad_norm 0.454933 rank 1
2025-01-10 18:30:04,796 DEBUG TRAIN Batch 85/1400 loss 0.082973 acc 0.944502 lr 0.00017387 grad_norm 0.446389 rank 0
2025-01-10 18:30:04,796 DEBUG TRAIN Batch 85/1400 loss 0.067330 acc 0.957209 lr 0.00017387 grad_norm 0.446389 rank 2
2025-01-10 18:30:04,796 DEBUG TRAIN Batch 85/1400 loss 0.046364 acc 0.967480 lr 0.00017387 grad_norm 0.446389 rank 1
2025-01-10 18:30:30,160 DEBUG TRAIN Batch 85/1500 loss 0.067110 acc 0.955107 lr 0.00017382 grad_norm 0.482334 rank 0
2025-01-10 18:30:30,161 DEBUG TRAIN Batch 85/1500 loss 0.068040 acc 0.954664 lr 0.00017382 grad_norm 0.482334 rank 2
2025-01-10 18:30:30,162 DEBUG TRAIN Batch 85/1500 loss 0.058280 acc 0.958750 lr 0.00017382 grad_norm 0.482334 rank 1
2025-01-10 18:30:55,116 DEBUG TRAIN Batch 85/1600 loss 0.060350 acc 0.959406 lr 0.00017377 grad_norm 0.446672 rank 0
2025-01-10 18:30:55,116 DEBUG TRAIN Batch 85/1600 loss 0.070327 acc 0.950698 lr 0.00017377 grad_norm 0.446672 rank 2
2025-01-10 18:30:55,116 DEBUG TRAIN Batch 85/1600 loss 0.040632 acc 0.973312 lr 0.00017377 grad_norm 0.446672 rank 1
2025-01-10 18:31:19,093 DEBUG TRAIN Batch 85/1700 loss 0.076725 acc 0.954046 lr 0.00017371 grad_norm 0.486897 rank 1
2025-01-10 18:31:19,094 DEBUG TRAIN Batch 85/1700 loss 0.073317 acc 0.949331 lr 0.00017371 grad_norm 0.486897 rank 0
2025-01-10 18:31:19,094 DEBUG TRAIN Batch 85/1700 loss 0.064498 acc 0.960000 lr 0.00017371 grad_norm 0.486897 rank 2
2025-01-10 18:31:43,172 DEBUG TRAIN Batch 85/1800 loss 0.079579 acc 0.944549 lr 0.00017366 grad_norm 0.487413 rank 0
2025-01-10 18:31:43,172 DEBUG TRAIN Batch 85/1800 loss 0.067219 acc 0.953211 lr 0.00017366 grad_norm 0.487413 rank 2
2025-01-10 18:31:43,172 DEBUG TRAIN Batch 85/1800 loss 0.066079 acc 0.956315 lr 0.00017366 grad_norm 0.487413 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 18:33:04,799 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 18:33:04,806 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 18:33:05,228 INFO Epoch 85 Step 82940 on_batch_end True CV rank 0
2025-01-10 18:33:05,228 INFO Epoch 85 Step 82940 on_batch_end True CV rank 1
2025-01-10 18:33:05,228 INFO Epoch 85 Step 82940 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 18:33:14,241 DEBUG CV Batch 85/100 loss 0.011735 acc 0.996656  rank 0
2025-01-10 18:33:14,696 DEBUG CV Batch 85/100 loss 0.011735 acc 0.996656  rank 2
2025-01-10 18:33:14,721 INFO Epoch 85 Step 82940 CV info lr 0.0001736152974872372 0 rank loss_2.2864074450458007 acc_0.7778966236009932
2025-01-10 18:33:14,862 DEBUG CV Batch 85/100 loss 0.011735 acc 0.996656  rank 1
2025-01-10 18:33:15,200 INFO Epoch 85 Step 82940 CV info lr 0.0001736152974872372 2 rank loss_2.2864074450458007 acc_0.7778966236009932
2025-01-10 18:33:15,399 INFO Epoch 85 Step 82940 CV info lr 0.0001736152974872372 1 rank loss_2.2864074450458007 acc_0.7778966236009932
2025-01-10 18:33:16,011 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_85_whole.pt
2025-01-10 18:33:16,033 INFO Added key: store_based_barrier_key:88 to store for rank: 0
2025-01-10 18:33:16,043 INFO Added key: store_based_barrier_key:88 to store for rank: 2
2025-01-10 18:33:16,043 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:88 with 3 nodes.
2025-01-10 18:33:16,043 INFO Added key: store_based_barrier_key:88 to store for rank: 1
2025-01-10 18:33:16,043 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:88 with 3 nodes.
2025-01-10 18:33:16,053 INFO Epoch 86 TRAIN info lr 0.0001736152974872372 rank 1
2025-01-10 18:33:16,053 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 18:33:16,053 INFO Epoch 86 TRAIN info lr 0.0001736152974872372 rank 2
2025-01-10 18:33:16,053 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 18:33:16,053 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:88 with 3 nodes.
2025-01-10 18:33:16,063 INFO Epoch 86 TRAIN info lr 0.0001736152974872372 rank 0
2025-01-10 18:33:16,063 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 18:33:47,410 DEBUG TRAIN Batch 86/100 loss 0.059668 acc 0.958289 lr 0.00017356 grad_norm 0.464239 rank 0
2025-01-10 18:33:47,410 DEBUG TRAIN Batch 86/100 loss 0.078633 acc 0.954152 lr 0.00017356 grad_norm 0.464239 rank 1
2025-01-10 18:33:47,410 DEBUG TRAIN Batch 86/100 loss 0.060682 acc 0.957601 lr 0.00017356 grad_norm 0.464239 rank 2
2025-01-10 18:34:11,364 DEBUG TRAIN Batch 86/200 loss 0.072993 acc 0.955702 lr 0.00017351 grad_norm 0.517499 rank 0
2025-01-10 18:34:11,365 DEBUG TRAIN Batch 86/200 loss 0.050696 acc 0.959236 lr 0.00017351 grad_norm 0.517499 rank 2
2025-01-10 18:34:11,365 DEBUG TRAIN Batch 86/200 loss 0.038547 acc 0.974779 lr 0.00017351 grad_norm 0.517499 rank 1
2025-01-10 18:34:34,893 DEBUG TRAIN Batch 86/300 loss 0.067243 acc 0.955744 lr 0.00017346 grad_norm 0.460224 rank 1
2025-01-10 18:34:34,893 DEBUG TRAIN Batch 86/300 loss 0.060406 acc 0.952885 lr 0.00017346 grad_norm 0.460224 rank 2
2025-01-10 18:34:34,894 DEBUG TRAIN Batch 86/300 loss 0.063374 acc 0.957916 lr 0.00017346 grad_norm 0.460224 rank 0
2025-01-10 18:34:58,656 DEBUG TRAIN Batch 86/400 loss 0.074954 acc 0.950652 lr 0.00017341 grad_norm 0.492263 rank 0
2025-01-10 18:34:58,656 DEBUG TRAIN Batch 86/400 loss 0.077642 acc 0.939810 lr 0.00017341 grad_norm 0.492263 rank 2
2025-01-10 18:34:58,657 DEBUG TRAIN Batch 86/400 loss 0.062393 acc 0.958256 lr 0.00017341 grad_norm 0.492263 rank 1
2025-01-10 18:35:22,640 DEBUG TRAIN Batch 86/500 loss 0.068757 acc 0.955868 lr 0.00017335 grad_norm 0.445638 rank 1
2025-01-10 18:35:22,640 DEBUG TRAIN Batch 86/500 loss 0.052335 acc 0.965415 lr 0.00017335 grad_norm 0.445638 rank 0
2025-01-10 18:35:22,641 DEBUG TRAIN Batch 86/500 loss 0.070185 acc 0.949674 lr 0.00017335 grad_norm 0.445638 rank 2
2025-01-10 18:35:46,334 DEBUG TRAIN Batch 86/600 loss 0.072216 acc 0.948940 lr 0.00017330 grad_norm 0.458417 rank 0
2025-01-10 18:35:46,335 DEBUG TRAIN Batch 86/600 loss 0.054872 acc 0.962136 lr 0.00017330 grad_norm 0.458417 rank 2
2025-01-10 18:35:46,335 DEBUG TRAIN Batch 86/600 loss 0.044676 acc 0.967672 lr 0.00017330 grad_norm 0.458417 rank 1
2025-01-10 18:36:10,480 DEBUG TRAIN Batch 86/700 loss 0.064633 acc 0.958374 lr 0.00017325 grad_norm 0.430709 rank 2
2025-01-10 18:36:10,480 DEBUG TRAIN Batch 86/700 loss 0.054030 acc 0.956656 lr 0.00017325 grad_norm 0.430709 rank 0
2025-01-10 18:36:10,481 DEBUG TRAIN Batch 86/700 loss 0.056575 acc 0.963330 lr 0.00017325 grad_norm 0.430709 rank 1
2025-01-10 18:36:34,171 DEBUG TRAIN Batch 86/800 loss 0.045313 acc 0.972689 lr 0.00017320 grad_norm 0.462777 rank 0
2025-01-10 18:36:34,171 DEBUG TRAIN Batch 86/800 loss 0.064723 acc 0.950564 lr 0.00017320 grad_norm 0.462777 rank 1
2025-01-10 18:36:34,171 DEBUG TRAIN Batch 86/800 loss 0.062210 acc 0.956565 lr 0.00017320 grad_norm 0.462777 rank 2
2025-01-10 18:36:59,011 DEBUG TRAIN Batch 86/900 loss 0.065837 acc 0.952202 lr 0.00017315 grad_norm 0.450918 rank 2
2025-01-10 18:36:59,011 DEBUG TRAIN Batch 86/900 loss 0.023850 acc 0.984823 lr 0.00017315 grad_norm 0.450918 rank 0
2025-01-10 18:36:59,012 DEBUG TRAIN Batch 86/900 loss 0.067021 acc 0.957525 lr 0.00017315 grad_norm 0.450918 rank 1
2025-01-10 18:37:22,340 DEBUG TRAIN Batch 86/1000 loss 0.060303 acc 0.954212 lr 0.00017309 grad_norm 0.433792 rank 1
2025-01-10 18:37:22,340 DEBUG TRAIN Batch 86/1000 loss 0.052844 acc 0.961264 lr 0.00017309 grad_norm 0.433792 rank 2
2025-01-10 18:37:22,340 DEBUG TRAIN Batch 86/1000 loss 0.036132 acc 0.977545 lr 0.00017309 grad_norm 0.433792 rank 0
2025-01-10 18:37:46,177 DEBUG TRAIN Batch 86/1100 loss 0.053729 acc 0.965000 lr 0.00017304 grad_norm 0.486995 rank 0
2025-01-10 18:37:46,177 DEBUG TRAIN Batch 86/1100 loss 0.055802 acc 0.954219 lr 0.00017304 grad_norm 0.486995 rank 1
2025-01-10 18:37:46,177 DEBUG TRAIN Batch 86/1100 loss 0.065055 acc 0.954321 lr 0.00017304 grad_norm 0.486995 rank 2
2025-01-10 18:38:11,059 DEBUG TRAIN Batch 86/1200 loss 0.065504 acc 0.952731 lr 0.00017299 grad_norm 0.496389 rank 1
2025-01-10 18:38:11,059 DEBUG TRAIN Batch 86/1200 loss 0.071227 acc 0.950521 lr 0.00017299 grad_norm 0.496389 rank 0
2025-01-10 18:38:11,060 DEBUG TRAIN Batch 86/1200 loss 0.072370 acc 0.955786 lr 0.00017299 grad_norm 0.496389 rank 2
2025-01-10 18:38:35,012 DEBUG TRAIN Batch 86/1300 loss 0.062516 acc 0.953649 lr 0.00017294 grad_norm 0.487682 rank 2
2025-01-10 18:38:35,012 DEBUG TRAIN Batch 86/1300 loss 0.046212 acc 0.964612 lr 0.00017294 grad_norm 0.487682 rank 0
2025-01-10 18:38:35,013 DEBUG TRAIN Batch 86/1300 loss 0.083415 acc 0.944896 lr 0.00017294 grad_norm 0.487682 rank 1
2025-01-10 18:38:59,935 DEBUG TRAIN Batch 86/1400 loss 0.067551 acc 0.957333 lr 0.00017289 grad_norm 0.472953 rank 0
2025-01-10 18:38:59,935 DEBUG TRAIN Batch 86/1400 loss 0.053694 acc 0.964471 lr 0.00017289 grad_norm 0.472953 rank 2
2025-01-10 18:38:59,935 DEBUG TRAIN Batch 86/1400 loss 0.057883 acc 0.957099 lr 0.00017289 grad_norm 0.472953 rank 1
2025-01-10 18:39:24,204 DEBUG TRAIN Batch 86/1500 loss 0.031643 acc 0.979938 lr 0.00017284 grad_norm 0.464181 rank 0
2025-01-10 18:39:24,205 DEBUG TRAIN Batch 86/1500 loss 0.040196 acc 0.973008 lr 0.00017284 grad_norm 0.464181 rank 2
2025-01-10 18:39:24,205 DEBUG TRAIN Batch 86/1500 loss 0.070813 acc 0.956379 lr 0.00017284 grad_norm 0.464181 rank 1
2025-01-10 18:39:49,106 DEBUG TRAIN Batch 86/1600 loss 0.036783 acc 0.978052 lr 0.00017278 grad_norm 0.466533 rank 0
2025-01-10 18:39:49,107 DEBUG TRAIN Batch 86/1600 loss 0.053844 acc 0.960043 lr 0.00017278 grad_norm 0.466533 rank 2
2025-01-10 18:39:49,107 DEBUG TRAIN Batch 86/1600 loss 0.070275 acc 0.950000 lr 0.00017278 grad_norm 0.466533 rank 1
2025-01-10 18:40:13,989 DEBUG TRAIN Batch 86/1700 loss 0.034477 acc 0.979200 lr 0.00017273 grad_norm 0.480156 rank 2
2025-01-10 18:40:13,989 DEBUG TRAIN Batch 86/1700 loss 0.040236 acc 0.972789 lr 0.00017273 grad_norm 0.480156 rank 0
2025-01-10 18:40:13,989 DEBUG TRAIN Batch 86/1700 loss 0.072062 acc 0.945487 lr 0.00017273 grad_norm 0.480156 rank 1
2025-01-10 18:40:39,081 DEBUG TRAIN Batch 86/1800 loss 0.033351 acc 0.976109 lr 0.00017268 grad_norm 0.454111 rank 1
2025-01-10 18:40:39,081 DEBUG TRAIN Batch 86/1800 loss 0.077310 acc 0.937332 lr 0.00017268 grad_norm 0.454111 rank 0
2025-01-10 18:40:39,082 DEBUG TRAIN Batch 86/1800 loss 0.047648 acc 0.965395 lr 0.00017268 grad_norm 0.454111 rank 2
2025-01-10 18:41:03,333 DEBUG TRAIN Batch 86/1900 loss 0.046136 acc 0.964097 lr 0.00017263 grad_norm 0.475871 rank 1
2025-01-10 18:41:03,334 DEBUG TRAIN Batch 86/1900 loss 0.071853 acc 0.946309 lr 0.00017263 grad_norm 0.475871 rank 0
2025-01-10 18:41:03,334 DEBUG TRAIN Batch 86/1900 loss 0.052598 acc 0.963057 lr 0.00017263 grad_norm 0.475871 rank 2
2025-01-10 18:41:28,051 DEBUG TRAIN Batch 86/2000 loss 0.044548 acc 0.971744 lr 0.00017258 grad_norm 0.451885 rank 1
2025-01-10 18:41:28,051 DEBUG TRAIN Batch 86/2000 loss 0.063031 acc 0.963475 lr 0.00017258 grad_norm 0.451885 rank 0
2025-01-10 18:41:28,052 DEBUG TRAIN Batch 86/2000 loss 0.049561 acc 0.971993 lr 0.00017258 grad_norm 0.451885 rank 2
2025-01-10 18:41:52,112 DEBUG TRAIN Batch 86/2100 loss 0.077487 acc 0.949866 lr 0.00017253 grad_norm 0.492053 rank 1
2025-01-10 18:41:52,112 DEBUG TRAIN Batch 86/2100 loss 0.064432 acc 0.958079 lr 0.00017253 grad_norm 0.492053 rank 0
2025-01-10 18:41:52,112 DEBUG TRAIN Batch 86/2100 loss 0.076869 acc 0.945874 lr 0.00017253 grad_norm 0.492053 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 18:42:56,845 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 18:42:56,845 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 18:42:57,273 INFO Epoch 86 Step 84000 on_batch_end True CV rank 0
2025-01-10 18:42:57,273 INFO Epoch 86 Step 84000 on_batch_end True CV rank 1
2025-01-10 18:42:57,273 INFO Epoch 86 Step 84000 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 18:43:06,395 DEBUG CV Batch 86/100 loss 0.011566 acc 0.995541  rank 0
2025-01-10 18:43:06,802 DEBUG CV Batch 86/100 loss 0.011566 acc 0.995541  rank 2
2025-01-10 18:43:06,916 INFO Epoch 86 Step 84000 CV info lr 0.00017251638983558856 0 rank loss_2.285452863911224 acc_0.7790247289496556
2025-01-10 18:43:07,150 DEBUG CV Batch 86/100 loss 0.011566 acc 0.995541  rank 1
2025-01-10 18:43:07,338 INFO Epoch 86 Step 84000 CV info lr 0.00017251638983558856 2 rank loss_2.285452863911224 acc_0.7790247289496556
2025-01-10 18:43:07,702 INFO Epoch 86 Step 84000 CV info lr 0.00017251638983558856 1 rank loss_2.285452863911224 acc_0.7790247289496556
2025-01-10 18:43:08,224 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_86_whole.pt
2025-01-10 18:43:08,245 INFO Added key: store_based_barrier_key:89 to store for rank: 0
2025-01-10 18:43:08,245 INFO Added key: store_based_barrier_key:89 to store for rank: 1
2025-01-10 18:43:08,245 INFO Added key: store_based_barrier_key:89 to store for rank: 2
2025-01-10 18:43:08,246 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:89 with 3 nodes.
2025-01-10 18:43:08,246 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:89 with 3 nodes.
2025-01-10 18:43:08,249 INFO Epoch 87 TRAIN info lr 0.00017251638983558856 rank 1
2025-01-10 18:43:08,249 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 18:43:08,255 INFO Epoch 87 TRAIN info lr 0.00017251638983558856 rank 2
2025-01-10 18:43:08,255 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 18:43:08,255 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:89 with 3 nodes.
2025-01-10 18:43:08,257 INFO Epoch 87 TRAIN info lr 0.00017251638983558856 rank 0
2025-01-10 18:43:08,257 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 18:43:39,604 DEBUG TRAIN Batch 87/100 loss 0.058701 acc 0.957156 lr 0.00017247 grad_norm 0.475551 rank 1
2025-01-10 18:43:39,604 DEBUG TRAIN Batch 87/100 loss 0.064631 acc 0.956685 lr 0.00017247 grad_norm 0.475551 rank 0
2025-01-10 18:43:39,605 DEBUG TRAIN Batch 87/100 loss 0.060367 acc 0.951681 lr 0.00017247 grad_norm 0.475551 rank 2
2025-01-10 18:44:03,511 DEBUG TRAIN Batch 87/200 loss 0.065413 acc 0.956055 lr 0.00017241 grad_norm 0.441809 rank 0
2025-01-10 18:44:03,512 DEBUG TRAIN Batch 87/200 loss 0.051424 acc 0.962637 lr 0.00017241 grad_norm 0.441809 rank 1
2025-01-10 18:44:03,512 DEBUG TRAIN Batch 87/200 loss 0.067459 acc 0.953982 lr 0.00017241 grad_norm 0.441809 rank 2
2025-01-10 18:44:27,160 DEBUG TRAIN Batch 87/300 loss 0.071988 acc 0.948029 lr 0.00017236 grad_norm 0.463662 rank 2
2025-01-10 18:44:27,161 DEBUG TRAIN Batch 87/300 loss 0.060214 acc 0.958154 lr 0.00017236 grad_norm 0.463662 rank 0
2025-01-10 18:44:27,161 DEBUG TRAIN Batch 87/300 loss 0.063455 acc 0.960000 lr 0.00017236 grad_norm 0.463662 rank 1
2025-01-10 18:44:51,045 DEBUG TRAIN Batch 87/400 loss 0.068143 acc 0.952008 lr 0.00017231 grad_norm 0.459952 rank 2
2025-01-10 18:44:51,045 DEBUG TRAIN Batch 87/400 loss 0.053192 acc 0.964865 lr 0.00017231 grad_norm 0.459952 rank 0
2025-01-10 18:44:51,046 DEBUG TRAIN Batch 87/400 loss 0.056548 acc 0.966785 lr 0.00017231 grad_norm 0.459952 rank 1
2025-01-10 18:45:15,102 DEBUG TRAIN Batch 87/500 loss 0.064675 acc 0.958904 lr 0.00017226 grad_norm 0.471110 rank 2
2025-01-10 18:45:15,102 DEBUG TRAIN Batch 87/500 loss 0.066058 acc 0.957205 lr 0.00017226 grad_norm 0.471110 rank 0
2025-01-10 18:45:15,103 DEBUG TRAIN Batch 87/500 loss 0.047882 acc 0.969409 lr 0.00017226 grad_norm 0.471110 rank 1
2025-01-10 18:45:38,613 DEBUG TRAIN Batch 87/600 loss 0.066506 acc 0.952118 lr 0.00017221 grad_norm 0.466023 rank 2
2025-01-10 18:45:38,614 DEBUG TRAIN Batch 87/600 loss 0.053104 acc 0.961694 lr 0.00017221 grad_norm 0.466023 rank 0
2025-01-10 18:45:38,614 DEBUG TRAIN Batch 87/600 loss 0.075034 acc 0.952166 lr 0.00017221 grad_norm 0.466023 rank 1
2025-01-10 18:46:02,276 DEBUG TRAIN Batch 87/700 loss 0.054375 acc 0.963228 lr 0.00017216 grad_norm 0.469068 rank 0
2025-01-10 18:46:02,276 DEBUG TRAIN Batch 87/700 loss 0.059251 acc 0.957055 lr 0.00017216 grad_norm 0.469068 rank 2
2025-01-10 18:46:02,277 DEBUG TRAIN Batch 87/700 loss 0.051688 acc 0.966395 lr 0.00017216 grad_norm 0.469068 rank 1
2025-01-10 18:46:25,825 DEBUG TRAIN Batch 87/800 loss 0.062214 acc 0.954861 lr 0.00017211 grad_norm 0.458735 rank 0
2025-01-10 18:46:25,825 DEBUG TRAIN Batch 87/800 loss 0.050741 acc 0.968560 lr 0.00017211 grad_norm 0.458735 rank 1
2025-01-10 18:46:25,826 DEBUG TRAIN Batch 87/800 loss 0.063454 acc 0.963706 lr 0.00017211 grad_norm 0.458735 rank 2
2025-01-10 18:46:49,490 DEBUG TRAIN Batch 87/900 loss 0.072071 acc 0.953263 lr 0.00017206 grad_norm 0.467166 rank 0
2025-01-10 18:46:49,490 DEBUG TRAIN Batch 87/900 loss 0.058686 acc 0.963519 lr 0.00017206 grad_norm 0.467166 rank 2
2025-01-10 18:46:49,490 DEBUG TRAIN Batch 87/900 loss 0.063488 acc 0.958763 lr 0.00017206 grad_norm 0.467166 rank 1
2025-01-10 18:47:13,464 DEBUG TRAIN Batch 87/1000 loss 0.056845 acc 0.960222 lr 0.00017201 grad_norm 0.458012 rank 1
2025-01-10 18:47:13,464 DEBUG TRAIN Batch 87/1000 loss 0.070084 acc 0.949379 lr 0.00017201 grad_norm 0.458012 rank 2
2025-01-10 18:47:13,464 DEBUG TRAIN Batch 87/1000 loss 0.053660 acc 0.965263 lr 0.00017201 grad_norm 0.458012 rank 0
2025-01-10 18:47:37,871 DEBUG TRAIN Batch 87/1100 loss 0.061606 acc 0.953488 lr 0.00017195 grad_norm 0.462952 rank 0
2025-01-10 18:47:37,871 DEBUG TRAIN Batch 87/1100 loss 0.070638 acc 0.949153 lr 0.00017195 grad_norm 0.462952 rank 2
2025-01-10 18:47:37,872 DEBUG TRAIN Batch 87/1100 loss 0.049374 acc 0.966851 lr 0.00017195 grad_norm 0.462952 rank 1
2025-01-10 18:48:02,436 DEBUG TRAIN Batch 87/1200 loss 0.082052 acc 0.937790 lr 0.00017190 grad_norm 0.502082 rank 2
2025-01-10 18:48:02,436 DEBUG TRAIN Batch 87/1200 loss 0.073352 acc 0.947541 lr 0.00017190 grad_norm 0.502082 rank 0
2025-01-10 18:48:02,437 DEBUG TRAIN Batch 87/1200 loss 0.061758 acc 0.960428 lr 0.00017190 grad_norm 0.502082 rank 1
2025-01-10 18:48:26,042 DEBUG TRAIN Batch 87/1300 loss 0.054768 acc 0.966457 lr 0.00017185 grad_norm 0.456300 rank 2
2025-01-10 18:48:26,043 DEBUG TRAIN Batch 87/1300 loss 0.054052 acc 0.965418 lr 0.00017185 grad_norm 0.456300 rank 1
2025-01-10 18:48:26,043 DEBUG TRAIN Batch 87/1300 loss 0.073707 acc 0.947842 lr 0.00017185 grad_norm 0.456300 rank 0
2025-01-10 18:48:50,126 DEBUG TRAIN Batch 87/1400 loss 0.065990 acc 0.960432 lr 0.00017180 grad_norm 0.459725 rank 1
2025-01-10 18:48:50,126 DEBUG TRAIN Batch 87/1400 loss 0.052104 acc 0.963995 lr 0.00017180 grad_norm 0.459725 rank 2
2025-01-10 18:48:50,128 DEBUG TRAIN Batch 87/1400 loss 0.049112 acc 0.963274 lr 0.00017180 grad_norm 0.459725 rank 0
2025-01-10 18:49:13,892 DEBUG TRAIN Batch 87/1500 loss 0.055376 acc 0.966574 lr 0.00017175 grad_norm 0.457739 rank 1
2025-01-10 18:49:13,892 DEBUG TRAIN Batch 87/1500 loss 0.068984 acc 0.950000 lr 0.00017175 grad_norm 0.457739 rank 2
2025-01-10 18:49:13,916 DEBUG TRAIN Batch 87/1500 loss 0.063000 acc 0.960615 lr 0.00017175 grad_norm 0.457739 rank 0
2025-01-10 18:49:38,384 DEBUG TRAIN Batch 87/1600 loss 0.061022 acc 0.956357 lr 0.00017170 grad_norm 0.496705 rank 1
2025-01-10 18:49:38,385 DEBUG TRAIN Batch 87/1600 loss 0.077938 acc 0.943820 lr 0.00017170 grad_norm 0.496705 rank 0
2025-01-10 18:49:38,385 DEBUG TRAIN Batch 87/1600 loss 0.085526 acc 0.943067 lr 0.00017170 grad_norm 0.496705 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 18:50:57,807 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 18:50:57,810 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 18:50:58,257 INFO Epoch 87 Step 84841 on_batch_end True CV rank 2
2025-01-10 18:50:58,257 INFO Epoch 87 Step 84841 on_batch_end True CV rank 0
2025-01-10 18:50:58,257 INFO Epoch 87 Step 84841 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 18:51:07,507 DEBUG CV Batch 87/100 loss 0.017849 acc 0.993311  rank 0
2025-01-10 18:51:07,712 DEBUG CV Batch 87/100 loss 0.017849 acc 0.993311  rank 2
2025-01-10 18:51:08,026 INFO Epoch 87 Step 84841 CV info lr 0.00017165921214577537 0 rank loss_2.2996609016799514 acc_0.778218990878055
2025-01-10 18:51:08,168 DEBUG CV Batch 87/100 loss 0.017849 acc 0.993311  rank 1
2025-01-10 18:51:08,242 INFO Epoch 87 Step 84841 CV info lr 0.00017165921214577537 2 rank loss_2.2996609016799514 acc_0.778218990878055
2025-01-10 18:51:08,728 INFO Epoch 87 Step 84841 CV info lr 0.00017165921214577537 1 rank loss_2.2996609016799514 acc_0.778218990878055
2025-01-10 18:51:09,320 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_87_whole.pt
2025-01-10 18:51:09,332 INFO Added key: store_based_barrier_key:90 to store for rank: 0
2025-01-10 18:51:09,342 INFO Added key: store_based_barrier_key:90 to store for rank: 2
2025-01-10 18:51:09,342 INFO Added key: store_based_barrier_key:90 to store for rank: 1
2025-01-10 18:51:09,343 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:90 with 3 nodes.
2025-01-10 18:51:09,345 INFO Epoch 88 TRAIN info lr 0.00017165921214577537 rank 1
2025-01-10 18:51:09,345 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 18:51:09,352 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:90 with 3 nodes.
2025-01-10 18:51:09,353 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:90 with 3 nodes.
2025-01-10 18:51:09,359 INFO Epoch 88 TRAIN info lr 0.00017165921214577537 rank 0
2025-01-10 18:51:09,359 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 18:51:09,361 INFO Epoch 88 TRAIN info lr 0.00017165921214577537 rank 2
2025-01-10 18:51:09,361 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 18:51:42,070 DEBUG TRAIN Batch 88/100 loss 0.053341 acc 0.965948 lr 0.00017161 grad_norm 0.468086 rank 1
2025-01-10 18:51:42,070 DEBUG TRAIN Batch 88/100 loss 0.060145 acc 0.959290 lr 0.00017161 grad_norm 0.468086 rank 0
2025-01-10 18:51:42,071 DEBUG TRAIN Batch 88/100 loss 0.078995 acc 0.950181 lr 0.00017161 grad_norm 0.468086 rank 2
2025-01-10 18:52:06,011 DEBUG TRAIN Batch 88/200 loss 0.085290 acc 0.947133 lr 0.00017156 grad_norm 0.478361 rank 2
2025-01-10 18:52:06,011 DEBUG TRAIN Batch 88/200 loss 0.064939 acc 0.951370 lr 0.00017156 grad_norm 0.478361 rank 0
2025-01-10 18:52:06,011 DEBUG TRAIN Batch 88/200 loss 0.048177 acc 0.962834 lr 0.00017156 grad_norm 0.478361 rank 1
2025-01-10 18:52:30,236 DEBUG TRAIN Batch 88/300 loss 0.060311 acc 0.960878 lr 0.00017151 grad_norm 0.458289 rank 0
2025-01-10 18:52:30,237 DEBUG TRAIN Batch 88/300 loss 0.060404 acc 0.957837 lr 0.00017151 grad_norm 0.458289 rank 2
2025-01-10 18:52:30,238 DEBUG TRAIN Batch 88/300 loss 0.050007 acc 0.962323 lr 0.00017151 grad_norm 0.458289 rank 1
2025-01-10 18:52:54,798 DEBUG TRAIN Batch 88/400 loss 0.063266 acc 0.959297 lr 0.00017146 grad_norm 0.466886 rank 1
2025-01-10 18:52:54,798 DEBUG TRAIN Batch 88/400 loss 0.078571 acc 0.948454 lr 0.00017146 grad_norm 0.466886 rank 0
2025-01-10 18:52:54,799 DEBUG TRAIN Batch 88/400 loss 0.044979 acc 0.966063 lr 0.00017146 grad_norm 0.466886 rank 2
2025-01-10 18:53:18,862 DEBUG TRAIN Batch 88/500 loss 0.094753 acc 0.934137 lr 0.00017141 grad_norm 0.487034 rank 1
2025-01-10 18:53:18,862 DEBUG TRAIN Batch 88/500 loss 0.081571 acc 0.943223 lr 0.00017141 grad_norm 0.487034 rank 0
2025-01-10 18:53:18,862 DEBUG TRAIN Batch 88/500 loss 0.049019 acc 0.961743 lr 0.00017141 grad_norm 0.487034 rank 2
2025-01-10 18:53:42,742 DEBUG TRAIN Batch 88/600 loss 0.074019 acc 0.951389 lr 0.00017136 grad_norm 0.455181 rank 0
2025-01-10 18:53:42,742 DEBUG TRAIN Batch 88/600 loss 0.053260 acc 0.967972 lr 0.00017136 grad_norm 0.455181 rank 2
2025-01-10 18:53:42,743 DEBUG TRAIN Batch 88/600 loss 0.062317 acc 0.953299 lr 0.00017136 grad_norm 0.455181 rank 1
2025-01-10 18:54:07,146 DEBUG TRAIN Batch 88/700 loss 0.076662 acc 0.950980 lr 0.00017131 grad_norm 0.489885 rank 0
2025-01-10 18:54:07,146 DEBUG TRAIN Batch 88/700 loss 0.076026 acc 0.948742 lr 0.00017131 grad_norm 0.489885 rank 2
2025-01-10 18:54:07,147 DEBUG TRAIN Batch 88/700 loss 0.051621 acc 0.967524 lr 0.00017131 grad_norm 0.489885 rank 1
2025-01-10 18:54:31,331 DEBUG TRAIN Batch 88/800 loss 0.065105 acc 0.960552 lr 0.00017126 grad_norm 0.452890 rank 0
2025-01-10 18:54:31,331 DEBUG TRAIN Batch 88/800 loss 0.054025 acc 0.961502 lr 0.00017126 grad_norm 0.452890 rank 1
2025-01-10 18:54:31,331 DEBUG TRAIN Batch 88/800 loss 0.067883 acc 0.949602 lr 0.00017126 grad_norm 0.452890 rank 2
2025-01-10 18:54:55,391 DEBUG TRAIN Batch 88/900 loss 0.047616 acc 0.971297 lr 0.00017121 grad_norm 0.440270 rank 0
2025-01-10 18:54:55,392 DEBUG TRAIN Batch 88/900 loss 0.056056 acc 0.962446 lr 0.00017121 grad_norm 0.440270 rank 2
2025-01-10 18:54:55,392 DEBUG TRAIN Batch 88/900 loss 0.036783 acc 0.968205 lr 0.00017121 grad_norm 0.440270 rank 1
2025-01-10 18:55:19,220 DEBUG TRAIN Batch 88/1000 loss 0.062872 acc 0.958296 lr 0.00017116 grad_norm 0.460376 rank 2
2025-01-10 18:55:19,221 DEBUG TRAIN Batch 88/1000 loss 0.058458 acc 0.960271 lr 0.00017116 grad_norm 0.460376 rank 1
2025-01-10 18:55:19,221 DEBUG TRAIN Batch 88/1000 loss 0.065652 acc 0.955910 lr 0.00017116 grad_norm 0.460376 rank 0
2025-01-10 18:55:43,241 DEBUG TRAIN Batch 88/1100 loss 0.055088 acc 0.966597 lr 0.00017111 grad_norm 0.435667 rank 0
2025-01-10 18:55:43,241 DEBUG TRAIN Batch 88/1100 loss 0.070528 acc 0.954291 lr 0.00017111 grad_norm 0.435667 rank 1
2025-01-10 18:55:43,242 DEBUG TRAIN Batch 88/1100 loss 0.063553 acc 0.954827 lr 0.00017111 grad_norm 0.435667 rank 2
2025-01-10 18:56:07,613 DEBUG TRAIN Batch 88/1200 loss 0.060325 acc 0.960587 lr 0.00017106 grad_norm 0.444552 rank 2
2025-01-10 18:56:07,613 DEBUG TRAIN Batch 88/1200 loss 0.029584 acc 0.983193 lr 0.00017106 grad_norm 0.444552 rank 0
2025-01-10 18:56:07,613 DEBUG TRAIN Batch 88/1200 loss 0.050285 acc 0.961039 lr 0.00017106 grad_norm 0.444552 rank 1
2025-01-10 18:56:31,282 DEBUG TRAIN Batch 88/1300 loss 0.056362 acc 0.960373 lr 0.00017101 grad_norm 0.473426 rank 1
2025-01-10 18:56:31,283 DEBUG TRAIN Batch 88/1300 loss 0.037958 acc 0.973214 lr 0.00017101 grad_norm 0.473426 rank 0
2025-01-10 18:56:31,283 DEBUG TRAIN Batch 88/1300 loss 0.055790 acc 0.959725 lr 0.00017101 grad_norm 0.473426 rank 2
2025-01-10 18:56:55,584 DEBUG TRAIN Batch 88/1400 loss 0.050289 acc 0.965131 lr 0.00017096 grad_norm 0.468854 rank 0
2025-01-10 18:56:55,585 DEBUG TRAIN Batch 88/1400 loss 0.051377 acc 0.964848 lr 0.00017096 grad_norm 0.468854 rank 2
2025-01-10 18:56:55,585 DEBUG TRAIN Batch 88/1400 loss 0.052554 acc 0.963504 lr 0.00017096 grad_norm 0.468854 rank 1
2025-01-10 18:57:20,308 DEBUG TRAIN Batch 88/1500 loss 0.051999 acc 0.965164 lr 0.00017091 grad_norm 0.490160 rank 0
2025-01-10 18:57:20,308 DEBUG TRAIN Batch 88/1500 loss 0.062755 acc 0.961290 lr 0.00017091 grad_norm 0.490160 rank 1
2025-01-10 18:57:20,309 DEBUG TRAIN Batch 88/1500 loss 0.065753 acc 0.953000 lr 0.00017091 grad_norm 0.490160 rank 2
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 18:58:24,164 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 18:58:24,172 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 18:58:24,593 INFO Epoch 88 Step 85599 on_batch_end True CV rank 1
2025-01-10 18:58:24,593 INFO Epoch 88 Step 85599 on_batch_end True CV rank 0
2025-01-10 18:58:24,593 INFO Epoch 88 Step 85599 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 18:58:33,460 DEBUG CV Batch 88/100 loss 0.027654 acc 0.992196  rank 0
2025-01-10 18:58:33,914 DEBUG CV Batch 88/100 loss 0.027654 acc 0.992196  rank 2
2025-01-10 18:58:33,941 INFO Epoch 88 Step 85599 CV info lr 0.00017089747999202512 0 rank loss_2.318621740678505 acc_0.779037899223336
2025-01-10 18:58:34,188 DEBUG CV Batch 88/100 loss 0.027654 acc 0.992196  rank 1
2025-01-10 18:58:34,460 INFO Epoch 88 Step 85599 CV info lr 0.00017089747999202512 2 rank loss_2.318621740678505 acc_0.779037899223336
2025-01-10 18:58:34,723 INFO Epoch 88 Step 85599 CV info lr 0.00017089747999202512 1 rank loss_2.318621740678505 acc_0.779037899223336
2025-01-10 18:58:35,208 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_88_whole.pt
2025-01-10 18:58:35,219 INFO Added key: store_based_barrier_key:91 to store for rank: 0
2025-01-10 18:58:35,229 INFO Added key: store_based_barrier_key:91 to store for rank: 2
2025-01-10 18:58:35,229 INFO Added key: store_based_barrier_key:91 to store for rank: 1
2025-01-10 18:58:35,230 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:91 with 3 nodes.
2025-01-10 18:58:35,230 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:91 with 3 nodes.
2025-01-10 18:58:35,238 INFO Epoch 89 TRAIN info lr 0.00017089747999202512 rank 1
2025-01-10 18:58:35,238 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 18:58:35,239 INFO Epoch 89 TRAIN info lr 0.00017089747999202512 rank 2
2025-01-10 18:58:35,239 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 18:58:35,240 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:91 with 3 nodes.
2025-01-10 18:58:35,246 INFO Epoch 89 TRAIN info lr 0.00017089747999202512 rank 0
2025-01-10 18:58:35,246 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 18:59:09,483 DEBUG TRAIN Batch 89/100 loss 0.067077 acc 0.954298 lr 0.00017085 grad_norm 0.415272 rank 1
2025-01-10 18:59:09,484 DEBUG TRAIN Batch 89/100 loss 0.048863 acc 0.959472 lr 0.00017085 grad_norm 0.415272 rank 2
2025-01-10 18:59:09,484 DEBUG TRAIN Batch 89/100 loss 0.044258 acc 0.969819 lr 0.00017085 grad_norm 0.415272 rank 0
2025-01-10 18:59:33,537 DEBUG TRAIN Batch 89/200 loss 0.067390 acc 0.959776 lr 0.00017080 grad_norm 0.433011 rank 2
2025-01-10 18:59:33,538 DEBUG TRAIN Batch 89/200 loss 0.049122 acc 0.964490 lr 0.00017080 grad_norm 0.433011 rank 1
2025-01-10 18:59:33,538 DEBUG TRAIN Batch 89/200 loss 0.057171 acc 0.965035 lr 0.00017080 grad_norm 0.433011 rank 0
2025-01-10 18:59:58,359 DEBUG TRAIN Batch 89/300 loss 0.055684 acc 0.962500 lr 0.00017075 grad_norm 0.488090 rank 0
2025-01-10 18:59:58,360 DEBUG TRAIN Batch 89/300 loss 0.048165 acc 0.963492 lr 0.00017075 grad_norm 0.488090 rank 1
2025-01-10 18:59:58,360 DEBUG TRAIN Batch 89/300 loss 0.061086 acc 0.953532 lr 0.00017075 grad_norm 0.488090 rank 2
2025-01-10 19:00:23,160 DEBUG TRAIN Batch 89/400 loss 0.052111 acc 0.966374 lr 0.00017070 grad_norm 0.469599 rank 0
2025-01-10 19:00:23,160 DEBUG TRAIN Batch 89/400 loss 0.048158 acc 0.958890 lr 0.00017070 grad_norm 0.469599 rank 2
2025-01-10 19:00:23,160 DEBUG TRAIN Batch 89/400 loss 0.062670 acc 0.957513 lr 0.00017070 grad_norm 0.469599 rank 1
2025-01-10 19:00:47,118 DEBUG TRAIN Batch 89/500 loss 0.038769 acc 0.972860 lr 0.00017065 grad_norm 0.470833 rank 0
2025-01-10 19:00:47,118 DEBUG TRAIN Batch 89/500 loss 0.060881 acc 0.957265 lr 0.00017065 grad_norm 0.470833 rank 2
2025-01-10 19:00:47,118 DEBUG TRAIN Batch 89/500 loss 0.078287 acc 0.953893 lr 0.00017065 grad_norm 0.470833 rank 1
2025-01-10 19:01:11,579 DEBUG TRAIN Batch 89/600 loss 0.051249 acc 0.960177 lr 0.00017060 grad_norm 0.451190 rank 1
2025-01-10 19:01:11,580 DEBUG TRAIN Batch 89/600 loss 0.064999 acc 0.954376 lr 0.00017060 grad_norm 0.451190 rank 2
2025-01-10 19:01:11,580 DEBUG TRAIN Batch 89/600 loss 0.041771 acc 0.971985 lr 0.00017060 grad_norm 0.451190 rank 0
2025-01-10 19:01:37,126 DEBUG TRAIN Batch 89/700 loss 0.067266 acc 0.953244 lr 0.00017055 grad_norm 0.490935 rank 2
2025-01-10 19:01:37,126 DEBUG TRAIN Batch 89/700 loss 0.061198 acc 0.958654 lr 0.00017055 grad_norm 0.490935 rank 0
2025-01-10 19:01:37,127 DEBUG TRAIN Batch 89/700 loss 0.053043 acc 0.967168 lr 0.00017055 grad_norm 0.490935 rank 1
2025-01-10 19:02:01,278 DEBUG TRAIN Batch 89/800 loss 0.042063 acc 0.972779 lr 0.00017050 grad_norm 0.454916 rank 0
2025-01-10 19:02:01,278 DEBUG TRAIN Batch 89/800 loss 0.065571 acc 0.953959 lr 0.00017050 grad_norm 0.454916 rank 2
2025-01-10 19:02:01,279 DEBUG TRAIN Batch 89/800 loss 0.057583 acc 0.954386 lr 0.00017050 grad_norm 0.454916 rank 1
2025-01-10 19:02:25,785 DEBUG TRAIN Batch 89/900 loss 0.052690 acc 0.965385 lr 0.00017045 grad_norm 0.484239 rank 0
2025-01-10 19:02:25,785 DEBUG TRAIN Batch 89/900 loss 0.038741 acc 0.975177 lr 0.00017045 grad_norm 0.484239 rank 2
2025-01-10 19:02:25,785 DEBUG TRAIN Batch 89/900 loss 0.071944 acc 0.944762 lr 0.00017045 grad_norm 0.484239 rank 1
2025-01-10 19:02:50,976 DEBUG TRAIN Batch 89/1000 loss 0.062911 acc 0.955969 lr 0.00017040 grad_norm 0.449372 rank 1
2025-01-10 19:02:50,976 DEBUG TRAIN Batch 89/1000 loss 0.063446 acc 0.957848 lr 0.00017040 grad_norm 0.449372 rank 0
2025-01-10 19:02:50,976 DEBUG TRAIN Batch 89/1000 loss 0.065048 acc 0.958121 lr 0.00017040 grad_norm 0.449372 rank 2
2025-01-10 19:03:14,714 DEBUG TRAIN Batch 89/1100 loss 0.072992 acc 0.943038 lr 0.00017035 grad_norm 0.490843 rank 1
2025-01-10 19:03:14,714 DEBUG TRAIN Batch 89/1100 loss 0.060576 acc 0.952381 lr 0.00017035 grad_norm 0.490843 rank 2
2025-01-10 19:03:14,715 DEBUG TRAIN Batch 89/1100 loss 0.083254 acc 0.936047 lr 0.00017035 grad_norm 0.490843 rank 0
2025-01-10 19:03:38,776 DEBUG TRAIN Batch 89/1200 loss 0.066609 acc 0.957328 lr 0.00017030 grad_norm 0.451083 rank 1
2025-01-10 19:03:38,777 DEBUG TRAIN Batch 89/1200 loss 0.050314 acc 0.963908 lr 0.00017030 grad_norm 0.451083 rank 2
2025-01-10 19:03:38,777 DEBUG TRAIN Batch 89/1200 loss 0.071222 acc 0.952830 lr 0.00017030 grad_norm 0.451083 rank 0
2025-01-10 19:04:02,610 DEBUG TRAIN Batch 89/1300 loss 0.076544 acc 0.945970 lr 0.00017025 grad_norm 0.509959 rank 0
2025-01-10 19:04:02,611 DEBUG TRAIN Batch 89/1300 loss 0.074914 acc 0.950960 lr 0.00017025 grad_norm 0.509959 rank 2
2025-01-10 19:04:02,612 DEBUG TRAIN Batch 89/1300 loss 0.064539 acc 0.950544 lr 0.00017025 grad_norm 0.509959 rank 1
2025-01-10 19:04:26,717 DEBUG TRAIN Batch 89/1400 loss 0.087735 acc 0.942601 lr 0.00017020 grad_norm 0.464334 rank 1
2025-01-10 19:04:26,717 DEBUG TRAIN Batch 89/1400 loss 0.075247 acc 0.954266 lr 0.00017020 grad_norm 0.464334 rank 2
2025-01-10 19:04:26,718 DEBUG TRAIN Batch 89/1400 loss 0.095483 acc 0.939394 lr 0.00017020 grad_norm 0.464334 rank 0
2025-01-10 19:04:51,938 DEBUG TRAIN Batch 89/1500 loss 0.058710 acc 0.957128 lr 0.00017015 grad_norm 0.504668 rank 2
2025-01-10 19:04:51,938 DEBUG TRAIN Batch 89/1500 loss 0.063698 acc 0.957330 lr 0.00017015 grad_norm 0.504668 rank 0
2025-01-10 19:04:51,939 DEBUG TRAIN Batch 89/1500 loss 0.065613 acc 0.953865 lr 0.00017015 grad_norm 0.504668 rank 1
2025-01-10 19:05:16,791 DEBUG TRAIN Batch 89/1600 loss 0.042864 acc 0.973042 lr 0.00017010 grad_norm 0.495551 rank 2
2025-01-10 19:05:16,792 DEBUG TRAIN Batch 89/1600 loss 0.068800 acc 0.952465 lr 0.00017010 grad_norm 0.495551 rank 0
2025-01-10 19:05:16,792 DEBUG TRAIN Batch 89/1600 loss 0.074363 acc 0.948780 lr 0.00017010 grad_norm 0.495551 rank 1
2025-01-10 19:05:40,836 DEBUG TRAIN Batch 89/1700 loss 0.062824 acc 0.953289 lr 0.00017006 grad_norm 0.474906 rank 0
2025-01-10 19:05:40,836 DEBUG TRAIN Batch 89/1700 loss 0.066239 acc 0.950304 lr 0.00017006 grad_norm 0.474906 rank 2
2025-01-10 19:05:40,836 DEBUG TRAIN Batch 89/1700 loss 0.081632 acc 0.945402 lr 0.00017006 grad_norm 0.474906 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 19:06:46,867 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 19:06:46,869 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 19:06:47,262 INFO Epoch 89 Step 86461 on_batch_end True CV rank 1
2025-01-10 19:06:47,262 INFO Epoch 89 Step 86461 on_batch_end True CV rank 0
2025-01-10 19:06:47,262 INFO Epoch 89 Step 86461 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 19:06:56,317 DEBUG CV Batch 89/100 loss 0.007458 acc 0.997770  rank 0
2025-01-10 19:06:56,748 DEBUG CV Batch 89/100 loss 0.007458 acc 0.997770  rank 2
2025-01-10 19:06:56,811 INFO Epoch 89 Step 86461 CV info lr 0.00017004343804312612 0 rank loss_2.300815906568651 acc_0.7808755434918822
2025-01-10 19:06:57,205 DEBUG CV Batch 89/100 loss 0.007458 acc 0.997770  rank 1
2025-01-10 19:06:57,301 INFO Epoch 89 Step 86461 CV info lr 0.00017004343804312612 2 rank loss_2.300815906568651 acc_0.7808755434918822
2025-01-10 19:06:57,770 INFO Epoch 89 Step 86461 CV info lr 0.00017004343804312612 1 rank loss_2.300815906568651 acc_0.7808755434918822
2025-01-10 19:06:58,109 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_89_whole.pt
2025-01-10 19:06:58,121 INFO Added key: store_based_barrier_key:92 to store for rank: 0
2025-01-10 19:06:58,131 INFO Added key: store_based_barrier_key:92 to store for rank: 2
2025-01-10 19:06:58,131 INFO Added key: store_based_barrier_key:92 to store for rank: 1
2025-01-10 19:06:58,131 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:92 with 3 nodes.
2025-01-10 19:06:58,131 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:92 with 3 nodes.
2025-01-10 19:06:58,134 INFO Epoch 90 TRAIN info lr 0.00017004343804312612 rank 1
2025-01-10 19:06:58,134 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 19:06:58,141 INFO Epoch 90 TRAIN info lr 0.00017004343804312612 rank 2
2025-01-10 19:06:58,141 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 19:06:58,141 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:92 with 3 nodes.
2025-01-10 19:06:58,149 INFO Epoch 90 TRAIN info lr 0.00017004343804312612 rank 0
2025-01-10 19:06:58,149 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 19:07:29,424 DEBUG TRAIN Batch 90/100 loss 0.055190 acc 0.956820 lr 0.00016999 grad_norm 0.466921 rank 1
2025-01-10 19:07:29,424 DEBUG TRAIN Batch 90/100 loss 0.080874 acc 0.948627 lr 0.00016999 grad_norm 0.466921 rank 0
2025-01-10 19:07:29,424 DEBUG TRAIN Batch 90/100 loss 0.052367 acc 0.964173 lr 0.00016999 grad_norm 0.466921 rank 2
2025-01-10 19:07:53,267 DEBUG TRAIN Batch 90/200 loss 0.051818 acc 0.968112 lr 0.00016995 grad_norm 0.467063 rank 2
2025-01-10 19:07:53,268 DEBUG TRAIN Batch 90/200 loss 0.051012 acc 0.966165 lr 0.00016995 grad_norm 0.467063 rank 0
2025-01-10 19:07:53,268 DEBUG TRAIN Batch 90/200 loss 0.056819 acc 0.960637 lr 0.00016995 grad_norm 0.467063 rank 1
2025-01-10 19:08:16,832 DEBUG TRAIN Batch 90/300 loss 0.081302 acc 0.946328 lr 0.00016990 grad_norm 0.471979 rank 0
2025-01-10 19:08:16,832 DEBUG TRAIN Batch 90/300 loss 0.071617 acc 0.954178 lr 0.00016990 grad_norm 0.471979 rank 2
2025-01-10 19:08:16,832 DEBUG TRAIN Batch 90/300 loss 0.070273 acc 0.947140 lr 0.00016990 grad_norm 0.471979 rank 1
2025-01-10 19:08:40,545 DEBUG TRAIN Batch 90/400 loss 0.066806 acc 0.953668 lr 0.00016985 grad_norm 0.497386 rank 0
2025-01-10 19:08:40,546 DEBUG TRAIN Batch 90/400 loss 0.070914 acc 0.949203 lr 0.00016985 grad_norm 0.497386 rank 2
2025-01-10 19:08:40,546 DEBUG TRAIN Batch 90/400 loss 0.053739 acc 0.964022 lr 0.00016985 grad_norm 0.497386 rank 1
2025-01-10 19:09:04,870 DEBUG TRAIN Batch 90/500 loss 0.049668 acc 0.963830 lr 0.00016980 grad_norm 0.438922 rank 2
2025-01-10 19:09:04,870 DEBUG TRAIN Batch 90/500 loss 0.075402 acc 0.953084 lr 0.00016980 grad_norm 0.438922 rank 0
2025-01-10 19:09:04,870 DEBUG TRAIN Batch 90/500 loss 0.064747 acc 0.954787 lr 0.00016980 grad_norm 0.438922 rank 1
2025-01-10 19:09:28,936 DEBUG TRAIN Batch 90/600 loss 0.084575 acc 0.939183 lr 0.00016975 grad_norm 0.453396 rank 2
2025-01-10 19:09:28,936 DEBUG TRAIN Batch 90/600 loss 0.066875 acc 0.951656 lr 0.00016975 grad_norm 0.453396 rank 0
2025-01-10 19:09:28,936 DEBUG TRAIN Batch 90/600 loss 0.049389 acc 0.959783 lr 0.00016975 grad_norm 0.453396 rank 1
2025-01-10 19:09:54,060 DEBUG TRAIN Batch 90/700 loss 0.050690 acc 0.965517 lr 0.00016970 grad_norm 0.405621 rank 2
2025-01-10 19:09:54,060 DEBUG TRAIN Batch 90/700 loss 0.065355 acc 0.954861 lr 0.00016970 grad_norm 0.405621 rank 0
2025-01-10 19:09:54,060 DEBUG TRAIN Batch 90/700 loss 0.028520 acc 0.978896 lr 0.00016970 grad_norm 0.405621 rank 1
2025-01-10 19:10:18,740 DEBUG TRAIN Batch 90/800 loss 0.055962 acc 0.954595 lr 0.00016965 grad_norm 0.459473 rank 0
2025-01-10 19:10:18,740 DEBUG TRAIN Batch 90/800 loss 0.060663 acc 0.954304 lr 0.00016965 grad_norm 0.459473 rank 2
2025-01-10 19:10:18,741 DEBUG TRAIN Batch 90/800 loss 0.065001 acc 0.955830 lr 0.00016965 grad_norm 0.459473 rank 1
2025-01-10 19:10:42,797 DEBUG TRAIN Batch 90/900 loss 0.064576 acc 0.963844 lr 0.00016960 grad_norm 0.466936 rank 0
2025-01-10 19:10:42,797 DEBUG TRAIN Batch 90/900 loss 0.043347 acc 0.968193 lr 0.00016960 grad_norm 0.466936 rank 1
2025-01-10 19:10:42,797 DEBUG TRAIN Batch 90/900 loss 0.050157 acc 0.966814 lr 0.00016960 grad_norm 0.466936 rank 2
2025-01-10 19:11:06,847 DEBUG TRAIN Batch 90/1000 loss 0.035626 acc 0.976459 lr 0.00016955 grad_norm 0.451632 rank 0
2025-01-10 19:11:06,847 DEBUG TRAIN Batch 90/1000 loss 0.050211 acc 0.970379 lr 0.00016955 grad_norm 0.451632 rank 2
2025-01-10 19:11:06,848 DEBUG TRAIN Batch 90/1000 loss 0.061068 acc 0.962025 lr 0.00016955 grad_norm 0.451632 rank 1
2025-01-10 19:11:31,696 DEBUG TRAIN Batch 90/1100 loss 0.059964 acc 0.963100 lr 0.00016951 grad_norm 0.448733 rank 0
2025-01-10 19:11:31,696 DEBUG TRAIN Batch 90/1100 loss 0.022170 acc 0.986799 lr 0.00016951 grad_norm 0.448733 rank 1
2025-01-10 19:11:31,696 DEBUG TRAIN Batch 90/1100 loss 0.035728 acc 0.974318 lr 0.00016951 grad_norm 0.448733 rank 2
2025-01-10 19:11:56,130 DEBUG TRAIN Batch 90/1200 loss 0.070892 acc 0.951521 lr 0.00016946 grad_norm 0.464065 rank 0
2025-01-10 19:11:56,130 DEBUG TRAIN Batch 90/1200 loss 0.062653 acc 0.961156 lr 0.00016946 grad_norm 0.464065 rank 2
2025-01-10 19:11:56,131 DEBUG TRAIN Batch 90/1200 loss 0.055498 acc 0.958829 lr 0.00016946 grad_norm 0.464065 rank 1
2025-01-10 19:12:20,088 DEBUG TRAIN Batch 90/1300 loss 0.038197 acc 0.973624 lr 0.00016941 grad_norm 0.460969 rank 1
2025-01-10 19:12:20,088 DEBUG TRAIN Batch 90/1300 loss 0.083410 acc 0.941392 lr 0.00016941 grad_norm 0.460969 rank 0
2025-01-10 19:12:20,088 DEBUG TRAIN Batch 90/1300 loss 0.049719 acc 0.964151 lr 0.00016941 grad_norm 0.460969 rank 2
2025-01-10 19:12:44,900 DEBUG TRAIN Batch 90/1400 loss 0.072671 acc 0.951691 lr 0.00016936 grad_norm 0.465449 rank 0
2025-01-10 19:12:44,900 DEBUG TRAIN Batch 90/1400 loss 0.075665 acc 0.947085 lr 0.00016936 grad_norm 0.465449 rank 1
2025-01-10 19:12:44,901 DEBUG TRAIN Batch 90/1400 loss 0.057990 acc 0.958215 lr 0.00016936 grad_norm 0.465449 rank 2
2025-01-10 19:13:08,542 DEBUG TRAIN Batch 90/1500 loss 0.040266 acc 0.976596 lr 0.00016931 grad_norm 0.487344 rank 2
2025-01-10 19:13:08,542 DEBUG TRAIN Batch 90/1500 loss 0.061075 acc 0.957557 lr 0.00016931 grad_norm 0.487344 rank 0
2025-01-10 19:13:08,542 DEBUG TRAIN Batch 90/1500 loss 0.039185 acc 0.972222 lr 0.00016931 grad_norm 0.487344 rank 1
2025-01-10 19:13:32,476 DEBUG TRAIN Batch 90/1600 loss 0.060386 acc 0.959360 lr 0.00016926 grad_norm 0.490443 rank 0
2025-01-10 19:13:32,476 DEBUG TRAIN Batch 90/1600 loss 0.078207 acc 0.944198 lr 0.00016926 grad_norm 0.490443 rank 2
2025-01-10 19:13:32,476 DEBUG TRAIN Batch 90/1600 loss 0.047526 acc 0.970310 lr 0.00016926 grad_norm 0.490443 rank 1
2025-01-10 19:13:58,046 DEBUG TRAIN Batch 90/1700 loss 0.059967 acc 0.960440 lr 0.00016921 grad_norm 0.461578 rank 1
2025-01-10 19:13:58,047 DEBUG TRAIN Batch 90/1700 loss 0.074120 acc 0.962157 lr 0.00016921 grad_norm 0.461578 rank 2
2025-01-10 19:13:58,047 DEBUG TRAIN Batch 90/1700 loss 0.061973 acc 0.955926 lr 0.00016921 grad_norm 0.461578 rank 0
2025-01-10 19:14:22,638 DEBUG TRAIN Batch 90/1800 loss 0.076173 acc 0.953603 lr 0.00016917 grad_norm 0.489458 rank 0
2025-01-10 19:14:22,638 DEBUG TRAIN Batch 90/1800 loss 0.057450 acc 0.967156 lr 0.00016917 grad_norm 0.489458 rank 1
2025-01-10 19:14:22,638 DEBUG TRAIN Batch 90/1800 loss 0.065004 acc 0.950355 lr 0.00016917 grad_norm 0.489458 rank 2
2025-01-10 19:14:46,733 DEBUG TRAIN Batch 90/1900 loss 0.068496 acc 0.955926 lr 0.00016912 grad_norm 0.481249 rank 1
2025-01-10 19:14:46,734 DEBUG TRAIN Batch 90/1900 loss 0.060543 acc 0.950311 lr 0.00016912 grad_norm 0.481249 rank 0
2025-01-10 19:14:46,734 DEBUG TRAIN Batch 90/1900 loss 0.051429 acc 0.966793 lr 0.00016912 grad_norm 0.481249 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 19:15:49,270 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 19:15:49,271 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 19:15:49,729 INFO Epoch 90 Step 87416 on_batch_end True CV rank 1
2025-01-10 19:15:49,729 INFO Epoch 90 Step 87416 on_batch_end True CV rank 0
2025-01-10 19:15:49,729 INFO Epoch 90 Step 87416 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 19:15:58,831 DEBUG CV Batch 90/100 loss 0.012084 acc 0.997770  rank 0
2025-01-10 19:15:59,156 DEBUG CV Batch 90/100 loss 0.012084 acc 0.997770  rank 2
2025-01-10 19:15:59,318 DEBUG CV Batch 90/100 loss 0.012084 acc 0.997770  rank 1
2025-01-10 19:15:59,338 INFO Epoch 90 Step 87416 CV info lr 0.0001691120442179923 0 rank loss_2.325788395455834 acc_0.778908128801145
2025-01-10 19:15:59,708 INFO Epoch 90 Step 87416 CV info lr 0.0001691120442179923 2 rank loss_2.325788395455834 acc_0.778908128801145
2025-01-10 19:15:59,845 INFO Epoch 90 Step 87416 CV info lr 0.0001691120442179923 1 rank loss_2.325788395455834 acc_0.778908128801145
2025-01-10 19:16:00,640 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_90_whole.pt
2025-01-10 19:16:00,652 INFO Added key: store_based_barrier_key:93 to store for rank: 0
2025-01-10 19:16:00,662 INFO Added key: store_based_barrier_key:93 to store for rank: 2
2025-01-10 19:16:00,662 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:93 with 3 nodes.
2025-01-10 19:16:00,662 INFO Added key: store_based_barrier_key:93 to store for rank: 1
2025-01-10 19:16:00,662 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:93 with 3 nodes.
2025-01-10 19:16:00,664 INFO Epoch 91 TRAIN info lr 0.0001691120442179923 rank 1
2025-01-10 19:16:00,664 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 19:16:00,669 INFO Epoch 91 TRAIN info lr 0.0001691120442179923 rank 2
2025-01-10 19:16:00,669 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 19:16:00,672 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:93 with 3 nodes.
2025-01-10 19:16:00,680 INFO Epoch 91 TRAIN info lr 0.0001691120442179923 rank 0
2025-01-10 19:16:00,680 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 19:16:32,633 DEBUG TRAIN Batch 91/100 loss 0.062024 acc 0.960041 lr 0.00016906 grad_norm 0.446194 rank 2
2025-01-10 19:16:32,634 DEBUG TRAIN Batch 91/100 loss 0.060351 acc 0.961012 lr 0.00016906 grad_norm 0.446194 rank 1
2025-01-10 19:16:32,634 DEBUG TRAIN Batch 91/100 loss 0.043518 acc 0.965941 lr 0.00016906 grad_norm 0.446194 rank 0
2025-01-10 19:16:56,692 DEBUG TRAIN Batch 91/200 loss 0.052681 acc 0.968610 lr 0.00016902 grad_norm 0.477786 rank 0
2025-01-10 19:16:56,692 DEBUG TRAIN Batch 91/200 loss 0.045885 acc 0.964557 lr 0.00016902 grad_norm 0.477786 rank 1
2025-01-10 19:16:56,693 DEBUG TRAIN Batch 91/200 loss 0.072439 acc 0.941818 lr 0.00016902 grad_norm 0.477786 rank 2
2025-01-10 19:17:21,091 DEBUG TRAIN Batch 91/300 loss 0.053299 acc 0.962193 lr 0.00016897 grad_norm 0.453225 rank 2
2025-01-10 19:17:21,091 DEBUG TRAIN Batch 91/300 loss 0.047018 acc 0.968147 lr 0.00016897 grad_norm 0.453225 rank 1
2025-01-10 19:17:21,091 DEBUG TRAIN Batch 91/300 loss 0.057901 acc 0.969481 lr 0.00016897 grad_norm 0.453225 rank 0
2025-01-10 19:17:44,561 DEBUG TRAIN Batch 91/400 loss 0.054159 acc 0.962000 lr 0.00016892 grad_norm 0.461643 rank 2
2025-01-10 19:17:44,561 DEBUG TRAIN Batch 91/400 loss 0.063405 acc 0.959755 lr 0.00016892 grad_norm 0.461643 rank 0
2025-01-10 19:17:44,561 DEBUG TRAIN Batch 91/400 loss 0.050829 acc 0.962925 lr 0.00016892 grad_norm 0.461643 rank 1
2025-01-10 19:18:08,904 DEBUG TRAIN Batch 91/500 loss 0.059077 acc 0.963327 lr 0.00016887 grad_norm 0.473487 rank 2
2025-01-10 19:18:08,904 DEBUG TRAIN Batch 91/500 loss 0.064206 acc 0.953026 lr 0.00016887 grad_norm 0.473487 rank 0
2025-01-10 19:18:08,904 DEBUG TRAIN Batch 91/500 loss 0.068342 acc 0.951852 lr 0.00016887 grad_norm 0.473487 rank 1
2025-01-10 19:18:33,320 DEBUG TRAIN Batch 91/600 loss 0.059289 acc 0.960526 lr 0.00016882 grad_norm 0.474705 rank 0
2025-01-10 19:18:33,320 DEBUG TRAIN Batch 91/600 loss 0.051426 acc 0.968691 lr 0.00016882 grad_norm 0.474705 rank 2
2025-01-10 19:18:33,321 DEBUG TRAIN Batch 91/600 loss 0.066558 acc 0.948960 lr 0.00016882 grad_norm 0.474705 rank 1
2025-01-10 19:18:57,288 DEBUG TRAIN Batch 91/700 loss 0.051072 acc 0.966189 lr 0.00016877 grad_norm 0.458827 rank 0
2025-01-10 19:18:57,288 DEBUG TRAIN Batch 91/700 loss 0.068818 acc 0.949818 lr 0.00016877 grad_norm 0.458827 rank 1
2025-01-10 19:18:57,288 DEBUG TRAIN Batch 91/700 loss 0.058109 acc 0.956289 lr 0.00016877 grad_norm 0.458827 rank 2
2025-01-10 19:19:20,977 DEBUG TRAIN Batch 91/800 loss 0.066200 acc 0.960204 lr 0.00016873 grad_norm 0.433309 rank 1
2025-01-10 19:19:20,977 DEBUG TRAIN Batch 91/800 loss 0.044227 acc 0.972919 lr 0.00016873 grad_norm 0.433309 rank 2
2025-01-10 19:19:20,977 DEBUG TRAIN Batch 91/800 loss 0.060224 acc 0.962996 lr 0.00016873 grad_norm 0.433309 rank 0
2025-01-10 19:19:44,772 DEBUG TRAIN Batch 91/900 loss 0.059610 acc 0.965142 lr 0.00016868 grad_norm 0.459503 rank 2
2025-01-10 19:19:44,772 DEBUG TRAIN Batch 91/900 loss 0.044748 acc 0.962229 lr 0.00016868 grad_norm 0.459503 rank 0
2025-01-10 19:19:44,772 DEBUG TRAIN Batch 91/900 loss 0.046728 acc 0.966912 lr 0.00016868 grad_norm 0.459503 rank 1
2025-01-10 19:20:08,637 DEBUG TRAIN Batch 91/1000 loss 0.063822 acc 0.956116 lr 0.00016863 grad_norm 0.454835 rank 2
2025-01-10 19:20:08,637 DEBUG TRAIN Batch 91/1000 loss 0.049101 acc 0.969697 lr 0.00016863 grad_norm 0.454835 rank 0
2025-01-10 19:20:08,638 DEBUG TRAIN Batch 91/1000 loss 0.057830 acc 0.959319 lr 0.00016863 grad_norm 0.454835 rank 1
2025-01-10 19:20:31,861 DEBUG TRAIN Batch 91/1100 loss 0.062212 acc 0.952652 lr 0.00016858 grad_norm 0.407979 rank 2
2025-01-10 19:20:31,861 DEBUG TRAIN Batch 91/1100 loss 0.049606 acc 0.968809 lr 0.00016858 grad_norm 0.407979 rank 0
2025-01-10 19:20:31,861 DEBUG TRAIN Batch 91/1100 loss 0.054555 acc 0.958699 lr 0.00016858 grad_norm 0.407979 rank 1
2025-01-10 19:20:55,494 DEBUG TRAIN Batch 91/1200 loss 0.064437 acc 0.953778 lr 0.00016853 grad_norm 0.455524 rank 0
2025-01-10 19:20:55,494 DEBUG TRAIN Batch 91/1200 loss 0.073026 acc 0.948529 lr 0.00016853 grad_norm 0.455524 rank 1
2025-01-10 19:20:55,494 DEBUG TRAIN Batch 91/1200 loss 0.050023 acc 0.965347 lr 0.00016853 grad_norm 0.455524 rank 2
2025-01-10 19:21:19,225 DEBUG TRAIN Batch 91/1300 loss 0.071850 acc 0.948416 lr 0.00016849 grad_norm 0.464080 rank 0
2025-01-10 19:21:19,226 DEBUG TRAIN Batch 91/1300 loss 0.065531 acc 0.950743 lr 0.00016849 grad_norm 0.464080 rank 2
2025-01-10 19:21:19,226 DEBUG TRAIN Batch 91/1300 loss 0.079881 acc 0.948624 lr 0.00016849 grad_norm 0.464080 rank 1
2025-01-10 19:21:42,917 DEBUG TRAIN Batch 91/1400 loss 0.052028 acc 0.964363 lr 0.00016844 grad_norm 0.419730 rank 1
2025-01-10 19:21:42,918 DEBUG TRAIN Batch 91/1400 loss 0.045079 acc 0.973099 lr 0.00016844 grad_norm 0.419730 rank 2
2025-01-10 19:21:42,918 DEBUG TRAIN Batch 91/1400 loss 0.058681 acc 0.957774 lr 0.00016844 grad_norm 0.419730 rank 0
2025-01-10 19:22:06,698 DEBUG TRAIN Batch 91/1500 loss 0.065930 acc 0.960145 lr 0.00016839 grad_norm 0.481930 rank 2
2025-01-10 19:22:06,698 DEBUG TRAIN Batch 91/1500 loss 0.053301 acc 0.966292 lr 0.00016839 grad_norm 0.481930 rank 0
2025-01-10 19:22:06,699 DEBUG TRAIN Batch 91/1500 loss 0.071978 acc 0.950877 lr 0.00016839 grad_norm 0.481930 rank 1
2025-01-10 19:22:30,399 DEBUG TRAIN Batch 91/1600 loss 0.050396 acc 0.966994 lr 0.00016834 grad_norm 0.465370 rank 0
2025-01-10 19:22:30,399 DEBUG TRAIN Batch 91/1600 loss 0.059610 acc 0.952522 lr 0.00016834 grad_norm 0.465370 rank 2
2025-01-10 19:22:30,399 DEBUG TRAIN Batch 91/1600 loss 0.067332 acc 0.958867 lr 0.00016834 grad_norm 0.465370 rank 1
2025-01-10 19:22:55,106 DEBUG TRAIN Batch 91/1700 loss 0.050263 acc 0.971207 lr 0.00016830 grad_norm 0.461402 rank 0
2025-01-10 19:22:55,107 DEBUG TRAIN Batch 91/1700 loss 0.064748 acc 0.953328 lr 0.00016830 grad_norm 0.461402 rank 2
2025-01-10 19:22:55,107 DEBUG TRAIN Batch 91/1700 loss 0.027756 acc 0.987443 lr 0.00016830 grad_norm 0.461402 rank 1
2025-01-10 19:23:20,350 DEBUG TRAIN Batch 91/1800 loss 0.094108 acc 0.930755 lr 0.00016825 grad_norm 0.485923 rank 0
2025-01-10 19:23:20,350 DEBUG TRAIN Batch 91/1800 loss 0.057504 acc 0.956320 lr 0.00016825 grad_norm 0.485923 rank 2
2025-01-10 19:23:20,350 DEBUG TRAIN Batch 91/1800 loss 0.054236 acc 0.960104 lr 0.00016825 grad_norm 0.485923 rank 1
2025-01-10 19:23:44,330 DEBUG TRAIN Batch 91/1900 loss 0.071447 acc 0.950341 lr 0.00016820 grad_norm 0.454167 rank 0
2025-01-10 19:23:44,330 DEBUG TRAIN Batch 91/1900 loss 0.058412 acc 0.964829 lr 0.00016820 grad_norm 0.454167 rank 2
2025-01-10 19:23:44,331 DEBUG TRAIN Batch 91/1900 loss 0.043233 acc 0.972098 lr 0.00016820 grad_norm 0.454167 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 19:25:07,239 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 19:25:07,245 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 19:25:07,682 INFO Epoch 91 Step 88412 on_batch_end True CV rank 0
2025-01-10 19:25:07,682 INFO Epoch 91 Step 88412 on_batch_end True CV rank 2
2025-01-10 19:25:07,682 INFO Epoch 91 Step 88412 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 19:25:16,692 DEBUG CV Batch 91/100 loss 0.018488 acc 0.994426  rank 0
2025-01-10 19:25:17,208 INFO Epoch 91 Step 88412 CV info lr 0.000168156785529899 0 rank loss_2.325002860030764 acc_0.7799914110648004
2025-01-10 19:25:17,238 DEBUG CV Batch 91/100 loss 0.018488 acc 0.994426  rank 2
2025-01-10 19:25:17,588 DEBUG CV Batch 91/100 loss 0.018488 acc 0.994426  rank 1
2025-01-10 19:25:17,791 INFO Epoch 91 Step 88412 CV info lr 0.000168156785529899 2 rank loss_2.325002860030764 acc_0.7799914110648004
2025-01-10 19:25:18,160 INFO Epoch 91 Step 88412 CV info lr 0.000168156785529899 1 rank loss_2.325002860030764 acc_0.7799914110648004
2025-01-10 19:25:18,500 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_91_whole.pt
2025-01-10 19:25:18,512 INFO Added key: store_based_barrier_key:94 to store for rank: 0
2025-01-10 19:25:18,522 INFO Added key: store_based_barrier_key:94 to store for rank: 2
2025-01-10 19:25:18,522 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:94 with 3 nodes.
2025-01-10 19:25:18,522 INFO Added key: store_based_barrier_key:94 to store for rank: 1
2025-01-10 19:25:18,522 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:94 with 3 nodes.
2025-01-10 19:25:18,525 INFO Epoch 92 TRAIN info lr 0.000168156785529899 rank 1
2025-01-10 19:25:18,525 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 19:25:18,527 INFO Epoch 92 TRAIN info lr 0.000168156785529899 rank 2
2025-01-10 19:25:18,527 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 19:25:18,532 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:94 with 3 nodes.
2025-01-10 19:25:18,536 INFO Epoch 92 TRAIN info lr 0.000168156785529899 rank 0
2025-01-10 19:25:18,536 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 19:25:49,539 DEBUG TRAIN Batch 92/100 loss 0.060925 acc 0.949571 lr 0.00016811 grad_norm 0.460255 rank 2
2025-01-10 19:25:49,539 DEBUG TRAIN Batch 92/100 loss 0.059130 acc 0.960905 lr 0.00016811 grad_norm 0.460255 rank 0
2025-01-10 19:25:49,539 DEBUG TRAIN Batch 92/100 loss 0.037927 acc 0.974359 lr 0.00016811 grad_norm 0.460255 rank 1
2025-01-10 19:26:13,606 DEBUG TRAIN Batch 92/200 loss 0.045944 acc 0.975919 lr 0.00016806 grad_norm 0.436193 rank 0
2025-01-10 19:26:13,606 DEBUG TRAIN Batch 92/200 loss 0.044707 acc 0.969668 lr 0.00016806 grad_norm 0.436193 rank 2
2025-01-10 19:26:13,606 DEBUG TRAIN Batch 92/200 loss 0.067515 acc 0.959633 lr 0.00016806 grad_norm 0.436193 rank 1
2025-01-10 19:26:36,889 DEBUG TRAIN Batch 92/300 loss 0.053946 acc 0.965854 lr 0.00016801 grad_norm 0.445449 rank 2
2025-01-10 19:26:36,890 DEBUG TRAIN Batch 92/300 loss 0.068797 acc 0.951784 lr 0.00016801 grad_norm 0.445449 rank 0
2025-01-10 19:26:36,890 DEBUG TRAIN Batch 92/300 loss 0.049887 acc 0.960310 lr 0.00016801 grad_norm 0.445449 rank 1
2025-01-10 19:27:00,538 DEBUG TRAIN Batch 92/400 loss 0.055948 acc 0.961224 lr 0.00016797 grad_norm 0.451117 rank 0
2025-01-10 19:27:00,538 DEBUG TRAIN Batch 92/400 loss 0.053203 acc 0.963138 lr 0.00016797 grad_norm 0.451117 rank 2
2025-01-10 19:27:00,539 DEBUG TRAIN Batch 92/400 loss 0.058966 acc 0.958071 lr 0.00016797 grad_norm 0.451117 rank 1
2025-01-10 19:27:24,498 DEBUG TRAIN Batch 92/500 loss 0.064312 acc 0.960595 lr 0.00016792 grad_norm 0.457635 rank 0
2025-01-10 19:27:24,498 DEBUG TRAIN Batch 92/500 loss 0.062082 acc 0.956172 lr 0.00016792 grad_norm 0.457635 rank 2
2025-01-10 19:27:24,498 DEBUG TRAIN Batch 92/500 loss 0.057847 acc 0.962038 lr 0.00016792 grad_norm 0.457635 rank 1
2025-01-10 19:27:48,601 DEBUG TRAIN Batch 92/600 loss 0.046121 acc 0.963928 lr 0.00016787 grad_norm 0.453389 rank 2
2025-01-10 19:27:48,602 DEBUG TRAIN Batch 92/600 loss 0.057040 acc 0.957428 lr 0.00016787 grad_norm 0.453389 rank 0
2025-01-10 19:27:48,602 DEBUG TRAIN Batch 92/600 loss 0.048157 acc 0.961841 lr 0.00016787 grad_norm 0.453389 rank 1
2025-01-10 19:28:12,969 DEBUG TRAIN Batch 92/700 loss 0.039500 acc 0.975135 lr 0.00016782 grad_norm 0.452441 rank 2
2025-01-10 19:28:12,969 DEBUG TRAIN Batch 92/700 loss 0.074143 acc 0.956480 lr 0.00016782 grad_norm 0.452441 rank 1
2025-01-10 19:28:12,969 DEBUG TRAIN Batch 92/700 loss 0.051585 acc 0.966825 lr 0.00016782 grad_norm 0.452441 rank 0
2025-01-10 19:28:37,764 DEBUG TRAIN Batch 92/800 loss 0.052478 acc 0.965772 lr 0.00016778 grad_norm 0.423996 rank 2
2025-01-10 19:28:37,765 DEBUG TRAIN Batch 92/800 loss 0.051646 acc 0.957692 lr 0.00016778 grad_norm 0.423996 rank 0
2025-01-10 19:28:37,765 DEBUG TRAIN Batch 92/800 loss 0.062438 acc 0.957733 lr 0.00016778 grad_norm 0.423996 rank 1
2025-01-10 19:29:02,151 DEBUG TRAIN Batch 92/900 loss 0.042894 acc 0.967581 lr 0.00016773 grad_norm 0.468997 rank 0
2025-01-10 19:29:02,152 DEBUG TRAIN Batch 92/900 loss 0.062554 acc 0.953991 lr 0.00016773 grad_norm 0.468997 rank 2
2025-01-10 19:29:02,152 DEBUG TRAIN Batch 92/900 loss 0.059933 acc 0.952995 lr 0.00016773 grad_norm 0.468997 rank 1
2025-01-10 19:29:26,431 DEBUG TRAIN Batch 92/1000 loss 0.050531 acc 0.960970 lr 0.00016768 grad_norm 0.454248 rank 0
2025-01-10 19:29:26,432 DEBUG TRAIN Batch 92/1000 loss 0.043586 acc 0.977401 lr 0.00016768 grad_norm 0.454248 rank 2
2025-01-10 19:29:26,432 DEBUG TRAIN Batch 92/1000 loss 0.068149 acc 0.953222 lr 0.00016768 grad_norm 0.454248 rank 1
2025-01-10 19:29:51,003 DEBUG TRAIN Batch 92/1100 loss 0.061895 acc 0.954851 lr 0.00016764 grad_norm 0.473648 rank 0
2025-01-10 19:29:51,004 DEBUG TRAIN Batch 92/1100 loss 0.075591 acc 0.954033 lr 0.00016764 grad_norm 0.473648 rank 1
2025-01-10 19:29:51,004 DEBUG TRAIN Batch 92/1100 loss 0.062123 acc 0.961111 lr 0.00016764 grad_norm 0.473648 rank 2
2025-01-10 19:30:15,627 DEBUG TRAIN Batch 92/1200 loss 0.062488 acc 0.949950 lr 0.00016759 grad_norm 0.504497 rank 0
2025-01-10 19:30:15,627 DEBUG TRAIN Batch 92/1200 loss 0.073426 acc 0.945722 lr 0.00016759 grad_norm 0.504497 rank 2
2025-01-10 19:30:15,627 DEBUG TRAIN Batch 92/1200 loss 0.073139 acc 0.948039 lr 0.00016759 grad_norm 0.504497 rank 1
2025-01-10 19:30:39,572 DEBUG TRAIN Batch 92/1300 loss 0.051697 acc 0.963429 lr 0.00016754 grad_norm 0.483931 rank 0
2025-01-10 19:30:39,573 DEBUG TRAIN Batch 92/1300 loss 0.069591 acc 0.956710 lr 0.00016754 grad_norm 0.483931 rank 2
2025-01-10 19:30:39,573 DEBUG TRAIN Batch 92/1300 loss 0.078025 acc 0.945802 lr 0.00016754 grad_norm 0.483931 rank 1
2025-01-10 19:31:03,739 DEBUG TRAIN Batch 92/1400 loss 0.047007 acc 0.969526 lr 0.00016750 grad_norm 0.456556 rank 2
2025-01-10 19:31:03,740 DEBUG TRAIN Batch 92/1400 loss 0.065561 acc 0.959637 lr 0.00016750 grad_norm 0.456556 rank 0
2025-01-10 19:31:03,740 DEBUG TRAIN Batch 92/1400 loss 0.051849 acc 0.965428 lr 0.00016750 grad_norm 0.456556 rank 1
2025-01-10 19:31:27,297 DEBUG TRAIN Batch 92/1500 loss 0.060394 acc 0.962185 lr 0.00016745 grad_norm 0.469920 rank 0
2025-01-10 19:31:27,297 DEBUG TRAIN Batch 92/1500 loss 0.066405 acc 0.960600 lr 0.00016745 grad_norm 0.469920 rank 2
2025-01-10 19:31:27,297 DEBUG TRAIN Batch 92/1500 loss 0.054253 acc 0.963208 lr 0.00016745 grad_norm 0.469920 rank 1
2025-01-10 19:31:51,273 DEBUG TRAIN Batch 92/1600 loss 0.038015 acc 0.980745 lr 0.00016740 grad_norm 0.460297 rank 0
2025-01-10 19:31:51,274 DEBUG TRAIN Batch 92/1600 loss 0.073562 acc 0.953140 lr 0.00016740 grad_norm 0.460297 rank 2
2025-01-10 19:31:51,274 DEBUG TRAIN Batch 92/1600 loss 0.045397 acc 0.966055 lr 0.00016740 grad_norm 0.460297 rank 1
2025-01-10 19:32:15,783 DEBUG TRAIN Batch 92/1700 loss 0.040303 acc 0.971569 lr 0.00016735 grad_norm 0.419373 rank 1
2025-01-10 19:32:15,783 DEBUG TRAIN Batch 92/1700 loss 0.054376 acc 0.964896 lr 0.00016735 grad_norm 0.419373 rank 0
2025-01-10 19:32:15,784 DEBUG TRAIN Batch 92/1700 loss 0.051457 acc 0.968504 lr 0.00016735 grad_norm 0.419373 rank 2
2025-01-10 19:32:39,968 DEBUG TRAIN Batch 92/1800 loss 0.053258 acc 0.965704 lr 0.00016731 grad_norm 0.447152 rank 1
2025-01-10 19:32:39,969 DEBUG TRAIN Batch 92/1800 loss 0.057500 acc 0.957447 lr 0.00016731 grad_norm 0.447152 rank 0
2025-01-10 19:32:39,969 DEBUG TRAIN Batch 92/1800 loss 0.036654 acc 0.977322 lr 0.00016731 grad_norm 0.447152 rank 2
2025-01-10 19:33:06,425 DEBUG TRAIN Batch 92/1900 loss 0.074442 acc 0.956034 lr 0.00016726 grad_norm 0.439337 rank 0
2025-01-10 19:33:06,425 DEBUG TRAIN Batch 92/1900 loss 0.044356 acc 0.969359 lr 0.00016726 grad_norm 0.439337 rank 2
2025-01-10 19:33:06,425 DEBUG TRAIN Batch 92/1900 loss 0.063784 acc 0.951644 lr 0.00016726 grad_norm 0.439337 rank 1
2025-01-10 19:33:30,539 DEBUG TRAIN Batch 92/2000 loss 0.079826 acc 0.937970 lr 0.00016721 grad_norm 0.474825 rank 2
2025-01-10 19:33:30,539 DEBUG TRAIN Batch 92/2000 loss 0.072777 acc 0.943571 lr 0.00016721 grad_norm 0.474825 rank 0
2025-01-10 19:33:30,539 DEBUG TRAIN Batch 92/2000 loss 0.067663 acc 0.951904 lr 0.00016721 grad_norm 0.474825 rank 1
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 19:34:48,398 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 19:34:48,400 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 19:34:48,803 INFO Epoch 92 Step 89447 on_batch_end True CV rank 0
2025-01-10 19:34:48,803 INFO Epoch 92 Step 89447 on_batch_end True CV rank 2
2025-01-10 19:34:48,804 INFO Epoch 92 Step 89447 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 19:34:58,065 DEBUG CV Batch 92/100 loss 0.014129 acc 0.994426  rank 0
2025-01-10 19:34:58,441 DEBUG CV Batch 92/100 loss 0.014129 acc 0.994426  rank 2
2025-01-10 19:34:58,603 INFO Epoch 92 Step 89447 CV info lr 0.0001671810754885865 0 rank loss_2.312405133542294 acc_0.7801249331811018
2025-01-10 19:34:58,680 DEBUG CV Batch 92/100 loss 0.014129 acc 0.994426  rank 1
2025-01-10 19:34:58,980 INFO Epoch 92 Step 89447 CV info lr 0.0001671810754885865 2 rank loss_2.312405133542294 acc_0.7801249331811018
2025-01-10 19:34:59,244 INFO Epoch 92 Step 89447 CV info lr 0.0001671810754885865 1 rank loss_2.312405133542294 acc_0.7801249331811018
2025-01-10 19:35:00,163 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_92_whole.pt
2025-01-10 19:35:00,185 INFO Added key: store_based_barrier_key:95 to store for rank: 0
2025-01-10 19:35:00,185 INFO Added key: store_based_barrier_key:95 to store for rank: 1
2025-01-10 19:35:00,186 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:95 with 3 nodes.
2025-01-10 19:35:00,186 INFO Added key: store_based_barrier_key:95 to store for rank: 2
2025-01-10 19:35:00,186 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:95 with 3 nodes.
2025-01-10 19:35:00,188 INFO Epoch 93 TRAIN info lr 0.0001671810754885865 rank 2
2025-01-10 19:35:00,189 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 19:35:00,194 INFO Epoch 93 TRAIN info lr 0.0001671810754885865 rank 1
2025-01-10 19:35:00,194 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 19:35:00,196 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:95 with 3 nodes.
2025-01-10 19:35:00,198 INFO Epoch 93 TRAIN info lr 0.0001671810754885865 rank 0
2025-01-10 19:35:00,198 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 19:35:32,735 DEBUG TRAIN Batch 93/100 loss 0.048707 acc 0.959364 lr 0.00016713 grad_norm 0.451712 rank 2
2025-01-10 19:35:32,736 DEBUG TRAIN Batch 93/100 loss 0.056549 acc 0.969432 lr 0.00016713 grad_norm 0.451712 rank 0
2025-01-10 19:35:32,736 DEBUG TRAIN Batch 93/100 loss 0.056306 acc 0.956564 lr 0.00016713 grad_norm 0.451712 rank 1
2025-01-10 19:35:56,451 DEBUG TRAIN Batch 93/200 loss 0.050730 acc 0.972350 lr 0.00016709 grad_norm 0.422070 rank 0
2025-01-10 19:35:56,451 DEBUG TRAIN Batch 93/200 loss 0.046435 acc 0.968691 lr 0.00016709 grad_norm 0.422070 rank 2
2025-01-10 19:35:56,451 DEBUG TRAIN Batch 93/200 loss 0.070554 acc 0.958073 lr 0.00016709 grad_norm 0.422070 rank 1
2025-01-10 19:36:20,657 DEBUG TRAIN Batch 93/300 loss 0.050793 acc 0.965328 lr 0.00016704 grad_norm 0.431229 rank 2
2025-01-10 19:36:20,657 DEBUG TRAIN Batch 93/300 loss 0.070280 acc 0.944798 lr 0.00016704 grad_norm 0.431229 rank 1
2025-01-10 19:36:20,657 DEBUG TRAIN Batch 93/300 loss 0.034533 acc 0.972447 lr 0.00016704 grad_norm 0.431229 rank 0
2025-01-10 19:36:45,012 DEBUG TRAIN Batch 93/400 loss 0.060028 acc 0.956933 lr 0.00016699 grad_norm 0.436554 rank 0
2025-01-10 19:36:45,012 DEBUG TRAIN Batch 93/400 loss 0.039607 acc 0.973877 lr 0.00016699 grad_norm 0.436554 rank 2
2025-01-10 19:36:45,013 DEBUG TRAIN Batch 93/400 loss 0.078362 acc 0.948962 lr 0.00016699 grad_norm 0.436554 rank 1
2025-01-10 19:37:09,525 DEBUG TRAIN Batch 93/500 loss 0.065126 acc 0.948898 lr 0.00016695 grad_norm 0.485580 rank 0
2025-01-10 19:37:09,525 DEBUG TRAIN Batch 93/500 loss 0.055053 acc 0.957311 lr 0.00016695 grad_norm 0.485580 rank 1
2025-01-10 19:37:09,525 DEBUG TRAIN Batch 93/500 loss 0.072058 acc 0.951526 lr 0.00016695 grad_norm 0.485580 rank 2
2025-01-10 19:37:34,190 DEBUG TRAIN Batch 93/600 loss 0.055075 acc 0.961825 lr 0.00016690 grad_norm 0.423497 rank 2
2025-01-10 19:37:34,191 DEBUG TRAIN Batch 93/600 loss 0.043320 acc 0.973404 lr 0.00016690 grad_norm 0.423497 rank 0
2025-01-10 19:37:34,191 DEBUG TRAIN Batch 93/600 loss 0.058046 acc 0.964974 lr 0.00016690 grad_norm 0.423497 rank 1
2025-01-10 19:37:58,570 DEBUG TRAIN Batch 93/700 loss 0.038741 acc 0.970109 lr 0.00016685 grad_norm 0.434930 rank 0
2025-01-10 19:37:58,570 DEBUG TRAIN Batch 93/700 loss 0.035726 acc 0.978578 lr 0.00016685 grad_norm 0.434930 rank 1
2025-01-10 19:37:58,570 DEBUG TRAIN Batch 93/700 loss 0.070621 acc 0.954242 lr 0.00016685 grad_norm 0.434930 rank 2
2025-01-10 19:38:22,740 DEBUG TRAIN Batch 93/800 loss 0.063736 acc 0.966912 lr 0.00016681 grad_norm 0.462095 rank 2
2025-01-10 19:38:22,740 DEBUG TRAIN Batch 93/800 loss 0.062787 acc 0.953069 lr 0.00016681 grad_norm 0.462095 rank 0
2025-01-10 19:38:22,740 DEBUG TRAIN Batch 93/800 loss 0.056166 acc 0.959162 lr 0.00016681 grad_norm 0.462095 rank 1
2025-01-10 19:38:47,078 DEBUG TRAIN Batch 93/900 loss 0.060486 acc 0.957490 lr 0.00016676 grad_norm 0.472549 rank 0
2025-01-10 19:38:47,079 DEBUG TRAIN Batch 93/900 loss 0.067223 acc 0.946444 lr 0.00016676 grad_norm 0.472549 rank 1
2025-01-10 19:38:47,079 DEBUG TRAIN Batch 93/900 loss 0.072243 acc 0.953831 lr 0.00016676 grad_norm 0.472549 rank 2
2025-01-10 19:39:11,947 DEBUG TRAIN Batch 93/1000 loss 0.070011 acc 0.954545 lr 0.00016672 grad_norm 0.430769 rank 1
2025-01-10 19:39:11,947 DEBUG TRAIN Batch 93/1000 loss 0.061712 acc 0.951009 lr 0.00016672 grad_norm 0.430769 rank 2
2025-01-10 19:39:11,948 DEBUG TRAIN Batch 93/1000 loss 0.042495 acc 0.972947 lr 0.00016672 grad_norm 0.430769 rank 0
2025-01-10 19:39:35,827 DEBUG TRAIN Batch 93/1100 loss 0.075902 acc 0.957195 lr 0.00016667 grad_norm 0.453775 rank 2
2025-01-10 19:39:35,827 DEBUG TRAIN Batch 93/1100 loss 0.057635 acc 0.964813 lr 0.00016667 grad_norm 0.453775 rank 1
2025-01-10 19:39:35,827 DEBUG TRAIN Batch 93/1100 loss 0.064066 acc 0.954383 lr 0.00016667 grad_norm 0.453775 rank 0
2025-01-10 19:39:59,630 DEBUG TRAIN Batch 93/1200 loss 0.056623 acc 0.961240 lr 0.00016662 grad_norm 0.437414 rank 1
2025-01-10 19:39:59,630 DEBUG TRAIN Batch 93/1200 loss 0.044077 acc 0.967442 lr 0.00016662 grad_norm 0.437414 rank 0
2025-01-10 19:39:59,630 DEBUG TRAIN Batch 93/1200 loss 0.079402 acc 0.947133 lr 0.00016662 grad_norm 0.437414 rank 2
2025-01-10 19:40:23,728 DEBUG TRAIN Batch 93/1300 loss 0.076337 acc 0.945026 lr 0.00016658 grad_norm 0.462343 rank 2
2025-01-10 19:40:23,728 DEBUG TRAIN Batch 93/1300 loss 0.071573 acc 0.953488 lr 0.00016658 grad_norm 0.462343 rank 1
2025-01-10 19:40:23,728 DEBUG TRAIN Batch 93/1300 loss 0.060294 acc 0.958984 lr 0.00016658 grad_norm 0.462343 rank 0
2025-01-10 19:40:48,012 DEBUG TRAIN Batch 93/1400 loss 0.070609 acc 0.956327 lr 0.00016653 grad_norm 0.503161 rank 0
2025-01-10 19:40:48,013 DEBUG TRAIN Batch 93/1400 loss 0.069892 acc 0.948819 lr 0.00016653 grad_norm 0.503161 rank 2
2025-01-10 19:40:48,013 DEBUG TRAIN Batch 93/1400 loss 0.092923 acc 0.930693 lr 0.00016653 grad_norm 0.503161 rank 1
2025-01-10 19:41:12,488 DEBUG TRAIN Batch 93/1500 loss 0.077068 acc 0.951992 lr 0.00016648 grad_norm 0.476571 rank 0
2025-01-10 19:41:12,488 DEBUG TRAIN Batch 93/1500 loss 0.064053 acc 0.956395 lr 0.00016648 grad_norm 0.476571 rank 1
2025-01-10 19:41:12,489 DEBUG TRAIN Batch 93/1500 loss 0.052303 acc 0.971132 lr 0.00016648 grad_norm 0.476571 rank 2
2025-01-10 19:41:36,680 DEBUG TRAIN Batch 93/1600 loss 0.062758 acc 0.962754 lr 0.00016644 grad_norm 0.495468 rank 0
2025-01-10 19:41:36,681 DEBUG TRAIN Batch 93/1600 loss 0.059781 acc 0.962512 lr 0.00016644 grad_norm 0.495468 rank 2
2025-01-10 19:41:36,681 DEBUG TRAIN Batch 93/1600 loss 0.091360 acc 0.941929 lr 0.00016644 grad_norm 0.495468 rank 1
2025-01-10 19:42:00,796 DEBUG TRAIN Batch 93/1700 loss 0.053234 acc 0.957360 lr 0.00016639 grad_norm 0.472805 rank 2
2025-01-10 19:42:00,796 DEBUG TRAIN Batch 93/1700 loss 0.060189 acc 0.960173 lr 0.00016639 grad_norm 0.472805 rank 0
2025-01-10 19:42:00,796 DEBUG TRAIN Batch 93/1700 loss 0.047763 acc 0.968153 lr 0.00016639 grad_norm 0.472805 rank 1
2025-01-10 19:42:26,195 DEBUG TRAIN Batch 93/1800 loss 0.037377 acc 0.971399 lr 0.00016635 grad_norm 0.452373 rank 0
2025-01-10 19:42:26,195 DEBUG TRAIN Batch 93/1800 loss 0.059432 acc 0.963449 lr 0.00016635 grad_norm 0.452373 rank 1
2025-01-10 19:42:26,195 DEBUG TRAIN Batch 93/1800 loss 0.024770 acc 0.978151 lr 0.00016635 grad_norm 0.452373 rank 2
2025-01-10 19:42:49,819 DEBUG TRAIN Batch 93/1900 loss 0.055306 acc 0.956716 lr 0.00016630 grad_norm 0.462211 rank 2
2025-01-10 19:42:49,820 DEBUG TRAIN Batch 93/1900 loss 0.037186 acc 0.977528 lr 0.00016630 grad_norm 0.462211 rank 0
2025-01-10 19:42:49,820 DEBUG TRAIN Batch 93/1900 loss 0.059518 acc 0.958663 lr 0.00016630 grad_norm 0.462211 rank 1
2025-01-10 19:43:14,342 DEBUG TRAIN Batch 93/2000 loss 0.063255 acc 0.952113 lr 0.00016625 grad_norm 0.470424 rank 1
2025-01-10 19:43:14,342 DEBUG TRAIN Batch 93/2000 loss 0.045155 acc 0.966395 lr 0.00016625 grad_norm 0.470424 rank 0
2025-01-10 19:43:14,343 DEBUG TRAIN Batch 93/2000 loss 0.078061 acc 0.946154 lr 0.00016625 grad_norm 0.470424 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 19:44:36,526 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 19:44:36,529 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 19:44:36,929 INFO Epoch 93 Step 90490 on_batch_end True CV rank 0
2025-01-10 19:44:36,929 INFO Epoch 93 Step 90490 on_batch_end True CV rank 2
2025-01-10 19:44:36,929 INFO Epoch 93 Step 90490 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 19:44:46,072 DEBUG CV Batch 93/100 loss 0.019244 acc 0.989967  rank 0
2025-01-10 19:44:46,258 DEBUG CV Batch 93/100 loss 0.019244 acc 0.989967  rank 2
2025-01-10 19:44:46,579 INFO Epoch 93 Step 90490 CV info lr 0.00016621480722084578 0 rank loss_2.326777377848007 acc_0.7801523697480821
2025-01-10 19:44:46,789 INFO Epoch 93 Step 90490 CV info lr 0.00016621480722084578 2 rank loss_2.326777377848007 acc_0.7801523697480821
2025-01-10 19:44:46,899 DEBUG CV Batch 93/100 loss 0.019244 acc 0.989967  rank 1
2025-01-10 19:44:47,455 INFO Epoch 93 Step 90490 CV info lr 0.00016621480722084578 1 rank loss_2.326777377848007 acc_0.7801523697480821
2025-01-10 19:44:47,884 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_93_whole.pt
2025-01-10 19:44:47,906 INFO Added key: store_based_barrier_key:96 to store for rank: 0
2025-01-10 19:44:47,916 INFO Added key: store_based_barrier_key:96 to store for rank: 2
2025-01-10 19:44:47,916 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:96 with 3 nodes.
2025-01-10 19:44:47,916 INFO Added key: store_based_barrier_key:96 to store for rank: 1
2025-01-10 19:44:47,916 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:96 with 3 nodes.
2025-01-10 19:44:47,921 INFO Epoch 94 TRAIN info lr 0.00016621480722084578 rank 1
2025-01-10 19:44:47,921 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 19:44:47,924 INFO Epoch 94 TRAIN info lr 0.00016621480722084578 rank 2
2025-01-10 19:44:47,924 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 19:44:47,926 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:96 with 3 nodes.
2025-01-10 19:44:47,934 INFO Epoch 94 TRAIN info lr 0.00016621480722084578 rank 0
2025-01-10 19:44:47,934 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 19:45:19,303 DEBUG TRAIN Batch 94/100 loss 0.060318 acc 0.955959 lr 0.00016617 grad_norm 0.432664 rank 2
2025-01-10 19:45:19,303 DEBUG TRAIN Batch 94/100 loss 0.045818 acc 0.971549 lr 0.00016617 grad_norm 0.432664 rank 0
2025-01-10 19:45:19,304 DEBUG TRAIN Batch 94/100 loss 0.065343 acc 0.956835 lr 0.00016617 grad_norm 0.432664 rank 1
2025-01-10 19:45:43,238 DEBUG TRAIN Batch 94/200 loss 0.042845 acc 0.969121 lr 0.00016612 grad_norm 0.452871 rank 2
2025-01-10 19:45:43,238 DEBUG TRAIN Batch 94/200 loss 0.061666 acc 0.954023 lr 0.00016612 grad_norm 0.452871 rank 1
2025-01-10 19:45:43,239 DEBUG TRAIN Batch 94/200 loss 0.037097 acc 0.974522 lr 0.00016612 grad_norm 0.452871 rank 0
2025-01-10 19:46:07,049 DEBUG TRAIN Batch 94/300 loss 0.054107 acc 0.959624 lr 0.00016608 grad_norm 0.430996 rank 1
2025-01-10 19:46:07,050 DEBUG TRAIN Batch 94/300 loss 0.067571 acc 0.953244 lr 0.00016608 grad_norm 0.430996 rank 0
2025-01-10 19:46:07,051 DEBUG TRAIN Batch 94/300 loss 0.040469 acc 0.974860 lr 0.00016608 grad_norm 0.430996 rank 2
2025-01-10 19:46:30,813 DEBUG TRAIN Batch 94/400 loss 0.056157 acc 0.966633 lr 0.00016603 grad_norm 0.481830 rank 1
2025-01-10 19:46:30,813 DEBUG TRAIN Batch 94/400 loss 0.068266 acc 0.951862 lr 0.00016603 grad_norm 0.481830 rank 2
2025-01-10 19:46:30,813 DEBUG TRAIN Batch 94/400 loss 0.053870 acc 0.967675 lr 0.00016603 grad_norm 0.481830 rank 0
2025-01-10 19:46:54,986 DEBUG TRAIN Batch 94/500 loss 0.044909 acc 0.974050 lr 0.00016599 grad_norm 0.418867 rank 1
2025-01-10 19:46:54,987 DEBUG TRAIN Batch 94/500 loss 0.063207 acc 0.953730 lr 0.00016599 grad_norm 0.418867 rank 0
2025-01-10 19:46:54,987 DEBUG TRAIN Batch 94/500 loss 0.045703 acc 0.963143 lr 0.00016599 grad_norm 0.418867 rank 2
2025-01-10 19:47:18,450 DEBUG TRAIN Batch 94/600 loss 0.059114 acc 0.963403 lr 0.00016594 grad_norm 0.428529 rank 2
2025-01-10 19:47:18,450 DEBUG TRAIN Batch 94/600 loss 0.060014 acc 0.961131 lr 0.00016594 grad_norm 0.428529 rank 1
2025-01-10 19:47:18,450 DEBUG TRAIN Batch 94/600 loss 0.058660 acc 0.958188 lr 0.00016594 grad_norm 0.428529 rank 0
2025-01-10 19:47:42,609 DEBUG TRAIN Batch 94/700 loss 0.050526 acc 0.966070 lr 0.00016589 grad_norm 0.453923 rank 1
2025-01-10 19:47:42,609 DEBUG TRAIN Batch 94/700 loss 0.045739 acc 0.972603 lr 0.00016589 grad_norm 0.453923 rank 0
2025-01-10 19:47:42,609 DEBUG TRAIN Batch 94/700 loss 0.061659 acc 0.953056 lr 0.00016589 grad_norm 0.453923 rank 2
2025-01-10 19:48:06,795 DEBUG TRAIN Batch 94/800 loss 0.054436 acc 0.965347 lr 0.00016585 grad_norm 0.458379 rank 0
2025-01-10 19:48:06,795 DEBUG TRAIN Batch 94/800 loss 0.070009 acc 0.948409 lr 0.00016585 grad_norm 0.458379 rank 1
2025-01-10 19:48:06,795 DEBUG TRAIN Batch 94/800 loss 0.062588 acc 0.961895 lr 0.00016585 grad_norm 0.458379 rank 2
2025-01-10 19:48:31,282 DEBUG TRAIN Batch 94/900 loss 0.039600 acc 0.973856 lr 0.00016580 grad_norm 0.442436 rank 2
2025-01-10 19:48:31,282 DEBUG TRAIN Batch 94/900 loss 0.061529 acc 0.960317 lr 0.00016580 grad_norm 0.442436 rank 1
2025-01-10 19:48:31,283 DEBUG TRAIN Batch 94/900 loss 0.060404 acc 0.957581 lr 0.00016580 grad_norm 0.442436 rank 0
2025-01-10 19:48:54,981 DEBUG TRAIN Batch 94/1000 loss 0.059248 acc 0.952077 lr 0.00016576 grad_norm 0.441329 rank 2
2025-01-10 19:48:54,981 DEBUG TRAIN Batch 94/1000 loss 0.043894 acc 0.971070 lr 0.00016576 grad_norm 0.441329 rank 0
2025-01-10 19:48:54,982 DEBUG TRAIN Batch 94/1000 loss 0.058358 acc 0.958979 lr 0.00016576 grad_norm 0.441329 rank 1
2025-01-10 19:49:20,211 DEBUG TRAIN Batch 94/1100 loss 0.047283 acc 0.965456 lr 0.00016571 grad_norm 0.419133 rank 1
2025-01-10 19:49:20,211 DEBUG TRAIN Batch 94/1100 loss 0.027623 acc 0.979487 lr 0.00016571 grad_norm 0.419133 rank 2
2025-01-10 19:49:20,211 DEBUG TRAIN Batch 94/1100 loss 0.047341 acc 0.965887 lr 0.00016571 grad_norm 0.419133 rank 0
2025-01-10 19:49:44,055 DEBUG TRAIN Batch 94/1200 loss 0.054568 acc 0.967939 lr 0.00016567 grad_norm 0.450777 rank 2
2025-01-10 19:49:44,056 DEBUG TRAIN Batch 94/1200 loss 0.054038 acc 0.967909 lr 0.00016567 grad_norm 0.450777 rank 0
2025-01-10 19:49:44,056 DEBUG TRAIN Batch 94/1200 loss 0.043717 acc 0.968254 lr 0.00016567 grad_norm 0.450777 rank 1
2025-01-10 19:50:08,821 DEBUG TRAIN Batch 94/1300 loss 0.049140 acc 0.967699 lr 0.00016562 grad_norm 0.447966 rank 2
2025-01-10 19:50:08,821 DEBUG TRAIN Batch 94/1300 loss 0.071172 acc 0.951287 lr 0.00016562 grad_norm 0.447966 rank 0
2025-01-10 19:50:08,821 DEBUG TRAIN Batch 94/1300 loss 0.044801 acc 0.969022 lr 0.00016562 grad_norm 0.447966 rank 1
2025-01-10 19:50:33,892 DEBUG TRAIN Batch 94/1400 loss 0.074655 acc 0.954964 lr 0.00016558 grad_norm 0.446858 rank 1
2025-01-10 19:50:33,892 DEBUG TRAIN Batch 94/1400 loss 0.049082 acc 0.963119 lr 0.00016558 grad_norm 0.446858 rank 0
2025-01-10 19:50:33,893 DEBUG TRAIN Batch 94/1400 loss 0.053708 acc 0.957929 lr 0.00016558 grad_norm 0.446858 rank 2
2025-01-10 19:50:58,774 DEBUG TRAIN Batch 94/1500 loss 0.055352 acc 0.962072 lr 0.00016553 grad_norm 0.436523 rank 1
2025-01-10 19:50:58,775 DEBUG TRAIN Batch 94/1500 loss 0.065398 acc 0.958574 lr 0.00016553 grad_norm 0.436523 rank 0
2025-01-10 19:50:58,775 DEBUG TRAIN Batch 94/1500 loss 0.065503 acc 0.958753 lr 0.00016553 grad_norm 0.436523 rank 2
2025-01-10 19:51:22,784 DEBUG TRAIN Batch 94/1600 loss 0.050468 acc 0.962487 lr 0.00016548 grad_norm 0.452377 rank 0
2025-01-10 19:51:22,784 DEBUG TRAIN Batch 94/1600 loss 0.050404 acc 0.968854 lr 0.00016548 grad_norm 0.452377 rank 1
2025-01-10 19:51:22,784 DEBUG TRAIN Batch 94/1600 loss 0.057055 acc 0.965447 lr 0.00016548 grad_norm 0.452377 rank 2
2025-01-10 19:51:47,728 DEBUG TRAIN Batch 94/1700 loss 0.033116 acc 0.971572 lr 0.00016544 grad_norm 0.491248 rank 2
2025-01-10 19:51:47,728 DEBUG TRAIN Batch 94/1700 loss 0.053542 acc 0.961661 lr 0.00016544 grad_norm 0.491248 rank 0
2025-01-10 19:51:47,729 DEBUG TRAIN Batch 94/1700 loss 0.071129 acc 0.950688 lr 0.00016544 grad_norm 0.491248 rank 1
2025-01-10 19:52:13,281 DEBUG TRAIN Batch 94/1800 loss 0.055513 acc 0.959660 lr 0.00016539 grad_norm 0.487105 rank 1
2025-01-10 19:52:13,281 DEBUG TRAIN Batch 94/1800 loss 0.045862 acc 0.973799 lr 0.00016539 grad_norm 0.487105 rank 2
2025-01-10 19:52:13,282 DEBUG TRAIN Batch 94/1800 loss 0.073537 acc 0.951020 lr 0.00016539 grad_norm 0.487105 rank 0
2025-01-10 19:52:38,120 DEBUG TRAIN Batch 94/1900 loss 0.030495 acc 0.979592 lr 0.00016535 grad_norm 0.508682 rank 0
2025-01-10 19:52:38,120 DEBUG TRAIN Batch 94/1900 loss 0.093061 acc 0.932285 lr 0.00016535 grad_norm 0.508682 rank 2
2025-01-10 19:52:38,120 DEBUG TRAIN Batch 94/1900 loss 0.052935 acc 0.961353 lr 0.00016535 grad_norm 0.508682 rank 1
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 19:53:51,955 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 19:53:51,960 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 19:53:52,341 INFO Epoch 94 Step 91466 on_batch_end True CV rank 2
2025-01-10 19:53:52,341 INFO Epoch 94 Step 91466 on_batch_end True CV rank 1
2025-01-10 19:53:52,341 INFO Epoch 94 Step 91466 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 19:54:01,561 DEBUG CV Batch 94/100 loss 0.017612 acc 0.994426  rank 0
2025-01-10 19:54:01,705 DEBUG CV Batch 94/100 loss 0.017612 acc 0.994426  rank 2
2025-01-10 19:54:02,109 INFO Epoch 94 Step 91466 CV info lr 0.0001653256203162412 0 rank loss_2.349023965111803 acc_0.7808171770813173
2025-01-10 19:54:02,238 INFO Epoch 94 Step 91466 CV info lr 0.0001653256203162412 2 rank loss_2.349023965111803 acc_0.7808171770813173
2025-01-10 19:54:02,323 DEBUG CV Batch 94/100 loss 0.017612 acc 0.994426  rank 1
2025-01-10 19:54:02,873 INFO Epoch 94 Step 91466 CV info lr 0.0001653256203162412 1 rank loss_2.349023965111803 acc_0.7808171770813173
2025-01-10 19:54:03,399 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_94_whole.pt
2025-01-10 19:54:03,410 INFO Added key: store_based_barrier_key:97 to store for rank: 0
2025-01-10 19:54:03,421 INFO Added key: store_based_barrier_key:97 to store for rank: 2
2025-01-10 19:54:03,421 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:97 with 3 nodes.
2025-01-10 19:54:03,421 INFO Added key: store_based_barrier_key:97 to store for rank: 1
2025-01-10 19:54:03,421 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:97 with 3 nodes.
2025-01-10 19:54:03,421 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:97 with 3 nodes.
2025-01-10 19:54:03,423 INFO Epoch 95 TRAIN info lr 0.0001653256203162412 rank 2
2025-01-10 19:54:03,423 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 19:54:03,424 INFO Epoch 95 TRAIN info lr 0.0001653256203162412 rank 0
2025-01-10 19:54:03,424 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 19:54:03,427 INFO Epoch 95 TRAIN info lr 0.0001653256203162412 rank 1
2025-01-10 19:54:03,427 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 19:54:37,262 DEBUG TRAIN Batch 95/100 loss 0.034946 acc 0.977848 lr 0.00016528 grad_norm 0.411161 rank 1
2025-01-10 19:54:37,262 DEBUG TRAIN Batch 95/100 loss 0.044657 acc 0.968932 lr 0.00016528 grad_norm 0.411161 rank 0
2025-01-10 19:54:37,262 DEBUG TRAIN Batch 95/100 loss 0.053701 acc 0.963415 lr 0.00016528 grad_norm 0.411161 rank 2
2025-01-10 19:55:01,619 DEBUG TRAIN Batch 95/200 loss 0.059355 acc 0.961470 lr 0.00016524 grad_norm 0.445208 rank 2
2025-01-10 19:55:01,620 DEBUG TRAIN Batch 95/200 loss 0.054379 acc 0.959578 lr 0.00016524 grad_norm 0.445208 rank 0
2025-01-10 19:55:01,620 DEBUG TRAIN Batch 95/200 loss 0.053107 acc 0.959866 lr 0.00016524 grad_norm 0.445208 rank 1
2025-01-10 19:55:25,844 DEBUG TRAIN Batch 95/300 loss 0.051505 acc 0.964509 lr 0.00016519 grad_norm 0.420505 rank 0
2025-01-10 19:55:25,844 DEBUG TRAIN Batch 95/300 loss 0.044512 acc 0.965398 lr 0.00016519 grad_norm 0.420505 rank 1
2025-01-10 19:55:25,844 DEBUG TRAIN Batch 95/300 loss 0.060269 acc 0.958374 lr 0.00016519 grad_norm 0.420505 rank 2
2025-01-10 19:55:50,203 DEBUG TRAIN Batch 95/400 loss 0.041667 acc 0.975528 lr 0.00016515 grad_norm 0.466213 rank 2
2025-01-10 19:55:50,203 DEBUG TRAIN Batch 95/400 loss 0.057852 acc 0.960512 lr 0.00016515 grad_norm 0.466213 rank 0
2025-01-10 19:55:50,203 DEBUG TRAIN Batch 95/400 loss 0.047022 acc 0.965484 lr 0.00016515 grad_norm 0.466213 rank 1
2025-01-10 19:56:13,932 DEBUG TRAIN Batch 95/500 loss 0.047518 acc 0.963320 lr 0.00016510 grad_norm 0.432827 rank 2
2025-01-10 19:56:13,932 DEBUG TRAIN Batch 95/500 loss 0.034850 acc 0.977516 lr 0.00016510 grad_norm 0.432827 rank 0
2025-01-10 19:56:13,932 DEBUG TRAIN Batch 95/500 loss 0.052821 acc 0.966492 lr 0.00016510 grad_norm 0.432827 rank 1
2025-01-10 19:56:38,790 DEBUG TRAIN Batch 95/600 loss 0.055911 acc 0.967864 lr 0.00016506 grad_norm 0.436236 rank 2
2025-01-10 19:56:38,790 DEBUG TRAIN Batch 95/600 loss 0.030184 acc 0.979487 lr 0.00016506 grad_norm 0.436236 rank 0
2025-01-10 19:56:38,790 DEBUG TRAIN Batch 95/600 loss 0.038969 acc 0.977621 lr 0.00016506 grad_norm 0.436236 rank 1
2025-01-10 19:57:02,845 DEBUG TRAIN Batch 95/700 loss 0.061721 acc 0.953386 lr 0.00016501 grad_norm 0.458475 rank 1
2025-01-10 19:57:02,846 DEBUG TRAIN Batch 95/700 loss 0.037835 acc 0.975647 lr 0.00016501 grad_norm 0.458475 rank 0
2025-01-10 19:57:02,846 DEBUG TRAIN Batch 95/700 loss 0.047716 acc 0.971214 lr 0.00016501 grad_norm 0.458475 rank 2
2025-01-10 19:57:27,905 DEBUG TRAIN Batch 95/800 loss 0.068766 acc 0.951598 lr 0.00016497 grad_norm 0.478361 rank 1
2025-01-10 19:57:27,905 DEBUG TRAIN Batch 95/800 loss 0.058974 acc 0.955526 lr 0.00016497 grad_norm 0.478361 rank 0
2025-01-10 19:57:27,906 DEBUG TRAIN Batch 95/800 loss 0.053739 acc 0.966698 lr 0.00016497 grad_norm 0.478361 rank 2
2025-01-10 19:57:52,952 DEBUG TRAIN Batch 95/900 loss 0.055001 acc 0.959843 lr 0.00016492 grad_norm 0.455807 rank 1
2025-01-10 19:57:52,952 DEBUG TRAIN Batch 95/900 loss 0.055052 acc 0.965480 lr 0.00016492 grad_norm 0.455807 rank 2
2025-01-10 19:57:52,952 DEBUG TRAIN Batch 95/900 loss 0.061182 acc 0.961934 lr 0.00016492 grad_norm 0.455807 rank 0
2025-01-10 19:58:17,390 DEBUG TRAIN Batch 95/1000 loss 0.054275 acc 0.958015 lr 0.00016488 grad_norm 0.453214 rank 2
2025-01-10 19:58:17,390 DEBUG TRAIN Batch 95/1000 loss 0.048783 acc 0.960699 lr 0.00016488 grad_norm 0.453214 rank 1
2025-01-10 19:58:17,390 DEBUG TRAIN Batch 95/1000 loss 0.067932 acc 0.947368 lr 0.00016488 grad_norm 0.453214 rank 0
2025-01-10 19:58:41,546 DEBUG TRAIN Batch 95/1100 loss 0.064575 acc 0.959627 lr 0.00016483 grad_norm 0.430751 rank 2
2025-01-10 19:58:41,546 DEBUG TRAIN Batch 95/1100 loss 0.051992 acc 0.965517 lr 0.00016483 grad_norm 0.430751 rank 0
2025-01-10 19:58:41,547 DEBUG TRAIN Batch 95/1100 loss 0.049766 acc 0.967742 lr 0.00016483 grad_norm 0.430751 rank 1
2025-01-10 19:59:06,526 DEBUG TRAIN Batch 95/1200 loss 0.033331 acc 0.980165 lr 0.00016479 grad_norm 0.464381 rank 0
2025-01-10 19:59:06,526 DEBUG TRAIN Batch 95/1200 loss 0.056433 acc 0.954895 lr 0.00016479 grad_norm 0.464381 rank 2
2025-01-10 19:59:06,526 DEBUG TRAIN Batch 95/1200 loss 0.062344 acc 0.953991 lr 0.00016479 grad_norm 0.464381 rank 1
2025-01-10 19:59:30,714 DEBUG TRAIN Batch 95/1300 loss 0.040442 acc 0.975469 lr 0.00016474 grad_norm 0.467887 rank 0
2025-01-10 19:59:30,715 DEBUG TRAIN Batch 95/1300 loss 0.065285 acc 0.948998 lr 0.00016474 grad_norm 0.467887 rank 2
2025-01-10 19:59:30,715 DEBUG TRAIN Batch 95/1300 loss 0.064538 acc 0.957130 lr 0.00016474 grad_norm 0.467887 rank 1
2025-01-10 19:59:55,242 DEBUG TRAIN Batch 95/1400 loss 0.039382 acc 0.977995 lr 0.00016470 grad_norm 0.427978 rank 0
2025-01-10 19:59:55,243 DEBUG TRAIN Batch 95/1400 loss 0.058971 acc 0.960894 lr 0.00016470 grad_norm 0.427978 rank 2
2025-01-10 19:59:55,243 DEBUG TRAIN Batch 95/1400 loss 0.057052 acc 0.962822 lr 0.00016470 grad_norm 0.427978 rank 1
2025-01-10 20:00:20,462 DEBUG TRAIN Batch 95/1500 loss 0.045728 acc 0.967112 lr 0.00016465 grad_norm 0.465663 rank 2
2025-01-10 20:00:20,463 DEBUG TRAIN Batch 95/1500 loss 0.066905 acc 0.957422 lr 0.00016465 grad_norm 0.465663 rank 1
2025-01-10 20:00:20,463 DEBUG TRAIN Batch 95/1500 loss 0.064574 acc 0.955172 lr 0.00016465 grad_norm 0.465663 rank 0
2025-01-10 20:00:44,914 DEBUG TRAIN Batch 95/1600 loss 0.051050 acc 0.969605 lr 0.00016461 grad_norm 0.499032 rank 2
2025-01-10 20:00:44,915 DEBUG TRAIN Batch 95/1600 loss 0.075654 acc 0.947464 lr 0.00016461 grad_norm 0.499032 rank 1
2025-01-10 20:00:44,915 DEBUG TRAIN Batch 95/1600 loss 0.062926 acc 0.952643 lr 0.00016461 grad_norm 0.499032 rank 0
2025-01-10 20:01:09,971 DEBUG TRAIN Batch 95/1700 loss 0.070188 acc 0.956172 lr 0.00016456 grad_norm 0.494530 rank 0
2025-01-10 20:01:09,971 DEBUG TRAIN Batch 95/1700 loss 0.066524 acc 0.945845 lr 0.00016456 grad_norm 0.494530 rank 1
2025-01-10 20:01:09,971 DEBUG TRAIN Batch 95/1700 loss 0.069608 acc 0.947982 lr 0.00016456 grad_norm 0.494530 rank 2
2025-01-10 20:01:33,824 DEBUG TRAIN Batch 95/1800 loss 0.065642 acc 0.958852 lr 0.00016452 grad_norm 0.479622 rank 1
2025-01-10 20:01:33,824 DEBUG TRAIN Batch 95/1800 loss 0.045282 acc 0.965247 lr 0.00016452 grad_norm 0.479622 rank 2
2025-01-10 20:01:33,825 DEBUG TRAIN Batch 95/1800 loss 0.074832 acc 0.951076 lr 0.00016452 grad_norm 0.479622 rank 0
2025-01-10 20:01:58,232 DEBUG TRAIN Batch 95/1900 loss 0.048433 acc 0.964891 lr 0.00016447 grad_norm 0.458563 rank 0
2025-01-10 20:01:58,232 DEBUG TRAIN Batch 95/1900 loss 0.041922 acc 0.974166 lr 0.00016447 grad_norm 0.458563 rank 1
2025-01-10 20:01:58,232 DEBUG TRAIN Batch 95/1900 loss 0.061850 acc 0.949640 lr 0.00016447 grad_norm 0.458563 rank 2
2025-01-10 20:02:23,166 DEBUG TRAIN Batch 95/2000 loss 0.054078 acc 0.964467 lr 0.00016443 grad_norm 0.476533 rank 2
2025-01-10 20:02:23,166 DEBUG TRAIN Batch 95/2000 loss 0.074277 acc 0.948905 lr 0.00016443 grad_norm 0.476533 rank 0
2025-01-10 20:02:23,167 DEBUG TRAIN Batch 95/2000 loss 0.042581 acc 0.972755 lr 0.00016443 grad_norm 0.476533 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 20:03:29,713 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59980ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 20:03:29,737 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 20:03:30,174 INFO Epoch 95 Step 92480 on_batch_end True CV rank 1
2025-01-10 20:03:30,174 INFO Epoch 95 Step 92480 on_batch_end True CV rank 0
2025-01-10 20:03:30,174 INFO Epoch 95 Step 92480 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 20:03:39,252 DEBUG CV Batch 95/100 loss 0.013637 acc 0.995541  rank 0
2025-01-10 20:03:39,536 DEBUG CV Batch 95/100 loss 0.013637 acc 0.995541  rank 2
2025-01-10 20:03:39,768 INFO Epoch 95 Step 92480 CV info lr 0.00016441676305145513 0 rank loss_2.3531103704069545 acc_0.7788819934715304
2025-01-10 20:03:40,095 INFO Epoch 95 Step 92480 CV info lr 0.00016441676305145513 2 rank loss_2.3531103704069545 acc_0.7788819934715304
2025-01-10 20:03:40,171 DEBUG CV Batch 95/100 loss 0.013637 acc 0.995541  rank 1
2025-01-10 20:03:40,738 INFO Epoch 95 Step 92480 CV info lr 0.00016441676305145513 1 rank loss_2.3531103704069545 acc_0.7788819934715304
2025-01-10 20:03:41,087 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_95_whole.pt
2025-01-10 20:03:41,109 INFO Added key: store_based_barrier_key:98 to store for rank: 0
2025-01-10 20:03:41,119 INFO Added key: store_based_barrier_key:98 to store for rank: 2
2025-01-10 20:03:41,119 INFO Added key: store_based_barrier_key:98 to store for rank: 1
2025-01-10 20:03:41,119 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:98 with 3 nodes.
2025-01-10 20:03:41,120 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:98 with 3 nodes.
2025-01-10 20:03:41,127 INFO Epoch 96 TRAIN info lr 0.00016441676305145513 rank 1
2025-01-10 20:03:41,127 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 20:03:41,129 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:98 with 3 nodes.
2025-01-10 20:03:41,129 INFO Epoch 96 TRAIN info lr 0.00016441676305145513 rank 2
2025-01-10 20:03:41,130 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 20:03:41,131 INFO Epoch 96 TRAIN info lr 0.00016441676305145513 rank 0
2025-01-10 20:03:41,131 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 20:04:17,852 DEBUG TRAIN Batch 96/100 loss 0.048396 acc 0.968051 lr 0.00016437 grad_norm 0.445318 rank 1
2025-01-10 20:04:17,852 DEBUG TRAIN Batch 96/100 loss 0.064613 acc 0.956650 lr 0.00016437 grad_norm 0.445318 rank 0
2025-01-10 20:04:17,853 DEBUG TRAIN Batch 96/100 loss 0.037644 acc 0.970551 lr 0.00016437 grad_norm 0.445318 rank 2
2025-01-10 20:04:42,323 DEBUG TRAIN Batch 96/200 loss 0.052745 acc 0.957031 lr 0.00016433 grad_norm 0.454893 rank 0
2025-01-10 20:04:42,323 DEBUG TRAIN Batch 96/200 loss 0.055611 acc 0.963585 lr 0.00016433 grad_norm 0.454893 rank 1
2025-01-10 20:04:42,323 DEBUG TRAIN Batch 96/200 loss 0.048942 acc 0.962818 lr 0.00016433 grad_norm 0.454893 rank 2
2025-01-10 20:05:07,485 DEBUG TRAIN Batch 96/300 loss 0.050149 acc 0.962996 lr 0.00016428 grad_norm 0.401215 rank 1
2025-01-10 20:05:07,485 DEBUG TRAIN Batch 96/300 loss 0.020266 acc 0.985294 lr 0.00016428 grad_norm 0.401215 rank 2
2025-01-10 20:05:07,489 DEBUG TRAIN Batch 96/300 loss 0.044000 acc 0.966258 lr 0.00016428 grad_norm 0.401215 rank 0
2025-01-10 20:05:32,069 DEBUG TRAIN Batch 96/400 loss 0.040140 acc 0.971795 lr 0.00016424 grad_norm 0.449922 rank 1
2025-01-10 20:05:32,069 DEBUG TRAIN Batch 96/400 loss 0.040327 acc 0.971551 lr 0.00016424 grad_norm 0.449922 rank 2
2025-01-10 20:05:32,070 DEBUG TRAIN Batch 96/400 loss 0.040643 acc 0.973804 lr 0.00016424 grad_norm 0.449922 rank 0
2025-01-10 20:05:56,670 DEBUG TRAIN Batch 96/500 loss 0.052972 acc 0.966265 lr 0.00016419 grad_norm 0.453748 rank 2
2025-01-10 20:05:56,670 DEBUG TRAIN Batch 96/500 loss 0.025679 acc 0.985646 lr 0.00016419 grad_norm 0.453748 rank 0
2025-01-10 20:05:56,671 DEBUG TRAIN Batch 96/500 loss 0.046798 acc 0.966245 lr 0.00016419 grad_norm 0.453748 rank 1
2025-01-10 20:06:22,480 DEBUG TRAIN Batch 96/600 loss 0.031969 acc 0.976242 lr 0.00016415 grad_norm 0.458886 rank 2
2025-01-10 20:06:22,480 DEBUG TRAIN Batch 96/600 loss 0.054539 acc 0.965057 lr 0.00016415 grad_norm 0.458886 rank 0
2025-01-10 20:06:22,480 DEBUG TRAIN Batch 96/600 loss 0.030727 acc 0.977124 lr 0.00016415 grad_norm 0.458886 rank 1
2025-01-10 20:06:47,707 DEBUG TRAIN Batch 96/700 loss 0.061904 acc 0.953712 lr 0.00016411 grad_norm 0.462758 rank 1
2025-01-10 20:06:47,707 DEBUG TRAIN Batch 96/700 loss 0.034765 acc 0.976496 lr 0.00016411 grad_norm 0.462758 rank 2
2025-01-10 20:06:47,707 DEBUG TRAIN Batch 96/700 loss 0.079630 acc 0.945681 lr 0.00016411 grad_norm 0.462758 rank 0
2025-01-10 20:07:13,262 DEBUG TRAIN Batch 96/800 loss 0.058198 acc 0.956635 lr 0.00016406 grad_norm 0.459152 rank 1
2025-01-10 20:07:13,262 DEBUG TRAIN Batch 96/800 loss 0.026707 acc 0.979661 lr 0.00016406 grad_norm 0.459152 rank 2
2025-01-10 20:07:13,263 DEBUG TRAIN Batch 96/800 loss 0.055893 acc 0.964355 lr 0.00016406 grad_norm 0.459152 rank 0
2025-01-10 20:07:37,253 DEBUG TRAIN Batch 96/900 loss 0.062420 acc 0.952133 lr 0.00016402 grad_norm 0.461004 rank 0
2025-01-10 20:07:37,253 DEBUG TRAIN Batch 96/900 loss 0.034628 acc 0.970748 lr 0.00016402 grad_norm 0.461004 rank 1
2025-01-10 20:07:37,253 DEBUG TRAIN Batch 96/900 loss 0.037720 acc 0.975831 lr 0.00016402 grad_norm 0.461004 rank 2
2025-01-10 20:08:02,781 DEBUG TRAIN Batch 96/1000 loss 0.041354 acc 0.974428 lr 0.00016397 grad_norm 0.442578 rank 2
2025-01-10 20:08:02,781 DEBUG TRAIN Batch 96/1000 loss 0.051675 acc 0.965241 lr 0.00016397 grad_norm 0.442578 rank 0
2025-01-10 20:08:02,781 DEBUG TRAIN Batch 96/1000 loss 0.034041 acc 0.975530 lr 0.00016397 grad_norm 0.442578 rank 1
2025-01-10 20:08:27,917 DEBUG TRAIN Batch 96/1100 loss 0.044892 acc 0.967078 lr 0.00016393 grad_norm 0.458312 rank 2
2025-01-10 20:08:27,917 DEBUG TRAIN Batch 96/1100 loss 0.057901 acc 0.959817 lr 0.00016393 grad_norm 0.458312 rank 0
2025-01-10 20:08:27,918 DEBUG TRAIN Batch 96/1100 loss 0.072321 acc 0.953289 lr 0.00016393 grad_norm 0.458312 rank 1
2025-01-10 20:08:51,741 DEBUG TRAIN Batch 96/1200 loss 0.052011 acc 0.969885 lr 0.00016389 grad_norm 0.451529 rank 0
2025-01-10 20:08:51,742 DEBUG TRAIN Batch 96/1200 loss 0.067016 acc 0.958101 lr 0.00016389 grad_norm 0.451529 rank 2
2025-01-10 20:08:51,742 DEBUG TRAIN Batch 96/1200 loss 0.075489 acc 0.955752 lr 0.00016389 grad_norm 0.451529 rank 1
2025-01-10 20:09:15,518 DEBUG TRAIN Batch 96/1300 loss 0.052574 acc 0.961825 lr 0.00016384 grad_norm 0.439329 rank 2
2025-01-10 20:09:15,518 DEBUG TRAIN Batch 96/1300 loss 0.046955 acc 0.959813 lr 0.00016384 grad_norm 0.439329 rank 0
2025-01-10 20:09:15,519 DEBUG TRAIN Batch 96/1300 loss 0.058664 acc 0.959548 lr 0.00016384 grad_norm 0.439329 rank 1
2025-01-10 20:09:39,154 DEBUG TRAIN Batch 96/1400 loss 0.058052 acc 0.962478 lr 0.00016380 grad_norm 0.449962 rank 2
2025-01-10 20:09:39,154 DEBUG TRAIN Batch 96/1400 loss 0.077601 acc 0.947166 lr 0.00016380 grad_norm 0.449962 rank 0
2025-01-10 20:09:39,155 DEBUG TRAIN Batch 96/1400 loss 0.062383 acc 0.952756 lr 0.00016380 grad_norm 0.449962 rank 1
2025-01-10 20:10:02,913 DEBUG TRAIN Batch 96/1500 loss 0.064628 acc 0.954751 lr 0.00016375 grad_norm 0.428281 rank 0
2025-01-10 20:10:02,914 DEBUG TRAIN Batch 96/1500 loss 0.058682 acc 0.956645 lr 0.00016375 grad_norm 0.428281 rank 2
2025-01-10 20:10:02,914 DEBUG TRAIN Batch 96/1500 loss 0.024883 acc 0.986885 lr 0.00016375 grad_norm 0.428281 rank 1
2025-01-10 20:10:26,998 DEBUG TRAIN Batch 96/1600 loss 0.075421 acc 0.942601 lr 0.00016371 grad_norm 0.490759 rank 2
2025-01-10 20:10:26,998 DEBUG TRAIN Batch 96/1600 loss 0.051201 acc 0.963690 lr 0.00016371 grad_norm 0.490759 rank 0
2025-01-10 20:10:26,999 DEBUG TRAIN Batch 96/1600 loss 0.059527 acc 0.960722 lr 0.00016371 grad_norm 0.490759 rank 1
2025-01-10 20:10:51,202 DEBUG TRAIN Batch 96/1700 loss 0.070154 acc 0.952562 lr 0.00016367 grad_norm 0.461052 rank 2
2025-01-10 20:10:51,202 DEBUG TRAIN Batch 96/1700 loss 0.045667 acc 0.962884 lr 0.00016367 grad_norm 0.461052 rank 0
2025-01-10 20:10:51,202 DEBUG TRAIN Batch 96/1700 loss 0.058396 acc 0.963229 lr 0.00016367 grad_norm 0.461052 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 20:12:14,655 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 20:12:14,661 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 20:12:15,108 INFO Epoch 96 Step 93379 on_batch_end True CV rank 0
2025-01-10 20:12:15,108 INFO Epoch 96 Step 93379 on_batch_end True CV rank 2
2025-01-10 20:12:15,108 INFO Epoch 96 Step 93379 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 20:12:24,333 DEBUG CV Batch 96/100 loss 0.010193 acc 0.998885  rank 0
2025-01-10 20:12:24,348 DEBUG CV Batch 96/100 loss 0.010193 acc 0.998885  rank 2
2025-01-10 20:12:24,877 INFO Epoch 96 Step 93379 CV info lr 0.00016362339327781038 0 rank loss_2.3677315047064904 acc_0.7794277698063014
2025-01-10 20:12:24,889 INFO Epoch 96 Step 93379 CV info lr 0.00016362339327781038 2 rank loss_2.3677315047064904 acc_0.7794277698063014
2025-01-10 20:12:24,889 DEBUG CV Batch 96/100 loss 0.010193 acc 0.998885  rank 1
2025-01-10 20:12:25,465 INFO Epoch 96 Step 93379 CV info lr 0.00016362339327781038 1 rank loss_2.3677315047064904 acc_0.7794277698063014
2025-01-10 20:12:26,187 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_96_whole.pt
2025-01-10 20:12:26,198 INFO Added key: store_based_barrier_key:99 to store for rank: 0
2025-01-10 20:12:26,208 INFO Added key: store_based_barrier_key:99 to store for rank: 1
2025-01-10 20:12:26,209 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:99 with 3 nodes.
2025-01-10 20:12:26,209 INFO Added key: store_based_barrier_key:99 to store for rank: 2
2025-01-10 20:12:26,209 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:99 with 3 nodes.
2025-01-10 20:12:26,209 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:99 with 3 nodes.
2025-01-10 20:12:26,212 INFO Epoch 97 TRAIN info lr 0.00016362339327781038 rank 1
2025-01-10 20:12:26,212 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 20:12:26,216 INFO Epoch 97 TRAIN info lr 0.00016362339327781038 rank 2
2025-01-10 20:12:26,216 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 20:12:26,217 INFO Epoch 97 TRAIN info lr 0.00016362339327781038 rank 0
2025-01-10 20:12:26,217 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 20:12:57,197 DEBUG TRAIN Batch 97/100 loss 0.051708 acc 0.960396 lr 0.00016358 grad_norm 0.414082 rank 2
2025-01-10 20:12:57,197 DEBUG TRAIN Batch 97/100 loss 0.036516 acc 0.974411 lr 0.00016358 grad_norm 0.414082 rank 0
2025-01-10 20:12:57,197 DEBUG TRAIN Batch 97/100 loss 0.055081 acc 0.953192 lr 0.00016358 grad_norm 0.414082 rank 1
2025-01-10 20:13:21,373 DEBUG TRAIN Batch 97/200 loss 0.033200 acc 0.979738 lr 0.00016354 grad_norm 0.432624 rank 2
2025-01-10 20:13:21,373 DEBUG TRAIN Batch 97/200 loss 0.070581 acc 0.953704 lr 0.00016354 grad_norm 0.432624 rank 1
2025-01-10 20:13:21,374 DEBUG TRAIN Batch 97/200 loss 0.041527 acc 0.974457 lr 0.00016354 grad_norm 0.432624 rank 0
2025-01-10 20:13:44,967 DEBUG TRAIN Batch 97/300 loss 0.032987 acc 0.974063 lr 0.00016349 grad_norm 0.425772 rank 1
2025-01-10 20:13:44,967 DEBUG TRAIN Batch 97/300 loss 0.047100 acc 0.967774 lr 0.00016349 grad_norm 0.425772 rank 0
2025-01-10 20:13:44,967 DEBUG TRAIN Batch 97/300 loss 0.053561 acc 0.958569 lr 0.00016349 grad_norm 0.425772 rank 2
2025-01-10 20:14:09,001 DEBUG TRAIN Batch 97/400 loss 0.027806 acc 0.985000 lr 0.00016345 grad_norm 0.429495 rank 2
2025-01-10 20:14:09,001 DEBUG TRAIN Batch 97/400 loss 0.037678 acc 0.974484 lr 0.00016345 grad_norm 0.429495 rank 1
2025-01-10 20:14:09,001 DEBUG TRAIN Batch 97/400 loss 0.054671 acc 0.967265 lr 0.00016345 grad_norm 0.429495 rank 0
2025-01-10 20:14:33,035 DEBUG TRAIN Batch 97/500 loss 0.066862 acc 0.957789 lr 0.00016340 grad_norm 0.443110 rank 0
2025-01-10 20:14:33,036 DEBUG TRAIN Batch 97/500 loss 0.043707 acc 0.977436 lr 0.00016340 grad_norm 0.443110 rank 2
2025-01-10 20:14:33,036 DEBUG TRAIN Batch 97/500 loss 0.050957 acc 0.967247 lr 0.00016340 grad_norm 0.443110 rank 1
2025-01-10 20:14:56,829 DEBUG TRAIN Batch 97/600 loss 0.081656 acc 0.947761 lr 0.00016336 grad_norm 0.469021 rank 0
2025-01-10 20:14:56,829 DEBUG TRAIN Batch 97/600 loss 0.067429 acc 0.952679 lr 0.00016336 grad_norm 0.469021 rank 2
2025-01-10 20:14:56,830 DEBUG TRAIN Batch 97/600 loss 0.060027 acc 0.963511 lr 0.00016336 grad_norm 0.469021 rank 1
2025-01-10 20:15:20,737 DEBUG TRAIN Batch 97/700 loss 0.061340 acc 0.956612 lr 0.00016332 grad_norm 0.421057 rank 0
2025-01-10 20:15:20,738 DEBUG TRAIN Batch 97/700 loss 0.054037 acc 0.963523 lr 0.00016332 grad_norm 0.421057 rank 2
2025-01-10 20:15:20,738 DEBUG TRAIN Batch 97/700 loss 0.055695 acc 0.961062 lr 0.00016332 grad_norm 0.421057 rank 1
2025-01-10 20:15:44,662 DEBUG TRAIN Batch 97/800 loss 0.055212 acc 0.970719 lr 0.00016327 grad_norm 0.445774 rank 2
2025-01-10 20:15:44,662 DEBUG TRAIN Batch 97/800 loss 0.064110 acc 0.955959 lr 0.00016327 grad_norm 0.445774 rank 0
2025-01-10 20:15:44,663 DEBUG TRAIN Batch 97/800 loss 0.062285 acc 0.961326 lr 0.00016327 grad_norm 0.445774 rank 1
2025-01-10 20:16:08,998 DEBUG TRAIN Batch 97/900 loss 0.075700 acc 0.949653 lr 0.00016323 grad_norm 0.462637 rank 0
2025-01-10 20:16:08,999 DEBUG TRAIN Batch 97/900 loss 0.049454 acc 0.967402 lr 0.00016323 grad_norm 0.462637 rank 1
2025-01-10 20:16:08,999 DEBUG TRAIN Batch 97/900 loss 0.052044 acc 0.963366 lr 0.00016323 grad_norm 0.462637 rank 2
2025-01-10 20:16:33,018 DEBUG TRAIN Batch 97/1000 loss 0.053002 acc 0.964471 lr 0.00016319 grad_norm 0.425698 rank 2
2025-01-10 20:16:33,018 DEBUG TRAIN Batch 97/1000 loss 0.043222 acc 0.974950 lr 0.00016319 grad_norm 0.425698 rank 0
2025-01-10 20:16:33,018 DEBUG TRAIN Batch 97/1000 loss 0.046360 acc 0.971119 lr 0.00016319 grad_norm 0.425698 rank 1
2025-01-10 20:16:57,085 DEBUG TRAIN Batch 97/1100 loss 0.050800 acc 0.964395 lr 0.00016314 grad_norm 0.453434 rank 2
2025-01-10 20:16:57,086 DEBUG TRAIN Batch 97/1100 loss 0.067783 acc 0.953247 lr 0.00016314 grad_norm 0.453434 rank 1
2025-01-10 20:16:57,086 DEBUG TRAIN Batch 97/1100 loss 0.052664 acc 0.961812 lr 0.00016314 grad_norm 0.453434 rank 0
2025-01-10 20:17:21,328 DEBUG TRAIN Batch 97/1200 loss 0.046620 acc 0.966845 lr 0.00016310 grad_norm 0.458469 rank 0
2025-01-10 20:17:21,328 DEBUG TRAIN Batch 97/1200 loss 0.030539 acc 0.978477 lr 0.00016310 grad_norm 0.458469 rank 2
2025-01-10 20:17:21,328 DEBUG TRAIN Batch 97/1200 loss 0.063314 acc 0.960387 lr 0.00016310 grad_norm 0.458469 rank 1
2025-01-10 20:17:45,408 DEBUG TRAIN Batch 97/1300 loss 0.077731 acc 0.949087 lr 0.00016306 grad_norm 0.457584 rank 0
2025-01-10 20:17:45,408 DEBUG TRAIN Batch 97/1300 loss 0.031959 acc 0.976879 lr 0.00016306 grad_norm 0.457584 rank 2
2025-01-10 20:17:45,409 DEBUG TRAIN Batch 97/1300 loss 0.052440 acc 0.968379 lr 0.00016306 grad_norm 0.457584 rank 1
2025-01-10 20:18:09,442 DEBUG TRAIN Batch 97/1400 loss 0.055697 acc 0.959271 lr 0.00016301 grad_norm 0.424471 rank 0
2025-01-10 20:18:09,443 DEBUG TRAIN Batch 97/1400 loss 0.029457 acc 0.986301 lr 0.00016301 grad_norm 0.424471 rank 2
2025-01-10 20:18:09,443 DEBUG TRAIN Batch 97/1400 loss 0.053543 acc 0.961081 lr 0.00016301 grad_norm 0.424471 rank 1
2025-01-10 20:18:34,476 DEBUG TRAIN Batch 97/1500 loss 0.056049 acc 0.957328 lr 0.00016297 grad_norm 0.451868 rank 0
2025-01-10 20:18:34,476 DEBUG TRAIN Batch 97/1500 loss 0.068228 acc 0.958791 lr 0.00016297 grad_norm 0.451868 rank 2
2025-01-10 20:18:34,477 DEBUG TRAIN Batch 97/1500 loss 0.055299 acc 0.963636 lr 0.00016297 grad_norm 0.451868 rank 1
2025-01-10 20:18:58,584 DEBUG TRAIN Batch 97/1600 loss 0.062506 acc 0.951896 lr 0.00016293 grad_norm 0.426293 rank 0
2025-01-10 20:18:58,584 DEBUG TRAIN Batch 97/1600 loss 0.047779 acc 0.966942 lr 0.00016293 grad_norm 0.426293 rank 1
2025-01-10 20:18:58,585 DEBUG TRAIN Batch 97/1600 loss 0.038308 acc 0.975664 lr 0.00016293 grad_norm 0.426293 rank 2
2025-01-10 20:19:24,260 DEBUG TRAIN Batch 97/1700 loss 0.030264 acc 0.978261 lr 0.00016288 grad_norm 0.466430 rank 1
2025-01-10 20:19:24,260 DEBUG TRAIN Batch 97/1700 loss 0.051685 acc 0.965340 lr 0.00016288 grad_norm 0.466430 rank 0
2025-01-10 20:19:24,261 DEBUG TRAIN Batch 97/1700 loss 0.058745 acc 0.958844 lr 0.00016288 grad_norm 0.466430 rank 2
2025-01-10 20:19:49,421 DEBUG TRAIN Batch 97/1800 loss 0.050728 acc 0.964853 lr 0.00016284 grad_norm 0.447598 rank 0
2025-01-10 20:19:49,421 DEBUG TRAIN Batch 97/1800 loss 0.028922 acc 0.981623 lr 0.00016284 grad_norm 0.447598 rank 2
2025-01-10 20:19:49,421 DEBUG TRAIN Batch 97/1800 loss 0.086027 acc 0.939836 lr 0.00016284 grad_norm 0.447598 rank 1
2025-01-10 20:20:13,815 DEBUG TRAIN Batch 97/1900 loss 0.057864 acc 0.963111 lr 0.00016280 grad_norm 0.443637 rank 0
2025-01-10 20:20:13,816 DEBUG TRAIN Batch 97/1900 loss 0.060967 acc 0.955769 lr 0.00016280 grad_norm 0.443637 rank 1
2025-01-10 20:20:13,816 DEBUG TRAIN Batch 97/1900 loss 0.042609 acc 0.967655 lr 0.00016280 grad_norm 0.443637 rank 2
2025-01-10 20:20:39,252 DEBUG TRAIN Batch 97/2000 loss 0.052872 acc 0.959445 lr 0.00016275 grad_norm 0.473609 rank 2
2025-01-10 20:20:39,252 DEBUG TRAIN Batch 97/2000 loss 0.061953 acc 0.957093 lr 0.00016275 grad_norm 0.473609 rank 0
2025-01-10 20:20:39,252 DEBUG TRAIN Batch 97/2000 loss 0.031647 acc 0.975329 lr 0.00016275 grad_norm 0.473609 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 20:21:54,599 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 20:21:54,607 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 20:21:54,977 INFO Epoch 97 Step 94409 on_batch_end True CV rank 2
2025-01-10 20:21:54,977 INFO Epoch 97 Step 94409 on_batch_end True CV rank 1
2025-01-10 20:21:54,977 INFO Epoch 97 Step 94409 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 20:22:04,211 DEBUG CV Batch 97/100 loss 0.011787 acc 0.996656  rank 0
2025-01-10 20:22:04,215 DEBUG CV Batch 97/100 loss 0.011787 acc 0.996656  rank 2
2025-01-10 20:22:04,630 DEBUG CV Batch 97/100 loss 0.011787 acc 0.996656  rank 1
2025-01-10 20:22:04,729 INFO Epoch 97 Step 94409 CV info lr 0.00016272838173169753 2 rank loss_2.35389779429942 acc_0.7788293126382326
2025-01-10 20:22:04,742 INFO Epoch 97 Step 94409 CV info lr 0.00016272838173169753 0 rank loss_2.35389779429942 acc_0.7788293126382326
2025-01-10 20:22:05,191 INFO Epoch 97 Step 94409 CV info lr 0.00016272838173169753 1 rank loss_2.35389779429942 acc_0.7788293126382326
2025-01-10 20:22:06,021 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_97_whole.pt
2025-01-10 20:22:06,043 INFO Added key: store_based_barrier_key:100 to store for rank: 0
2025-01-10 20:22:06,053 INFO Added key: store_based_barrier_key:100 to store for rank: 2
2025-01-10 20:22:06,053 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:100 with 3 nodes.
2025-01-10 20:22:06,053 INFO Added key: store_based_barrier_key:100 to store for rank: 1
2025-01-10 20:22:06,053 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:100 with 3 nodes.
2025-01-10 20:22:06,055 INFO Epoch 98 TRAIN info lr 0.00016272838173169753 rank 2
2025-01-10 20:22:06,055 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 20:22:06,059 INFO Epoch 98 TRAIN info lr 0.00016272838173169753 rank 1
2025-01-10 20:22:06,059 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 20:22:06,063 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:100 with 3 nodes.
2025-01-10 20:22:06,070 INFO Epoch 98 TRAIN info lr 0.00016272838173169753 rank 0
2025-01-10 20:22:06,070 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 20:22:37,877 DEBUG TRAIN Batch 98/100 loss 0.045488 acc 0.965636 lr 0.00016269 grad_norm 0.407531 rank 1
2025-01-10 20:22:37,878 DEBUG TRAIN Batch 98/100 loss 0.068159 acc 0.962511 lr 0.00016269 grad_norm 0.407531 rank 0
2025-01-10 20:22:37,878 DEBUG TRAIN Batch 98/100 loss 0.051632 acc 0.965589 lr 0.00016269 grad_norm 0.407531 rank 2
2025-01-10 20:23:01,707 DEBUG TRAIN Batch 98/200 loss 0.050660 acc 0.965693 lr 0.00016264 grad_norm 0.463517 rank 1
2025-01-10 20:23:01,707 DEBUG TRAIN Batch 98/200 loss 0.053914 acc 0.958384 lr 0.00016264 grad_norm 0.463517 rank 0
2025-01-10 20:23:01,707 DEBUG TRAIN Batch 98/200 loss 0.055304 acc 0.961646 lr 0.00016264 grad_norm 0.463517 rank 2
2025-01-10 20:23:26,030 DEBUG TRAIN Batch 98/300 loss 0.051162 acc 0.966241 lr 0.00016260 grad_norm 0.444550 rank 0
2025-01-10 20:23:26,030 DEBUG TRAIN Batch 98/300 loss 0.056749 acc 0.958647 lr 0.00016260 grad_norm 0.444550 rank 1
2025-01-10 20:23:26,030 DEBUG TRAIN Batch 98/300 loss 0.064778 acc 0.951155 lr 0.00016260 grad_norm 0.444550 rank 2
2025-01-10 20:23:49,692 DEBUG TRAIN Batch 98/400 loss 0.043587 acc 0.968944 lr 0.00016256 grad_norm 0.428879 rank 0
2025-01-10 20:23:49,692 DEBUG TRAIN Batch 98/400 loss 0.046250 acc 0.959566 lr 0.00016256 grad_norm 0.428879 rank 1
2025-01-10 20:23:49,692 DEBUG TRAIN Batch 98/400 loss 0.049408 acc 0.967526 lr 0.00016256 grad_norm 0.428879 rank 2
2025-01-10 20:24:14,118 DEBUG TRAIN Batch 98/500 loss 0.076926 acc 0.943674 lr 0.00016251 grad_norm 0.454584 rank 1
2025-01-10 20:24:14,118 DEBUG TRAIN Batch 98/500 loss 0.052081 acc 0.962332 lr 0.00016251 grad_norm 0.454584 rank 0
2025-01-10 20:24:14,119 DEBUG TRAIN Batch 98/500 loss 0.052023 acc 0.965388 lr 0.00016251 grad_norm 0.454584 rank 2
2025-01-10 20:24:38,868 DEBUG TRAIN Batch 98/600 loss 0.056706 acc 0.959816 lr 0.00016247 grad_norm 0.444283 rank 2
2025-01-10 20:24:38,869 DEBUG TRAIN Batch 98/600 loss 0.072157 acc 0.953171 lr 0.00016247 grad_norm 0.444283 rank 0
2025-01-10 20:24:38,869 DEBUG TRAIN Batch 98/600 loss 0.045820 acc 0.971647 lr 0.00016247 grad_norm 0.444283 rank 1
2025-01-10 20:25:02,997 DEBUG TRAIN Batch 98/700 loss 0.050657 acc 0.969780 lr 0.00016243 grad_norm 0.440909 rank 1
2025-01-10 20:25:02,997 DEBUG TRAIN Batch 98/700 loss 0.061835 acc 0.960159 lr 0.00016243 grad_norm 0.440909 rank 0
2025-01-10 20:25:02,998 DEBUG TRAIN Batch 98/700 loss 0.044218 acc 0.970135 lr 0.00016243 grad_norm 0.440909 rank 2
2025-01-10 20:25:26,821 DEBUG TRAIN Batch 98/800 loss 0.049415 acc 0.967864 lr 0.00016238 grad_norm 0.419263 rank 1
2025-01-10 20:25:26,821 DEBUG TRAIN Batch 98/800 loss 0.050137 acc 0.970213 lr 0.00016238 grad_norm 0.419263 rank 2
2025-01-10 20:25:26,821 DEBUG TRAIN Batch 98/800 loss 0.064510 acc 0.951242 lr 0.00016238 grad_norm 0.419263 rank 0
2025-01-10 20:25:50,949 DEBUG TRAIN Batch 98/900 loss 0.058429 acc 0.961403 lr 0.00016234 grad_norm 0.456256 rank 2
2025-01-10 20:25:50,949 DEBUG TRAIN Batch 98/900 loss 0.047240 acc 0.965882 lr 0.00016234 grad_norm 0.456256 rank 0
2025-01-10 20:25:50,949 DEBUG TRAIN Batch 98/900 loss 0.055847 acc 0.961661 lr 0.00016234 grad_norm 0.456256 rank 1
2025-01-10 20:26:15,033 DEBUG TRAIN Batch 98/1000 loss 0.053201 acc 0.959700 lr 0.00016230 grad_norm 0.455201 rank 2
2025-01-10 20:26:15,033 DEBUG TRAIN Batch 98/1000 loss 0.037097 acc 0.975379 lr 0.00016230 grad_norm 0.455201 rank 0
2025-01-10 20:26:15,034 DEBUG TRAIN Batch 98/1000 loss 0.061671 acc 0.951351 lr 0.00016230 grad_norm 0.455201 rank 1
2025-01-10 20:26:39,679 DEBUG TRAIN Batch 98/1100 loss 0.049954 acc 0.960251 lr 0.00016226 grad_norm 0.447633 rank 2
2025-01-10 20:26:39,679 DEBUG TRAIN Batch 98/1100 loss 0.037215 acc 0.978177 lr 0.00016226 grad_norm 0.447633 rank 1
2025-01-10 20:26:39,679 DEBUG TRAIN Batch 98/1100 loss 0.067480 acc 0.961240 lr 0.00016226 grad_norm 0.447633 rank 0
2025-01-10 20:27:03,559 DEBUG TRAIN Batch 98/1200 loss 0.061807 acc 0.957350 lr 0.00016221 grad_norm 0.445970 rank 2
2025-01-10 20:27:03,559 DEBUG TRAIN Batch 98/1200 loss 0.054464 acc 0.965147 lr 0.00016221 grad_norm 0.445970 rank 0
2025-01-10 20:27:03,560 DEBUG TRAIN Batch 98/1200 loss 0.058171 acc 0.956279 lr 0.00016221 grad_norm 0.445970 rank 1
2025-01-10 20:27:27,388 DEBUG TRAIN Batch 98/1300 loss 0.059361 acc 0.958008 lr 0.00016217 grad_norm 0.439179 rank 1
2025-01-10 20:27:27,389 DEBUG TRAIN Batch 98/1300 loss 0.054587 acc 0.965286 lr 0.00016217 grad_norm 0.439179 rank 2
2025-01-10 20:27:27,388 DEBUG TRAIN Batch 98/1300 loss 0.051181 acc 0.969014 lr 0.00016217 grad_norm 0.439179 rank 0
2025-01-10 20:27:51,328 DEBUG TRAIN Batch 98/1400 loss 0.047135 acc 0.965184 lr 0.00016213 grad_norm 0.421563 rank 0
2025-01-10 20:27:51,328 DEBUG TRAIN Batch 98/1400 loss 0.048319 acc 0.971216 lr 0.00016213 grad_norm 0.421563 rank 1
2025-01-10 20:27:51,329 DEBUG TRAIN Batch 98/1400 loss 0.049466 acc 0.961538 lr 0.00016213 grad_norm 0.421563 rank 2
2025-01-10 20:28:15,820 DEBUG TRAIN Batch 98/1500 loss 0.060009 acc 0.955301 lr 0.00016209 grad_norm 0.467386 rank 1
2025-01-10 20:28:15,820 DEBUG TRAIN Batch 98/1500 loss 0.061130 acc 0.955135 lr 0.00016209 grad_norm 0.467386 rank 0
2025-01-10 20:28:15,821 DEBUG TRAIN Batch 98/1500 loss 0.046996 acc 0.966387 lr 0.00016209 grad_norm 0.467386 rank 2
2025-01-10 20:28:39,913 DEBUG TRAIN Batch 98/1600 loss 0.072328 acc 0.954128 lr 0.00016204 grad_norm 0.469250 rank 1
2025-01-10 20:28:39,913 DEBUG TRAIN Batch 98/1600 loss 0.068129 acc 0.949647 lr 0.00016204 grad_norm 0.469250 rank 2
2025-01-10 20:28:39,913 DEBUG TRAIN Batch 98/1600 loss 0.065741 acc 0.956315 lr 0.00016204 grad_norm 0.469250 rank 0
2025-01-10 20:29:03,488 DEBUG TRAIN Batch 98/1700 loss 0.065231 acc 0.954505 lr 0.00016200 grad_norm 0.457052 rank 1
2025-01-10 20:29:03,488 DEBUG TRAIN Batch 98/1700 loss 0.047355 acc 0.971549 lr 0.00016200 grad_norm 0.457052 rank 2
2025-01-10 20:29:03,488 DEBUG TRAIN Batch 98/1700 loss 0.056188 acc 0.957407 lr 0.00016200 grad_norm 0.457052 rank 0
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 20:30:15,395 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 20:30:15,397 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 20:30:15,905 INFO Epoch 98 Step 95284 on_batch_end True CV rank 1
2025-01-10 20:30:15,905 INFO Epoch 98 Step 95284 on_batch_end True CV rank 2
2025-01-10 20:30:15,905 INFO Epoch 98 Step 95284 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 20:30:25,014 DEBUG CV Batch 98/100 loss 0.009743 acc 0.996656  rank 0
2025-01-10 20:30:25,405 DEBUG CV Batch 98/100 loss 0.009743 acc 0.996656  rank 2
2025-01-10 20:30:25,556 INFO Epoch 98 Step 95284 CV info lr 0.00016197948510711762 0 rank loss_2.3665677323358403 acc_0.78062832067933
2025-01-10 20:30:25,564 DEBUG CV Batch 98/100 loss 0.009743 acc 0.996656  rank 1
2025-01-10 20:30:25,944 INFO Epoch 98 Step 95284 CV info lr 0.00016197948510711762 2 rank loss_2.3665677323358403 acc_0.78062832067933
2025-01-10 20:30:26,121 INFO Epoch 98 Step 95284 CV info lr 0.00016197948510711762 1 rank loss_2.3665677323358403 acc_0.78062832067933
2025-01-10 20:30:26,877 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_98_whole.pt
2025-01-10 20:30:26,889 INFO Added key: store_based_barrier_key:101 to store for rank: 0
2025-01-10 20:30:26,899 INFO Added key: store_based_barrier_key:101 to store for rank: 2
2025-01-10 20:30:26,899 INFO Added key: store_based_barrier_key:101 to store for rank: 1
2025-01-10 20:30:26,900 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:101 with 3 nodes.
2025-01-10 20:30:26,900 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:101 with 3 nodes.
2025-01-10 20:30:26,901 INFO Epoch 99 TRAIN info lr 0.00016197948510711762 rank 1
2025-01-10 20:30:26,901 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 20:30:26,902 INFO Epoch 99 TRAIN info lr 0.00016197948510711762 rank 2
2025-01-10 20:30:26,902 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 20:30:26,910 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:101 with 3 nodes.
2025-01-10 20:30:26,916 INFO Epoch 99 TRAIN info lr 0.00016197948510711762 rank 0
2025-01-10 20:30:26,916 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 20:30:57,548 DEBUG TRAIN Batch 99/100 loss 0.045134 acc 0.978903 lr 0.00016194 grad_norm 0.421448 rank 1
2025-01-10 20:30:57,548 DEBUG TRAIN Batch 99/100 loss 0.052048 acc 0.962825 lr 0.00016194 grad_norm 0.421448 rank 2
2025-01-10 20:30:57,548 DEBUG TRAIN Batch 99/100 loss 0.043294 acc 0.969217 lr 0.00016194 grad_norm 0.421448 rank 0
2025-01-10 20:31:21,123 DEBUG TRAIN Batch 99/200 loss 0.041525 acc 0.975410 lr 0.00016189 grad_norm 0.439225 rank 1
2025-01-10 20:31:21,123 DEBUG TRAIN Batch 99/200 loss 0.052082 acc 0.959276 lr 0.00016189 grad_norm 0.439225 rank 0
2025-01-10 20:31:21,124 DEBUG TRAIN Batch 99/200 loss 0.059276 acc 0.965889 lr 0.00016189 grad_norm 0.439225 rank 2
2025-01-10 20:31:44,551 DEBUG TRAIN Batch 99/300 loss 0.046598 acc 0.965106 lr 0.00016185 grad_norm 0.475674 rank 1
2025-01-10 20:31:44,551 DEBUG TRAIN Batch 99/300 loss 0.059631 acc 0.966249 lr 0.00016185 grad_norm 0.475674 rank 0
2025-01-10 20:31:44,552 DEBUG TRAIN Batch 99/300 loss 0.071796 acc 0.949423 lr 0.00016185 grad_norm 0.475674 rank 2
2025-01-10 20:32:08,260 DEBUG TRAIN Batch 99/400 loss 0.061972 acc 0.958333 lr 0.00016181 grad_norm 0.465958 rank 0
2025-01-10 20:32:08,261 DEBUG TRAIN Batch 99/400 loss 0.057483 acc 0.956232 lr 0.00016181 grad_norm 0.465958 rank 2
2025-01-10 20:32:08,261 DEBUG TRAIN Batch 99/400 loss 0.055103 acc 0.970845 lr 0.00016181 grad_norm 0.465958 rank 1
2025-01-10 20:32:32,622 DEBUG TRAIN Batch 99/500 loss 0.051431 acc 0.962431 lr 0.00016177 grad_norm 0.424027 rank 0
2025-01-10 20:32:32,622 DEBUG TRAIN Batch 99/500 loss 0.035930 acc 0.978313 lr 0.00016177 grad_norm 0.424027 rank 2
2025-01-10 20:32:32,622 DEBUG TRAIN Batch 99/500 loss 0.051537 acc 0.966418 lr 0.00016177 grad_norm 0.424027 rank 1
2025-01-10 20:32:56,512 DEBUG TRAIN Batch 99/600 loss 0.054598 acc 0.967008 lr 0.00016173 grad_norm 0.462606 rank 0
2025-01-10 20:32:56,513 DEBUG TRAIN Batch 99/600 loss 0.035388 acc 0.972558 lr 0.00016173 grad_norm 0.462606 rank 1
2025-01-10 20:32:56,513 DEBUG TRAIN Batch 99/600 loss 0.051434 acc 0.958154 lr 0.00016173 grad_norm 0.462606 rank 2
2025-01-10 20:33:20,933 DEBUG TRAIN Batch 99/700 loss 0.047701 acc 0.965517 lr 0.00016168 grad_norm 0.450184 rank 1
2025-01-10 20:33:20,933 DEBUG TRAIN Batch 99/700 loss 0.047730 acc 0.974436 lr 0.00016168 grad_norm 0.450184 rank 0
2025-01-10 20:33:20,934 DEBUG TRAIN Batch 99/700 loss 0.054565 acc 0.957627 lr 0.00016168 grad_norm 0.450184 rank 2
2025-01-10 20:33:45,332 DEBUG TRAIN Batch 99/800 loss 0.065133 acc 0.953111 lr 0.00016164 grad_norm 0.424487 rank 0
2025-01-10 20:33:45,332 DEBUG TRAIN Batch 99/800 loss 0.045871 acc 0.971872 lr 0.00016164 grad_norm 0.424487 rank 2
2025-01-10 20:33:45,333 DEBUG TRAIN Batch 99/800 loss 0.046568 acc 0.964217 lr 0.00016164 grad_norm 0.424487 rank 1
2025-01-10 20:34:09,505 DEBUG TRAIN Batch 99/900 loss 0.069713 acc 0.950504 lr 0.00016160 grad_norm 0.460429 rank 0
2025-01-10 20:34:09,506 DEBUG TRAIN Batch 99/900 loss 0.045960 acc 0.968497 lr 0.00016160 grad_norm 0.460429 rank 1
2025-01-10 20:34:09,506 DEBUG TRAIN Batch 99/900 loss 0.052485 acc 0.967949 lr 0.00016160 grad_norm 0.460429 rank 2
2025-01-10 20:34:33,556 DEBUG TRAIN Batch 99/1000 loss 0.066236 acc 0.958753 lr 0.00016156 grad_norm 0.448038 rank 0
2025-01-10 20:34:33,556 DEBUG TRAIN Batch 99/1000 loss 0.054649 acc 0.961690 lr 0.00016156 grad_norm 0.448038 rank 2
2025-01-10 20:34:33,556 DEBUG TRAIN Batch 99/1000 loss 0.040885 acc 0.971859 lr 0.00016156 grad_norm 0.448038 rank 1
2025-01-10 20:34:58,140 DEBUG TRAIN Batch 99/1100 loss 0.058235 acc 0.967871 lr 0.00016151 grad_norm 0.462022 rank 1
2025-01-10 20:34:58,140 DEBUG TRAIN Batch 99/1100 loss 0.039952 acc 0.978261 lr 0.00016151 grad_norm 0.462022 rank 0
2025-01-10 20:34:58,141 DEBUG TRAIN Batch 99/1100 loss 0.066579 acc 0.957173 lr 0.00016151 grad_norm 0.462022 rank 2
2025-01-10 20:35:23,255 DEBUG TRAIN Batch 99/1200 loss 0.051755 acc 0.962963 lr 0.00016147 grad_norm 0.450954 rank 0
2025-01-10 20:35:23,255 DEBUG TRAIN Batch 99/1200 loss 0.051346 acc 0.966571 lr 0.00016147 grad_norm 0.450954 rank 1
2025-01-10 20:35:23,255 DEBUG TRAIN Batch 99/1200 loss 0.034626 acc 0.975806 lr 0.00016147 grad_norm 0.450954 rank 2
2025-01-10 20:35:47,861 DEBUG TRAIN Batch 99/1300 loss 0.052901 acc 0.963542 lr 0.00016143 grad_norm 0.450519 rank 1
2025-01-10 20:35:47,861 DEBUG TRAIN Batch 99/1300 loss 0.046203 acc 0.968553 lr 0.00016143 grad_norm 0.450519 rank 2
2025-01-10 20:35:47,861 DEBUG TRAIN Batch 99/1300 loss 0.038381 acc 0.975062 lr 0.00016143 grad_norm 0.450519 rank 0
2025-01-10 20:36:13,179 DEBUG TRAIN Batch 99/1400 loss 0.063567 acc 0.960326 lr 0.00016139 grad_norm 0.444175 rank 0
2025-01-10 20:36:13,179 DEBUG TRAIN Batch 99/1400 loss 0.043570 acc 0.974763 lr 0.00016139 grad_norm 0.444175 rank 1
2025-01-10 20:36:13,179 DEBUG TRAIN Batch 99/1400 loss 0.052275 acc 0.963218 lr 0.00016139 grad_norm 0.444175 rank 2
2025-01-10 20:36:38,490 DEBUG TRAIN Batch 99/1500 loss 0.021060 acc 0.988060 lr 0.00016135 grad_norm 0.417981 rank 0
2025-01-10 20:36:38,490 DEBUG TRAIN Batch 99/1500 loss 0.048436 acc 0.968394 lr 0.00016135 grad_norm 0.417981 rank 1
2025-01-10 20:36:38,491 DEBUG TRAIN Batch 99/1500 loss 0.029351 acc 0.973228 lr 0.00016135 grad_norm 0.417981 rank 2
2025-01-10 20:37:03,837 DEBUG TRAIN Batch 99/1600 loss 0.037488 acc 0.971277 lr 0.00016130 grad_norm 0.497058 rank 0
2025-01-10 20:37:03,837 DEBUG TRAIN Batch 99/1600 loss 0.058563 acc 0.958498 lr 0.00016130 grad_norm 0.497058 rank 1
2025-01-10 20:37:03,837 DEBUG TRAIN Batch 99/1600 loss 0.133777 acc 0.897492 lr 0.00016130 grad_norm 0.497058 rank 2
2025-01-10 20:37:28,273 DEBUG TRAIN Batch 99/1700 loss 0.028216 acc 0.979369 lr 0.00016126 grad_norm 0.451966 rank 0
2025-01-10 20:37:28,273 DEBUG TRAIN Batch 99/1700 loss 0.043940 acc 0.974529 lr 0.00016126 grad_norm 0.451966 rank 1
2025-01-10 20:37:28,273 DEBUG TRAIN Batch 99/1700 loss 0.056046 acc 0.959854 lr 0.00016126 grad_norm 0.451966 rank 2
2025-01-10 20:37:53,077 DEBUG TRAIN Batch 99/1800 loss 0.062132 acc 0.962366 lr 0.00016122 grad_norm 0.497607 rank 1
2025-01-10 20:37:53,077 DEBUG TRAIN Batch 99/1800 loss 0.071147 acc 0.950730 lr 0.00016122 grad_norm 0.497607 rank 2
2025-01-10 20:37:53,077 DEBUG TRAIN Batch 99/1800 loss 0.054721 acc 0.960591 lr 0.00016122 grad_norm 0.497607 rank 0
2025-01-10 20:38:17,242 DEBUG TRAIN Batch 99/1900 loss 0.057704 acc 0.958333 lr 0.00016118 grad_norm 0.447609 rank 1
2025-01-10 20:38:17,242 DEBUG TRAIN Batch 99/1900 loss 0.036799 acc 0.973966 lr 0.00016118 grad_norm 0.447609 rank 0
2025-01-10 20:38:17,244 DEBUG TRAIN Batch 99/1900 loss 0.050467 acc 0.969072 lr 0.00016118 grad_norm 0.447609 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 20:39:32,858 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 20:39:32,860 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 20:39:33,239 INFO Epoch 99 Step 96266 on_batch_end True CV rank 2
2025-01-10 20:39:33,239 INFO Epoch 99 Step 96266 on_batch_end True CV rank 0
2025-01-10 20:39:33,239 INFO Epoch 99 Step 96266 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 20:39:42,206 DEBUG CV Batch 99/100 loss 0.011636 acc 0.996656  rank 0
2025-01-10 20:39:42,536 DEBUG CV Batch 99/100 loss 0.011636 acc 0.996656  rank 2
2025-01-10 20:39:42,715 INFO Epoch 99 Step 96266 CV info lr 0.00016115119897631015 0 rank loss_2.365536380845138 acc_0.7805982551030946
2025-01-10 20:39:42,959 DEBUG CV Batch 99/100 loss 0.011636 acc 0.996656  rank 1
2025-01-10 20:39:43,076 INFO Epoch 99 Step 96266 CV info lr 0.00016115119897631015 2 rank loss_2.365536380845138 acc_0.7805982551030946
2025-01-10 20:39:43,497 INFO Epoch 99 Step 96266 CV info lr 0.00016115119897631015 1 rank loss_2.365536380845138 acc_0.7805982551030946
2025-01-10 20:39:44,021 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_99_whole.pt
2025-01-10 20:39:44,033 INFO Added key: store_based_barrier_key:102 to store for rank: 0
2025-01-10 20:39:44,043 INFO Added key: store_based_barrier_key:102 to store for rank: 2
2025-01-10 20:39:44,043 INFO Added key: store_based_barrier_key:102 to store for rank: 1
2025-01-10 20:39:44,043 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:102 with 3 nodes.
2025-01-10 20:39:44,043 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:102 with 3 nodes.
2025-01-10 20:39:44,044 INFO Epoch 100 TRAIN info lr 0.00016115119897631015 rank 1
2025-01-10 20:39:44,044 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 20:39:44,051 INFO Epoch 100 TRAIN info lr 0.00016115119897631015 rank 2
2025-01-10 20:39:44,051 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 20:39:44,053 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:102 with 3 nodes.
2025-01-10 20:39:44,054 INFO Epoch 100 TRAIN info lr 0.00016115119897631015 rank 0
2025-01-10 20:39:44,054 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 20:40:14,958 DEBUG TRAIN Batch 100/100 loss 0.055073 acc 0.960581 lr 0.00016111 grad_norm 0.444397 rank 1
2025-01-10 20:40:14,958 DEBUG TRAIN Batch 100/100 loss 0.055930 acc 0.959752 lr 0.00016111 grad_norm 0.444397 rank 2
2025-01-10 20:40:14,958 DEBUG TRAIN Batch 100/100 loss 0.051029 acc 0.970409 lr 0.00016111 grad_norm 0.444397 rank 0
2025-01-10 20:40:38,818 DEBUG TRAIN Batch 100/200 loss 0.048374 acc 0.974268 lr 0.00016107 grad_norm 0.424630 rank 1
2025-01-10 20:40:38,818 DEBUG TRAIN Batch 100/200 loss 0.036662 acc 0.974425 lr 0.00016107 grad_norm 0.424630 rank 2
2025-01-10 20:40:38,818 DEBUG TRAIN Batch 100/200 loss 0.048183 acc 0.964795 lr 0.00016107 grad_norm 0.424630 rank 0
2025-01-10 20:41:02,367 DEBUG TRAIN Batch 100/300 loss 0.050158 acc 0.964043 lr 0.00016103 grad_norm 0.414733 rank 1
2025-01-10 20:41:02,368 DEBUG TRAIN Batch 100/300 loss 0.046015 acc 0.973938 lr 0.00016103 grad_norm 0.414733 rank 0
2025-01-10 20:41:02,369 DEBUG TRAIN Batch 100/300 loss 0.055808 acc 0.966698 lr 0.00016103 grad_norm 0.414733 rank 2
2025-01-10 20:41:26,053 DEBUG TRAIN Batch 100/400 loss 0.042876 acc 0.971549 lr 0.00016098 grad_norm 0.439211 rank 1
2025-01-10 20:41:26,053 DEBUG TRAIN Batch 100/400 loss 0.047704 acc 0.969730 lr 0.00016098 grad_norm 0.439211 rank 0
2025-01-10 20:41:26,055 DEBUG TRAIN Batch 100/400 loss 0.060737 acc 0.958115 lr 0.00016098 grad_norm 0.439211 rank 2
2025-01-10 20:41:51,129 DEBUG TRAIN Batch 100/500 loss 0.053031 acc 0.957944 lr 0.00016094 grad_norm 0.436120 rank 0
2025-01-10 20:41:51,129 DEBUG TRAIN Batch 100/500 loss 0.057346 acc 0.961233 lr 0.00016094 grad_norm 0.436120 rank 1
2025-01-10 20:41:51,130 DEBUG TRAIN Batch 100/500 loss 0.056937 acc 0.961895 lr 0.00016094 grad_norm 0.436120 rank 2
2025-01-10 20:42:15,304 DEBUG TRAIN Batch 100/600 loss 0.046988 acc 0.972678 lr 0.00016090 grad_norm 0.425185 rank 1
2025-01-10 20:42:15,304 DEBUG TRAIN Batch 100/600 loss 0.025706 acc 0.984424 lr 0.00016090 grad_norm 0.425185 rank 0
2025-01-10 20:42:15,305 DEBUG TRAIN Batch 100/600 loss 0.038845 acc 0.974448 lr 0.00016090 grad_norm 0.425185 rank 2
2025-01-10 20:42:40,497 DEBUG TRAIN Batch 100/700 loss 0.062457 acc 0.949355 lr 0.00016086 grad_norm 0.442734 rank 2
2025-01-10 20:42:40,497 DEBUG TRAIN Batch 100/700 loss 0.044391 acc 0.969006 lr 0.00016086 grad_norm 0.442734 rank 1
2025-01-10 20:42:40,498 DEBUG TRAIN Batch 100/700 loss 0.053705 acc 0.970699 lr 0.00016086 grad_norm 0.442734 rank 0
2025-01-10 20:43:05,493 DEBUG TRAIN Batch 100/800 loss 0.060786 acc 0.954120 lr 0.00016082 grad_norm 0.444867 rank 0
2025-01-10 20:43:05,494 DEBUG TRAIN Batch 100/800 loss 0.056642 acc 0.963277 lr 0.00016082 grad_norm 0.444867 rank 1
2025-01-10 20:43:05,494 DEBUG TRAIN Batch 100/800 loss 0.032534 acc 0.975498 lr 0.00016082 grad_norm 0.444867 rank 2
2025-01-10 20:43:29,726 DEBUG TRAIN Batch 100/900 loss 0.054303 acc 0.957240 lr 0.00016078 grad_norm 0.459580 rank 0
2025-01-10 20:43:29,726 DEBUG TRAIN Batch 100/900 loss 0.050402 acc 0.970278 lr 0.00016078 grad_norm 0.459580 rank 1
2025-01-10 20:43:29,726 DEBUG TRAIN Batch 100/900 loss 0.049243 acc 0.966533 lr 0.00016078 grad_norm 0.459580 rank 2
2025-01-10 20:43:55,135 DEBUG TRAIN Batch 100/1000 loss 0.042688 acc 0.971850 lr 0.00016073 grad_norm 0.466375 rank 0
2025-01-10 20:43:55,135 DEBUG TRAIN Batch 100/1000 loss 0.064169 acc 0.950835 lr 0.00016073 grad_norm 0.466375 rank 1
2025-01-10 20:43:55,136 DEBUG TRAIN Batch 100/1000 loss 0.045643 acc 0.965746 lr 0.00016073 grad_norm 0.466375 rank 2
2025-01-10 20:44:19,797 DEBUG TRAIN Batch 100/1100 loss 0.031918 acc 0.978355 lr 0.00016069 grad_norm 0.439129 rank 0
2025-01-10 20:44:19,797 DEBUG TRAIN Batch 100/1100 loss 0.039294 acc 0.975238 lr 0.00016069 grad_norm 0.439129 rank 2
2025-01-10 20:44:19,797 DEBUG TRAIN Batch 100/1100 loss 0.058387 acc 0.959668 lr 0.00016069 grad_norm 0.439129 rank 1
2025-01-10 20:44:43,721 DEBUG TRAIN Batch 100/1200 loss 0.069166 acc 0.955929 lr 0.00016065 grad_norm 0.471254 rank 1
2025-01-10 20:44:43,721 DEBUG TRAIN Batch 100/1200 loss 0.033676 acc 0.975460 lr 0.00016065 grad_norm 0.471254 rank 0
2025-01-10 20:44:43,722 DEBUG TRAIN Batch 100/1200 loss 0.059610 acc 0.954000 lr 0.00016065 grad_norm 0.471254 rank 2
2025-01-10 20:45:08,728 DEBUG TRAIN Batch 100/1300 loss 0.046950 acc 0.971033 lr 0.00016061 grad_norm 0.442207 rank 1
2025-01-10 20:45:08,728 DEBUG TRAIN Batch 100/1300 loss 0.047391 acc 0.965035 lr 0.00016061 grad_norm 0.442207 rank 0
2025-01-10 20:45:08,729 DEBUG TRAIN Batch 100/1300 loss 0.030450 acc 0.981636 lr 0.00016061 grad_norm 0.442207 rank 2
2025-01-10 20:45:33,227 DEBUG TRAIN Batch 100/1400 loss 0.059882 acc 0.954286 lr 0.00016057 grad_norm 0.457661 rank 1
2025-01-10 20:45:33,227 DEBUG TRAIN Batch 100/1400 loss 0.032089 acc 0.970634 lr 0.00016057 grad_norm 0.457661 rank 0
2025-01-10 20:45:33,227 DEBUG TRAIN Batch 100/1400 loss 0.033373 acc 0.982143 lr 0.00016057 grad_norm 0.457661 rank 2
2025-01-10 20:45:57,393 DEBUG TRAIN Batch 100/1500 loss 0.062230 acc 0.949223 lr 0.00016053 grad_norm 0.460165 rank 1
2025-01-10 20:45:57,393 DEBUG TRAIN Batch 100/1500 loss 0.037231 acc 0.971396 lr 0.00016053 grad_norm 0.460165 rank 0
2025-01-10 20:45:57,394 DEBUG TRAIN Batch 100/1500 loss 0.042485 acc 0.972112 lr 0.00016053 grad_norm 0.460165 rank 2
2025-01-10 20:46:22,935 DEBUG TRAIN Batch 100/1600 loss 0.068506 acc 0.951465 lr 0.00016049 grad_norm 0.453590 rank 1
2025-01-10 20:46:22,935 DEBUG TRAIN Batch 100/1600 loss 0.027924 acc 0.982051 lr 0.00016049 grad_norm 0.453590 rank 0
2025-01-10 20:46:22,935 DEBUG TRAIN Batch 100/1600 loss 0.060398 acc 0.959821 lr 0.00016049 grad_norm 0.453590 rank 2
2025-01-10 20:46:46,793 DEBUG TRAIN Batch 100/1700 loss 0.073686 acc 0.951482 lr 0.00016044 grad_norm 0.460130 rank 1
2025-01-10 20:46:46,793 DEBUG TRAIN Batch 100/1700 loss 0.041673 acc 0.969214 lr 0.00016044 grad_norm 0.460130 rank 0
2025-01-10 20:46:46,793 DEBUG TRAIN Batch 100/1700 loss 0.053033 acc 0.958773 lr 0.00016044 grad_norm 0.460130 rank 2
2025-01-10 20:47:11,514 DEBUG TRAIN Batch 100/1800 loss 0.050690 acc 0.965714 lr 0.00016040 grad_norm 0.466628 rank 1
2025-01-10 20:47:11,514 DEBUG TRAIN Batch 100/1800 loss 0.056355 acc 0.969256 lr 0.00016040 grad_norm 0.466628 rank 0
2025-01-10 20:47:11,514 DEBUG TRAIN Batch 100/1800 loss 0.052208 acc 0.962513 lr 0.00016040 grad_norm 0.466628 rank 2
2025-01-10 20:47:34,995 DEBUG TRAIN Batch 100/1900 loss 0.055619 acc 0.956701 lr 0.00016036 grad_norm 0.488532 rank 1
2025-01-10 20:47:34,995 DEBUG TRAIN Batch 100/1900 loss 0.065545 acc 0.953110 lr 0.00016036 grad_norm 0.488532 rank 0
2025-01-10 20:47:34,995 DEBUG TRAIN Batch 100/1900 loss 0.059955 acc 0.963781 lr 0.00016036 grad_norm 0.488532 rank 2
2025-01-10 20:47:58,698 DEBUG TRAIN Batch 100/2000 loss 0.050738 acc 0.964545 lr 0.00016032 grad_norm 0.418522 rank 1
2025-01-10 20:47:58,699 DEBUG TRAIN Batch 100/2000 loss 0.060331 acc 0.954894 lr 0.00016032 grad_norm 0.418522 rank 2
2025-01-10 20:47:58,699 DEBUG TRAIN Batch 100/2000 loss 0.045403 acc 0.971596 lr 0.00016032 grad_norm 0.418522 rank 0
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 20:49:21,698 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 20:49:21,705 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 20:49:22,060 INFO Epoch 100 Step 97314 on_batch_end True CV rank 0
2025-01-10 20:49:22,060 INFO Epoch 100 Step 97314 on_batch_end True CV rank 2
2025-01-10 20:49:22,060 INFO Epoch 100 Step 97314 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 20:49:31,064 DEBUG CV Batch 100/100 loss 0.018791 acc 0.996656  rank 0
2025-01-10 20:49:31,574 INFO Epoch 100 Step 97314 CV info lr 0.0001602811103090001 0 rank loss_2.3635113159513197 acc_0.7788705761756813
2025-01-10 20:49:31,613 DEBUG CV Batch 100/100 loss 0.018791 acc 0.996656  rank 2
2025-01-10 20:49:31,794 DEBUG CV Batch 100/100 loss 0.018791 acc 0.996656  rank 1
2025-01-10 20:49:32,151 INFO Epoch 100 Step 97314 CV info lr 0.0001602811103090001 2 rank loss_2.3635113159513197 acc_0.7788705761756813
2025-01-10 20:49:32,361 INFO Epoch 100 Step 97314 CV info lr 0.0001602811103090001 1 rank loss_2.3635113159513197 acc_0.7788705761756813
2025-01-10 20:49:32,877 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_100_whole.pt
2025-01-10 20:49:32,899 INFO Added key: store_based_barrier_key:103 to store for rank: 0
2025-01-10 20:49:32,909 INFO Added key: store_based_barrier_key:103 to store for rank: 1
2025-01-10 20:49:32,909 INFO Added key: store_based_barrier_key:103 to store for rank: 2
2025-01-10 20:49:32,909 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:103 with 3 nodes.
2025-01-10 20:49:32,909 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:103 with 3 nodes.
2025-01-10 20:49:32,914 INFO Epoch 101 TRAIN info lr 0.0001602811103090001 rank 2
2025-01-10 20:49:32,914 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 20:49:32,915 INFO Epoch 101 TRAIN info lr 0.0001602811103090001 rank 1
2025-01-10 20:49:32,915 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 20:49:32,919 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:103 with 3 nodes.
2025-01-10 20:49:32,925 INFO Epoch 101 TRAIN info lr 0.0001602811103090001 rank 0
2025-01-10 20:49:32,925 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 20:50:06,303 DEBUG TRAIN Batch 101/100 loss 0.064149 acc 0.958042 lr 0.00016024 grad_norm 0.437158 rank 1
2025-01-10 20:50:06,303 DEBUG TRAIN Batch 101/100 loss 0.043829 acc 0.967403 lr 0.00016024 grad_norm 0.437158 rank 0
2025-01-10 20:50:06,304 DEBUG TRAIN Batch 101/100 loss 0.043065 acc 0.972467 lr 0.00016024 grad_norm 0.437158 rank 2
2025-01-10 20:50:30,345 DEBUG TRAIN Batch 101/200 loss 0.044346 acc 0.971526 lr 0.00016020 grad_norm 0.429982 rank 1
2025-01-10 20:50:30,345 DEBUG TRAIN Batch 101/200 loss 0.046809 acc 0.968045 lr 0.00016020 grad_norm 0.429982 rank 0
2025-01-10 20:50:30,346 DEBUG TRAIN Batch 101/200 loss 0.045595 acc 0.970623 lr 0.00016020 grad_norm 0.429982 rank 2
2025-01-10 20:50:54,788 DEBUG TRAIN Batch 101/300 loss 0.063300 acc 0.950136 lr 0.00016016 grad_norm 0.439039 rank 0
2025-01-10 20:50:54,789 DEBUG TRAIN Batch 101/300 loss 0.049488 acc 0.966229 lr 0.00016016 grad_norm 0.439039 rank 1
2025-01-10 20:50:54,789 DEBUG TRAIN Batch 101/300 loss 0.036916 acc 0.976038 lr 0.00016016 grad_norm 0.439039 rank 2
2025-01-10 20:51:19,588 DEBUG TRAIN Batch 101/400 loss 0.051678 acc 0.966696 lr 0.00016012 grad_norm 0.480510 rank 1
2025-01-10 20:51:19,588 DEBUG TRAIN Batch 101/400 loss 0.062298 acc 0.966337 lr 0.00016012 grad_norm 0.480510 rank 2
2025-01-10 20:51:19,589 DEBUG TRAIN Batch 101/400 loss 0.055051 acc 0.954248 lr 0.00016012 grad_norm 0.480510 rank 0
2025-01-10 20:51:43,765 DEBUG TRAIN Batch 101/500 loss 0.069659 acc 0.949954 lr 0.00016008 grad_norm 0.428300 rank 1
2025-01-10 20:51:43,765 DEBUG TRAIN Batch 101/500 loss 0.054661 acc 0.963214 lr 0.00016008 grad_norm 0.428300 rank 2
2025-01-10 20:51:43,765 DEBUG TRAIN Batch 101/500 loss 0.051899 acc 0.965170 lr 0.00016008 grad_norm 0.428300 rank 0
2025-01-10 20:52:07,793 DEBUG TRAIN Batch 101/600 loss 0.059223 acc 0.956167 lr 0.00016003 grad_norm 0.437345 rank 1
2025-01-10 20:52:07,794 DEBUG TRAIN Batch 101/600 loss 0.045899 acc 0.968868 lr 0.00016003 grad_norm 0.437345 rank 0
2025-01-10 20:52:07,794 DEBUG TRAIN Batch 101/600 loss 0.049850 acc 0.965760 lr 0.00016003 grad_norm 0.437345 rank 2
2025-01-10 20:52:33,102 DEBUG TRAIN Batch 101/700 loss 0.055423 acc 0.968553 lr 0.00015999 grad_norm 0.441446 rank 1
2025-01-10 20:52:33,102 DEBUG TRAIN Batch 101/700 loss 0.057458 acc 0.959184 lr 0.00015999 grad_norm 0.441446 rank 0
2025-01-10 20:52:33,102 DEBUG TRAIN Batch 101/700 loss 0.045772 acc 0.968536 lr 0.00015999 grad_norm 0.441446 rank 2
2025-01-10 20:52:57,486 DEBUG TRAIN Batch 101/800 loss 0.066389 acc 0.952545 lr 0.00015995 grad_norm 0.484792 rank 1
2025-01-10 20:52:57,487 DEBUG TRAIN Batch 101/800 loss 0.061655 acc 0.961802 lr 0.00015995 grad_norm 0.484792 rank 2
2025-01-10 20:52:57,487 DEBUG TRAIN Batch 101/800 loss 0.044088 acc 0.968444 lr 0.00015995 grad_norm 0.484792 rank 0
2025-01-10 20:53:21,783 DEBUG TRAIN Batch 101/900 loss 0.067825 acc 0.956951 lr 0.00015991 grad_norm 0.449794 rank 1
2025-01-10 20:53:21,784 DEBUG TRAIN Batch 101/900 loss 0.051236 acc 0.965070 lr 0.00015991 grad_norm 0.449794 rank 2
2025-01-10 20:53:21,785 DEBUG TRAIN Batch 101/900 loss 0.057430 acc 0.961580 lr 0.00015991 grad_norm 0.449794 rank 0
2025-01-10 20:53:46,530 DEBUG TRAIN Batch 101/1000 loss 0.062571 acc 0.959223 lr 0.00015987 grad_norm 0.457713 rank 0
2025-01-10 20:53:46,531 DEBUG TRAIN Batch 101/1000 loss 0.052146 acc 0.963277 lr 0.00015987 grad_norm 0.457713 rank 1
2025-01-10 20:53:46,531 DEBUG TRAIN Batch 101/1000 loss 0.050045 acc 0.965714 lr 0.00015987 grad_norm 0.457713 rank 2
2025-01-10 20:54:10,342 DEBUG TRAIN Batch 101/1100 loss 0.054589 acc 0.964320 lr 0.00015983 grad_norm 0.477364 rank 1
2025-01-10 20:54:10,342 DEBUG TRAIN Batch 101/1100 loss 0.063529 acc 0.955429 lr 0.00015983 grad_norm 0.477364 rank 2
2025-01-10 20:54:10,343 DEBUG TRAIN Batch 101/1100 loss 0.037190 acc 0.979127 lr 0.00015983 grad_norm 0.477364 rank 0
2025-01-10 20:54:34,231 DEBUG TRAIN Batch 101/1200 loss 0.039171 acc 0.977193 lr 0.00015979 grad_norm 0.428930 rank 1
2025-01-10 20:54:34,232 DEBUG TRAIN Batch 101/1200 loss 0.050968 acc 0.962799 lr 0.00015979 grad_norm 0.428930 rank 0
2025-01-10 20:54:34,232 DEBUG TRAIN Batch 101/1200 loss 0.054107 acc 0.962894 lr 0.00015979 grad_norm 0.428930 rank 2
2025-01-10 20:54:57,905 DEBUG TRAIN Batch 101/1300 loss 0.051473 acc 0.964611 lr 0.00015975 grad_norm 0.434886 rank 2
2025-01-10 20:54:57,905 DEBUG TRAIN Batch 101/1300 loss 0.053203 acc 0.961707 lr 0.00015975 grad_norm 0.434886 rank 0
2025-01-10 20:54:57,905 DEBUG TRAIN Batch 101/1300 loss 0.048317 acc 0.967456 lr 0.00015975 grad_norm 0.434886 rank 1
2025-01-10 20:55:22,174 DEBUG TRAIN Batch 101/1400 loss 0.047513 acc 0.968592 lr 0.00015971 grad_norm 0.419675 rank 1
2025-01-10 20:55:22,174 DEBUG TRAIN Batch 101/1400 loss 0.014206 acc 0.990099 lr 0.00015971 grad_norm 0.419675 rank 0
2025-01-10 20:55:22,174 DEBUG TRAIN Batch 101/1400 loss 0.054509 acc 0.960000 lr 0.00015971 grad_norm 0.419675 rank 2
2025-01-10 20:55:45,626 DEBUG TRAIN Batch 101/1500 loss 0.045783 acc 0.969896 lr 0.00015967 grad_norm 0.441467 rank 1
2025-01-10 20:55:45,626 DEBUG TRAIN Batch 101/1500 loss 0.040918 acc 0.973188 lr 0.00015967 grad_norm 0.441467 rank 0
2025-01-10 20:55:45,627 DEBUG TRAIN Batch 101/1500 loss 0.055993 acc 0.962090 lr 0.00015967 grad_norm 0.441467 rank 2
2025-01-10 20:56:09,886 DEBUG TRAIN Batch 101/1600 loss 0.058991 acc 0.953319 lr 0.00015963 grad_norm 0.435222 rank 1
2025-01-10 20:56:09,887 DEBUG TRAIN Batch 101/1600 loss 0.045692 acc 0.969203 lr 0.00015963 grad_norm 0.435222 rank 0
2025-01-10 20:56:09,887 DEBUG TRAIN Batch 101/1600 loss 0.052447 acc 0.968497 lr 0.00015963 grad_norm 0.435222 rank 2
2025-01-10 20:56:33,883 DEBUG TRAIN Batch 101/1700 loss 0.036851 acc 0.973742 lr 0.00015959 grad_norm 0.441446 rank 0
2025-01-10 20:56:33,884 DEBUG TRAIN Batch 101/1700 loss 0.051234 acc 0.966372 lr 0.00015959 grad_norm 0.441446 rank 1
2025-01-10 20:56:33,884 DEBUG TRAIN Batch 101/1700 loss 0.073120 acc 0.952598 lr 0.00015959 grad_norm 0.441446 rank 2
2025-01-10 20:56:58,604 DEBUG TRAIN Batch 101/1800 loss 0.073765 acc 0.950640 lr 0.00015955 grad_norm 0.464163 rank 1
2025-01-10 20:56:58,605 DEBUG TRAIN Batch 101/1800 loss 0.018993 acc 0.986486 lr 0.00015955 grad_norm 0.464163 rank 0
2025-01-10 20:56:58,605 DEBUG TRAIN Batch 101/1800 loss 0.055821 acc 0.967920 lr 0.00015955 grad_norm 0.464163 rank 2
2025-01-10 20:57:22,595 DEBUG TRAIN Batch 101/1900 loss 0.045267 acc 0.962625 lr 0.00015950 grad_norm 0.446796 rank 0
2025-01-10 20:57:22,595 DEBUG TRAIN Batch 101/1900 loss 0.054861 acc 0.957707 lr 0.00015950 grad_norm 0.446796 rank 1
2025-01-10 20:57:22,596 DEBUG TRAIN Batch 101/1900 loss 0.028165 acc 0.978856 lr 0.00015950 grad_norm 0.446796 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 20:58:26,138 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 20:58:26,149 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 20:58:26,577 INFO Epoch 101 Step 98271 on_batch_end True CV rank 1
2025-01-10 20:58:26,577 INFO Epoch 101 Step 98271 on_batch_end True CV rank 0
2025-01-10 20:58:26,577 INFO Epoch 101 Step 98271 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 20:58:35,638 DEBUG CV Batch 101/100 loss 0.009627 acc 0.996656  rank 0
2025-01-10 20:58:35,870 DEBUG CV Batch 101/100 loss 0.009627 acc 0.996656  rank 2
2025-01-10 20:58:36,151 INFO Epoch 101 Step 98271 CV info lr 0.00015949876204718764 0 rank loss_2.3831286789964796 acc_0.7796718527873358
2025-01-10 20:58:36,399 INFO Epoch 101 Step 98271 CV info lr 0.00015949876204718764 2 rank loss_2.3831286789964796 acc_0.7796718527873358
2025-01-10 20:58:36,425 DEBUG CV Batch 101/100 loss 0.009627 acc 0.996656  rank 1
2025-01-10 20:58:36,975 INFO Epoch 101 Step 98271 CV info lr 0.00015949876204718764 1 rank loss_2.3831286789964796 acc_0.7796718527873358
2025-01-10 20:58:37,464 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_101_whole.pt
2025-01-10 20:58:37,485 INFO Added key: store_based_barrier_key:104 to store for rank: 0
2025-01-10 20:58:37,496 INFO Added key: store_based_barrier_key:104 to store for rank: 1
2025-01-10 20:58:37,497 INFO Added key: store_based_barrier_key:104 to store for rank: 2
2025-01-10 20:58:37,497 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:104 with 3 nodes.
2025-01-10 20:58:37,504 INFO Epoch 102 TRAIN info lr 0.00015949876204718764 rank 2
2025-01-10 20:58:37,504 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 20:58:37,506 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:104 with 3 nodes.
2025-01-10 20:58:37,506 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:104 with 3 nodes.
2025-01-10 20:58:37,507 INFO Epoch 102 TRAIN info lr 0.00015949876204718764 rank 0
2025-01-10 20:58:37,507 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 20:58:37,509 INFO Epoch 102 TRAIN info lr 0.00015949876204718764 rank 1
2025-01-10 20:58:37,509 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 20:59:08,640 DEBUG TRAIN Batch 102/100 loss 0.049380 acc 0.967413 lr 0.00015946 grad_norm 0.444970 rank 1
2025-01-10 20:59:08,640 DEBUG TRAIN Batch 102/100 loss 0.049928 acc 0.961658 lr 0.00015946 grad_norm 0.444970 rank 2
2025-01-10 20:59:08,640 DEBUG TRAIN Batch 102/100 loss 0.037755 acc 0.971992 lr 0.00015946 grad_norm 0.444970 rank 0
2025-01-10 20:59:32,652 DEBUG TRAIN Batch 102/200 loss 0.026548 acc 0.979408 lr 0.00015942 grad_norm 0.379684 rank 1
2025-01-10 20:59:32,652 DEBUG TRAIN Batch 102/200 loss 0.027373 acc 0.980595 lr 0.00015942 grad_norm 0.379684 rank 0
2025-01-10 20:59:32,653 DEBUG TRAIN Batch 102/200 loss 0.034937 acc 0.982323 lr 0.00015942 grad_norm 0.379684 rank 2
2025-01-10 20:59:56,171 DEBUG TRAIN Batch 102/300 loss 0.042432 acc 0.967276 lr 0.00015938 grad_norm 0.420027 rank 1
2025-01-10 20:59:56,172 DEBUG TRAIN Batch 102/300 loss 0.038933 acc 0.974743 lr 0.00015938 grad_norm 0.420027 rank 0
2025-01-10 20:59:56,172 DEBUG TRAIN Batch 102/300 loss 0.058537 acc 0.960711 lr 0.00015938 grad_norm 0.420027 rank 2
2025-01-10 21:00:19,949 DEBUG TRAIN Batch 102/400 loss 0.052849 acc 0.965065 lr 0.00015934 grad_norm 0.430633 rank 0
2025-01-10 21:00:19,949 DEBUG TRAIN Batch 102/400 loss 0.030551 acc 0.978355 lr 0.00015934 grad_norm 0.430633 rank 1
2025-01-10 21:00:19,949 DEBUG TRAIN Batch 102/400 loss 0.054071 acc 0.968597 lr 0.00015934 grad_norm 0.430633 rank 2
2025-01-10 21:00:44,232 DEBUG TRAIN Batch 102/500 loss 0.047498 acc 0.962963 lr 0.00015930 grad_norm 0.418419 rank 0
2025-01-10 21:00:44,232 DEBUG TRAIN Batch 102/500 loss 0.040445 acc 0.974482 lr 0.00015930 grad_norm 0.418419 rank 1
2025-01-10 21:00:44,232 DEBUG TRAIN Batch 102/500 loss 0.055333 acc 0.966272 lr 0.00015930 grad_norm 0.418419 rank 2
2025-01-10 21:01:08,432 DEBUG TRAIN Batch 102/600 loss 0.057179 acc 0.959333 lr 0.00015926 grad_norm 0.459898 rank 0
2025-01-10 21:01:08,432 DEBUG TRAIN Batch 102/600 loss 0.048059 acc 0.970526 lr 0.00015926 grad_norm 0.459898 rank 1
2025-01-10 21:01:08,432 DEBUG TRAIN Batch 102/600 loss 0.034444 acc 0.975916 lr 0.00015926 grad_norm 0.459898 rank 2
2025-01-10 21:01:33,103 DEBUG TRAIN Batch 102/700 loss 0.039357 acc 0.966814 lr 0.00015922 grad_norm 0.418003 rank 0
2025-01-10 21:01:33,104 DEBUG TRAIN Batch 102/700 loss 0.042612 acc 0.972015 lr 0.00015922 grad_norm 0.418003 rank 2
2025-01-10 21:01:33,105 DEBUG TRAIN Batch 102/700 loss 0.033341 acc 0.973552 lr 0.00015922 grad_norm 0.418003 rank 1
2025-01-10 21:01:56,921 DEBUG TRAIN Batch 102/800 loss 0.044921 acc 0.965094 lr 0.00015918 grad_norm 0.449580 rank 1
2025-01-10 21:01:56,922 DEBUG TRAIN Batch 102/800 loss 0.056104 acc 0.957798 lr 0.00015918 grad_norm 0.449580 rank 0
2025-01-10 21:01:56,922 DEBUG TRAIN Batch 102/800 loss 0.051095 acc 0.968868 lr 0.00015918 grad_norm 0.449580 rank 2
2025-01-10 21:02:21,800 DEBUG TRAIN Batch 102/900 loss 0.062574 acc 0.961610 lr 0.00015913 grad_norm 0.444016 rank 1
2025-01-10 21:02:21,800 DEBUG TRAIN Batch 102/900 loss 0.057869 acc 0.958225 lr 0.00015913 grad_norm 0.444016 rank 2
2025-01-10 21:02:21,800 DEBUG TRAIN Batch 102/900 loss 0.049366 acc 0.966964 lr 0.00015913 grad_norm 0.444016 rank 0
2025-01-10 21:02:46,484 DEBUG TRAIN Batch 102/1000 loss 0.046994 acc 0.971400 lr 0.00015909 grad_norm 0.438109 rank 1
2025-01-10 21:02:46,484 DEBUG TRAIN Batch 102/1000 loss 0.048783 acc 0.968623 lr 0.00015909 grad_norm 0.438109 rank 0
2025-01-10 21:02:46,485 DEBUG TRAIN Batch 102/1000 loss 0.048372 acc 0.965950 lr 0.00015909 grad_norm 0.438109 rank 2
2025-01-10 21:03:10,289 DEBUG TRAIN Batch 102/1100 loss 0.041698 acc 0.968362 lr 0.00015905 grad_norm 0.450111 rank 1
2025-01-10 21:03:10,289 DEBUG TRAIN Batch 102/1100 loss 0.045816 acc 0.972755 lr 0.00015905 grad_norm 0.450111 rank 2
2025-01-10 21:03:10,289 DEBUG TRAIN Batch 102/1100 loss 0.053679 acc 0.965998 lr 0.00015905 grad_norm 0.450111 rank 0
2025-01-10 21:03:36,009 DEBUG TRAIN Batch 102/1200 loss 0.059239 acc 0.961759 lr 0.00015901 grad_norm 0.450229 rank 0
2025-01-10 21:03:36,009 DEBUG TRAIN Batch 102/1200 loss 0.057760 acc 0.960644 lr 0.00015901 grad_norm 0.450229 rank 1
2025-01-10 21:03:36,009 DEBUG TRAIN Batch 102/1200 loss 0.049375 acc 0.969582 lr 0.00015901 grad_norm 0.450229 rank 2
2025-01-10 21:03:59,794 DEBUG TRAIN Batch 102/1300 loss 0.050570 acc 0.966734 lr 0.00015897 grad_norm 0.445655 rank 2
2025-01-10 21:03:59,794 DEBUG TRAIN Batch 102/1300 loss 0.045313 acc 0.968861 lr 0.00015897 grad_norm 0.445655 rank 1
2025-01-10 21:03:59,794 DEBUG TRAIN Batch 102/1300 loss 0.053324 acc 0.965128 lr 0.00015897 grad_norm 0.445655 rank 0
2025-01-10 21:04:23,763 DEBUG TRAIN Batch 102/1400 loss 0.052305 acc 0.970748 lr 0.00015893 grad_norm 0.432288 rank 0
2025-01-10 21:04:23,763 DEBUG TRAIN Batch 102/1400 loss 0.049007 acc 0.961934 lr 0.00015893 grad_norm 0.432288 rank 1
2025-01-10 21:04:23,763 DEBUG TRAIN Batch 102/1400 loss 0.044045 acc 0.968750 lr 0.00015893 grad_norm 0.432288 rank 2
2025-01-10 21:04:48,877 DEBUG TRAIN Batch 102/1500 loss 0.032239 acc 0.981154 lr 0.00015889 grad_norm 0.458018 rank 1
2025-01-10 21:04:48,877 DEBUG TRAIN Batch 102/1500 loss 0.036233 acc 0.970213 lr 0.00015889 grad_norm 0.458018 rank 0
2025-01-10 21:04:48,878 DEBUG TRAIN Batch 102/1500 loss 0.053401 acc 0.965486 lr 0.00015889 grad_norm 0.458018 rank 2
2025-01-10 21:05:13,867 DEBUG TRAIN Batch 102/1600 loss 0.068119 acc 0.951974 lr 0.00015885 grad_norm 0.487951 rank 2
2025-01-10 21:05:13,867 DEBUG TRAIN Batch 102/1600 loss 0.063650 acc 0.959544 lr 0.00015885 grad_norm 0.487951 rank 0
2025-01-10 21:05:13,868 DEBUG TRAIN Batch 102/1600 loss 0.053312 acc 0.962756 lr 0.00015885 grad_norm 0.487951 rank 1
2025-01-10 21:05:38,999 DEBUG TRAIN Batch 102/1700 loss 0.031446 acc 0.983459 lr 0.00015881 grad_norm 0.449639 rank 1
2025-01-10 21:05:38,999 DEBUG TRAIN Batch 102/1700 loss 0.057893 acc 0.965950 lr 0.00015881 grad_norm 0.449639 rank 0
2025-01-10 21:05:38,999 DEBUG TRAIN Batch 102/1700 loss 0.061486 acc 0.964727 lr 0.00015881 grad_norm 0.449639 rank 2
2025-01-10 21:06:04,257 DEBUG TRAIN Batch 102/1800 loss 0.023028 acc 0.989955 lr 0.00015877 grad_norm 0.426639 rank 1
2025-01-10 21:06:04,257 DEBUG TRAIN Batch 102/1800 loss 0.035666 acc 0.972603 lr 0.00015877 grad_norm 0.426639 rank 0
2025-01-10 21:06:04,258 DEBUG TRAIN Batch 102/1800 loss 0.053894 acc 0.968085 lr 0.00015877 grad_norm 0.426639 rank 2
2025-01-10 21:06:28,559 DEBUG TRAIN Batch 102/1900 loss 0.037595 acc 0.968828 lr 0.00015873 grad_norm 0.487996 rank 1
2025-01-10 21:06:28,559 DEBUG TRAIN Batch 102/1900 loss 0.059836 acc 0.951382 lr 0.00015873 grad_norm 0.487996 rank 2
2025-01-10 21:06:28,559 DEBUG TRAIN Batch 102/1900 loss 0.066146 acc 0.947217 lr 0.00015873 grad_norm 0.487996 rank 0
2025-01-10 21:06:52,634 DEBUG TRAIN Batch 102/2000 loss 0.050174 acc 0.960251 lr 0.00015869 grad_norm 0.474307 rank 1
2025-01-10 21:06:52,634 DEBUG TRAIN Batch 102/2000 loss 0.068692 acc 0.953917 lr 0.00015869 grad_norm 0.474307 rank 0
2025-01-10 21:06:52,635 DEBUG TRAIN Batch 102/2000 loss 0.049112 acc 0.966997 lr 0.00015869 grad_norm 0.474307 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 21:08:16,382 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 21:08:16,389 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 21:08:16,807 INFO Epoch 102 Step 99319 on_batch_end True CV rank 1
2025-01-10 21:08:16,807 INFO Epoch 102 Step 99319 on_batch_end True CV rank 2
2025-01-10 21:08:16,807 INFO Epoch 102 Step 99319 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 21:08:26,122 DEBUG CV Batch 102/100 loss 0.005153 acc 1.000000  rank 0
2025-01-10 21:08:26,213 DEBUG CV Batch 102/100 loss 0.005153 acc 1.000000  rank 2
2025-01-10 21:08:26,658 INFO Epoch 102 Step 99319 CV info lr 0.00015865502624300392 0 rank loss_2.3890279139292003 acc_0.7797806469494837
2025-01-10 21:08:26,661 DEBUG CV Batch 102/100 loss 0.005153 acc 1.000000  rank 1
2025-01-10 21:08:26,750 INFO Epoch 102 Step 99319 CV info lr 0.00015865502624300392 2 rank loss_2.3890279139292003 acc_0.7797806469494837
2025-01-10 21:08:27,220 INFO Epoch 102 Step 99319 CV info lr 0.00015865502624300392 1 rank loss_2.3890279139292003 acc_0.7797806469494837
2025-01-10 21:08:27,939 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_102_whole.pt
2025-01-10 21:08:27,950 INFO Added key: store_based_barrier_key:105 to store for rank: 0
2025-01-10 21:08:27,961 INFO Added key: store_based_barrier_key:105 to store for rank: 2
2025-01-10 21:08:27,961 INFO Added key: store_based_barrier_key:105 to store for rank: 1
2025-01-10 21:08:27,961 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:105 with 3 nodes.
2025-01-10 21:08:27,961 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:105 with 3 nodes.
2025-01-10 21:08:27,961 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:105 with 3 nodes.
2025-01-10 21:08:27,965 INFO Epoch 103 TRAIN info lr 0.00015865502624300392 rank 0
2025-01-10 21:08:27,965 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 21:08:27,965 INFO Epoch 103 TRAIN info lr 0.00015865502624300392 rank 2
2025-01-10 21:08:27,966 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 21:08:27,966 INFO Epoch 103 TRAIN info lr 0.00015865502624300392 rank 1
2025-01-10 21:08:27,966 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 21:09:00,294 DEBUG TRAIN Batch 103/100 loss 0.048643 acc 0.973299 lr 0.00015862 grad_norm 0.426278 rank 2
2025-01-10 21:09:00,295 DEBUG TRAIN Batch 103/100 loss 0.058576 acc 0.960550 lr 0.00015862 grad_norm 0.426278 rank 1
2025-01-10 21:09:00,295 DEBUG TRAIN Batch 103/100 loss 0.044956 acc 0.972763 lr 0.00015862 grad_norm 0.426278 rank 0
2025-01-10 21:09:24,208 DEBUG TRAIN Batch 103/200 loss 0.058341 acc 0.960369 lr 0.00015858 grad_norm 0.428078 rank 0
2025-01-10 21:09:24,208 DEBUG TRAIN Batch 103/200 loss 0.047572 acc 0.970727 lr 0.00015858 grad_norm 0.428078 rank 2
2025-01-10 21:09:24,209 DEBUG TRAIN Batch 103/200 loss 0.036687 acc 0.979567 lr 0.00015858 grad_norm 0.428078 rank 1
2025-01-10 21:09:48,809 DEBUG TRAIN Batch 103/300 loss 0.057930 acc 0.970243 lr 0.00015854 grad_norm 0.439528 rank 1
2025-01-10 21:09:48,809 DEBUG TRAIN Batch 103/300 loss 0.037681 acc 0.971323 lr 0.00015854 grad_norm 0.439528 rank 2
2025-01-10 21:09:48,810 DEBUG TRAIN Batch 103/300 loss 0.051566 acc 0.964509 lr 0.00015854 grad_norm 0.439528 rank 0
2025-01-10 21:10:12,488 DEBUG TRAIN Batch 103/400 loss 0.045117 acc 0.964020 lr 0.00015850 grad_norm 0.469346 rank 1
2025-01-10 21:10:12,489 DEBUG TRAIN Batch 103/400 loss 0.050713 acc 0.963511 lr 0.00015850 grad_norm 0.469346 rank 2
2025-01-10 21:10:12,495 DEBUG TRAIN Batch 103/400 loss 0.052553 acc 0.965804 lr 0.00015850 grad_norm 0.469346 rank 0
2025-01-10 21:10:36,746 DEBUG TRAIN Batch 103/500 loss 0.065662 acc 0.958692 lr 0.00015846 grad_norm 0.431142 rank 1
2025-01-10 21:10:36,746 DEBUG TRAIN Batch 103/500 loss 0.050543 acc 0.960749 lr 0.00015846 grad_norm 0.431142 rank 0
2025-01-10 21:10:36,746 DEBUG TRAIN Batch 103/500 loss 0.049051 acc 0.955806 lr 0.00015846 grad_norm 0.431142 rank 2
2025-01-10 21:11:01,195 DEBUG TRAIN Batch 103/600 loss 0.049698 acc 0.966697 lr 0.00015842 grad_norm 0.424224 rank 1
2025-01-10 21:11:01,195 DEBUG TRAIN Batch 103/600 loss 0.055069 acc 0.959038 lr 0.00015842 grad_norm 0.424224 rank 0
2025-01-10 21:11:01,196 DEBUG TRAIN Batch 103/600 loss 0.056118 acc 0.959624 lr 0.00015842 grad_norm 0.424224 rank 2
2025-01-10 21:11:25,212 DEBUG TRAIN Batch 103/700 loss 0.050513 acc 0.968976 lr 0.00015838 grad_norm 0.430717 rank 2
2025-01-10 21:11:25,212 DEBUG TRAIN Batch 103/700 loss 0.055125 acc 0.960345 lr 0.00015838 grad_norm 0.430717 rank 1
2025-01-10 21:11:25,212 DEBUG TRAIN Batch 103/700 loss 0.043291 acc 0.970136 lr 0.00015838 grad_norm 0.430717 rank 0
2025-01-10 21:11:49,153 DEBUG TRAIN Batch 103/800 loss 0.049439 acc 0.972888 lr 0.00015834 grad_norm 0.450323 rank 0
2025-01-10 21:11:49,154 DEBUG TRAIN Batch 103/800 loss 0.043063 acc 0.970524 lr 0.00015834 grad_norm 0.450323 rank 1
2025-01-10 21:11:49,154 DEBUG TRAIN Batch 103/800 loss 0.073811 acc 0.951510 lr 0.00015834 grad_norm 0.450323 rank 2
2025-01-10 21:12:13,279 DEBUG TRAIN Batch 103/900 loss 0.056835 acc 0.967167 lr 0.00015830 grad_norm 0.448302 rank 1
2025-01-10 21:12:13,279 DEBUG TRAIN Batch 103/900 loss 0.061828 acc 0.954963 lr 0.00015830 grad_norm 0.448302 rank 2
2025-01-10 21:12:13,279 DEBUG TRAIN Batch 103/900 loss 0.048549 acc 0.965580 lr 0.00015830 grad_norm 0.448302 rank 0
2025-01-10 21:12:37,069 DEBUG TRAIN Batch 103/1000 loss 0.051124 acc 0.963616 lr 0.00015826 grad_norm 0.463499 rank 2
2025-01-10 21:12:37,069 DEBUG TRAIN Batch 103/1000 loss 0.051356 acc 0.966254 lr 0.00015826 grad_norm 0.463499 rank 0
2025-01-10 21:12:37,069 DEBUG TRAIN Batch 103/1000 loss 0.051764 acc 0.968614 lr 0.00015826 grad_norm 0.463499 rank 1
2025-01-10 21:13:00,889 DEBUG TRAIN Batch 103/1100 loss 0.048021 acc 0.965061 lr 0.00015822 grad_norm 0.463815 rank 1
2025-01-10 21:13:00,889 DEBUG TRAIN Batch 103/1100 loss 0.053053 acc 0.961456 lr 0.00015822 grad_norm 0.463815 rank 2
2025-01-10 21:13:00,890 DEBUG TRAIN Batch 103/1100 loss 0.069212 acc 0.955816 lr 0.00015822 grad_norm 0.463815 rank 0
2025-01-10 21:13:24,584 DEBUG TRAIN Batch 103/1200 loss 0.039136 acc 0.969849 lr 0.00015818 grad_norm 0.427312 rank 1
2025-01-10 21:13:24,584 DEBUG TRAIN Batch 103/1200 loss 0.063639 acc 0.951336 lr 0.00015818 grad_norm 0.427312 rank 2
2025-01-10 21:13:24,585 DEBUG TRAIN Batch 103/1200 loss 0.048395 acc 0.973684 lr 0.00015818 grad_norm 0.427312 rank 0
2025-01-10 21:13:49,381 DEBUG TRAIN Batch 103/1300 loss 0.060249 acc 0.958596 lr 0.00015814 grad_norm 0.429465 rank 0
2025-01-10 21:13:49,381 DEBUG TRAIN Batch 103/1300 loss 0.057334 acc 0.956014 lr 0.00015814 grad_norm 0.429465 rank 1
2025-01-10 21:13:49,381 DEBUG TRAIN Batch 103/1300 loss 0.049292 acc 0.963899 lr 0.00015814 grad_norm 0.429465 rank 2
2025-01-10 21:14:13,441 DEBUG TRAIN Batch 103/1400 loss 0.042202 acc 0.974237 lr 0.00015810 grad_norm 0.442979 rank 0
2025-01-10 21:14:13,442 DEBUG TRAIN Batch 103/1400 loss 0.073478 acc 0.949912 lr 0.00015810 grad_norm 0.442979 rank 2
2025-01-10 21:14:13,442 DEBUG TRAIN Batch 103/1400 loss 0.055973 acc 0.956522 lr 0.00015810 grad_norm 0.442979 rank 1
2025-01-10 21:14:37,719 DEBUG TRAIN Batch 103/1500 loss 0.068318 acc 0.953125 lr 0.00015806 grad_norm 0.453965 rank 1
2025-01-10 21:14:37,720 DEBUG TRAIN Batch 103/1500 loss 0.049418 acc 0.970796 lr 0.00015806 grad_norm 0.453965 rank 0
2025-01-10 21:14:37,720 DEBUG TRAIN Batch 103/1500 loss 0.075096 acc 0.948787 lr 0.00015806 grad_norm 0.453965 rank 2
2025-01-10 21:15:01,878 DEBUG TRAIN Batch 103/1600 loss 0.050922 acc 0.964801 lr 0.00015802 grad_norm 0.425643 rank 1
2025-01-10 21:15:01,878 DEBUG TRAIN Batch 103/1600 loss 0.056263 acc 0.960123 lr 0.00015802 grad_norm 0.425643 rank 2
2025-01-10 21:15:01,878 DEBUG TRAIN Batch 103/1600 loss 0.037494 acc 0.975419 lr 0.00015802 grad_norm 0.425643 rank 0
2025-01-10 21:15:26,760 DEBUG TRAIN Batch 103/1700 loss 0.061060 acc 0.958297 lr 0.00015798 grad_norm 0.455846 rank 1
2025-01-10 21:15:26,760 DEBUG TRAIN Batch 103/1700 loss 0.043646 acc 0.968627 lr 0.00015798 grad_norm 0.455846 rank 0
2025-01-10 21:15:26,761 DEBUG TRAIN Batch 103/1700 loss 0.054846 acc 0.959954 lr 0.00015798 grad_norm 0.455846 rank 2
2025-01-10 21:15:51,772 DEBUG TRAIN Batch 103/1800 loss 0.047215 acc 0.969697 lr 0.00015794 grad_norm 0.424843 rank 1
2025-01-10 21:15:51,772 DEBUG TRAIN Batch 103/1800 loss 0.051054 acc 0.965606 lr 0.00015794 grad_norm 0.424843 rank 2
2025-01-10 21:15:51,772 DEBUG TRAIN Batch 103/1800 loss 0.035693 acc 0.969253 lr 0.00015794 grad_norm 0.424843 rank 0
2025-01-10 21:16:17,439 DEBUG TRAIN Batch 103/1900 loss 0.036224 acc 0.975322 lr 0.00015790 grad_norm 0.424028 rank 0
2025-01-10 21:16:17,439 DEBUG TRAIN Batch 103/1900 loss 0.049647 acc 0.964539 lr 0.00015790 grad_norm 0.424028 rank 1
2025-01-10 21:16:17,439 DEBUG TRAIN Batch 103/1900 loss 0.048054 acc 0.968872 lr 0.00015790 grad_norm 0.424028 rank 2
2025-01-10 21:16:42,442 DEBUG TRAIN Batch 103/2000 loss 0.045614 acc 0.971453 lr 0.00015786 grad_norm 0.421982 rank 1
2025-01-10 21:16:42,442 DEBUG TRAIN Batch 103/2000 loss 0.056394 acc 0.960222 lr 0.00015786 grad_norm 0.421982 rank 2
2025-01-10 21:16:42,443 DEBUG TRAIN Batch 103/2000 loss 0.033775 acc 0.971088 lr 0.00015786 grad_norm 0.421982 rank 0
2025-01-10 21:17:06,477 DEBUG TRAIN Batch 103/2100 loss 0.054970 acc 0.960074 lr 0.00015782 grad_norm 0.453649 rank 1
2025-01-10 21:17:06,477 DEBUG TRAIN Batch 103/2100 loss 0.067483 acc 0.952424 lr 0.00015782 grad_norm 0.453649 rank 2
2025-01-10 21:17:06,478 DEBUG TRAIN Batch 103/2100 loss 0.052661 acc 0.969003 lr 0.00015782 grad_norm 0.453649 rank 0
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 21:18:25,372 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 21:18:25,373 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 21:18:25,663 INFO Epoch 103 Step 100405 on_batch_end True CV rank 2
2025-01-10 21:18:25,663 INFO Epoch 103 Step 100405 on_batch_end True CV rank 0
2025-01-10 21:18:25,663 INFO Epoch 103 Step 100405 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 21:18:34,785 DEBUG CV Batch 103/100 loss 0.011500 acc 0.996656  rank 0
2025-01-10 21:18:35,000 DEBUG CV Batch 103/100 loss 0.011500 acc 0.996656  rank 2
2025-01-10 21:18:35,295 INFO Epoch 103 Step 100405 CV info lr 0.0001577946716731772 0 rank loss_2.396657886074472 acc_0.7791396099747273
2025-01-10 21:18:35,409 DEBUG CV Batch 103/100 loss 0.011500 acc 0.996656  rank 1
2025-01-10 21:18:35,531 INFO Epoch 103 Step 100405 CV info lr 0.0001577946716731772 2 rank loss_2.396657886074472 acc_0.7791396099747273
2025-01-10 21:18:35,954 INFO Epoch 103 Step 100405 CV info lr 0.0001577946716731772 1 rank loss_2.396657886074472 acc_0.7791396099747273
2025-01-10 21:18:36,593 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_103_whole.pt
2025-01-10 21:18:36,614 INFO Added key: store_based_barrier_key:106 to store for rank: 0
2025-01-10 21:18:36,614 INFO Added key: store_based_barrier_key:106 to store for rank: 1
2025-01-10 21:18:36,614 INFO Added key: store_based_barrier_key:106 to store for rank: 2
2025-01-10 21:18:36,615 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:106 with 3 nodes.
2025-01-10 21:18:36,615 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:106 with 3 nodes.
2025-01-10 21:18:36,616 INFO Epoch 104 TRAIN info lr 0.0001577946716731772 rank 2
2025-01-10 21:18:36,616 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 21:18:36,624 INFO Epoch 104 TRAIN info lr 0.0001577946716731772 rank 1
2025-01-10 21:18:36,624 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 21:18:36,625 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:106 with 3 nodes.
2025-01-10 21:18:36,635 INFO Epoch 104 TRAIN info lr 0.0001577946716731772 rank 0
2025-01-10 21:18:36,635 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 21:19:11,081 DEBUG TRAIN Batch 104/100 loss 0.044261 acc 0.969940 lr 0.00015776 grad_norm 0.447527 rank 0
2025-01-10 21:19:11,081 DEBUG TRAIN Batch 104/100 loss 0.062597 acc 0.954783 lr 0.00015776 grad_norm 0.447527 rank 1
2025-01-10 21:19:11,081 DEBUG TRAIN Batch 104/100 loss 0.059456 acc 0.966422 lr 0.00015776 grad_norm 0.447527 rank 2
2025-01-10 21:19:35,462 DEBUG TRAIN Batch 104/200 loss 0.059953 acc 0.957858 lr 0.00015772 grad_norm 0.413203 rank 0
2025-01-10 21:19:35,462 DEBUG TRAIN Batch 104/200 loss 0.035160 acc 0.976010 lr 0.00015772 grad_norm 0.413203 rank 2
2025-01-10 21:19:35,462 DEBUG TRAIN Batch 104/200 loss 0.030759 acc 0.981641 lr 0.00015772 grad_norm 0.413203 rank 1
2025-01-10 21:20:00,846 DEBUG TRAIN Batch 104/300 loss 0.054226 acc 0.964117 lr 0.00015768 grad_norm 0.417119 rank 2
2025-01-10 21:20:00,846 DEBUG TRAIN Batch 104/300 loss 0.041441 acc 0.970135 lr 0.00015768 grad_norm 0.417119 rank 0
2025-01-10 21:20:00,846 DEBUG TRAIN Batch 104/300 loss 0.042544 acc 0.966543 lr 0.00015768 grad_norm 0.417119 rank 1
2025-01-10 21:20:25,063 DEBUG TRAIN Batch 104/400 loss 0.035143 acc 0.972160 lr 0.00015764 grad_norm 0.397194 rank 0
2025-01-10 21:20:25,064 DEBUG TRAIN Batch 104/400 loss 0.034380 acc 0.976166 lr 0.00015764 grad_norm 0.397194 rank 2
2025-01-10 21:20:25,064 DEBUG TRAIN Batch 104/400 loss 0.045223 acc 0.972665 lr 0.00015764 grad_norm 0.397194 rank 1
2025-01-10 21:20:49,364 DEBUG TRAIN Batch 104/500 loss 0.061985 acc 0.959285 lr 0.00015760 grad_norm 0.459378 rank 1
2025-01-10 21:20:49,365 DEBUG TRAIN Batch 104/500 loss 0.029571 acc 0.979730 lr 0.00015760 grad_norm 0.459378 rank 0
2025-01-10 21:20:49,365 DEBUG TRAIN Batch 104/500 loss 0.062292 acc 0.959350 lr 0.00015760 grad_norm 0.459378 rank 2
2025-01-10 21:21:14,016 DEBUG TRAIN Batch 104/600 loss 0.066702 acc 0.961772 lr 0.00015756 grad_norm 0.417964 rank 1
2025-01-10 21:21:14,016 DEBUG TRAIN Batch 104/600 loss 0.044505 acc 0.964789 lr 0.00015756 grad_norm 0.417964 rank 2
2025-01-10 21:21:14,017 DEBUG TRAIN Batch 104/600 loss 0.051506 acc 0.962145 lr 0.00015756 grad_norm 0.417964 rank 0
2025-01-10 21:21:38,539 DEBUG TRAIN Batch 104/700 loss 0.045260 acc 0.967262 lr 0.00015752 grad_norm 0.420144 rank 2
2025-01-10 21:21:38,539 DEBUG TRAIN Batch 104/700 loss 0.051048 acc 0.963605 lr 0.00015752 grad_norm 0.420144 rank 0
2025-01-10 21:21:38,539 DEBUG TRAIN Batch 104/700 loss 0.069608 acc 0.953289 lr 0.00015752 grad_norm 0.420144 rank 1
2025-01-10 21:22:03,127 DEBUG TRAIN Batch 104/800 loss 0.056438 acc 0.955483 lr 0.00015748 grad_norm 0.451045 rank 1
2025-01-10 21:22:03,127 DEBUG TRAIN Batch 104/800 loss 0.054739 acc 0.964835 lr 0.00015748 grad_norm 0.451045 rank 2
2025-01-10 21:22:03,127 DEBUG TRAIN Batch 104/800 loss 0.051479 acc 0.967652 lr 0.00015748 grad_norm 0.451045 rank 0
2025-01-10 21:22:26,887 DEBUG TRAIN Batch 104/900 loss 0.051522 acc 0.959459 lr 0.00015744 grad_norm 0.426295 rank 1
2025-01-10 21:22:26,887 DEBUG TRAIN Batch 104/900 loss 0.035470 acc 0.975238 lr 0.00015744 grad_norm 0.426295 rank 2
2025-01-10 21:22:26,887 DEBUG TRAIN Batch 104/900 loss 0.054967 acc 0.970501 lr 0.00015744 grad_norm 0.426295 rank 0
2025-01-10 21:22:51,112 DEBUG TRAIN Batch 104/1000 loss 0.059862 acc 0.957885 lr 0.00015740 grad_norm 0.446873 rank 0
2025-01-10 21:22:51,112 DEBUG TRAIN Batch 104/1000 loss 0.056683 acc 0.965473 lr 0.00015740 grad_norm 0.446873 rank 1
2025-01-10 21:22:51,112 DEBUG TRAIN Batch 104/1000 loss 0.037231 acc 0.971396 lr 0.00015740 grad_norm 0.446873 rank 2
2025-01-10 21:23:15,102 DEBUG TRAIN Batch 104/1100 loss 0.044231 acc 0.969697 lr 0.00015736 grad_norm 0.444036 rank 1
2025-01-10 21:23:15,102 DEBUG TRAIN Batch 104/1100 loss 0.052855 acc 0.963570 lr 0.00015736 grad_norm 0.444036 rank 2
2025-01-10 21:23:15,105 DEBUG TRAIN Batch 104/1100 loss 0.059058 acc 0.953991 lr 0.00015736 grad_norm 0.444036 rank 0
2025-01-10 21:23:39,617 DEBUG TRAIN Batch 104/1200 loss 0.060129 acc 0.958410 lr 0.00015733 grad_norm 0.465028 rank 1
2025-01-10 21:23:39,618 DEBUG TRAIN Batch 104/1200 loss 0.062420 acc 0.954389 lr 0.00015733 grad_norm 0.465028 rank 0
2025-01-10 21:23:39,618 DEBUG TRAIN Batch 104/1200 loss 0.065236 acc 0.951784 lr 0.00015733 grad_norm 0.465028 rank 2
2025-01-10 21:24:04,218 DEBUG TRAIN Batch 104/1300 loss 0.042771 acc 0.968313 lr 0.00015729 grad_norm 0.438248 rank 2
2025-01-10 21:24:04,219 DEBUG TRAIN Batch 104/1300 loss 0.043322 acc 0.964117 lr 0.00015729 grad_norm 0.438248 rank 1
2025-01-10 21:24:04,219 DEBUG TRAIN Batch 104/1300 loss 0.041070 acc 0.962930 lr 0.00015729 grad_norm 0.438248 rank 0
2025-01-10 21:24:27,696 DEBUG TRAIN Batch 104/1400 loss 0.059388 acc 0.948744 lr 0.00015725 grad_norm 0.469923 rank 1
2025-01-10 21:24:27,696 DEBUG TRAIN Batch 104/1400 loss 0.051613 acc 0.964248 lr 0.00015725 grad_norm 0.469923 rank 0
2025-01-10 21:24:27,697 DEBUG TRAIN Batch 104/1400 loss 0.056279 acc 0.965458 lr 0.00015725 grad_norm 0.469923 rank 2
2025-01-10 21:24:51,777 DEBUG TRAIN Batch 104/1500 loss 0.035238 acc 0.974074 lr 0.00015721 grad_norm 0.450920 rank 2
2025-01-10 21:24:51,777 DEBUG TRAIN Batch 104/1500 loss 0.061633 acc 0.960379 lr 0.00015721 grad_norm 0.450920 rank 0
2025-01-10 21:24:51,777 DEBUG TRAIN Batch 104/1500 loss 0.042978 acc 0.974215 lr 0.00015721 grad_norm 0.450920 rank 1
2025-01-10 21:25:16,114 DEBUG TRAIN Batch 104/1600 loss 0.062673 acc 0.953774 lr 0.00015717 grad_norm 0.441875 rank 2
2025-01-10 21:25:16,114 DEBUG TRAIN Batch 104/1600 loss 0.050471 acc 0.973415 lr 0.00015717 grad_norm 0.441875 rank 0
2025-01-10 21:25:16,115 DEBUG TRAIN Batch 104/1600 loss 0.044617 acc 0.970288 lr 0.00015717 grad_norm 0.441875 rank 1
2025-01-10 21:25:40,333 DEBUG TRAIN Batch 104/1700 loss 0.044961 acc 0.971645 lr 0.00015713 grad_norm 0.453440 rank 0
2025-01-10 21:25:40,333 DEBUG TRAIN Batch 104/1700 loss 0.054225 acc 0.965342 lr 0.00015713 grad_norm 0.453440 rank 1
2025-01-10 21:25:40,333 DEBUG TRAIN Batch 104/1700 loss 0.060189 acc 0.955169 lr 0.00015713 grad_norm 0.453440 rank 2
2025-01-10 21:26:03,945 DEBUG TRAIN Batch 104/1800 loss 0.053139 acc 0.963801 lr 0.00015709 grad_norm 0.434277 rank 0
2025-01-10 21:26:03,945 DEBUG TRAIN Batch 104/1800 loss 0.058319 acc 0.958446 lr 0.00015709 grad_norm 0.434277 rank 1
2025-01-10 21:26:03,945 DEBUG TRAIN Batch 104/1800 loss 0.056582 acc 0.956642 lr 0.00015709 grad_norm 0.434277 rank 2
2025-01-10 21:26:28,138 DEBUG TRAIN Batch 104/1900 loss 0.042900 acc 0.972938 lr 0.00015705 grad_norm 0.433485 rank 2
2025-01-10 21:26:28,138 DEBUG TRAIN Batch 104/1900 loss 0.042798 acc 0.965673 lr 0.00015705 grad_norm 0.433485 rank 0
2025-01-10 21:26:28,138 DEBUG TRAIN Batch 104/1900 loss 0.032905 acc 0.981278 lr 0.00015705 grad_norm 0.433485 rank 1
2025-01-10 21:26:52,935 DEBUG TRAIN Batch 104/2000 loss 0.048078 acc 0.960446 lr 0.00015701 grad_norm 0.466826 rank 2
2025-01-10 21:26:52,935 DEBUG TRAIN Batch 104/2000 loss 0.057831 acc 0.958376 lr 0.00015701 grad_norm 0.466826 rank 0
2025-01-10 21:26:52,935 DEBUG TRAIN Batch 104/2000 loss 0.033361 acc 0.976994 lr 0.00015701 grad_norm 0.466826 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 21:28:00,890 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59981ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 21:28:00,916 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 21:28:01,357 INFO Epoch 104 Step 101421 on_batch_end True CV rank 0
2025-01-10 21:28:01,357 INFO Epoch 104 Step 101421 on_batch_end True CV rank 1
2025-01-10 21:28:01,357 INFO Epoch 104 Step 101421 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 21:28:10,479 DEBUG CV Batch 104/100 loss 0.007357 acc 1.000000  rank 0
2025-01-10 21:28:10,833 DEBUG CV Batch 104/100 loss 0.007357 acc 1.000000  rank 2
2025-01-10 21:28:10,994 INFO Epoch 104 Step 101421 CV info lr 0.00015700231646066643 0 rank loss_2.4080232085165845 acc_0.778159917446605
2025-01-10 21:28:11,128 DEBUG CV Batch 104/100 loss 0.007357 acc 1.000000  rank 1
2025-01-10 21:28:11,390 INFO Epoch 104 Step 101421 CV info lr 0.00015700231646066643 2 rank loss_2.4080232085165845 acc_0.778159917446605
2025-01-10 21:28:11,690 INFO Epoch 104 Step 101421 CV info lr 0.00015700231646066643 1 rank loss_2.4080232085165845 acc_0.778159917446605
2025-01-10 21:28:12,289 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_104_whole.pt
2025-01-10 21:28:12,311 INFO Added key: store_based_barrier_key:107 to store for rank: 0
2025-01-10 21:28:12,321 INFO Added key: store_based_barrier_key:107 to store for rank: 2
2025-01-10 21:28:12,321 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:107 with 3 nodes.
2025-01-10 21:28:12,321 INFO Added key: store_based_barrier_key:107 to store for rank: 1
2025-01-10 21:28:12,321 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:107 with 3 nodes.
2025-01-10 21:28:12,322 INFO Epoch 105 TRAIN info lr 0.00015700231646066643 rank 1
2025-01-10 21:28:12,322 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 21:28:12,324 INFO Epoch 105 TRAIN info lr 0.00015700231646066643 rank 2
2025-01-10 21:28:12,324 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 21:28:12,331 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:107 with 3 nodes.
2025-01-10 21:28:12,342 INFO Epoch 105 TRAIN info lr 0.00015700231646066643 rank 0
2025-01-10 21:28:12,342 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 21:28:43,203 DEBUG TRAIN Batch 105/100 loss 0.046673 acc 0.968037 lr 0.00015696 grad_norm 0.424027 rank 0
2025-01-10 21:28:43,203 DEBUG TRAIN Batch 105/100 loss 0.043692 acc 0.970588 lr 0.00015696 grad_norm 0.424027 rank 1
2025-01-10 21:28:43,203 DEBUG TRAIN Batch 105/100 loss 0.057434 acc 0.964896 lr 0.00015696 grad_norm 0.424027 rank 2
2025-01-10 21:29:07,043 DEBUG TRAIN Batch 105/200 loss 0.030362 acc 0.976834 lr 0.00015692 grad_norm 0.423368 rank 1
2025-01-10 21:29:07,043 DEBUG TRAIN Batch 105/200 loss 0.054390 acc 0.965233 lr 0.00015692 grad_norm 0.423368 rank 2
2025-01-10 21:29:07,043 DEBUG TRAIN Batch 105/200 loss 0.034474 acc 0.969697 lr 0.00015692 grad_norm 0.423368 rank 0
2025-01-10 21:29:30,762 DEBUG TRAIN Batch 105/300 loss 0.058625 acc 0.955224 lr 0.00015689 grad_norm 0.428652 rank 2
2025-01-10 21:29:30,762 DEBUG TRAIN Batch 105/300 loss 0.043643 acc 0.973874 lr 0.00015689 grad_norm 0.428652 rank 0
2025-01-10 21:29:30,763 DEBUG TRAIN Batch 105/300 loss 0.046684 acc 0.964809 lr 0.00015689 grad_norm 0.428652 rank 1
2025-01-10 21:29:54,766 DEBUG TRAIN Batch 105/400 loss 0.049366 acc 0.966435 lr 0.00015685 grad_norm 0.443410 rank 0
2025-01-10 21:29:54,766 DEBUG TRAIN Batch 105/400 loss 0.052383 acc 0.965440 lr 0.00015685 grad_norm 0.443410 rank 1
2025-01-10 21:29:54,766 DEBUG TRAIN Batch 105/400 loss 0.055344 acc 0.963458 lr 0.00015685 grad_norm 0.443410 rank 2
2025-01-10 21:30:19,245 DEBUG TRAIN Batch 105/500 loss 0.050819 acc 0.965054 lr 0.00015681 grad_norm 0.416372 rank 0
2025-01-10 21:30:19,245 DEBUG TRAIN Batch 105/500 loss 0.023867 acc 0.979266 lr 0.00015681 grad_norm 0.416372 rank 1
2025-01-10 21:30:19,245 DEBUG TRAIN Batch 105/500 loss 0.051439 acc 0.963323 lr 0.00015681 grad_norm 0.416372 rank 2
2025-01-10 21:30:43,688 DEBUG TRAIN Batch 105/600 loss 0.052000 acc 0.967343 lr 0.00015677 grad_norm 0.426425 rank 2
2025-01-10 21:30:43,688 DEBUG TRAIN Batch 105/600 loss 0.071973 acc 0.949212 lr 0.00015677 grad_norm 0.426425 rank 0
2025-01-10 21:30:43,688 DEBUG TRAIN Batch 105/600 loss 0.042695 acc 0.967368 lr 0.00015677 grad_norm 0.426425 rank 1
2025-01-10 21:31:07,798 DEBUG TRAIN Batch 105/700 loss 0.061584 acc 0.963478 lr 0.00015673 grad_norm 0.465273 rank 1
2025-01-10 21:31:07,798 DEBUG TRAIN Batch 105/700 loss 0.052348 acc 0.960265 lr 0.00015673 grad_norm 0.465273 rank 0
2025-01-10 21:31:07,798 DEBUG TRAIN Batch 105/700 loss 0.052570 acc 0.967003 lr 0.00015673 grad_norm 0.465273 rank 2
2025-01-10 21:31:32,719 DEBUG TRAIN Batch 105/800 loss 0.042449 acc 0.974747 lr 0.00015669 grad_norm 0.450571 rank 2
2025-01-10 21:31:32,719 DEBUG TRAIN Batch 105/800 loss 0.060909 acc 0.962928 lr 0.00015669 grad_norm 0.450571 rank 1
2025-01-10 21:31:32,719 DEBUG TRAIN Batch 105/800 loss 0.053447 acc 0.962693 lr 0.00015669 grad_norm 0.450571 rank 0
2025-01-10 21:31:57,021 DEBUG TRAIN Batch 105/900 loss 0.046519 acc 0.970854 lr 0.00015666 grad_norm 0.484071 rank 1
2025-01-10 21:31:57,021 DEBUG TRAIN Batch 105/900 loss 0.049279 acc 0.968290 lr 0.00015666 grad_norm 0.484071 rank 2
2025-01-10 21:31:57,022 DEBUG TRAIN Batch 105/900 loss 0.060894 acc 0.961233 lr 0.00015666 grad_norm 0.484071 rank 0
2025-01-10 21:32:21,344 DEBUG TRAIN Batch 105/1000 loss 0.047136 acc 0.965930 lr 0.00015662 grad_norm 0.402801 rank 2
2025-01-10 21:32:21,345 DEBUG TRAIN Batch 105/1000 loss 0.045340 acc 0.971143 lr 0.00015662 grad_norm 0.402801 rank 0
2025-01-10 21:32:21,345 DEBUG TRAIN Batch 105/1000 loss 0.037975 acc 0.973044 lr 0.00015662 grad_norm 0.402801 rank 1
2025-01-10 21:32:44,974 DEBUG TRAIN Batch 105/1100 loss 0.037116 acc 0.976331 lr 0.00015658 grad_norm 0.428030 rank 2
2025-01-10 21:32:44,975 DEBUG TRAIN Batch 105/1100 loss 0.050334 acc 0.967156 lr 0.00015658 grad_norm 0.428030 rank 0
2025-01-10 21:32:44,975 DEBUG TRAIN Batch 105/1100 loss 0.066383 acc 0.955397 lr 0.00015658 grad_norm 0.428030 rank 1
2025-01-10 21:33:08,644 DEBUG TRAIN Batch 105/1200 loss 0.051127 acc 0.962591 lr 0.00015654 grad_norm 0.419445 rank 2
2025-01-10 21:33:08,644 DEBUG TRAIN Batch 105/1200 loss 0.058398 acc 0.957784 lr 0.00015654 grad_norm 0.419445 rank 0
2025-01-10 21:33:08,644 DEBUG TRAIN Batch 105/1200 loss 0.053993 acc 0.963327 lr 0.00015654 grad_norm 0.419445 rank 1
2025-01-10 21:33:32,232 DEBUG TRAIN Batch 105/1300 loss 0.052187 acc 0.962924 lr 0.00015650 grad_norm 0.423325 rank 1
2025-01-10 21:33:32,232 DEBUG TRAIN Batch 105/1300 loss 0.024969 acc 0.983640 lr 0.00015650 grad_norm 0.423325 rank 0
2025-01-10 21:33:32,232 DEBUG TRAIN Batch 105/1300 loss 0.055894 acc 0.964585 lr 0.00015650 grad_norm 0.423325 rank 2
2025-01-10 21:33:56,028 DEBUG TRAIN Batch 105/1400 loss 0.054048 acc 0.966028 lr 0.00015646 grad_norm 0.413477 rank 2
2025-01-10 21:33:56,028 DEBUG TRAIN Batch 105/1400 loss 0.034428 acc 0.980973 lr 0.00015646 grad_norm 0.413477 rank 0
2025-01-10 21:33:56,029 DEBUG TRAIN Batch 105/1400 loss 0.043593 acc 0.966919 lr 0.00015646 grad_norm 0.413477 rank 1
2025-01-10 21:34:20,738 DEBUG TRAIN Batch 105/1500 loss 0.024280 acc 0.983051 lr 0.00015643 grad_norm 0.416735 rank 0
2025-01-10 21:34:20,738 DEBUG TRAIN Batch 105/1500 loss 0.038204 acc 0.972035 lr 0.00015643 grad_norm 0.416735 rank 1
2025-01-10 21:34:20,738 DEBUG TRAIN Batch 105/1500 loss 0.045999 acc 0.967742 lr 0.00015643 grad_norm 0.416735 rank 2
2025-01-10 21:34:44,667 DEBUG TRAIN Batch 105/1600 loss 0.071072 acc 0.953888 lr 0.00015639 grad_norm 0.446126 rank 2
2025-01-10 21:34:44,667 DEBUG TRAIN Batch 105/1600 loss 0.044874 acc 0.976012 lr 0.00015639 grad_norm 0.446126 rank 0
2025-01-10 21:34:44,668 DEBUG TRAIN Batch 105/1600 loss 0.046202 acc 0.968623 lr 0.00015639 grad_norm 0.446126 rank 1
2025-01-10 21:35:08,918 DEBUG TRAIN Batch 105/1700 loss 0.050306 acc 0.962963 lr 0.00015635 grad_norm 0.496687 rank 2
2025-01-10 21:35:08,918 DEBUG TRAIN Batch 105/1700 loss 0.051288 acc 0.966975 lr 0.00015635 grad_norm 0.496687 rank 0
2025-01-10 21:35:08,918 DEBUG TRAIN Batch 105/1700 loss 0.055601 acc 0.951740 lr 0.00015635 grad_norm 0.496687 rank 1
2025-01-10 21:35:35,110 DEBUG TRAIN Batch 105/1800 loss 0.047227 acc 0.967675 lr 0.00015631 grad_norm 0.459902 rank 0
2025-01-10 21:35:35,110 DEBUG TRAIN Batch 105/1800 loss 0.042128 acc 0.964286 lr 0.00015631 grad_norm 0.459902 rank 2
2025-01-10 21:35:35,110 DEBUG TRAIN Batch 105/1800 loss 0.061303 acc 0.959641 lr 0.00015631 grad_norm 0.459902 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 21:36:48,629 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59976ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 21:36:48,647 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 21:36:49,161 INFO Epoch 105 Step 102348 on_batch_end True CV rank 1
2025-01-10 21:36:49,161 INFO Epoch 105 Step 102348 on_batch_end True CV rank 0
2025-01-10 21:36:49,161 INFO Epoch 105 Step 102348 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 21:36:58,104 DEBUG CV Batch 105/100 loss 0.008087 acc 0.997770  rank 0
2025-01-10 21:36:58,652 INFO Epoch 105 Step 102348 CV info lr 0.00015628968796773692 0 rank loss_2.4095530953486 acc_0.7784041347995139
2025-01-10 21:36:58,780 DEBUG CV Batch 105/100 loss 0.008087 acc 0.997770  rank 2
2025-01-10 21:36:59,107 DEBUG CV Batch 105/100 loss 0.008087 acc 0.997770  rank 1
2025-01-10 21:36:59,316 INFO Epoch 105 Step 102348 CV info lr 0.00015628968796773692 2 rank loss_2.4095530953486 acc_0.7784041347995139
2025-01-10 21:36:59,637 INFO Epoch 105 Step 102348 CV info lr 0.00015628968796773692 1 rank loss_2.4095530953486 acc_0.7784041347995139
2025-01-10 21:36:59,936 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_105_whole.pt
2025-01-10 21:36:59,958 INFO Added key: store_based_barrier_key:108 to store for rank: 0
2025-01-10 21:36:59,958 INFO Added key: store_based_barrier_key:108 to store for rank: 1
2025-01-10 21:36:59,958 INFO Added key: store_based_barrier_key:108 to store for rank: 2
2025-01-10 21:36:59,958 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:108 with 3 nodes.
2025-01-10 21:36:59,962 INFO Epoch 106 TRAIN info lr 0.00015628968796773692 rank 2
2025-01-10 21:36:59,962 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 21:36:59,968 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:108 with 3 nodes.
2025-01-10 21:36:59,968 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:108 with 3 nodes.
2025-01-10 21:36:59,972 INFO Epoch 106 TRAIN info lr 0.00015628968796773692 rank 1
2025-01-10 21:36:59,972 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 21:36:59,975 INFO Epoch 106 TRAIN info lr 0.00015628968796773692 rank 0
2025-01-10 21:36:59,975 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 21:37:36,841 DEBUG TRAIN Batch 106/100 loss 0.037176 acc 0.970555 lr 0.00015625 grad_norm 0.397083 rank 1
2025-01-10 21:37:36,841 DEBUG TRAIN Batch 106/100 loss 0.044344 acc 0.967480 lr 0.00015625 grad_norm 0.397083 rank 0
2025-01-10 21:37:36,842 DEBUG TRAIN Batch 106/100 loss 0.046447 acc 0.966565 lr 0.00015625 grad_norm 0.397083 rank 2
2025-01-10 21:38:01,011 DEBUG TRAIN Batch 106/200 loss 0.043450 acc 0.972758 lr 0.00015621 grad_norm 0.403077 rank 1
2025-01-10 21:38:01,011 DEBUG TRAIN Batch 106/200 loss 0.039283 acc 0.969458 lr 0.00015621 grad_norm 0.403077 rank 2
2025-01-10 21:38:01,011 DEBUG TRAIN Batch 106/200 loss 0.034381 acc 0.977186 lr 0.00015621 grad_norm 0.403077 rank 0
2025-01-10 21:38:26,178 DEBUG TRAIN Batch 106/300 loss 0.039546 acc 0.979859 lr 0.00015618 grad_norm 0.419621 rank 0
2025-01-10 21:38:26,178 DEBUG TRAIN Batch 106/300 loss 0.044594 acc 0.967213 lr 0.00015618 grad_norm 0.419621 rank 2
2025-01-10 21:38:26,178 DEBUG TRAIN Batch 106/300 loss 0.032220 acc 0.977742 lr 0.00015618 grad_norm 0.419621 rank 1
2025-01-10 21:38:50,452 DEBUG TRAIN Batch 106/400 loss 0.042825 acc 0.971237 lr 0.00015614 grad_norm 0.405635 rank 2
2025-01-10 21:38:50,452 DEBUG TRAIN Batch 106/400 loss 0.053769 acc 0.966667 lr 0.00015614 grad_norm 0.405635 rank 1
2025-01-10 21:38:50,453 DEBUG TRAIN Batch 106/400 loss 0.048411 acc 0.963907 lr 0.00015614 grad_norm 0.405635 rank 0
2025-01-10 21:39:15,409 DEBUG TRAIN Batch 106/500 loss 0.055742 acc 0.960181 lr 0.00015610 grad_norm 0.438271 rank 1
2025-01-10 21:39:15,409 DEBUG TRAIN Batch 106/500 loss 0.041515 acc 0.973206 lr 0.00015610 grad_norm 0.438271 rank 0
2025-01-10 21:39:15,409 DEBUG TRAIN Batch 106/500 loss 0.047747 acc 0.967442 lr 0.00015610 grad_norm 0.438271 rank 2
2025-01-10 21:39:40,696 DEBUG TRAIN Batch 106/600 loss 0.039241 acc 0.972783 lr 0.00015606 grad_norm 0.425441 rank 2
2025-01-10 21:39:40,696 DEBUG TRAIN Batch 106/600 loss 0.053148 acc 0.969154 lr 0.00015606 grad_norm 0.425441 rank 1
2025-01-10 21:39:40,696 DEBUG TRAIN Batch 106/600 loss 0.046681 acc 0.972112 lr 0.00015606 grad_norm 0.425441 rank 0
2025-01-10 21:40:05,367 DEBUG TRAIN Batch 106/700 loss 0.037560 acc 0.972826 lr 0.00015602 grad_norm 0.417397 rank 1
2025-01-10 21:40:05,367 DEBUG TRAIN Batch 106/700 loss 0.059967 acc 0.960000 lr 0.00015602 grad_norm 0.417397 rank 2
2025-01-10 21:40:05,367 DEBUG TRAIN Batch 106/700 loss 0.045508 acc 0.965517 lr 0.00015602 grad_norm 0.417397 rank 0
2025-01-10 21:40:30,661 DEBUG TRAIN Batch 106/800 loss 0.055285 acc 0.961896 lr 0.00015599 grad_norm 0.438302 rank 2
2025-01-10 21:40:30,662 DEBUG TRAIN Batch 106/800 loss 0.054923 acc 0.959566 lr 0.00015599 grad_norm 0.438302 rank 1
2025-01-10 21:40:30,662 DEBUG TRAIN Batch 106/800 loss 0.048861 acc 0.971287 lr 0.00015599 grad_norm 0.438302 rank 0
2025-01-10 21:40:54,438 DEBUG TRAIN Batch 106/900 loss 0.044596 acc 0.969538 lr 0.00015595 grad_norm 0.445879 rank 0
2025-01-10 21:40:54,438 DEBUG TRAIN Batch 106/900 loss 0.057346 acc 0.958654 lr 0.00015595 grad_norm 0.445879 rank 2
2025-01-10 21:40:54,438 DEBUG TRAIN Batch 106/900 loss 0.051435 acc 0.963170 lr 0.00015595 grad_norm 0.445879 rank 1
2025-01-10 21:41:18,441 DEBUG TRAIN Batch 106/1000 loss 0.051873 acc 0.963190 lr 0.00015591 grad_norm 0.442867 rank 1
2025-01-10 21:41:18,441 DEBUG TRAIN Batch 106/1000 loss 0.043654 acc 0.970335 lr 0.00015591 grad_norm 0.442867 rank 2
2025-01-10 21:41:18,441 DEBUG TRAIN Batch 106/1000 loss 0.040917 acc 0.970677 lr 0.00015591 grad_norm 0.442867 rank 0
2025-01-10 21:41:43,572 DEBUG TRAIN Batch 106/1100 loss 0.036148 acc 0.976136 lr 0.00015587 grad_norm 0.415939 rank 1
2025-01-10 21:41:43,572 DEBUG TRAIN Batch 106/1100 loss 0.058667 acc 0.957560 lr 0.00015587 grad_norm 0.415939 rank 0
2025-01-10 21:41:43,573 DEBUG TRAIN Batch 106/1100 loss 0.045057 acc 0.960360 lr 0.00015587 grad_norm 0.415939 rank 2
2025-01-10 21:42:08,199 DEBUG TRAIN Batch 106/1200 loss 0.045432 acc 0.968781 lr 0.00015583 grad_norm 0.420622 rank 2
2025-01-10 21:42:08,200 DEBUG TRAIN Batch 106/1200 loss 0.050039 acc 0.962891 lr 0.00015583 grad_norm 0.420622 rank 0
2025-01-10 21:42:08,200 DEBUG TRAIN Batch 106/1200 loss 0.039955 acc 0.975791 lr 0.00015583 grad_norm 0.420622 rank 1
2025-01-10 21:42:32,039 DEBUG TRAIN Batch 106/1300 loss 0.038777 acc 0.971223 lr 0.00015580 grad_norm 0.440996 rank 1
2025-01-10 21:42:32,040 DEBUG TRAIN Batch 106/1300 loss 0.050265 acc 0.968984 lr 0.00015580 grad_norm 0.440996 rank 0
2025-01-10 21:42:32,040 DEBUG TRAIN Batch 106/1300 loss 0.057428 acc 0.960458 lr 0.00015580 grad_norm 0.440996 rank 2
2025-01-10 21:42:56,310 DEBUG TRAIN Batch 106/1400 loss 0.033983 acc 0.978448 lr 0.00015576 grad_norm 0.414336 rank 1
2025-01-10 21:42:56,310 DEBUG TRAIN Batch 106/1400 loss 0.053454 acc 0.961538 lr 0.00015576 grad_norm 0.414336 rank 0
2025-01-10 21:42:56,311 DEBUG TRAIN Batch 106/1400 loss 0.047182 acc 0.974874 lr 0.00015576 grad_norm 0.414336 rank 2
2025-01-10 21:43:21,101 DEBUG TRAIN Batch 106/1500 loss 0.038890 acc 0.971545 lr 0.00015572 grad_norm 0.431201 rank 1
2025-01-10 21:43:21,101 DEBUG TRAIN Batch 106/1500 loss 0.080630 acc 0.944601 lr 0.00015572 grad_norm 0.431201 rank 0
2025-01-10 21:43:21,101 DEBUG TRAIN Batch 106/1500 loss 0.042357 acc 0.973003 lr 0.00015572 grad_norm 0.431201 rank 2
2025-01-10 21:43:45,286 DEBUG TRAIN Batch 106/1600 loss 0.062782 acc 0.953084 lr 0.00015568 grad_norm 0.438027 rank 1
2025-01-10 21:43:45,286 DEBUG TRAIN Batch 106/1600 loss 0.037671 acc 0.975042 lr 0.00015568 grad_norm 0.438027 rank 0
2025-01-10 21:43:45,287 DEBUG TRAIN Batch 106/1600 loss 0.035707 acc 0.976804 lr 0.00015568 grad_norm 0.438027 rank 2
2025-01-10 21:44:09,278 DEBUG TRAIN Batch 106/1700 loss 0.034245 acc 0.975782 lr 0.00015564 grad_norm 0.442070 rank 1
2025-01-10 21:44:09,278 DEBUG TRAIN Batch 106/1700 loss 0.058412 acc 0.956933 lr 0.00015564 grad_norm 0.442070 rank 0
2025-01-10 21:44:09,279 DEBUG TRAIN Batch 106/1700 loss 0.044946 acc 0.969792 lr 0.00015564 grad_norm 0.442070 rank 2
2025-01-10 21:44:33,782 DEBUG TRAIN Batch 106/1800 loss 0.056480 acc 0.961233 lr 0.00015561 grad_norm 0.455021 rank 1
2025-01-10 21:44:33,782 DEBUG TRAIN Batch 106/1800 loss 0.070757 acc 0.954669 lr 0.00015561 grad_norm 0.455021 rank 0
2025-01-10 21:44:33,782 DEBUG TRAIN Batch 106/1800 loss 0.022662 acc 0.985669 lr 0.00015561 grad_norm 0.455021 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 21:45:49,626 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 21:45:49,640 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 21:45:50,121 INFO Epoch 106 Step 103281 on_batch_end True CV rank 2
2025-01-10 21:45:50,121 INFO Epoch 106 Step 103281 on_batch_end True CV rank 0
2025-01-10 21:45:50,121 INFO Epoch 106 Step 103281 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 21:45:59,484 DEBUG CV Batch 106/100 loss 0.008103 acc 0.998885  rank 0
2025-01-10 21:45:59,592 DEBUG CV Batch 106/100 loss 0.008103 acc 0.998885  rank 2
2025-01-10 21:45:59,838 DEBUG CV Batch 106/100 loss 0.008103 acc 0.998885  rank 1
2025-01-10 21:46:00,017 INFO Epoch 106 Step 103281 CV info lr 0.00015558215661612732 0 rank loss_2.4269770890792928 acc_0.7795555828171864
2025-01-10 21:46:00,131 INFO Epoch 106 Step 103281 CV info lr 0.00015558215661612732 2 rank loss_2.4269770890792928 acc_0.7795555828171864
2025-01-10 21:46:00,386 INFO Epoch 106 Step 103281 CV info lr 0.00015558215661612732 1 rank loss_2.4269770890792928 acc_0.7795555828171864
2025-01-10 21:46:01,335 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_106_whole.pt
2025-01-10 21:46:01,357 INFO Added key: store_based_barrier_key:109 to store for rank: 0
2025-01-10 21:46:01,357 INFO Added key: store_based_barrier_key:109 to store for rank: 1
2025-01-10 21:46:01,357 INFO Added key: store_based_barrier_key:109 to store for rank: 2
2025-01-10 21:46:01,358 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:109 with 3 nodes.
2025-01-10 21:46:01,364 INFO Epoch 107 TRAIN info lr 0.00015558215661612732 rank 2
2025-01-10 21:46:01,364 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 21:46:01,367 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:109 with 3 nodes.
2025-01-10 21:46:01,367 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:109 with 3 nodes.
2025-01-10 21:46:01,375 INFO Epoch 107 TRAIN info lr 0.00015558215661612732 rank 1
2025-01-10 21:46:01,375 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 21:46:01,375 INFO Epoch 107 TRAIN info lr 0.00015558215661612732 rank 0
2025-01-10 21:46:01,375 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 21:46:34,581 DEBUG TRAIN Batch 107/100 loss 0.043809 acc 0.973376 lr 0.00015554 grad_norm 0.446900 rank 0
2025-01-10 21:46:34,581 DEBUG TRAIN Batch 107/100 loss 0.039440 acc 0.971396 lr 0.00015554 grad_norm 0.446900 rank 1
2025-01-10 21:46:34,581 DEBUG TRAIN Batch 107/100 loss 0.050942 acc 0.961005 lr 0.00015554 grad_norm 0.446900 rank 2
2025-01-10 21:46:58,616 DEBUG TRAIN Batch 107/200 loss 0.048659 acc 0.968966 lr 0.00015551 grad_norm 0.456476 rank 1
2025-01-10 21:46:58,616 DEBUG TRAIN Batch 107/200 loss 0.050567 acc 0.966516 lr 0.00015551 grad_norm 0.456476 rank 0
2025-01-10 21:46:58,616 DEBUG TRAIN Batch 107/200 loss 0.040610 acc 0.972840 lr 0.00015551 grad_norm 0.456476 rank 2
2025-01-10 21:47:23,095 DEBUG TRAIN Batch 107/300 loss 0.023775 acc 0.985163 lr 0.00015547 grad_norm 0.415895 rank 1
2025-01-10 21:47:23,096 DEBUG TRAIN Batch 107/300 loss 0.045738 acc 0.969896 lr 0.00015547 grad_norm 0.415895 rank 2
2025-01-10 21:47:23,096 DEBUG TRAIN Batch 107/300 loss 0.043784 acc 0.966387 lr 0.00015547 grad_norm 0.415895 rank 0
2025-01-10 21:47:47,710 DEBUG TRAIN Batch 107/400 loss 0.044348 acc 0.969835 lr 0.00015543 grad_norm 0.455221 rank 1
2025-01-10 21:47:47,711 DEBUG TRAIN Batch 107/400 loss 0.063354 acc 0.954587 lr 0.00015543 grad_norm 0.455221 rank 2
2025-01-10 21:47:47,711 DEBUG TRAIN Batch 107/400 loss 0.039096 acc 0.975879 lr 0.00015543 grad_norm 0.455221 rank 0
2025-01-10 21:48:11,976 DEBUG TRAIN Batch 107/500 loss 0.043679 acc 0.968335 lr 0.00015539 grad_norm 0.425202 rank 0
2025-01-10 21:48:11,977 DEBUG TRAIN Batch 107/500 loss 0.050514 acc 0.968548 lr 0.00015539 grad_norm 0.425202 rank 1
2025-01-10 21:48:11,977 DEBUG TRAIN Batch 107/500 loss 0.067436 acc 0.954064 lr 0.00015539 grad_norm 0.425202 rank 2
2025-01-10 21:48:36,163 DEBUG TRAIN Batch 107/600 loss 0.046928 acc 0.964965 lr 0.00015536 grad_norm 0.429069 rank 1
2025-01-10 21:48:36,163 DEBUG TRAIN Batch 107/600 loss 0.048047 acc 0.964758 lr 0.00015536 grad_norm 0.429069 rank 0
2025-01-10 21:48:36,164 DEBUG TRAIN Batch 107/600 loss 0.071248 acc 0.955492 lr 0.00015536 grad_norm 0.429069 rank 2
2025-01-10 21:49:00,942 DEBUG TRAIN Batch 107/700 loss 0.029153 acc 0.982240 lr 0.00015532 grad_norm 0.425177 rank 1
2025-01-10 21:49:00,943 DEBUG TRAIN Batch 107/700 loss 0.056831 acc 0.959499 lr 0.00015532 grad_norm 0.425177 rank 0
2025-01-10 21:49:00,943 DEBUG TRAIN Batch 107/700 loss 0.050339 acc 0.970669 lr 0.00015532 grad_norm 0.425177 rank 2
2025-01-10 21:49:26,168 DEBUG TRAIN Batch 107/800 loss 0.031471 acc 0.978434 lr 0.00015528 grad_norm 0.415940 rank 2
2025-01-10 21:49:26,168 DEBUG TRAIN Batch 107/800 loss 0.030303 acc 0.977728 lr 0.00015528 grad_norm 0.415940 rank 1
2025-01-10 21:49:26,168 DEBUG TRAIN Batch 107/800 loss 0.063002 acc 0.953425 lr 0.00015528 grad_norm 0.415940 rank 0
2025-01-10 21:49:50,236 DEBUG TRAIN Batch 107/900 loss 0.050061 acc 0.960366 lr 0.00015524 grad_norm 0.391094 rank 2
2025-01-10 21:49:50,236 DEBUG TRAIN Batch 107/900 loss 0.025849 acc 0.983627 lr 0.00015524 grad_norm 0.391094 rank 1
2025-01-10 21:49:50,236 DEBUG TRAIN Batch 107/900 loss 0.034944 acc 0.978317 lr 0.00015524 grad_norm 0.391094 rank 0
2025-01-10 21:50:14,412 DEBUG TRAIN Batch 107/1000 loss 0.060613 acc 0.959746 lr 0.00015521 grad_norm 0.432834 rank 2
2025-01-10 21:50:14,412 DEBUG TRAIN Batch 107/1000 loss 0.055507 acc 0.960334 lr 0.00015521 grad_norm 0.432834 rank 0
2025-01-10 21:50:14,413 DEBUG TRAIN Batch 107/1000 loss 0.040176 acc 0.973306 lr 0.00015521 grad_norm 0.432834 rank 1
2025-01-10 21:50:39,539 DEBUG TRAIN Batch 107/1100 loss 0.032963 acc 0.982972 lr 0.00015517 grad_norm 0.418717 rank 1
2025-01-10 21:50:39,539 DEBUG TRAIN Batch 107/1100 loss 0.036696 acc 0.972362 lr 0.00015517 grad_norm 0.418717 rank 2
2025-01-10 21:50:39,540 DEBUG TRAIN Batch 107/1100 loss 0.035261 acc 0.979566 lr 0.00015517 grad_norm 0.418717 rank 0
2025-01-10 21:51:03,407 DEBUG TRAIN Batch 107/1200 loss 0.041448 acc 0.972707 lr 0.00015513 grad_norm 0.421878 rank 1
2025-01-10 21:51:03,407 DEBUG TRAIN Batch 107/1200 loss 0.036656 acc 0.969961 lr 0.00015513 grad_norm 0.421878 rank 2
2025-01-10 21:51:03,409 DEBUG TRAIN Batch 107/1200 loss 0.057590 acc 0.966249 lr 0.00015513 grad_norm 0.421878 rank 0
2025-01-10 21:51:27,714 DEBUG TRAIN Batch 107/1300 loss 0.055083 acc 0.963497 lr 0.00015509 grad_norm 0.424919 rank 2
2025-01-10 21:51:27,714 DEBUG TRAIN Batch 107/1300 loss 0.034129 acc 0.974010 lr 0.00015509 grad_norm 0.424919 rank 1
2025-01-10 21:51:27,715 DEBUG TRAIN Batch 107/1300 loss 0.053884 acc 0.960566 lr 0.00015509 grad_norm 0.424919 rank 0
2025-01-10 21:51:52,424 DEBUG TRAIN Batch 107/1400 loss 0.061097 acc 0.961913 lr 0.00015506 grad_norm 0.423834 rank 0
2025-01-10 21:51:52,424 DEBUG TRAIN Batch 107/1400 loss 0.053515 acc 0.963377 lr 0.00015506 grad_norm 0.423834 rank 1
2025-01-10 21:51:52,424 DEBUG TRAIN Batch 107/1400 loss 0.041047 acc 0.968497 lr 0.00015506 grad_norm 0.423834 rank 2
2025-01-10 21:52:18,145 DEBUG TRAIN Batch 107/1500 loss 0.036233 acc 0.976216 lr 0.00015502 grad_norm 0.383790 rank 2
2025-01-10 21:52:18,145 DEBUG TRAIN Batch 107/1500 loss 0.046661 acc 0.973085 lr 0.00015502 grad_norm 0.383790 rank 0
2025-01-10 21:52:18,146 DEBUG TRAIN Batch 107/1500 loss 0.019314 acc 0.985714 lr 0.00015502 grad_norm 0.383790 rank 1
2025-01-10 21:52:41,947 DEBUG TRAIN Batch 107/1600 loss 0.066286 acc 0.956406 lr 0.00015498 grad_norm 0.444014 rank 0
2025-01-10 21:52:41,947 DEBUG TRAIN Batch 107/1600 loss 0.041173 acc 0.974187 lr 0.00015498 grad_norm 0.444014 rank 1
2025-01-10 21:52:41,948 DEBUG TRAIN Batch 107/1600 loss 0.061835 acc 0.955638 lr 0.00015498 grad_norm 0.444014 rank 2
2025-01-10 21:53:06,212 DEBUG TRAIN Batch 107/1700 loss 0.051519 acc 0.966908 lr 0.00015495 grad_norm 0.459177 rank 0
2025-01-10 21:53:06,212 DEBUG TRAIN Batch 107/1700 loss 0.068275 acc 0.954674 lr 0.00015495 grad_norm 0.459177 rank 1
2025-01-10 21:53:06,213 DEBUG TRAIN Batch 107/1700 loss 0.035904 acc 0.973094 lr 0.00015495 grad_norm 0.459177 rank 2
2025-01-10 21:53:31,069 DEBUG TRAIN Batch 107/1800 loss 0.049076 acc 0.964161 lr 0.00015491 grad_norm 0.426018 rank 0
2025-01-10 21:53:31,069 DEBUG TRAIN Batch 107/1800 loss 0.051422 acc 0.965226 lr 0.00015491 grad_norm 0.426018 rank 1
2025-01-10 21:53:31,069 DEBUG TRAIN Batch 107/1800 loss 0.048254 acc 0.968582 lr 0.00015491 grad_norm 0.426018 rank 2
2025-01-10 21:53:54,807 DEBUG TRAIN Batch 107/1900 loss 0.041833 acc 0.970233 lr 0.00015487 grad_norm 0.414455 rank 0
2025-01-10 21:53:54,808 DEBUG TRAIN Batch 107/1900 loss 0.044656 acc 0.967621 lr 0.00015487 grad_norm 0.414455 rank 1
2025-01-10 21:53:54,808 DEBUG TRAIN Batch 107/1900 loss 0.035850 acc 0.974918 lr 0.00015487 grad_norm 0.414455 rank 2
2025-01-10 21:54:19,667 DEBUG TRAIN Batch 107/2000 loss 0.054901 acc 0.966394 lr 0.00015483 grad_norm 0.427817 rank 2
2025-01-10 21:54:19,667 DEBUG TRAIN Batch 107/2000 loss 0.044052 acc 0.962281 lr 0.00015483 grad_norm 0.427817 rank 0
2025-01-10 21:54:19,668 DEBUG TRAIN Batch 107/2000 loss 0.048713 acc 0.967876 lr 0.00015483 grad_norm 0.427817 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 21:55:35,255 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 21:55:35,258 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 21:55:35,720 INFO Epoch 107 Step 104314 on_batch_end True CV rank 2
2025-01-10 21:55:35,720 INFO Epoch 107 Step 104314 on_batch_end True CV rank 1
2025-01-10 21:55:35,720 INFO Epoch 107 Step 104314 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 21:55:44,956 DEBUG CV Batch 107/100 loss 0.009160 acc 0.996656  rank 0
2025-01-10 21:55:45,034 DEBUG CV Batch 107/100 loss 0.009160 acc 0.996656  rank 2
2025-01-10 21:55:45,363 DEBUG CV Batch 107/100 loss 0.009160 acc 0.996656  rank 1
2025-01-10 21:55:45,491 INFO Epoch 107 Step 104314 CV info lr 0.00015480989097872092 0 rank loss_2.4224824638523597 acc_0.7804802763357497
2025-01-10 21:55:45,565 INFO Epoch 107 Step 104314 CV info lr 0.00015480989097872092 2 rank loss_2.4224824638523597 acc_0.7804802763357497
2025-01-10 21:55:45,904 INFO Epoch 107 Step 104314 CV info lr 0.00015480989097872092 1 rank loss_2.4224824638523597 acc_0.7804802763357497
2025-01-10 21:55:46,791 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_107_whole.pt
2025-01-10 21:55:46,812 INFO Added key: store_based_barrier_key:110 to store for rank: 0
2025-01-10 21:55:46,813 INFO Added key: store_based_barrier_key:110 to store for rank: 1
2025-01-10 21:55:46,813 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:110 with 3 nodes.
2025-01-10 21:55:46,813 INFO Added key: store_based_barrier_key:110 to store for rank: 2
2025-01-10 21:55:46,813 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:110 with 3 nodes.
2025-01-10 21:55:46,814 INFO Epoch 108 TRAIN info lr 0.00015480989097872092 rank 1
2025-01-10 21:55:46,814 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 21:55:46,818 INFO Epoch 108 TRAIN info lr 0.00015480989097872092 rank 2
2025-01-10 21:55:46,818 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 21:55:46,823 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:110 with 3 nodes.
2025-01-10 21:55:46,832 INFO Epoch 108 TRAIN info lr 0.00015480989097872092 rank 0
2025-01-10 21:55:46,832 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 21:56:17,813 DEBUG TRAIN Batch 108/100 loss 0.038138 acc 0.971715 lr 0.00015477 grad_norm 0.404559 rank 1
2025-01-10 21:56:17,813 DEBUG TRAIN Batch 108/100 loss 0.062924 acc 0.953793 lr 0.00015477 grad_norm 0.404559 rank 2
2025-01-10 21:56:17,814 DEBUG TRAIN Batch 108/100 loss 0.050012 acc 0.963955 lr 0.00015477 grad_norm 0.404559 rank 0
2025-01-10 21:56:41,951 DEBUG TRAIN Batch 108/200 loss 0.045604 acc 0.973684 lr 0.00015474 grad_norm 0.429160 rank 1
2025-01-10 21:56:41,952 DEBUG TRAIN Batch 108/200 loss 0.049915 acc 0.961735 lr 0.00015474 grad_norm 0.429160 rank 0
2025-01-10 21:56:41,952 DEBUG TRAIN Batch 108/200 loss 0.045138 acc 0.969001 lr 0.00015474 grad_norm 0.429160 rank 2
2025-01-10 21:57:05,512 DEBUG TRAIN Batch 108/300 loss 0.053744 acc 0.965360 lr 0.00015470 grad_norm 0.418363 rank 2
2025-01-10 21:57:05,512 DEBUG TRAIN Batch 108/300 loss 0.048839 acc 0.964381 lr 0.00015470 grad_norm 0.418363 rank 1
2025-01-10 21:57:05,513 DEBUG TRAIN Batch 108/300 loss 0.042964 acc 0.967807 lr 0.00015470 grad_norm 0.418363 rank 0
2025-01-10 21:57:29,376 DEBUG TRAIN Batch 108/400 loss 0.036667 acc 0.977500 lr 0.00015466 grad_norm 0.409534 rank 2
2025-01-10 21:57:29,376 DEBUG TRAIN Batch 108/400 loss 0.065424 acc 0.957202 lr 0.00015466 grad_norm 0.409534 rank 0
2025-01-10 21:57:29,377 DEBUG TRAIN Batch 108/400 loss 0.027444 acc 0.985697 lr 0.00015466 grad_norm 0.409534 rank 1
2025-01-10 21:57:53,196 DEBUG TRAIN Batch 108/500 loss 0.052850 acc 0.962282 lr 0.00015462 grad_norm 0.452410 rank 2
2025-01-10 21:57:53,196 DEBUG TRAIN Batch 108/500 loss 0.052805 acc 0.959711 lr 0.00015462 grad_norm 0.452410 rank 1
2025-01-10 21:57:53,197 DEBUG TRAIN Batch 108/500 loss 0.058298 acc 0.959962 lr 0.00015462 grad_norm 0.452410 rank 0
2025-01-10 21:58:16,659 DEBUG TRAIN Batch 108/600 loss 0.064577 acc 0.960784 lr 0.00015459 grad_norm 0.440447 rank 2
2025-01-10 21:58:16,659 DEBUG TRAIN Batch 108/600 loss 0.043341 acc 0.964946 lr 0.00015459 grad_norm 0.440447 rank 0
2025-01-10 21:58:16,660 DEBUG TRAIN Batch 108/600 loss 0.051531 acc 0.960945 lr 0.00015459 grad_norm 0.440447 rank 1
2025-01-10 21:58:40,030 DEBUG TRAIN Batch 108/700 loss 0.049806 acc 0.964182 lr 0.00015455 grad_norm 0.458067 rank 2
2025-01-10 21:58:40,030 DEBUG TRAIN Batch 108/700 loss 0.045592 acc 0.973399 lr 0.00015455 grad_norm 0.458067 rank 0
2025-01-10 21:58:40,031 DEBUG TRAIN Batch 108/700 loss 0.051196 acc 0.965517 lr 0.00015455 grad_norm 0.458067 rank 1
2025-01-10 21:59:03,894 DEBUG TRAIN Batch 108/800 loss 0.045195 acc 0.971300 lr 0.00015451 grad_norm 0.395976 rank 1
2025-01-10 21:59:03,895 DEBUG TRAIN Batch 108/800 loss 0.032472 acc 0.977778 lr 0.00015451 grad_norm 0.395976 rank 0
2025-01-10 21:59:03,895 DEBUG TRAIN Batch 108/800 loss 0.058353 acc 0.964317 lr 0.00015451 grad_norm 0.395976 rank 2
2025-01-10 21:59:27,322 DEBUG TRAIN Batch 108/900 loss 0.056864 acc 0.963801 lr 0.00015448 grad_norm 0.432556 rank 2
2025-01-10 21:59:27,322 DEBUG TRAIN Batch 108/900 loss 0.041971 acc 0.972381 lr 0.00015448 grad_norm 0.432556 rank 1
2025-01-10 21:59:27,322 DEBUG TRAIN Batch 108/900 loss 0.040271 acc 0.967949 lr 0.00015448 grad_norm 0.432556 rank 0
2025-01-10 21:59:51,558 DEBUG TRAIN Batch 108/1000 loss 0.034162 acc 0.974333 lr 0.00015444 grad_norm 0.426067 rank 0
2025-01-10 21:59:51,558 DEBUG TRAIN Batch 108/1000 loss 0.056647 acc 0.960981 lr 0.00015444 grad_norm 0.426067 rank 2
2025-01-10 21:59:51,558 DEBUG TRAIN Batch 108/1000 loss 0.047929 acc 0.962002 lr 0.00015444 grad_norm 0.426067 rank 1
2025-01-10 22:00:15,372 DEBUG TRAIN Batch 108/1100 loss 0.049388 acc 0.968051 lr 0.00015440 grad_norm 0.439059 rank 1
2025-01-10 22:00:15,372 DEBUG TRAIN Batch 108/1100 loss 0.053933 acc 0.959662 lr 0.00015440 grad_norm 0.439059 rank 0
2025-01-10 22:00:15,372 DEBUG TRAIN Batch 108/1100 loss 0.043087 acc 0.968652 lr 0.00015440 grad_norm 0.439059 rank 2
2025-01-10 22:00:39,673 DEBUG TRAIN Batch 108/1200 loss 0.063554 acc 0.956522 lr 0.00015437 grad_norm 0.444593 rank 0
2025-01-10 22:00:39,673 DEBUG TRAIN Batch 108/1200 loss 0.060571 acc 0.957905 lr 0.00015437 grad_norm 0.444593 rank 1
2025-01-10 22:00:39,674 DEBUG TRAIN Batch 108/1200 loss 0.058829 acc 0.959350 lr 0.00015437 grad_norm 0.444593 rank 2
2025-01-10 22:01:04,332 DEBUG TRAIN Batch 108/1300 loss 0.058083 acc 0.964351 lr 0.00015433 grad_norm 0.425775 rank 2
2025-01-10 22:01:04,332 DEBUG TRAIN Batch 108/1300 loss 0.044117 acc 0.970320 lr 0.00015433 grad_norm 0.425775 rank 0
2025-01-10 22:01:04,333 DEBUG TRAIN Batch 108/1300 loss 0.045470 acc 0.969669 lr 0.00015433 grad_norm 0.425775 rank 1
2025-01-10 22:01:28,269 DEBUG TRAIN Batch 108/1400 loss 0.032576 acc 0.970488 lr 0.00015429 grad_norm 0.387383 rank 2
2025-01-10 22:01:28,269 DEBUG TRAIN Batch 108/1400 loss 0.042886 acc 0.973124 lr 0.00015429 grad_norm 0.387383 rank 1
2025-01-10 22:01:28,269 DEBUG TRAIN Batch 108/1400 loss 0.044589 acc 0.968921 lr 0.00015429 grad_norm 0.387383 rank 0
2025-01-10 22:01:53,621 DEBUG TRAIN Batch 108/1500 loss 0.059022 acc 0.961165 lr 0.00015426 grad_norm 0.439819 rank 0
2025-01-10 22:01:53,621 DEBUG TRAIN Batch 108/1500 loss 0.063441 acc 0.955237 lr 0.00015426 grad_norm 0.439819 rank 1
2025-01-10 22:01:53,621 DEBUG TRAIN Batch 108/1500 loss 0.050535 acc 0.966928 lr 0.00015426 grad_norm 0.439819 rank 2
2025-01-10 22:02:18,782 DEBUG TRAIN Batch 108/1600 loss 0.041970 acc 0.972093 lr 0.00015422 grad_norm 0.456948 rank 2
2025-01-10 22:02:18,782 DEBUG TRAIN Batch 108/1600 loss 0.078510 acc 0.948229 lr 0.00015422 grad_norm 0.456948 rank 1
2025-01-10 22:02:18,782 DEBUG TRAIN Batch 108/1600 loss 0.050841 acc 0.958451 lr 0.00015422 grad_norm 0.456948 rank 0
2025-01-10 22:02:43,167 DEBUG TRAIN Batch 108/1700 loss 0.073614 acc 0.950348 lr 0.00015418 grad_norm 0.437022 rank 2
2025-01-10 22:02:43,167 DEBUG TRAIN Batch 108/1700 loss 0.055418 acc 0.955224 lr 0.00015418 grad_norm 0.437022 rank 0
2025-01-10 22:02:43,167 DEBUG TRAIN Batch 108/1700 loss 0.042903 acc 0.965560 lr 0.00015418 grad_norm 0.437022 rank 1
2025-01-10 22:03:09,136 DEBUG TRAIN Batch 108/1800 loss 0.041151 acc 0.976000 lr 0.00015415 grad_norm 0.425144 rank 1
2025-01-10 22:03:09,137 DEBUG TRAIN Batch 108/1800 loss 0.056477 acc 0.966431 lr 0.00015415 grad_norm 0.425144 rank 2
2025-01-10 22:03:09,137 DEBUG TRAIN Batch 108/1800 loss 0.055316 acc 0.968582 lr 0.00015415 grad_norm 0.425144 rank 0
2025-01-10 22:03:33,037 DEBUG TRAIN Batch 108/1900 loss 0.067598 acc 0.950692 lr 0.00015411 grad_norm 0.428419 rank 0
2025-01-10 22:03:33,037 DEBUG TRAIN Batch 108/1900 loss 0.041690 acc 0.970309 lr 0.00015411 grad_norm 0.428419 rank 1
2025-01-10 22:03:33,038 DEBUG TRAIN Batch 108/1900 loss 0.047856 acc 0.965336 lr 0.00015411 grad_norm 0.428419 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 22:04:53,164 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 22:04:53,166 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 22:04:53,619 INFO Epoch 108 Step 105302 on_batch_end True CV rank 0
2025-01-10 22:04:53,619 INFO Epoch 108 Step 105302 on_batch_end True CV rank 2
2025-01-10 22:04:53,619 INFO Epoch 108 Step 105302 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 22:05:02,856 DEBUG CV Batch 108/100 loss 0.007935 acc 0.996656  rank 0
2025-01-10 22:05:03,131 DEBUG CV Batch 108/100 loss 0.007935 acc 0.996656  rank 2
2025-01-10 22:05:03,388 INFO Epoch 108 Step 105302 CV info lr 0.0001540819245811491 0 rank loss_2.4338657435115523 acc_0.7790467791390001
2025-01-10 22:05:03,476 DEBUG CV Batch 108/100 loss 0.007935 acc 0.996656  rank 1
2025-01-10 22:05:03,659 INFO Epoch 108 Step 105302 CV info lr 0.0001540819245811491 2 rank loss_2.4338657435115523 acc_0.7790467791390001
2025-01-10 22:05:04,013 INFO Epoch 108 Step 105302 CV info lr 0.0001540819245811491 1 rank loss_2.4338657435115523 acc_0.7790467791390001
2025-01-10 22:05:04,680 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_108_whole.pt
2025-01-10 22:05:04,691 INFO Added key: store_based_barrier_key:111 to store for rank: 0
2025-01-10 22:05:04,702 INFO Added key: store_based_barrier_key:111 to store for rank: 2
2025-01-10 22:05:04,702 INFO Added key: store_based_barrier_key:111 to store for rank: 1
2025-01-10 22:05:04,702 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:111 with 3 nodes.
2025-01-10 22:05:04,702 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:111 with 3 nodes.
2025-01-10 22:05:04,706 INFO Epoch 109 TRAIN info lr 0.0001540819245811491 rank 1
2025-01-10 22:05:04,706 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 22:05:04,707 INFO Epoch 109 TRAIN info lr 0.0001540819245811491 rank 2
2025-01-10 22:05:04,707 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 22:05:04,712 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:111 with 3 nodes.
2025-01-10 22:05:04,714 INFO Epoch 109 TRAIN info lr 0.0001540819245811491 rank 0
2025-01-10 22:05:04,714 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 22:05:36,765 DEBUG TRAIN Batch 109/100 loss 0.039392 acc 0.976440 lr 0.00015405 grad_norm 0.409620 rank 0
2025-01-10 22:05:36,766 DEBUG TRAIN Batch 109/100 loss 0.033987 acc 0.982036 lr 0.00015405 grad_norm 0.409620 rank 2
2025-01-10 22:05:36,766 DEBUG TRAIN Batch 109/100 loss 0.051641 acc 0.965642 lr 0.00015405 grad_norm 0.409620 rank 1
2025-01-10 22:06:00,753 DEBUG TRAIN Batch 109/200 loss 0.048961 acc 0.970120 lr 0.00015401 grad_norm 0.396946 rank 1
2025-01-10 22:06:00,753 DEBUG TRAIN Batch 109/200 loss 0.043734 acc 0.970696 lr 0.00015401 grad_norm 0.396946 rank 2
2025-01-10 22:06:00,754 DEBUG TRAIN Batch 109/200 loss 0.026624 acc 0.986369 lr 0.00015401 grad_norm 0.396946 rank 0
2025-01-10 22:06:25,110 DEBUG TRAIN Batch 109/300 loss 0.049732 acc 0.972171 lr 0.00015397 grad_norm 0.423907 rank 0
2025-01-10 22:06:25,110 DEBUG TRAIN Batch 109/300 loss 0.049291 acc 0.963996 lr 0.00015397 grad_norm 0.423907 rank 1
2025-01-10 22:06:25,110 DEBUG TRAIN Batch 109/300 loss 0.035658 acc 0.978836 lr 0.00015397 grad_norm 0.423907 rank 2
2025-01-10 22:06:49,171 DEBUG TRAIN Batch 109/400 loss 0.046117 acc 0.970217 lr 0.00015394 grad_norm 0.440349 rank 0
2025-01-10 22:06:49,172 DEBUG TRAIN Batch 109/400 loss 0.055849 acc 0.963255 lr 0.00015394 grad_norm 0.440349 rank 2
2025-01-10 22:06:49,172 DEBUG TRAIN Batch 109/400 loss 0.050692 acc 0.968051 lr 0.00015394 grad_norm 0.440349 rank 1
2025-01-10 22:07:13,533 DEBUG TRAIN Batch 109/500 loss 0.036499 acc 0.977012 lr 0.00015390 grad_norm 0.427648 rank 2
2025-01-10 22:07:13,533 DEBUG TRAIN Batch 109/500 loss 0.053087 acc 0.965986 lr 0.00015390 grad_norm 0.427648 rank 1
2025-01-10 22:07:13,534 DEBUG TRAIN Batch 109/500 loss 0.049507 acc 0.965009 lr 0.00015390 grad_norm 0.427648 rank 0
2025-01-10 22:07:38,352 DEBUG TRAIN Batch 109/600 loss 0.043068 acc 0.970874 lr 0.00015386 grad_norm 0.428042 rank 0
2025-01-10 22:07:38,352 DEBUG TRAIN Batch 109/600 loss 0.066285 acc 0.962048 lr 0.00015386 grad_norm 0.428042 rank 1
2025-01-10 22:07:38,352 DEBUG TRAIN Batch 109/600 loss 0.036056 acc 0.971347 lr 0.00015386 grad_norm 0.428042 rank 2
2025-01-10 22:08:02,441 DEBUG TRAIN Batch 109/700 loss 0.041676 acc 0.970936 lr 0.00015383 grad_norm 0.435446 rank 2
2025-01-10 22:08:02,441 DEBUG TRAIN Batch 109/700 loss 0.053639 acc 0.963115 lr 0.00015383 grad_norm 0.435446 rank 1
2025-01-10 22:08:02,441 DEBUG TRAIN Batch 109/700 loss 0.069840 acc 0.954755 lr 0.00015383 grad_norm 0.435446 rank 0
2025-01-10 22:08:26,601 DEBUG TRAIN Batch 109/800 loss 0.049487 acc 0.963480 lr 0.00015379 grad_norm 0.425456 rank 1
2025-01-10 22:08:26,601 DEBUG TRAIN Batch 109/800 loss 0.038815 acc 0.972522 lr 0.00015379 grad_norm 0.425456 rank 0
2025-01-10 22:08:26,602 DEBUG TRAIN Batch 109/800 loss 0.045079 acc 0.964951 lr 0.00015379 grad_norm 0.425456 rank 2
2025-01-10 22:08:51,302 DEBUG TRAIN Batch 109/900 loss 0.040591 acc 0.970509 lr 0.00015375 grad_norm 0.402498 rank 1
2025-01-10 22:08:51,302 DEBUG TRAIN Batch 109/900 loss 0.056848 acc 0.959201 lr 0.00015375 grad_norm 0.402498 rank 2
2025-01-10 22:08:51,303 DEBUG TRAIN Batch 109/900 loss 0.033318 acc 0.974178 lr 0.00015375 grad_norm 0.402498 rank 0
2025-01-10 22:09:15,850 DEBUG TRAIN Batch 109/1000 loss 0.048049 acc 0.968966 lr 0.00015372 grad_norm 0.424074 rank 1
2025-01-10 22:09:15,850 DEBUG TRAIN Batch 109/1000 loss 0.061456 acc 0.954588 lr 0.00015372 grad_norm 0.424074 rank 2
2025-01-10 22:09:15,850 DEBUG TRAIN Batch 109/1000 loss 0.043720 acc 0.972350 lr 0.00015372 grad_norm 0.424074 rank 0
2025-01-10 22:09:40,476 DEBUG TRAIN Batch 109/1100 loss 0.035477 acc 0.975580 lr 0.00015368 grad_norm 0.444659 rank 1
2025-01-10 22:09:40,477 DEBUG TRAIN Batch 109/1100 loss 0.045144 acc 0.965342 lr 0.00015368 grad_norm 0.444659 rank 2
2025-01-10 22:09:40,477 DEBUG TRAIN Batch 109/1100 loss 0.028139 acc 0.977707 lr 0.00015368 grad_norm 0.444659 rank 0
2025-01-10 22:10:05,016 DEBUG TRAIN Batch 109/1200 loss 0.029339 acc 0.976744 lr 0.00015364 grad_norm 0.436683 rank 1
2025-01-10 22:10:05,016 DEBUG TRAIN Batch 109/1200 loss 0.055610 acc 0.960000 lr 0.00015364 grad_norm 0.436683 rank 2
2025-01-10 22:10:05,017 DEBUG TRAIN Batch 109/1200 loss 0.038508 acc 0.969101 lr 0.00015364 grad_norm 0.436683 rank 0
2025-01-10 22:10:29,890 DEBUG TRAIN Batch 109/1300 loss 0.046558 acc 0.970000 lr 0.00015361 grad_norm 0.464748 rank 1
2025-01-10 22:10:29,890 DEBUG TRAIN Batch 109/1300 loss 0.058370 acc 0.958802 lr 0.00015361 grad_norm 0.464748 rank 2
2025-01-10 22:10:29,890 DEBUG TRAIN Batch 109/1300 loss 0.067915 acc 0.950506 lr 0.00015361 grad_norm 0.464748 rank 0
2025-01-10 22:10:53,759 DEBUG TRAIN Batch 109/1400 loss 0.055270 acc 0.953608 lr 0.00015357 grad_norm 0.429222 rank 1
2025-01-10 22:10:53,760 DEBUG TRAIN Batch 109/1400 loss 0.054368 acc 0.971429 lr 0.00015357 grad_norm 0.429222 rank 2
2025-01-10 22:10:53,760 DEBUG TRAIN Batch 109/1400 loss 0.047304 acc 0.969286 lr 0.00015357 grad_norm 0.429222 rank 0
2025-01-10 22:11:18,216 DEBUG TRAIN Batch 109/1500 loss 0.056326 acc 0.959857 lr 0.00015354 grad_norm 0.450732 rank 1
2025-01-10 22:11:18,216 DEBUG TRAIN Batch 109/1500 loss 0.050848 acc 0.963222 lr 0.00015354 grad_norm 0.450732 rank 2
2025-01-10 22:11:18,216 DEBUG TRAIN Batch 109/1500 loss 0.040626 acc 0.970617 lr 0.00015354 grad_norm 0.450732 rank 0
2025-01-10 22:11:42,946 DEBUG TRAIN Batch 109/1600 loss 0.049078 acc 0.969671 lr 0.00015350 grad_norm 0.438459 rank 2
2025-01-10 22:11:42,946 DEBUG TRAIN Batch 109/1600 loss 0.025121 acc 0.978723 lr 0.00015350 grad_norm 0.438459 rank 0
2025-01-10 22:11:42,946 DEBUG TRAIN Batch 109/1600 loss 0.055325 acc 0.958654 lr 0.00015350 grad_norm 0.438459 rank 1
2025-01-10 22:12:06,566 DEBUG TRAIN Batch 109/1700 loss 0.034037 acc 0.978655 lr 0.00015346 grad_norm 0.416963 rank 1
2025-01-10 22:12:06,566 DEBUG TRAIN Batch 109/1700 loss 0.049548 acc 0.963093 lr 0.00015346 grad_norm 0.416963 rank 2
2025-01-10 22:12:06,567 DEBUG TRAIN Batch 109/1700 loss 0.043125 acc 0.970930 lr 0.00015346 grad_norm 0.416963 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 22:13:12,482 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 22:13:12,486 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 22:13:12,961 INFO Epoch 109 Step 106164 on_batch_end True CV rank 1
2025-01-10 22:13:12,961 INFO Epoch 109 Step 106164 on_batch_end True CV rank 0
2025-01-10 22:13:12,961 INFO Epoch 109 Step 106164 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 22:13:22,120 DEBUG CV Batch 109/100 loss 0.008902 acc 0.997770  rank 0
2025-01-10 22:13:22,362 DEBUG CV Batch 109/100 loss 0.008902 acc 0.997770  rank 2
2025-01-10 22:13:22,649 INFO Epoch 109 Step 106164 CV info lr 0.00015345511452905466 0 rank loss_2.4227505862348298 acc_0.7797433854195109
2025-01-10 22:13:22,651 DEBUG CV Batch 109/100 loss 0.008902 acc 0.997770  rank 1
2025-01-10 22:13:22,887 INFO Epoch 109 Step 106164 CV info lr 0.00015345511452905466 2 rank loss_2.4227505862348298 acc_0.7797433854195109
2025-01-10 22:13:23,216 INFO Epoch 109 Step 106164 CV info lr 0.00015345511452905466 1 rank loss_2.4227505862348298 acc_0.7797433854195109
2025-01-10 22:13:23,953 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_109_whole.pt
2025-01-10 22:13:23,965 INFO Added key: store_based_barrier_key:112 to store for rank: 0
2025-01-10 22:13:23,975 INFO Added key: store_based_barrier_key:112 to store for rank: 2
2025-01-10 22:13:23,976 INFO Added key: store_based_barrier_key:112 to store for rank: 1
2025-01-10 22:13:23,976 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:112 with 3 nodes.
2025-01-10 22:13:23,984 INFO Epoch 110 TRAIN info lr 0.00015345511452905466 rank 1
2025-01-10 22:13:23,985 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 22:13:23,986 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:112 with 3 nodes.
2025-01-10 22:13:23,986 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:112 with 3 nodes.
2025-01-10 22:13:23,989 INFO Epoch 110 TRAIN info lr 0.00015345511452905466 rank 2
2025-01-10 22:13:23,989 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 22:13:23,991 INFO Epoch 110 TRAIN info lr 0.00015345511452905466 rank 0
2025-01-10 22:13:23,991 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 22:13:55,012 DEBUG TRAIN Batch 110/100 loss 0.033745 acc 0.978632 lr 0.00015342 grad_norm 0.412308 rank 1
2025-01-10 22:13:55,012 DEBUG TRAIN Batch 110/100 loss 0.028645 acc 0.978947 lr 0.00015342 grad_norm 0.412308 rank 2
2025-01-10 22:13:55,013 DEBUG TRAIN Batch 110/100 loss 0.052108 acc 0.959913 lr 0.00015342 grad_norm 0.412308 rank 0
2025-01-10 22:14:18,934 DEBUG TRAIN Batch 110/200 loss 0.047114 acc 0.971505 lr 0.00015338 grad_norm 0.427341 rank 1
2025-01-10 22:14:18,934 DEBUG TRAIN Batch 110/200 loss 0.039454 acc 0.974425 lr 0.00015338 grad_norm 0.427341 rank 2
2025-01-10 22:14:18,935 DEBUG TRAIN Batch 110/200 loss 0.058469 acc 0.959684 lr 0.00015338 grad_norm 0.427341 rank 0
2025-01-10 22:14:42,622 DEBUG TRAIN Batch 110/300 loss 0.040892 acc 0.975970 lr 0.00015335 grad_norm 0.387897 rank 2
2025-01-10 22:14:42,622 DEBUG TRAIN Batch 110/300 loss 0.045932 acc 0.960222 lr 0.00015335 grad_norm 0.387897 rank 1
2025-01-10 22:14:42,622 DEBUG TRAIN Batch 110/300 loss 0.034921 acc 0.974954 lr 0.00015335 grad_norm 0.387897 rank 0
2025-01-10 22:15:06,386 DEBUG TRAIN Batch 110/400 loss 0.034428 acc 0.975427 lr 0.00015331 grad_norm 0.398929 rank 0
2025-01-10 22:15:06,386 DEBUG TRAIN Batch 110/400 loss 0.053064 acc 0.961985 lr 0.00015331 grad_norm 0.398929 rank 1
2025-01-10 22:15:06,387 DEBUG TRAIN Batch 110/400 loss 0.039220 acc 0.970755 lr 0.00015331 grad_norm 0.398929 rank 2
2025-01-10 22:15:30,574 DEBUG TRAIN Batch 110/500 loss 0.034283 acc 0.972538 lr 0.00015327 grad_norm 0.426972 rank 1
2025-01-10 22:15:30,574 DEBUG TRAIN Batch 110/500 loss 0.040792 acc 0.971963 lr 0.00015327 grad_norm 0.426972 rank 2
2025-01-10 22:15:30,574 DEBUG TRAIN Batch 110/500 loss 0.037497 acc 0.969666 lr 0.00015327 grad_norm 0.426972 rank 0
2025-01-10 22:15:53,796 DEBUG TRAIN Batch 110/600 loss 0.043489 acc 0.968182 lr 0.00015324 grad_norm 0.396035 rank 2
2025-01-10 22:15:53,796 DEBUG TRAIN Batch 110/600 loss 0.044368 acc 0.971972 lr 0.00015324 grad_norm 0.396035 rank 0
2025-01-10 22:15:53,796 DEBUG TRAIN Batch 110/600 loss 0.034342 acc 0.976258 lr 0.00015324 grad_norm 0.396035 rank 1
2025-01-10 22:16:18,026 DEBUG TRAIN Batch 110/700 loss 0.050764 acc 0.961610 lr 0.00015320 grad_norm 0.427978 rank 1
2025-01-10 22:16:18,026 DEBUG TRAIN Batch 110/700 loss 0.054656 acc 0.959319 lr 0.00015320 grad_norm 0.427978 rank 0
2025-01-10 22:16:18,027 DEBUG TRAIN Batch 110/700 loss 0.041852 acc 0.967834 lr 0.00015320 grad_norm 0.427978 rank 2
2025-01-10 22:16:42,569 DEBUG TRAIN Batch 110/800 loss 0.033827 acc 0.980899 lr 0.00015317 grad_norm 0.408551 rank 2
2025-01-10 22:16:42,569 DEBUG TRAIN Batch 110/800 loss 0.056355 acc 0.964286 lr 0.00015317 grad_norm 0.408551 rank 1
2025-01-10 22:16:42,569 DEBUG TRAIN Batch 110/800 loss 0.048446 acc 0.962801 lr 0.00015317 grad_norm 0.408551 rank 0
2025-01-10 22:17:07,561 DEBUG TRAIN Batch 110/900 loss 0.047152 acc 0.965517 lr 0.00015313 grad_norm 0.421900 rank 2
2025-01-10 22:17:07,562 DEBUG TRAIN Batch 110/900 loss 0.049313 acc 0.965550 lr 0.00015313 grad_norm 0.421900 rank 0
2025-01-10 22:17:07,562 DEBUG TRAIN Batch 110/900 loss 0.045175 acc 0.968205 lr 0.00015313 grad_norm 0.421900 rank 1
2025-01-10 22:17:31,570 DEBUG TRAIN Batch 110/1000 loss 0.050310 acc 0.966535 lr 0.00015310 grad_norm 0.412756 rank 0
2025-01-10 22:17:31,570 DEBUG TRAIN Batch 110/1000 loss 0.044161 acc 0.969203 lr 0.00015310 grad_norm 0.412756 rank 1
2025-01-10 22:17:31,571 DEBUG TRAIN Batch 110/1000 loss 0.031799 acc 0.980000 lr 0.00015310 grad_norm 0.412756 rank 2
2025-01-10 22:17:56,068 DEBUG TRAIN Batch 110/1100 loss 0.056758 acc 0.966423 lr 0.00015306 grad_norm 0.500022 rank 1
2025-01-10 22:17:56,068 DEBUG TRAIN Batch 110/1100 loss 0.042816 acc 0.970849 lr 0.00015306 grad_norm 0.500022 rank 0
2025-01-10 22:17:56,069 DEBUG TRAIN Batch 110/1100 loss 0.041053 acc 0.969739 lr 0.00015306 grad_norm 0.500022 rank 2
2025-01-10 22:18:22,172 DEBUG TRAIN Batch 110/1200 loss 0.049443 acc 0.967562 lr 0.00015302 grad_norm 0.432425 rank 2
2025-01-10 22:18:22,172 DEBUG TRAIN Batch 110/1200 loss 0.048948 acc 0.965070 lr 0.00015302 grad_norm 0.432425 rank 0
2025-01-10 22:18:22,172 DEBUG TRAIN Batch 110/1200 loss 0.039212 acc 0.979508 lr 0.00015302 grad_norm 0.432425 rank 1
2025-01-10 22:18:46,988 DEBUG TRAIN Batch 110/1300 loss 0.058355 acc 0.964066 lr 0.00015299 grad_norm 0.439189 rank 0
2025-01-10 22:18:46,989 DEBUG TRAIN Batch 110/1300 loss 0.041244 acc 0.969586 lr 0.00015299 grad_norm 0.439189 rank 1
2025-01-10 22:18:46,989 DEBUG TRAIN Batch 110/1300 loss 0.052685 acc 0.964251 lr 0.00015299 grad_norm 0.439189 rank 2
2025-01-10 22:19:11,931 DEBUG TRAIN Batch 110/1400 loss 0.038606 acc 0.978306 lr 0.00015295 grad_norm 0.443727 rank 2
2025-01-10 22:19:11,931 DEBUG TRAIN Batch 110/1400 loss 0.044304 acc 0.972222 lr 0.00015295 grad_norm 0.443727 rank 1
2025-01-10 22:19:11,931 DEBUG TRAIN Batch 110/1400 loss 0.072780 acc 0.952636 lr 0.00015295 grad_norm 0.443727 rank 0
2025-01-10 22:19:36,501 DEBUG TRAIN Batch 110/1500 loss 0.049210 acc 0.964085 lr 0.00015292 grad_norm 0.427634 rank 0
2025-01-10 22:19:36,501 DEBUG TRAIN Batch 110/1500 loss 0.023695 acc 0.983278 lr 0.00015292 grad_norm 0.427634 rank 2
2025-01-10 22:19:36,501 DEBUG TRAIN Batch 110/1500 loss 0.045943 acc 0.971098 lr 0.00015292 grad_norm 0.427634 rank 1
2025-01-10 22:20:00,428 DEBUG TRAIN Batch 110/1600 loss 0.054617 acc 0.963619 lr 0.00015288 grad_norm 0.420097 rank 0
2025-01-10 22:20:00,428 DEBUG TRAIN Batch 110/1600 loss 0.041510 acc 0.971296 lr 0.00015288 grad_norm 0.420097 rank 1
2025-01-10 22:20:00,428 DEBUG TRAIN Batch 110/1600 loss 0.031804 acc 0.971768 lr 0.00015288 grad_norm 0.420097 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 22:21:13,805 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 22:21:13,807 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 22:21:14,253 INFO Epoch 110 Step 106992 on_batch_end True CV rank 0
2025-01-10 22:21:14,253 INFO Epoch 110 Step 106992 on_batch_end True CV rank 1
2025-01-10 22:21:14,253 INFO Epoch 110 Step 106992 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 22:21:23,555 DEBUG CV Batch 110/100 loss 0.012025 acc 0.994426  rank 0
2025-01-10 22:21:23,598 DEBUG CV Batch 110/100 loss 0.012025 acc 0.994426  rank 2
2025-01-10 22:21:23,985 DEBUG CV Batch 110/100 loss 0.012025 acc 0.994426  rank 1
2025-01-10 22:21:24,093 INFO Epoch 110 Step 106992 CV info lr 0.0001528601746348027 2 rank loss_2.442911706941423 acc_0.7793199843481967
2025-01-10 22:21:24,106 INFO Epoch 110 Step 106992 CV info lr 0.0001528601746348027 0 rank loss_2.442911706941423 acc_0.7793199843481967
2025-01-10 22:21:24,533 INFO Epoch 110 Step 106992 CV info lr 0.0001528601746348027 1 rank loss_2.442911706941423 acc_0.7793199843481967
2025-01-10 22:21:25,393 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_110_whole.pt
2025-01-10 22:21:25,415 INFO Added key: store_based_barrier_key:113 to store for rank: 0
2025-01-10 22:21:25,426 INFO Added key: store_based_barrier_key:113 to store for rank: 2
2025-01-10 22:21:25,426 INFO Added key: store_based_barrier_key:113 to store for rank: 1
2025-01-10 22:21:25,426 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:113 with 3 nodes.
2025-01-10 22:21:25,426 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:113 with 3 nodes.
2025-01-10 22:21:25,429 INFO Epoch 111 TRAIN info lr 0.0001528601746348027 rank 1
2025-01-10 22:21:25,429 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 22:21:25,436 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:113 with 3 nodes.
2025-01-10 22:21:25,436 INFO Epoch 111 TRAIN info lr 0.0001528601746348027 rank 2
2025-01-10 22:21:25,436 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 22:21:25,436 INFO Epoch 111 TRAIN info lr 0.0001528601746348027 rank 0
2025-01-10 22:21:25,437 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 22:21:59,821 DEBUG TRAIN Batch 111/100 loss 0.044666 acc 0.967607 lr 0.00015282 grad_norm 0.396861 rank 0
2025-01-10 22:21:59,821 DEBUG TRAIN Batch 111/100 loss 0.037675 acc 0.976092 lr 0.00015282 grad_norm 0.396861 rank 1
2025-01-10 22:21:59,822 DEBUG TRAIN Batch 111/100 loss 0.043180 acc 0.969474 lr 0.00015282 grad_norm 0.396861 rank 2
2025-01-10 22:22:24,030 DEBUG TRAIN Batch 111/200 loss 0.035756 acc 0.978670 lr 0.00015279 grad_norm 0.427665 rank 2
2025-01-10 22:22:24,030 DEBUG TRAIN Batch 111/200 loss 0.062708 acc 0.952548 lr 0.00015279 grad_norm 0.427665 rank 1
2025-01-10 22:22:24,031 DEBUG TRAIN Batch 111/200 loss 0.036005 acc 0.980198 lr 0.00015279 grad_norm 0.427665 rank 0
2025-01-10 22:22:48,294 DEBUG TRAIN Batch 111/300 loss 0.070603 acc 0.951485 lr 0.00015275 grad_norm 0.435664 rank 1
2025-01-10 22:22:48,295 DEBUG TRAIN Batch 111/300 loss 0.054509 acc 0.965616 lr 0.00015275 grad_norm 0.435664 rank 2
2025-01-10 22:22:48,296 DEBUG TRAIN Batch 111/300 loss 0.036127 acc 0.976657 lr 0.00015275 grad_norm 0.435664 rank 0
2025-01-10 22:23:12,538 DEBUG TRAIN Batch 111/400 loss 0.051544 acc 0.965517 lr 0.00015272 grad_norm 0.403113 rank 1
2025-01-10 22:23:12,538 DEBUG TRAIN Batch 111/400 loss 0.035503 acc 0.982218 lr 0.00015272 grad_norm 0.403113 rank 2
2025-01-10 22:23:12,538 DEBUG TRAIN Batch 111/400 loss 0.042120 acc 0.967807 lr 0.00015272 grad_norm 0.403113 rank 0
2025-01-10 22:23:36,556 DEBUG TRAIN Batch 111/500 loss 0.049444 acc 0.967245 lr 0.00015268 grad_norm 0.421622 rank 1
2025-01-10 22:23:36,556 DEBUG TRAIN Batch 111/500 loss 0.043504 acc 0.967198 lr 0.00015268 grad_norm 0.421622 rank 2
2025-01-10 22:23:36,556 DEBUG TRAIN Batch 111/500 loss 0.053463 acc 0.961676 lr 0.00015268 grad_norm 0.421622 rank 0
2025-01-10 22:24:00,549 DEBUG TRAIN Batch 111/600 loss 0.039338 acc 0.971516 lr 0.00015265 grad_norm 0.409289 rank 0
2025-01-10 22:24:00,549 DEBUG TRAIN Batch 111/600 loss 0.038744 acc 0.973948 lr 0.00015265 grad_norm 0.409289 rank 1
2025-01-10 22:24:00,549 DEBUG TRAIN Batch 111/600 loss 0.058878 acc 0.951941 lr 0.00015265 grad_norm 0.409289 rank 2
2025-01-10 22:24:25,311 DEBUG TRAIN Batch 111/700 loss 0.047650 acc 0.969953 lr 0.00015261 grad_norm 0.427979 rank 2
2025-01-10 22:24:25,311 DEBUG TRAIN Batch 111/700 loss 0.025935 acc 0.978261 lr 0.00015261 grad_norm 0.427979 rank 0
2025-01-10 22:24:25,311 DEBUG TRAIN Batch 111/700 loss 0.050868 acc 0.962114 lr 0.00015261 grad_norm 0.427979 rank 1
2025-01-10 22:24:50,006 DEBUG TRAIN Batch 111/800 loss 0.053265 acc 0.969031 lr 0.00015258 grad_norm 0.466793 rank 0
2025-01-10 22:24:50,007 DEBUG TRAIN Batch 111/800 loss 0.037703 acc 0.972727 lr 0.00015258 grad_norm 0.466793 rank 2
2025-01-10 22:24:50,006 DEBUG TRAIN Batch 111/800 loss 0.048253 acc 0.965552 lr 0.00015258 grad_norm 0.466793 rank 1
2025-01-10 22:25:14,136 DEBUG TRAIN Batch 111/900 loss 0.049685 acc 0.962424 lr 0.00015254 grad_norm 0.445433 rank 2
2025-01-10 22:25:14,137 DEBUG TRAIN Batch 111/900 loss 0.055691 acc 0.959670 lr 0.00015254 grad_norm 0.445433 rank 0
2025-01-10 22:25:14,137 DEBUG TRAIN Batch 111/900 loss 0.051664 acc 0.963908 lr 0.00015254 grad_norm 0.445433 rank 1
2025-01-10 22:25:38,666 DEBUG TRAIN Batch 111/1000 loss 0.045298 acc 0.968872 lr 0.00015250 grad_norm 0.407654 rank 2
2025-01-10 22:25:38,667 DEBUG TRAIN Batch 111/1000 loss 0.033915 acc 0.976428 lr 0.00015250 grad_norm 0.407654 rank 1
2025-01-10 22:25:38,667 DEBUG TRAIN Batch 111/1000 loss 0.034960 acc 0.978723 lr 0.00015250 grad_norm 0.407654 rank 0
2025-01-10 22:26:04,099 DEBUG TRAIN Batch 111/1100 loss 0.046231 acc 0.966102 lr 0.00015247 grad_norm 0.403770 rank 2
2025-01-10 22:26:04,100 DEBUG TRAIN Batch 111/1100 loss 0.042656 acc 0.966070 lr 0.00015247 grad_norm 0.403770 rank 1
2025-01-10 22:26:04,100 DEBUG TRAIN Batch 111/1100 loss 0.040447 acc 0.975701 lr 0.00015247 grad_norm 0.403770 rank 0
2025-01-10 22:26:27,369 DEBUG TRAIN Batch 111/1200 loss 0.042059 acc 0.966102 lr 0.00015243 grad_norm 0.428771 rank 2
2025-01-10 22:26:27,369 DEBUG TRAIN Batch 111/1200 loss 0.051645 acc 0.962398 lr 0.00015243 grad_norm 0.428771 rank 1
2025-01-10 22:26:27,370 DEBUG TRAIN Batch 111/1200 loss 0.049741 acc 0.968750 lr 0.00015243 grad_norm 0.428771 rank 0
2025-01-10 22:26:51,810 DEBUG TRAIN Batch 111/1300 loss 0.036516 acc 0.973945 lr 0.00015240 grad_norm 0.422574 rank 1
2025-01-10 22:26:51,810 DEBUG TRAIN Batch 111/1300 loss 0.051747 acc 0.959016 lr 0.00015240 grad_norm 0.422574 rank 2
2025-01-10 22:26:51,810 DEBUG TRAIN Batch 111/1300 loss 0.042259 acc 0.974766 lr 0.00015240 grad_norm 0.422574 rank 0
2025-01-10 22:27:17,442 DEBUG TRAIN Batch 111/1400 loss 0.054860 acc 0.965613 lr 0.00015236 grad_norm 0.443291 rank 1
2025-01-10 22:27:17,442 DEBUG TRAIN Batch 111/1400 loss 0.060721 acc 0.954990 lr 0.00015236 grad_norm 0.443291 rank 2
2025-01-10 22:27:17,442 DEBUG TRAIN Batch 111/1400 loss 0.043396 acc 0.969697 lr 0.00015236 grad_norm 0.443291 rank 0
2025-01-10 22:27:41,482 DEBUG TRAIN Batch 111/1500 loss 0.048438 acc 0.962355 lr 0.00015233 grad_norm 0.442019 rank 2
2025-01-10 22:27:41,482 DEBUG TRAIN Batch 111/1500 loss 0.047868 acc 0.964775 lr 0.00015233 grad_norm 0.442019 rank 1
2025-01-10 22:27:41,482 DEBUG TRAIN Batch 111/1500 loss 0.047426 acc 0.974668 lr 0.00015233 grad_norm 0.442019 rank 0
2025-01-10 22:28:05,789 DEBUG TRAIN Batch 111/1600 loss 0.038459 acc 0.974432 lr 0.00015229 grad_norm 0.413770 rank 1
2025-01-10 22:28:05,789 DEBUG TRAIN Batch 111/1600 loss 0.053236 acc 0.966636 lr 0.00015229 grad_norm 0.413770 rank 0
2025-01-10 22:28:05,789 DEBUG TRAIN Batch 111/1600 loss 0.036911 acc 0.972393 lr 0.00015229 grad_norm 0.413770 rank 2
2025-01-10 22:28:30,955 DEBUG TRAIN Batch 111/1700 loss 0.044141 acc 0.974070 lr 0.00015226 grad_norm 0.441767 rank 1
2025-01-10 22:28:30,955 DEBUG TRAIN Batch 111/1700 loss 0.043448 acc 0.966512 lr 0.00015226 grad_norm 0.441767 rank 2
2025-01-10 22:28:30,956 DEBUG TRAIN Batch 111/1700 loss 0.033444 acc 0.971049 lr 0.00015226 grad_norm 0.441767 rank 0
2025-01-10 22:28:54,759 DEBUG TRAIN Batch 111/1800 loss 0.047472 acc 0.966189 lr 0.00015222 grad_norm 0.463426 rank 1
2025-01-10 22:28:54,759 DEBUG TRAIN Batch 111/1800 loss 0.056963 acc 0.963077 lr 0.00015222 grad_norm 0.463426 rank 0
2025-01-10 22:28:54,759 DEBUG TRAIN Batch 111/1800 loss 0.057571 acc 0.956767 lr 0.00015222 grad_norm 0.463426 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 22:30:12,641 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 22:30:12,642 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 22:30:13,059 INFO Epoch 111 Step 107928 on_batch_end True CV rank 0
2025-01-10 22:30:13,059 INFO Epoch 111 Step 107928 on_batch_end True CV rank 1
2025-01-10 22:30:13,059 INFO Epoch 111 Step 107928 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 22:30:22,214 DEBUG CV Batch 111/100 loss 0.003938 acc 1.000000  rank 0
2025-01-10 22:30:22,471 DEBUG CV Batch 111/100 loss 0.003938 acc 1.000000  rank 2
2025-01-10 22:30:22,746 INFO Epoch 111 Step 107928 CV info lr 0.00015219589528578855 0 rank loss_2.4469488736981395 acc_0.7796372147767168
2025-01-10 22:30:22,773 DEBUG CV Batch 111/100 loss 0.003938 acc 1.000000  rank 1
2025-01-10 22:30:23,007 INFO Epoch 111 Step 107928 CV info lr 0.00015219589528578855 2 rank loss_2.4469488736981395 acc_0.7796372147767168
2025-01-10 22:30:23,306 INFO Epoch 111 Step 107928 CV info lr 0.00015219589528578855 1 rank loss_2.4469488736981395 acc_0.7796372147767168
2025-01-10 22:30:24,086 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_111_whole.pt
2025-01-10 22:30:24,098 INFO Added key: store_based_barrier_key:114 to store for rank: 0
2025-01-10 22:30:24,108 INFO Added key: store_based_barrier_key:114 to store for rank: 1
2025-01-10 22:30:24,108 INFO Added key: store_based_barrier_key:114 to store for rank: 2
2025-01-10 22:30:24,108 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:114 with 3 nodes.
2025-01-10 22:30:24,108 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:114 with 3 nodes.
2025-01-10 22:30:24,109 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:114 with 3 nodes.
2025-01-10 22:30:24,111 INFO Epoch 112 TRAIN info lr 0.00015219589528578855 rank 1
2025-01-10 22:30:24,112 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 22:30:24,113 INFO Epoch 112 TRAIN info lr 0.00015219589528578855 rank 2
2025-01-10 22:30:24,113 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 22:30:24,114 INFO Epoch 112 TRAIN info lr 0.00015219589528578855 rank 0
2025-01-10 22:30:24,114 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 22:30:55,302 DEBUG TRAIN Batch 112/100 loss 0.062163 acc 0.958451 lr 0.00015216 grad_norm 0.419123 rank 2
2025-01-10 22:30:55,302 DEBUG TRAIN Batch 112/100 loss 0.045697 acc 0.964222 lr 0.00015216 grad_norm 0.419123 rank 0
2025-01-10 22:30:55,303 DEBUG TRAIN Batch 112/100 loss 0.049817 acc 0.967156 lr 0.00015216 grad_norm 0.419123 rank 1
2025-01-10 22:31:19,183 DEBUG TRAIN Batch 112/200 loss 0.039443 acc 0.972702 lr 0.00015213 grad_norm 0.412973 rank 0
2025-01-10 22:31:19,183 DEBUG TRAIN Batch 112/200 loss 0.050301 acc 0.964158 lr 0.00015213 grad_norm 0.412973 rank 2
2025-01-10 22:31:19,183 DEBUG TRAIN Batch 112/200 loss 0.033679 acc 0.976601 lr 0.00015213 grad_norm 0.412973 rank 1
2025-01-10 22:31:42,761 DEBUG TRAIN Batch 112/300 loss 0.045825 acc 0.968601 lr 0.00015209 grad_norm 0.393620 rank 1
2025-01-10 22:31:42,762 DEBUG TRAIN Batch 112/300 loss 0.039720 acc 0.973761 lr 0.00015209 grad_norm 0.393620 rank 0
2025-01-10 22:31:42,762 DEBUG TRAIN Batch 112/300 loss 0.043172 acc 0.970588 lr 0.00015209 grad_norm 0.393620 rank 2
2025-01-10 22:32:06,552 DEBUG TRAIN Batch 112/400 loss 0.043007 acc 0.970845 lr 0.00015206 grad_norm 0.423950 rank 1
2025-01-10 22:32:06,553 DEBUG TRAIN Batch 112/400 loss 0.053463 acc 0.967196 lr 0.00015206 grad_norm 0.423950 rank 2
2025-01-10 22:32:06,554 DEBUG TRAIN Batch 112/400 loss 0.034379 acc 0.978155 lr 0.00015206 grad_norm 0.423950 rank 0
2025-01-10 22:32:30,765 DEBUG TRAIN Batch 112/500 loss 0.034135 acc 0.977754 lr 0.00015202 grad_norm 0.421300 rank 1
2025-01-10 22:32:30,766 DEBUG TRAIN Batch 112/500 loss 0.052236 acc 0.966457 lr 0.00015202 grad_norm 0.421300 rank 2
2025-01-10 22:32:30,766 DEBUG TRAIN Batch 112/500 loss 0.058158 acc 0.959817 lr 0.00015202 grad_norm 0.421300 rank 0
2025-01-10 22:32:54,860 DEBUG TRAIN Batch 112/600 loss 0.024958 acc 0.981760 lr 0.00015198 grad_norm 0.404381 rank 1
2025-01-10 22:32:54,860 DEBUG TRAIN Batch 112/600 loss 0.050205 acc 0.962014 lr 0.00015198 grad_norm 0.404381 rank 2
2025-01-10 22:32:54,860 DEBUG TRAIN Batch 112/600 loss 0.042779 acc 0.971668 lr 0.00015198 grad_norm 0.404381 rank 0
2025-01-10 22:33:19,933 DEBUG TRAIN Batch 112/700 loss 0.024714 acc 0.982993 lr 0.00015195 grad_norm 0.425425 rank 1
2025-01-10 22:33:19,933 DEBUG TRAIN Batch 112/700 loss 0.053926 acc 0.965389 lr 0.00015195 grad_norm 0.425425 rank 2
2025-01-10 22:33:19,934 DEBUG TRAIN Batch 112/700 loss 0.043245 acc 0.970588 lr 0.00015195 grad_norm 0.425425 rank 0
2025-01-10 22:33:43,213 DEBUG TRAIN Batch 112/800 loss 0.054920 acc 0.960332 lr 0.00015191 grad_norm 0.451226 rank 0
2025-01-10 22:33:43,214 DEBUG TRAIN Batch 112/800 loss 0.056420 acc 0.957490 lr 0.00015191 grad_norm 0.451226 rank 2
2025-01-10 22:33:43,279 DEBUG TRAIN Batch 112/800 loss 0.037634 acc 0.971299 lr 0.00015191 grad_norm 0.451226 rank 1
2025-01-10 22:34:07,666 DEBUG TRAIN Batch 112/900 loss 0.014766 acc 0.989501 lr 0.00015188 grad_norm 0.431950 rank 1
2025-01-10 22:34:07,667 DEBUG TRAIN Batch 112/900 loss 0.039596 acc 0.969142 lr 0.00015188 grad_norm 0.431950 rank 2
2025-01-10 22:34:07,667 DEBUG TRAIN Batch 112/900 loss 0.034675 acc 0.976109 lr 0.00015188 grad_norm 0.431950 rank 0
2025-01-10 22:34:33,361 DEBUG TRAIN Batch 112/1000 loss 0.031506 acc 0.980702 lr 0.00015184 grad_norm 0.420029 rank 1
2025-01-10 22:34:33,361 DEBUG TRAIN Batch 112/1000 loss 0.037711 acc 0.971270 lr 0.00015184 grad_norm 0.420029 rank 2
2025-01-10 22:34:33,362 DEBUG TRAIN Batch 112/1000 loss 0.047452 acc 0.968238 lr 0.00015184 grad_norm 0.420029 rank 0
2025-01-10 22:34:57,816 DEBUG TRAIN Batch 112/1100 loss 0.044087 acc 0.974296 lr 0.00015181 grad_norm 0.430613 rank 1
2025-01-10 22:34:57,816 DEBUG TRAIN Batch 112/1100 loss 0.056986 acc 0.958297 lr 0.00015181 grad_norm 0.430613 rank 2
2025-01-10 22:34:57,816 DEBUG TRAIN Batch 112/1100 loss 0.054029 acc 0.955185 lr 0.00015181 grad_norm 0.430613 rank 0
2025-01-10 22:35:22,058 DEBUG TRAIN Batch 112/1200 loss 0.036840 acc 0.976415 lr 0.00015177 grad_norm 0.422384 rank 1
2025-01-10 22:35:22,058 DEBUG TRAIN Batch 112/1200 loss 0.037467 acc 0.977195 lr 0.00015177 grad_norm 0.422384 rank 0
2025-01-10 22:35:22,058 DEBUG TRAIN Batch 112/1200 loss 0.058077 acc 0.961326 lr 0.00015177 grad_norm 0.422384 rank 2
2025-01-10 22:35:46,917 DEBUG TRAIN Batch 112/1300 loss 0.042425 acc 0.968235 lr 0.00015174 grad_norm 0.475256 rank 2
2025-01-10 22:35:46,917 DEBUG TRAIN Batch 112/1300 loss 0.029764 acc 0.979133 lr 0.00015174 grad_norm 0.475256 rank 1
2025-01-10 22:35:46,918 DEBUG TRAIN Batch 112/1300 loss 0.027431 acc 0.977157 lr 0.00015174 grad_norm 0.475256 rank 0
2025-01-10 22:36:10,852 DEBUG TRAIN Batch 112/1400 loss 0.046160 acc 0.973660 lr 0.00015170 grad_norm 0.532530 rank 2
2025-01-10 22:36:10,852 DEBUG TRAIN Batch 112/1400 loss 0.044527 acc 0.963617 lr 0.00015170 grad_norm 0.532530 rank 0
2025-01-10 22:36:10,852 DEBUG TRAIN Batch 112/1400 loss 0.104169 acc 0.945714 lr 0.00015170 grad_norm 0.532530 rank 1
2025-01-10 22:36:35,633 DEBUG TRAIN Batch 112/1500 loss 0.063692 acc 0.953461 lr 0.00015167 grad_norm 0.411457 rank 1
2025-01-10 22:36:35,633 DEBUG TRAIN Batch 112/1500 loss 0.018335 acc 0.990506 lr 0.00015167 grad_norm 0.411457 rank 0
2025-01-10 22:36:35,633 DEBUG TRAIN Batch 112/1500 loss 0.043543 acc 0.973577 lr 0.00015167 grad_norm 0.411457 rank 2
2025-01-10 22:37:00,427 DEBUG TRAIN Batch 112/1600 loss 0.032525 acc 0.974138 lr 0.00015163 grad_norm 0.435203 rank 0
2025-01-10 22:37:00,427 DEBUG TRAIN Batch 112/1600 loss 0.054547 acc 0.964559 lr 0.00015163 grad_norm 0.435203 rank 2
2025-01-10 22:37:00,427 DEBUG TRAIN Batch 112/1600 loss 0.058919 acc 0.962300 lr 0.00015163 grad_norm 0.435203 rank 1
2025-01-10 22:37:23,989 DEBUG TRAIN Batch 112/1700 loss 0.031932 acc 0.973282 lr 0.00015160 grad_norm 0.445608 rank 0
2025-01-10 22:37:23,990 DEBUG TRAIN Batch 112/1700 loss 0.051274 acc 0.963470 lr 0.00015160 grad_norm 0.445608 rank 1
2025-01-10 22:37:23,990 DEBUG TRAIN Batch 112/1700 loss 0.054475 acc 0.968717 lr 0.00015160 grad_norm 0.445608 rank 2
2025-01-10 22:37:48,055 DEBUG TRAIN Batch 112/1800 loss 0.053842 acc 0.961682 lr 0.00015157 grad_norm 0.448109 rank 1
2025-01-10 22:37:48,055 DEBUG TRAIN Batch 112/1800 loss 0.042141 acc 0.964989 lr 0.00015157 grad_norm 0.448109 rank 2
2025-01-10 22:37:48,055 DEBUG TRAIN Batch 112/1800 loss 0.061419 acc 0.957447 lr 0.00015157 grad_norm 0.448109 rank 0
2025-01-10 22:38:12,669 DEBUG TRAIN Batch 112/1900 loss 0.031819 acc 0.975858 lr 0.00015153 grad_norm 0.468279 rank 0
2025-01-10 22:38:12,669 DEBUG TRAIN Batch 112/1900 loss 0.064846 acc 0.949074 lr 0.00015153 grad_norm 0.468279 rank 1
2025-01-10 22:38:12,669 DEBUG TRAIN Batch 112/1900 loss 0.040939 acc 0.973988 lr 0.00015153 grad_norm 0.468279 rank 2
2025-01-10 22:38:36,981 DEBUG TRAIN Batch 112/2000 loss 0.039169 acc 0.968105 lr 0.00015150 grad_norm 0.453063 rank 0
2025-01-10 22:38:36,981 DEBUG TRAIN Batch 112/2000 loss 0.057364 acc 0.950730 lr 0.00015150 grad_norm 0.453063 rank 1
2025-01-10 22:38:36,982 DEBUG TRAIN Batch 112/2000 loss 0.062095 acc 0.961934 lr 0.00015150 grad_norm 0.453063 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 22:40:00,146 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 22:40:00,146 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 22:40:00,550 INFO Epoch 112 Step 108977 on_batch_end True CV rank 2
2025-01-10 22:40:00,550 INFO Epoch 112 Step 108977 on_batch_end True CV rank 1
2025-01-10 22:40:00,550 INFO Epoch 112 Step 108977 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 22:40:09,738 DEBUG CV Batch 112/100 loss 0.005459 acc 0.998885  rank 2
2025-01-10 22:40:09,982 DEBUG CV Batch 112/100 loss 0.005459 acc 0.998885  rank 0
2025-01-10 22:40:10,136 DEBUG CV Batch 112/100 loss 0.005459 acc 0.998885  rank 1
2025-01-10 22:40:10,263 INFO Epoch 112 Step 108977 CV info lr 0.00015146161394195967 2 rank loss_2.450020949722098 acc_0.7796316468401959
2025-01-10 22:40:10,507 INFO Epoch 112 Step 108977 CV info lr 0.00015146161394195967 0 rank loss_2.450020949722098 acc_0.7796316468401959
2025-01-10 22:40:10,698 INFO Epoch 112 Step 108977 CV info lr 0.00015146161394195967 1 rank loss_2.450020949722098 acc_0.7796316468401959
2025-01-10 22:40:11,828 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_112_whole.pt
2025-01-10 22:40:11,850 INFO Added key: store_based_barrier_key:115 to store for rank: 0
2025-01-10 22:40:11,860 INFO Added key: store_based_barrier_key:115 to store for rank: 2
2025-01-10 22:40:11,860 INFO Added key: store_based_barrier_key:115 to store for rank: 1
2025-01-10 22:40:11,860 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:115 with 3 nodes.
2025-01-10 22:40:11,860 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:115 with 3 nodes.
2025-01-10 22:40:11,860 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:115 with 3 nodes.
2025-01-10 22:40:11,864 INFO Epoch 113 TRAIN info lr 0.00015146161394195967 rank 2
2025-01-10 22:40:11,864 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 22:40:11,864 INFO Epoch 113 TRAIN info lr 0.00015146161394195967 rank 0
2025-01-10 22:40:11,865 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 22:40:11,867 INFO Epoch 113 TRAIN info lr 0.00015146161394195967 rank 1
2025-01-10 22:40:11,867 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 22:40:45,512 DEBUG TRAIN Batch 113/100 loss 0.043338 acc 0.966189 lr 0.00015143 grad_norm 0.423037 rank 0
2025-01-10 22:40:45,512 DEBUG TRAIN Batch 113/100 loss 0.038884 acc 0.980021 lr 0.00015143 grad_norm 0.423037 rank 2
2025-01-10 22:40:45,512 DEBUG TRAIN Batch 113/100 loss 0.039544 acc 0.970408 lr 0.00015143 grad_norm 0.423037 rank 1
2025-01-10 22:41:09,709 DEBUG TRAIN Batch 113/200 loss 0.042167 acc 0.971360 lr 0.00015139 grad_norm 0.397185 rank 1
2025-01-10 22:41:09,709 DEBUG TRAIN Batch 113/200 loss 0.029309 acc 0.978960 lr 0.00015139 grad_norm 0.397185 rank 2
2025-01-10 22:41:09,710 DEBUG TRAIN Batch 113/200 loss 0.039585 acc 0.971481 lr 0.00015139 grad_norm 0.397185 rank 0
2025-01-10 22:41:33,978 DEBUG TRAIN Batch 113/300 loss 0.049060 acc 0.967074 lr 0.00015136 grad_norm 0.418841 rank 2
2025-01-10 22:41:33,979 DEBUG TRAIN Batch 113/300 loss 0.047812 acc 0.970810 lr 0.00015136 grad_norm 0.418841 rank 0
2025-01-10 22:41:33,979 DEBUG TRAIN Batch 113/300 loss 0.037284 acc 0.972328 lr 0.00015136 grad_norm 0.418841 rank 1
2025-01-10 22:41:58,347 DEBUG TRAIN Batch 113/400 loss 0.049439 acc 0.970707 lr 0.00015132 grad_norm 0.421242 rank 2
2025-01-10 22:41:58,347 DEBUG TRAIN Batch 113/400 loss 0.035841 acc 0.975540 lr 0.00015132 grad_norm 0.421242 rank 1
2025-01-10 22:41:58,348 DEBUG TRAIN Batch 113/400 loss 0.031612 acc 0.978373 lr 0.00015132 grad_norm 0.421242 rank 0
2025-01-10 22:42:22,399 DEBUG TRAIN Batch 113/500 loss 0.036942 acc 0.976891 lr 0.00015129 grad_norm 0.380587 rank 1
2025-01-10 22:42:22,399 DEBUG TRAIN Batch 113/500 loss 0.034919 acc 0.975585 lr 0.00015129 grad_norm 0.380587 rank 2
2025-01-10 22:42:22,399 DEBUG TRAIN Batch 113/500 loss 0.024875 acc 0.981763 lr 0.00015129 grad_norm 0.380587 rank 0
2025-01-10 22:42:46,557 DEBUG TRAIN Batch 113/600 loss 0.032496 acc 0.977108 lr 0.00015125 grad_norm 0.428374 rank 1
2025-01-10 22:42:46,557 DEBUG TRAIN Batch 113/600 loss 0.047918 acc 0.965554 lr 0.00015125 grad_norm 0.428374 rank 2
2025-01-10 22:42:46,558 DEBUG TRAIN Batch 113/600 loss 0.036017 acc 0.973124 lr 0.00015125 grad_norm 0.428374 rank 0
2025-01-10 22:43:11,317 DEBUG TRAIN Batch 113/700 loss 0.036485 acc 0.975799 lr 0.00015122 grad_norm 0.430695 rank 1
2025-01-10 22:43:11,317 DEBUG TRAIN Batch 113/700 loss 0.046235 acc 0.968411 lr 0.00015122 grad_norm 0.430695 rank 2
2025-01-10 22:43:11,317 DEBUG TRAIN Batch 113/700 loss 0.061430 acc 0.957157 lr 0.00015122 grad_norm 0.430695 rank 0
2025-01-10 22:43:35,962 DEBUG TRAIN Batch 113/800 loss 0.031528 acc 0.979769 lr 0.00015118 grad_norm 0.443228 rank 1
2025-01-10 22:43:35,962 DEBUG TRAIN Batch 113/800 loss 0.050874 acc 0.962551 lr 0.00015118 grad_norm 0.443228 rank 0
2025-01-10 22:43:35,962 DEBUG TRAIN Batch 113/800 loss 0.058968 acc 0.964664 lr 0.00015118 grad_norm 0.443228 rank 2
2025-01-10 22:44:00,208 DEBUG TRAIN Batch 113/900 loss 0.040947 acc 0.970667 lr 0.00015115 grad_norm 0.420648 rank 2
2025-01-10 22:44:00,208 DEBUG TRAIN Batch 113/900 loss 0.040023 acc 0.966981 lr 0.00015115 grad_norm 0.420648 rank 1
2025-01-10 22:44:00,208 DEBUG TRAIN Batch 113/900 loss 0.054353 acc 0.964286 lr 0.00015115 grad_norm 0.420648 rank 0
2025-01-10 22:44:23,645 DEBUG TRAIN Batch 113/1000 loss 0.044359 acc 0.969175 lr 0.00015112 grad_norm 0.422316 rank 1
2025-01-10 22:44:23,646 DEBUG TRAIN Batch 113/1000 loss 0.040824 acc 0.974438 lr 0.00015112 grad_norm 0.422316 rank 0
2025-01-10 22:44:23,646 DEBUG TRAIN Batch 113/1000 loss 0.036071 acc 0.974385 lr 0.00015112 grad_norm 0.422316 rank 2
2025-01-10 22:44:47,602 DEBUG TRAIN Batch 113/1100 loss 0.050398 acc 0.966764 lr 0.00015108 grad_norm 0.443129 rank 1
2025-01-10 22:44:47,602 DEBUG TRAIN Batch 113/1100 loss 0.041754 acc 0.968597 lr 0.00015108 grad_norm 0.443129 rank 0
2025-01-10 22:44:47,603 DEBUG TRAIN Batch 113/1100 loss 0.056722 acc 0.959397 lr 0.00015108 grad_norm 0.443129 rank 2
2025-01-10 22:45:11,681 DEBUG TRAIN Batch 113/1200 loss 0.049327 acc 0.962803 lr 0.00015105 grad_norm 0.424280 rank 2
2025-01-10 22:45:11,682 DEBUG TRAIN Batch 113/1200 loss 0.041121 acc 0.973262 lr 0.00015105 grad_norm 0.424280 rank 1
2025-01-10 22:45:11,682 DEBUG TRAIN Batch 113/1200 loss 0.044966 acc 0.970250 lr 0.00015105 grad_norm 0.424280 rank 0
2025-01-10 22:45:36,449 DEBUG TRAIN Batch 113/1300 loss 0.053200 acc 0.965324 lr 0.00015101 grad_norm 0.455130 rank 0
2025-01-10 22:45:36,449 DEBUG TRAIN Batch 113/1300 loss 0.028902 acc 0.979432 lr 0.00015101 grad_norm 0.455130 rank 1
2025-01-10 22:45:36,450 DEBUG TRAIN Batch 113/1300 loss 0.060182 acc 0.956645 lr 0.00015101 grad_norm 0.455130 rank 2
2025-01-10 22:46:00,304 DEBUG TRAIN Batch 113/1400 loss 0.045971 acc 0.970750 lr 0.00015098 grad_norm 0.420737 rank 1
2025-01-10 22:46:00,304 DEBUG TRAIN Batch 113/1400 loss 0.060978 acc 0.960463 lr 0.00015098 grad_norm 0.420737 rank 2
2025-01-10 22:46:00,305 DEBUG TRAIN Batch 113/1400 loss 0.049561 acc 0.963570 lr 0.00015098 grad_norm 0.420737 rank 0
2025-01-10 22:46:24,390 DEBUG TRAIN Batch 113/1500 loss 0.036085 acc 0.972660 lr 0.00015094 grad_norm 0.419279 rank 1
2025-01-10 22:46:24,390 DEBUG TRAIN Batch 113/1500 loss 0.053399 acc 0.961211 lr 0.00015094 grad_norm 0.419279 rank 0
2025-01-10 22:46:24,390 DEBUG TRAIN Batch 113/1500 loss 0.042921 acc 0.967816 lr 0.00015094 grad_norm 0.419279 rank 2
2025-01-10 22:46:48,498 DEBUG TRAIN Batch 113/1600 loss 0.053213 acc 0.958988 lr 0.00015091 grad_norm 0.430211 rank 0
2025-01-10 22:46:48,498 DEBUG TRAIN Batch 113/1600 loss 0.050616 acc 0.964762 lr 0.00015091 grad_norm 0.430211 rank 2
2025-01-10 22:46:48,498 DEBUG TRAIN Batch 113/1600 loss 0.048848 acc 0.967066 lr 0.00015091 grad_norm 0.430211 rank 1
2025-01-10 22:47:12,932 DEBUG TRAIN Batch 113/1700 loss 0.054793 acc 0.963126 lr 0.00015087 grad_norm 0.455548 rank 1
2025-01-10 22:47:12,932 DEBUG TRAIN Batch 113/1700 loss 0.040370 acc 0.970738 lr 0.00015087 grad_norm 0.455548 rank 0
2025-01-10 22:47:12,933 DEBUG TRAIN Batch 113/1700 loss 0.056875 acc 0.957181 lr 0.00015087 grad_norm 0.455548 rank 2
2025-01-10 22:47:36,889 DEBUG TRAIN Batch 113/1800 loss 0.034303 acc 0.980498 lr 0.00015084 grad_norm 0.433580 rank 1
2025-01-10 22:47:36,889 DEBUG TRAIN Batch 113/1800 loss 0.050824 acc 0.963537 lr 0.00015084 grad_norm 0.433580 rank 2
2025-01-10 22:47:36,889 DEBUG TRAIN Batch 113/1800 loss 0.038274 acc 0.972376 lr 0.00015084 grad_norm 0.433580 rank 0
2025-01-10 22:48:00,691 DEBUG TRAIN Batch 113/1900 loss 0.047055 acc 0.970707 lr 0.00015081 grad_norm 0.422178 rank 0
2025-01-10 22:48:00,692 DEBUG TRAIN Batch 113/1900 loss 0.057104 acc 0.960836 lr 0.00015081 grad_norm 0.422178 rank 1
2025-01-10 22:48:00,692 DEBUG TRAIN Batch 113/1900 loss 0.045408 acc 0.971402 lr 0.00015081 grad_norm 0.422178 rank 2
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-10 22:49:18,272 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 22:49:18,283 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 22:49:18,741 INFO Epoch 113 Step 109963 on_batch_end True CV rank 1
2025-01-10 22:49:18,741 INFO Epoch 113 Step 109963 on_batch_end True CV rank 0
2025-01-10 22:49:18,741 INFO Epoch 113 Step 109963 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 22:49:27,752 DEBUG CV Batch 113/100 loss 0.004057 acc 0.998885  rank 0
2025-01-10 22:49:28,067 DEBUG CV Batch 113/100 loss 0.004057 acc 0.998885  rank 2
2025-01-10 22:49:28,268 INFO Epoch 113 Step 109963 CV info lr 0.00015078103304995633 0 rank loss_2.4405683819133084 acc_0.7807880553760027
2025-01-10 22:49:28,373 DEBUG CV Batch 113/100 loss 0.004057 acc 0.998885  rank 1
2025-01-10 22:49:28,605 INFO Epoch 113 Step 109963 CV info lr 0.00015078103304995633 2 rank loss_2.4405683819133084 acc_0.7807880553760027
2025-01-10 22:49:28,916 INFO Epoch 113 Step 109963 CV info lr 0.00015078103304995633 1 rank loss_2.4405683819133084 acc_0.7807880553760027
2025-01-10 22:49:29,577 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_113_whole.pt
2025-01-10 22:49:29,589 INFO Added key: store_based_barrier_key:116 to store for rank: 0
2025-01-10 22:49:29,599 INFO Added key: store_based_barrier_key:116 to store for rank: 1
2025-01-10 22:49:29,599 INFO Added key: store_based_barrier_key:116 to store for rank: 2
2025-01-10 22:49:29,599 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:116 with 3 nodes.
2025-01-10 22:49:29,599 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:116 with 3 nodes.
2025-01-10 22:49:29,604 INFO Epoch 114 TRAIN info lr 0.00015078103304995633 rank 2
2025-01-10 22:49:29,605 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 22:49:29,607 INFO Epoch 114 TRAIN info lr 0.00015078103304995633 rank 1
2025-01-10 22:49:29,608 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 22:49:29,609 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:116 with 3 nodes.
2025-01-10 22:49:29,612 INFO Epoch 114 TRAIN info lr 0.00015078103304995633 rank 0
2025-01-10 22:49:29,612 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 22:50:06,240 DEBUG TRAIN Batch 114/100 loss 0.031030 acc 0.974969 lr 0.00015075 grad_norm 0.403943 rank 2
2025-01-10 22:50:06,241 DEBUG TRAIN Batch 114/100 loss 0.045576 acc 0.972603 lr 0.00015075 grad_norm 0.403943 rank 1
2025-01-10 22:50:06,241 DEBUG TRAIN Batch 114/100 loss 0.042873 acc 0.969246 lr 0.00015075 grad_norm 0.403943 rank 0
2025-01-10 22:50:30,483 DEBUG TRAIN Batch 114/200 loss 0.029942 acc 0.982394 lr 0.00015071 grad_norm 0.413226 rank 1
2025-01-10 22:50:30,483 DEBUG TRAIN Batch 114/200 loss 0.041386 acc 0.978703 lr 0.00015071 grad_norm 0.413226 rank 2
2025-01-10 22:50:30,484 DEBUG TRAIN Batch 114/200 loss 0.042662 acc 0.970899 lr 0.00015071 grad_norm 0.413226 rank 0
2025-01-10 22:50:55,388 DEBUG TRAIN Batch 114/300 loss 0.029082 acc 0.977124 lr 0.00015068 grad_norm 0.389767 rank 2
2025-01-10 22:50:55,388 DEBUG TRAIN Batch 114/300 loss 0.041912 acc 0.966236 lr 0.00015068 grad_norm 0.389767 rank 0
2025-01-10 22:50:55,389 DEBUG TRAIN Batch 114/300 loss 0.033806 acc 0.977885 lr 0.00015068 grad_norm 0.389767 rank 1
2025-01-10 22:51:19,364 DEBUG TRAIN Batch 114/400 loss 0.036529 acc 0.973333 lr 0.00015064 grad_norm 0.391485 rank 2
2025-01-10 22:51:19,364 DEBUG TRAIN Batch 114/400 loss 0.036995 acc 0.976821 lr 0.00015064 grad_norm 0.391485 rank 0
2025-01-10 22:51:19,364 DEBUG TRAIN Batch 114/400 loss 0.021016 acc 0.986842 lr 0.00015064 grad_norm 0.391485 rank 1
2025-01-10 22:51:44,217 DEBUG TRAIN Batch 114/500 loss 0.030213 acc 0.977974 lr 0.00015061 grad_norm 0.427863 rank 1
2025-01-10 22:51:44,217 DEBUG TRAIN Batch 114/500 loss 0.030381 acc 0.977671 lr 0.00015061 grad_norm 0.427863 rank 0
2025-01-10 22:51:44,217 DEBUG TRAIN Batch 114/500 loss 0.031810 acc 0.977273 lr 0.00015061 grad_norm 0.427863 rank 2
2025-01-10 22:52:09,531 DEBUG TRAIN Batch 114/600 loss 0.031309 acc 0.972840 lr 0.00015058 grad_norm 0.431128 rank 1
2025-01-10 22:52:09,531 DEBUG TRAIN Batch 114/600 loss 0.038030 acc 0.976169 lr 0.00015058 grad_norm 0.431128 rank 2
2025-01-10 22:52:09,531 DEBUG TRAIN Batch 114/600 loss 0.041958 acc 0.971030 lr 0.00015058 grad_norm 0.431128 rank 0
2025-01-10 22:52:34,534 DEBUG TRAIN Batch 114/700 loss 0.034544 acc 0.973451 lr 0.00015054 grad_norm 0.402314 rank 1
2025-01-10 22:52:34,534 DEBUG TRAIN Batch 114/700 loss 0.028732 acc 0.977246 lr 0.00015054 grad_norm 0.402314 rank 2
2025-01-10 22:52:34,535 DEBUG TRAIN Batch 114/700 loss 0.054659 acc 0.966455 lr 0.00015054 grad_norm 0.402314 rank 0
2025-01-10 22:53:00,259 DEBUG TRAIN Batch 114/800 loss 0.037003 acc 0.967509 lr 0.00015051 grad_norm 0.395570 rank 2
2025-01-10 22:53:00,259 DEBUG TRAIN Batch 114/800 loss 0.024212 acc 0.988304 lr 0.00015051 grad_norm 0.395570 rank 1
2025-01-10 22:53:00,259 DEBUG TRAIN Batch 114/800 loss 0.047753 acc 0.965709 lr 0.00015051 grad_norm 0.395570 rank 0
2025-01-10 22:53:24,137 DEBUG TRAIN Batch 114/900 loss 0.038195 acc 0.977692 lr 0.00015047 grad_norm 0.407460 rank 1
2025-01-10 22:53:24,137 DEBUG TRAIN Batch 114/900 loss 0.030216 acc 0.977029 lr 0.00015047 grad_norm 0.407460 rank 2
2025-01-10 22:53:24,138 DEBUG TRAIN Batch 114/900 loss 0.042426 acc 0.971014 lr 0.00015047 grad_norm 0.407460 rank 0
2025-01-10 22:53:48,472 DEBUG TRAIN Batch 114/1000 loss 0.031271 acc 0.978523 lr 0.00015044 grad_norm 0.440750 rank 2
2025-01-10 22:53:48,472 DEBUG TRAIN Batch 114/1000 loss 0.052589 acc 0.960000 lr 0.00015044 grad_norm 0.440750 rank 0
2025-01-10 22:53:48,473 DEBUG TRAIN Batch 114/1000 loss 0.043151 acc 0.972634 lr 0.00015044 grad_norm 0.440750 rank 1
2025-01-10 22:54:14,497 DEBUG TRAIN Batch 114/1100 loss 0.037078 acc 0.971910 lr 0.00015041 grad_norm 0.441257 rank 0
2025-01-10 22:54:14,497 DEBUG TRAIN Batch 114/1100 loss 0.059634 acc 0.961580 lr 0.00015041 grad_norm 0.441257 rank 2
2025-01-10 22:54:14,497 DEBUG TRAIN Batch 114/1100 loss 0.043209 acc 0.968485 lr 0.00015041 grad_norm 0.441257 rank 1
2025-01-10 22:54:39,283 DEBUG TRAIN Batch 114/1200 loss 0.038430 acc 0.972522 lr 0.00015037 grad_norm 0.396966 rank 1
2025-01-10 22:54:39,283 DEBUG TRAIN Batch 114/1200 loss 0.056233 acc 0.963940 lr 0.00015037 grad_norm 0.396966 rank 2
2025-01-10 22:54:39,283 DEBUG TRAIN Batch 114/1200 loss 0.049569 acc 0.965867 lr 0.00015037 grad_norm 0.396966 rank 0
2025-01-10 22:55:03,472 DEBUG TRAIN Batch 114/1300 loss 0.051384 acc 0.964497 lr 0.00015034 grad_norm 0.450198 rank 1
2025-01-10 22:55:03,472 DEBUG TRAIN Batch 114/1300 loss 0.048695 acc 0.961089 lr 0.00015034 grad_norm 0.450198 rank 2
2025-01-10 22:55:03,473 DEBUG TRAIN Batch 114/1300 loss 0.056294 acc 0.956796 lr 0.00015034 grad_norm 0.450198 rank 0
2025-01-10 22:55:28,049 DEBUG TRAIN Batch 114/1400 loss 0.039158 acc 0.971831 lr 0.00015030 grad_norm 0.429670 rank 1
2025-01-10 22:55:28,050 DEBUG TRAIN Batch 114/1400 loss 0.039197 acc 0.975570 lr 0.00015030 grad_norm 0.429670 rank 0
2025-01-10 22:55:28,050 DEBUG TRAIN Batch 114/1400 loss 0.043518 acc 0.966355 lr 0.00015030 grad_norm 0.429670 rank 2
2025-01-10 22:55:51,600 DEBUG TRAIN Batch 114/1500 loss 0.053335 acc 0.970027 lr 0.00015027 grad_norm 0.428003 rank 0
2025-01-10 22:55:51,601 DEBUG TRAIN Batch 114/1500 loss 0.061418 acc 0.957086 lr 0.00015027 grad_norm 0.428003 rank 1
2025-01-10 22:55:51,601 DEBUG TRAIN Batch 114/1500 loss 0.049459 acc 0.966546 lr 0.00015027 grad_norm 0.428003 rank 2
2025-01-10 22:56:15,358 DEBUG TRAIN Batch 114/1600 loss 0.062284 acc 0.956422 lr 0.00015024 grad_norm 0.442384 rank 1
2025-01-10 22:56:15,358 DEBUG TRAIN Batch 114/1600 loss 0.058063 acc 0.963370 lr 0.00015024 grad_norm 0.442384 rank 2
2025-01-10 22:56:15,358 DEBUG TRAIN Batch 114/1600 loss 0.045858 acc 0.966952 lr 0.00015024 grad_norm 0.442384 rank 0
2025-01-10 22:56:38,765 DEBUG TRAIN Batch 114/1700 loss 0.054771 acc 0.965919 lr 0.00015020 grad_norm 0.394983 rank 1
2025-01-10 22:56:38,765 DEBUG TRAIN Batch 114/1700 loss 0.047978 acc 0.965899 lr 0.00015020 grad_norm 0.394983 rank 0
2025-01-10 22:56:38,766 DEBUG TRAIN Batch 114/1700 loss 0.039607 acc 0.976626 lr 0.00015020 grad_norm 0.394983 rank 2
2025-01-10 22:57:02,329 DEBUG TRAIN Batch 114/1800 loss 0.034734 acc 0.977070 lr 0.00015017 grad_norm 0.414150 rank 0
2025-01-10 22:57:02,330 DEBUG TRAIN Batch 114/1800 loss 0.041555 acc 0.971031 lr 0.00015017 grad_norm 0.414150 rank 1
2025-01-10 22:57:02,330 DEBUG TRAIN Batch 114/1800 loss 0.050004 acc 0.969159 lr 0.00015017 grad_norm 0.414150 rank 2
2025-01-10 22:57:25,797 DEBUG TRAIN Batch 114/1900 loss 0.035177 acc 0.975402 lr 0.00015013 grad_norm 0.405943 rank 0
2025-01-10 22:57:25,797 DEBUG TRAIN Batch 114/1900 loss 0.042529 acc 0.973081 lr 0.00015013 grad_norm 0.405943 rank 1
2025-01-10 22:57:25,797 DEBUG TRAIN Batch 114/1900 loss 0.036804 acc 0.976116 lr 0.00015013 grad_norm 0.405943 rank 2
2025-01-10 22:57:49,535 DEBUG TRAIN Batch 114/2000 loss 0.067045 acc 0.954145 lr 0.00015010 grad_norm 0.445940 rank 2
2025-01-10 22:57:49,535 DEBUG TRAIN Batch 114/2000 loss 0.066393 acc 0.951542 lr 0.00015010 grad_norm 0.445940 rank 1
2025-01-10 22:57:49,536 DEBUG TRAIN Batch 114/2000 loss 0.042082 acc 0.968504 lr 0.00015010 grad_norm 0.445940 rank 0
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 22:59:01,287 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 22:59:01,290 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-10 22:59:01,706 INFO Epoch 114 Step 110987 on_batch_end True CV rank 2
2025-01-10 22:59:01,706 INFO Epoch 114 Step 110987 on_batch_end True CV rank 1
2025-01-10 22:59:01,706 INFO Epoch 114 Step 110987 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 22:59:10,886 DEBUG CV Batch 114/100 loss 0.006984 acc 0.997770  rank 0
2025-01-10 22:59:11,117 DEBUG CV Batch 114/100 loss 0.006984 acc 0.997770  rank 2
2025-01-10 22:59:11,335 DEBUG CV Batch 114/100 loss 0.006984 acc 0.997770  rank 1
2025-01-10 22:59:11,437 INFO Epoch 114 Step 110987 CV info lr 0.00015008384524789839 0 rank loss_2.4777334068744574 acc_0.7806664424245817
2025-01-10 22:59:11,653 INFO Epoch 114 Step 110987 CV info lr 0.00015008384524789839 2 rank loss_2.4777334068744574 acc_0.7806664424245817
2025-01-10 22:59:11,885 INFO Epoch 114 Step 110987 CV info lr 0.00015008384524789839 1 rank loss_2.4777334068744574 acc_0.7806664424245817
2025-01-10 22:59:12,768 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_114_whole.pt
2025-01-10 22:59:12,791 INFO Added key: store_based_barrier_key:117 to store for rank: 0
2025-01-10 22:59:12,791 INFO Added key: store_based_barrier_key:117 to store for rank: 2
2025-01-10 22:59:12,791 INFO Added key: store_based_barrier_key:117 to store for rank: 1
2025-01-10 22:59:12,791 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:117 with 3 nodes.
2025-01-10 22:59:12,791 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:117 with 3 nodes.
2025-01-10 22:59:12,791 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:117 with 3 nodes.
2025-01-10 22:59:12,791 INFO Epoch 115 TRAIN info lr 0.00015008384524789839 rank 2
2025-01-10 22:59:12,791 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 22:59:12,791 INFO Epoch 115 TRAIN info lr 0.00015008384524789839 rank 1
2025-01-10 22:59:12,791 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 22:59:12,800 INFO Epoch 115 TRAIN info lr 0.00015008384524789839 rank 0
2025-01-10 22:59:12,800 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 22:59:44,069 DEBUG TRAIN Batch 115/100 loss 0.034540 acc 0.978659 lr 0.00015005 grad_norm 0.380103 rank 0
2025-01-10 22:59:44,069 DEBUG TRAIN Batch 115/100 loss 0.040896 acc 0.978012 lr 0.00015005 grad_norm 0.380103 rank 1
2025-01-10 22:59:44,069 DEBUG TRAIN Batch 115/100 loss 0.038355 acc 0.970528 lr 0.00015005 grad_norm 0.380103 rank 2
2025-01-10 23:00:08,071 DEBUG TRAIN Batch 115/200 loss 0.037328 acc 0.970437 lr 0.00015002 grad_norm 0.432073 rank 0
2025-01-10 23:00:08,071 DEBUG TRAIN Batch 115/200 loss 0.045577 acc 0.964789 lr 0.00015002 grad_norm 0.432073 rank 2
2025-01-10 23:00:08,072 DEBUG TRAIN Batch 115/200 loss 0.034237 acc 0.977907 lr 0.00015002 grad_norm 0.432073 rank 1
2025-01-10 23:00:31,747 DEBUG TRAIN Batch 115/300 loss 0.039934 acc 0.971070 lr 0.00014998 grad_norm 0.420622 rank 2
2025-01-10 23:00:31,747 DEBUG TRAIN Batch 115/300 loss 0.038652 acc 0.977817 lr 0.00014998 grad_norm 0.420622 rank 1
2025-01-10 23:00:31,749 DEBUG TRAIN Batch 115/300 loss 0.049140 acc 0.967480 lr 0.00014998 grad_norm 0.420622 rank 0
2025-01-10 23:00:55,609 DEBUG TRAIN Batch 115/400 loss 0.046214 acc 0.974848 lr 0.00014995 grad_norm 0.408383 rank 1
2025-01-10 23:00:55,609 DEBUG TRAIN Batch 115/400 loss 0.047207 acc 0.969231 lr 0.00014995 grad_norm 0.408383 rank 2
2025-01-10 23:00:55,610 DEBUG TRAIN Batch 115/400 loss 0.042796 acc 0.970276 lr 0.00014995 grad_norm 0.408383 rank 0
2025-01-10 23:01:19,725 DEBUG TRAIN Batch 115/500 loss 0.040894 acc 0.965953 lr 0.00014992 grad_norm 0.411387 rank 1
2025-01-10 23:01:19,725 DEBUG TRAIN Batch 115/500 loss 0.048221 acc 0.968619 lr 0.00014992 grad_norm 0.411387 rank 2
2025-01-10 23:01:19,726 DEBUG TRAIN Batch 115/500 loss 0.049489 acc 0.967259 lr 0.00014992 grad_norm 0.411387 rank 0
2025-01-10 23:01:44,050 DEBUG TRAIN Batch 115/600 loss 0.043120 acc 0.970476 lr 0.00014988 grad_norm 0.412600 rank 1
2025-01-10 23:01:44,050 DEBUG TRAIN Batch 115/600 loss 0.056469 acc 0.966786 lr 0.00014988 grad_norm 0.412600 rank 2
2025-01-10 23:01:44,051 DEBUG TRAIN Batch 115/600 loss 0.044243 acc 0.966942 lr 0.00014988 grad_norm 0.412600 rank 0
2025-01-10 23:02:07,888 DEBUG TRAIN Batch 115/700 loss 0.030779 acc 0.978239 lr 0.00014985 grad_norm 0.400576 rank 0
2025-01-10 23:02:07,888 DEBUG TRAIN Batch 115/700 loss 0.039216 acc 0.970021 lr 0.00014985 grad_norm 0.400576 rank 2
2025-01-10 23:02:07,889 DEBUG TRAIN Batch 115/700 loss 0.031526 acc 0.979610 lr 0.00014985 grad_norm 0.400576 rank 1
2025-01-10 23:02:31,904 DEBUG TRAIN Batch 115/800 loss 0.052357 acc 0.960538 lr 0.00014981 grad_norm 0.409856 rank 1
2025-01-10 23:02:31,904 DEBUG TRAIN Batch 115/800 loss 0.027082 acc 0.985248 lr 0.00014981 grad_norm 0.409856 rank 0
2025-01-10 23:02:31,904 DEBUG TRAIN Batch 115/800 loss 0.059140 acc 0.957604 lr 0.00014981 grad_norm 0.409856 rank 2
2025-01-10 23:02:57,280 DEBUG TRAIN Batch 115/900 loss 0.060695 acc 0.955516 lr 0.00014978 grad_norm 0.461792 rank 0
2025-01-10 23:02:57,280 DEBUG TRAIN Batch 115/900 loss 0.042585 acc 0.970370 lr 0.00014978 grad_norm 0.461792 rank 1
2025-01-10 23:02:57,280 DEBUG TRAIN Batch 115/900 loss 0.059891 acc 0.966551 lr 0.00014978 grad_norm 0.461792 rank 2
2025-01-10 23:03:21,048 DEBUG TRAIN Batch 115/1000 loss 0.048049 acc 0.964728 lr 0.00014975 grad_norm 0.404414 rank 0
2025-01-10 23:03:21,048 DEBUG TRAIN Batch 115/1000 loss 0.045437 acc 0.969819 lr 0.00014975 grad_norm 0.404414 rank 1
2025-01-10 23:03:21,048 DEBUG TRAIN Batch 115/1000 loss 0.042413 acc 0.975258 lr 0.00014975 grad_norm 0.404414 rank 2
2025-01-10 23:03:44,753 DEBUG TRAIN Batch 115/1100 loss 0.045926 acc 0.963138 lr 0.00014971 grad_norm 0.430121 rank 2
2025-01-10 23:03:44,753 DEBUG TRAIN Batch 115/1100 loss 0.041874 acc 0.970556 lr 0.00014971 grad_norm 0.430121 rank 1
2025-01-10 23:03:44,754 DEBUG TRAIN Batch 115/1100 loss 0.038287 acc 0.978373 lr 0.00014971 grad_norm 0.430121 rank 0
2025-01-10 23:04:09,549 DEBUG TRAIN Batch 115/1200 loss 0.045014 acc 0.968627 lr 0.00014968 grad_norm 0.408123 rank 0
2025-01-10 23:04:09,550 DEBUG TRAIN Batch 115/1200 loss 0.040006 acc 0.972894 lr 0.00014968 grad_norm 0.408123 rank 2
2025-01-10 23:04:09,550 DEBUG TRAIN Batch 115/1200 loss 0.037174 acc 0.971513 lr 0.00014968 grad_norm 0.408123 rank 1
2025-01-10 23:04:33,020 DEBUG TRAIN Batch 115/1300 loss 0.048041 acc 0.970619 lr 0.00014965 grad_norm 0.446400 rank 0
2025-01-10 23:04:33,020 DEBUG TRAIN Batch 115/1300 loss 0.051721 acc 0.960613 lr 0.00014965 grad_norm 0.446400 rank 1
2025-01-10 23:04:33,020 DEBUG TRAIN Batch 115/1300 loss 0.047441 acc 0.966480 lr 0.00014965 grad_norm 0.446400 rank 2
2025-01-10 23:04:58,156 DEBUG TRAIN Batch 115/1400 loss 0.066685 acc 0.955988 lr 0.00014961 grad_norm 0.470046 rank 0
2025-01-10 23:04:58,156 DEBUG TRAIN Batch 115/1400 loss 0.048907 acc 0.966314 lr 0.00014961 grad_norm 0.470046 rank 2
2025-01-10 23:04:58,157 DEBUG TRAIN Batch 115/1400 loss 0.044133 acc 0.967153 lr 0.00014961 grad_norm 0.470046 rank 1
2025-01-10 23:05:23,904 DEBUG TRAIN Batch 115/1500 loss 0.040228 acc 0.970472 lr 0.00014958 grad_norm 0.421888 rank 1
2025-01-10 23:05:23,904 DEBUG TRAIN Batch 115/1500 loss 0.052743 acc 0.968528 lr 0.00014958 grad_norm 0.421888 rank 2
2025-01-10 23:05:23,905 DEBUG TRAIN Batch 115/1500 loss 0.034419 acc 0.976721 lr 0.00014958 grad_norm 0.421888 rank 0
2025-01-10 23:05:48,443 DEBUG TRAIN Batch 115/1600 loss 0.047327 acc 0.965720 lr 0.00014955 grad_norm 0.418104 rank 1
2025-01-10 23:05:48,444 DEBUG TRAIN Batch 115/1600 loss 0.027590 acc 0.984962 lr 0.00014955 grad_norm 0.418104 rank 2
2025-01-10 23:05:48,444 DEBUG TRAIN Batch 115/1600 loss 0.048402 acc 0.964222 lr 0.00014955 grad_norm 0.418104 rank 0
2025-01-10 23:06:12,857 DEBUG TRAIN Batch 115/1700 loss 0.052993 acc 0.960915 lr 0.00014951 grad_norm 0.451600 rank 2
2025-01-10 23:06:12,857 DEBUG TRAIN Batch 115/1700 loss 0.039812 acc 0.974790 lr 0.00014951 grad_norm 0.451600 rank 1
2025-01-10 23:06:12,857 DEBUG TRAIN Batch 115/1700 loss 0.040891 acc 0.966880 lr 0.00014951 grad_norm 0.451600 rank 0
2025-01-10 23:06:37,320 DEBUG TRAIN Batch 115/1800 loss 0.048279 acc 0.970755 lr 0.00014948 grad_norm 0.445522 rank 0
2025-01-10 23:06:37,320 DEBUG TRAIN Batch 115/1800 loss 0.036410 acc 0.973629 lr 0.00014948 grad_norm 0.445522 rank 2
2025-01-10 23:06:37,320 DEBUG TRAIN Batch 115/1800 loss 0.052312 acc 0.962142 lr 0.00014948 grad_norm 0.445522 rank 1
2025-01-10 23:07:01,944 DEBUG TRAIN Batch 115/1900 loss 0.030139 acc 0.977371 lr 0.00014945 grad_norm 0.418730 rank 1
2025-01-10 23:07:01,944 DEBUG TRAIN Batch 115/1900 loss 0.036335 acc 0.974907 lr 0.00014945 grad_norm 0.418730 rank 0
2025-01-10 23:07:01,944 DEBUG TRAIN Batch 115/1900 loss 0.040424 acc 0.966887 lr 0.00014945 grad_norm 0.418730 rank 2
2025-01-10 23:07:26,602 DEBUG TRAIN Batch 115/2000 loss 0.044211 acc 0.964829 lr 0.00014941 grad_norm 0.431678 rank 0
2025-01-10 23:07:26,602 DEBUG TRAIN Batch 115/2000 loss 0.036152 acc 0.973790 lr 0.00014941 grad_norm 0.431678 rank 2
2025-01-10 23:07:26,602 DEBUG TRAIN Batch 115/2000 loss 0.051375 acc 0.963972 lr 0.00014941 grad_norm 0.431678 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 23:08:35,598 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 23:08:35,602 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 23:08:36,007 INFO Epoch 115 Step 112005 on_batch_end True CV rank 0
2025-01-10 23:08:36,007 INFO Epoch 115 Step 112005 on_batch_end True CV rank 2
2025-01-10 23:08:36,007 INFO Epoch 115 Step 112005 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 23:08:45,199 DEBUG CV Batch 115/100 loss 0.002615 acc 1.000000  rank 0
2025-01-10 23:08:45,235 DEBUG CV Batch 115/100 loss 0.002615 acc 1.000000  rank 2
2025-01-10 23:08:45,572 DEBUG CV Batch 115/100 loss 0.002615 acc 1.000000  rank 1
2025-01-10 23:08:45,716 INFO Epoch 115 Step 112005 CV info lr 0.00014940024137720097 2 rank loss_2.4706289902985046 acc_0.7801378007259285
2025-01-10 23:08:45,742 INFO Epoch 115 Step 112005 CV info lr 0.00014940024137720097 0 rank loss_2.4706289902985046 acc_0.7801378007259285
2025-01-10 23:08:46,085 INFO Epoch 115 Step 112005 CV info lr 0.00014940024137720097 1 rank loss_2.4706289902985046 acc_0.7801378007259285
2025-01-10 23:08:47,090 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_115_whole.pt
2025-01-10 23:08:47,112 INFO Added key: store_based_barrier_key:118 to store for rank: 0
2025-01-10 23:08:47,122 INFO Added key: store_based_barrier_key:118 to store for rank: 2
2025-01-10 23:08:47,122 INFO Added key: store_based_barrier_key:118 to store for rank: 1
2025-01-10 23:08:47,122 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:118 with 3 nodes.
2025-01-10 23:08:47,122 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:118 with 3 nodes.
2025-01-10 23:08:47,122 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:118 with 3 nodes.
2025-01-10 23:08:47,123 INFO Epoch 116 TRAIN info lr 0.00014940024137720097 rank 2
2025-01-10 23:08:47,123 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 23:08:47,131 INFO Epoch 116 TRAIN info lr 0.00014940024137720097 rank 0
2025-01-10 23:08:47,131 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 23:08:47,132 INFO Epoch 116 TRAIN info lr 0.00014940024137720097 rank 1
2025-01-10 23:08:47,132 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 23:09:17,477 DEBUG TRAIN Batch 116/100 loss 0.039516 acc 0.975891 lr 0.00014937 grad_norm 0.409956 rank 0
2025-01-10 23:09:17,478 DEBUG TRAIN Batch 116/100 loss 0.038978 acc 0.968041 lr 0.00014937 grad_norm 0.409956 rank 1
2025-01-10 23:09:17,478 DEBUG TRAIN Batch 116/100 loss 0.051758 acc 0.971681 lr 0.00014937 grad_norm 0.409956 rank 2
2025-01-10 23:09:40,815 DEBUG TRAIN Batch 116/200 loss 0.049553 acc 0.971576 lr 0.00014933 grad_norm 0.422825 rank 0
2025-01-10 23:09:40,815 DEBUG TRAIN Batch 116/200 loss 0.034073 acc 0.975495 lr 0.00014933 grad_norm 0.422825 rank 1
2025-01-10 23:09:40,815 DEBUG TRAIN Batch 116/200 loss 0.050357 acc 0.968310 lr 0.00014933 grad_norm 0.422825 rank 2
2025-01-10 23:10:04,468 DEBUG TRAIN Batch 116/300 loss 0.036829 acc 0.971456 lr 0.00014930 grad_norm 0.430413 rank 0
2025-01-10 23:10:04,469 DEBUG TRAIN Batch 116/300 loss 0.049262 acc 0.963285 lr 0.00014930 grad_norm 0.430413 rank 2
2025-01-10 23:10:04,469 DEBUG TRAIN Batch 116/300 loss 0.034003 acc 0.973585 lr 0.00014930 grad_norm 0.430413 rank 1
2025-01-10 23:10:28,073 DEBUG TRAIN Batch 116/400 loss 0.034134 acc 0.981172 lr 0.00014927 grad_norm 0.398336 rank 0
2025-01-10 23:10:28,074 DEBUG TRAIN Batch 116/400 loss 0.045021 acc 0.970106 lr 0.00014927 grad_norm 0.398336 rank 1
2025-01-10 23:10:28,074 DEBUG TRAIN Batch 116/400 loss 0.034800 acc 0.973166 lr 0.00014927 grad_norm 0.398336 rank 2
2025-01-10 23:10:52,340 DEBUG TRAIN Batch 116/500 loss 0.052907 acc 0.963370 lr 0.00014923 grad_norm 0.415030 rank 0
2025-01-10 23:10:52,340 DEBUG TRAIN Batch 116/500 loss 0.046323 acc 0.965328 lr 0.00014923 grad_norm 0.415030 rank 2
2025-01-10 23:10:52,341 DEBUG TRAIN Batch 116/500 loss 0.044422 acc 0.970648 lr 0.00014923 grad_norm 0.415030 rank 1
2025-01-10 23:11:16,071 DEBUG TRAIN Batch 116/600 loss 0.045613 acc 0.964789 lr 0.00014920 grad_norm 0.434096 rank 1
2025-01-10 23:11:16,071 DEBUG TRAIN Batch 116/600 loss 0.043246 acc 0.970588 lr 0.00014920 grad_norm 0.434096 rank 2
2025-01-10 23:11:16,071 DEBUG TRAIN Batch 116/600 loss 0.043270 acc 0.968362 lr 0.00014920 grad_norm 0.434096 rank 0
2025-01-10 23:11:40,511 DEBUG TRAIN Batch 116/700 loss 0.054093 acc 0.961310 lr 0.00014917 grad_norm 0.433361 rank 1
2025-01-10 23:11:40,511 DEBUG TRAIN Batch 116/700 loss 0.056349 acc 0.964559 lr 0.00014917 grad_norm 0.433361 rank 0
2025-01-10 23:11:40,512 DEBUG TRAIN Batch 116/700 loss 0.056904 acc 0.962963 lr 0.00014917 grad_norm 0.433361 rank 2
2025-01-10 23:12:04,864 DEBUG TRAIN Batch 116/800 loss 0.032928 acc 0.975585 lr 0.00014913 grad_norm 0.420758 rank 0
2025-01-10 23:12:04,864 DEBUG TRAIN Batch 116/800 loss 0.037354 acc 0.968615 lr 0.00014913 grad_norm 0.420758 rank 1
2025-01-10 23:12:04,865 DEBUG TRAIN Batch 116/800 loss 0.046451 acc 0.969412 lr 0.00014913 grad_norm 0.420758 rank 2
2025-01-10 23:12:28,727 DEBUG TRAIN Batch 116/900 loss 0.036401 acc 0.975278 lr 0.00014910 grad_norm 0.403928 rank 0
2025-01-10 23:12:28,728 DEBUG TRAIN Batch 116/900 loss 0.051427 acc 0.962706 lr 0.00014910 grad_norm 0.403928 rank 1
2025-01-10 23:12:28,728 DEBUG TRAIN Batch 116/900 loss 0.063323 acc 0.959095 lr 0.00014910 grad_norm 0.403928 rank 2
2025-01-10 23:12:53,457 DEBUG TRAIN Batch 116/1000 loss 0.043287 acc 0.974522 lr 0.00014907 grad_norm 0.442356 rank 0
2025-01-10 23:12:53,457 DEBUG TRAIN Batch 116/1000 loss 0.070320 acc 0.952703 lr 0.00014907 grad_norm 0.442356 rank 1
2025-01-10 23:12:53,458 DEBUG TRAIN Batch 116/1000 loss 0.035107 acc 0.975177 lr 0.00014907 grad_norm 0.442356 rank 2
2025-01-10 23:13:18,124 DEBUG TRAIN Batch 116/1100 loss 0.050070 acc 0.964611 lr 0.00014903 grad_norm 0.404814 rank 1
2025-01-10 23:13:18,125 DEBUG TRAIN Batch 116/1100 loss 0.046695 acc 0.970534 lr 0.00014903 grad_norm 0.404814 rank 2
2025-01-10 23:13:18,125 DEBUG TRAIN Batch 116/1100 loss 0.040857 acc 0.974384 lr 0.00014903 grad_norm 0.404814 rank 0
2025-01-10 23:13:42,256 DEBUG TRAIN Batch 116/1200 loss 0.051455 acc 0.965238 lr 0.00014900 grad_norm 0.419972 rank 1
2025-01-10 23:13:42,257 DEBUG TRAIN Batch 116/1200 loss 0.036991 acc 0.977688 lr 0.00014900 grad_norm 0.419972 rank 0
2025-01-10 23:13:42,257 DEBUG TRAIN Batch 116/1200 loss 0.047301 acc 0.964945 lr 0.00014900 grad_norm 0.419972 rank 2
2025-01-10 23:14:07,297 DEBUG TRAIN Batch 116/1300 loss 0.052956 acc 0.960000 lr 0.00014897 grad_norm 0.439956 rank 0
2025-01-10 23:14:07,297 DEBUG TRAIN Batch 116/1300 loss 0.066756 acc 0.951686 lr 0.00014897 grad_norm 0.439956 rank 1
2025-01-10 23:14:07,298 DEBUG TRAIN Batch 116/1300 loss 0.036837 acc 0.972591 lr 0.00014897 grad_norm 0.439956 rank 2
2025-01-10 23:14:30,921 DEBUG TRAIN Batch 116/1400 loss 0.047818 acc 0.972949 lr 0.00014894 grad_norm 0.416887 rank 0
2025-01-10 23:14:30,922 DEBUG TRAIN Batch 116/1400 loss 0.054693 acc 0.957696 lr 0.00014894 grad_norm 0.416887 rank 1
2025-01-10 23:14:30,922 DEBUG TRAIN Batch 116/1400 loss 0.046699 acc 0.969147 lr 0.00014894 grad_norm 0.416887 rank 2
2025-01-10 23:14:55,098 DEBUG TRAIN Batch 116/1500 loss 0.039477 acc 0.976608 lr 0.00014890 grad_norm 0.412849 rank 1
2025-01-10 23:14:55,098 DEBUG TRAIN Batch 116/1500 loss 0.048205 acc 0.968254 lr 0.00014890 grad_norm 0.412849 rank 0
2025-01-10 23:14:55,099 DEBUG TRAIN Batch 116/1500 loss 0.051129 acc 0.972401 lr 0.00014890 grad_norm 0.412849 rank 2
2025-01-10 23:15:20,052 DEBUG TRAIN Batch 116/1600 loss 0.048308 acc 0.965804 lr 0.00014887 grad_norm 0.406252 rank 0
2025-01-10 23:15:20,052 DEBUG TRAIN Batch 116/1600 loss 0.047140 acc 0.970681 lr 0.00014887 grad_norm 0.406252 rank 1
2025-01-10 23:15:20,052 DEBUG TRAIN Batch 116/1600 loss 0.048246 acc 0.971204 lr 0.00014887 grad_norm 0.406252 rank 2
2025-01-10 23:15:44,059 DEBUG TRAIN Batch 116/1700 loss 0.063010 acc 0.955744 lr 0.00014884 grad_norm 0.426752 rank 1
2025-01-10 23:15:44,059 DEBUG TRAIN Batch 116/1700 loss 0.029553 acc 0.979638 lr 0.00014884 grad_norm 0.426752 rank 2
2025-01-10 23:15:44,059 DEBUG TRAIN Batch 116/1700 loss 0.042425 acc 0.981685 lr 0.00014884 grad_norm 0.426752 rank 0
2025-01-10 23:16:08,593 DEBUG TRAIN Batch 116/1800 loss 0.051797 acc 0.963235 lr 0.00014880 grad_norm 0.437729 rank 2
2025-01-10 23:16:08,594 DEBUG TRAIN Batch 116/1800 loss 0.054943 acc 0.965368 lr 0.00014880 grad_norm 0.437729 rank 1
2025-01-10 23:16:08,594 DEBUG TRAIN Batch 116/1800 loss 0.035302 acc 0.974232 lr 0.00014880 grad_norm 0.437729 rank 0
2025-01-10 23:16:32,530 DEBUG TRAIN Batch 116/1900 loss 0.047831 acc 0.971707 lr 0.00014877 grad_norm 0.427172 rank 0
2025-01-10 23:16:32,531 DEBUG TRAIN Batch 116/1900 loss 0.034147 acc 0.974529 lr 0.00014877 grad_norm 0.427172 rank 1
2025-01-10 23:16:32,531 DEBUG TRAIN Batch 116/1900 loss 0.039165 acc 0.968786 lr 0.00014877 grad_norm 0.427172 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 23:17:44,486 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 23:17:44,493 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 23:17:44,909 INFO Epoch 116 Step 112979 on_batch_end True CV rank 0
2025-01-10 23:17:44,909 INFO Epoch 116 Step 112979 on_batch_end True CV rank 2
2025-01-10 23:17:44,909 INFO Epoch 116 Step 112979 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 23:17:54,080 DEBUG CV Batch 116/100 loss 0.004510 acc 0.998885  rank 2
2025-01-10 23:17:54,374 DEBUG CV Batch 116/100 loss 0.004510 acc 0.998885  rank 0
2025-01-10 23:17:54,580 INFO Epoch 116 Step 112979 CV info lr 0.00014875485232296553 2 rank loss_2.4700089862729473 acc_0.7798468660105738
2025-01-10 23:17:54,853 DEBUG CV Batch 116/100 loss 0.004510 acc 0.998885  rank 1
2025-01-10 23:17:54,912 INFO Epoch 116 Step 112979 CV info lr 0.00014875485232296553 0 rank loss_2.4700089862729473 acc_0.7798468660105738
2025-01-10 23:17:55,400 INFO Epoch 116 Step 112979 CV info lr 0.00014875485232296553 1 rank loss_2.4700089862729473 acc_0.7798468660105738
2025-01-10 23:17:56,256 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_116_whole.pt
2025-01-10 23:17:56,278 INFO Added key: store_based_barrier_key:119 to store for rank: 1
2025-01-10 23:17:56,278 INFO Added key: store_based_barrier_key:119 to store for rank: 0
2025-01-10 23:17:56,278 INFO Added key: store_based_barrier_key:119 to store for rank: 2
2025-01-10 23:17:56,279 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:119 with 3 nodes.
2025-01-10 23:17:56,284 INFO Epoch 117 TRAIN info lr 0.00014875485232296553 rank 2
2025-01-10 23:17:56,284 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 23:17:56,289 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:119 with 3 nodes.
2025-01-10 23:17:56,289 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:119 with 3 nodes.
2025-01-10 23:17:56,292 INFO Epoch 117 TRAIN info lr 0.00014875485232296553 rank 1
2025-01-10 23:17:56,292 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 23:17:56,294 INFO Epoch 117 TRAIN info lr 0.00014875485232296553 rank 0
2025-01-10 23:17:56,294 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 23:18:28,546 DEBUG TRAIN Batch 117/100 loss 0.041263 acc 0.966330 lr 0.00014872 grad_norm 0.411813 rank 0
2025-01-10 23:18:28,546 DEBUG TRAIN Batch 117/100 loss 0.029835 acc 0.981053 lr 0.00014872 grad_norm 0.411813 rank 2
2025-01-10 23:18:28,547 DEBUG TRAIN Batch 117/100 loss 0.048631 acc 0.966816 lr 0.00014872 grad_norm 0.411813 rank 1
2025-01-10 23:18:52,426 DEBUG TRAIN Batch 117/200 loss 0.033078 acc 0.973618 lr 0.00014869 grad_norm 0.416676 rank 2
2025-01-10 23:18:52,426 DEBUG TRAIN Batch 117/200 loss 0.049754 acc 0.960280 lr 0.00014869 grad_norm 0.416676 rank 0
2025-01-10 23:18:52,426 DEBUG TRAIN Batch 117/200 loss 0.029639 acc 0.982648 lr 0.00014869 grad_norm 0.416676 rank 1
2025-01-10 23:19:16,136 DEBUG TRAIN Batch 117/300 loss 0.024011 acc 0.985359 lr 0.00014866 grad_norm 0.392395 rank 0
2025-01-10 23:19:16,136 DEBUG TRAIN Batch 117/300 loss 0.031139 acc 0.975610 lr 0.00014866 grad_norm 0.392395 rank 1
2025-01-10 23:19:16,136 DEBUG TRAIN Batch 117/300 loss 0.037087 acc 0.977626 lr 0.00014866 grad_norm 0.392395 rank 2
2025-01-10 23:19:40,324 DEBUG TRAIN Batch 117/400 loss 0.057112 acc 0.966425 lr 0.00014862 grad_norm 0.443665 rank 0
2025-01-10 23:19:40,324 DEBUG TRAIN Batch 117/400 loss 0.048461 acc 0.968577 lr 0.00014862 grad_norm 0.443665 rank 1
2025-01-10 23:19:40,324 DEBUG TRAIN Batch 117/400 loss 0.039958 acc 0.974306 lr 0.00014862 grad_norm 0.443665 rank 2
2025-01-10 23:20:04,438 DEBUG TRAIN Batch 117/500 loss 0.036108 acc 0.976485 lr 0.00014859 grad_norm 0.398214 rank 1
2025-01-10 23:20:04,438 DEBUG TRAIN Batch 117/500 loss 0.054315 acc 0.957858 lr 0.00014859 grad_norm 0.398214 rank 2
2025-01-10 23:20:04,439 DEBUG TRAIN Batch 117/500 loss 0.048803 acc 0.965961 lr 0.00014859 grad_norm 0.398214 rank 0
2025-01-10 23:20:28,209 DEBUG TRAIN Batch 117/600 loss 0.061264 acc 0.954464 lr 0.00014856 grad_norm 0.426810 rank 0
2025-01-10 23:20:28,210 DEBUG TRAIN Batch 117/600 loss 0.035784 acc 0.973869 lr 0.00014856 grad_norm 0.426810 rank 1
2025-01-10 23:20:28,210 DEBUG TRAIN Batch 117/600 loss 0.059830 acc 0.959809 lr 0.00014856 grad_norm 0.426810 rank 2
2025-01-10 23:20:52,725 DEBUG TRAIN Batch 117/700 loss 0.036611 acc 0.981233 lr 0.00014852 grad_norm 0.413330 rank 0
2025-01-10 23:20:52,726 DEBUG TRAIN Batch 117/700 loss 0.050675 acc 0.967943 lr 0.00014852 grad_norm 0.413330 rank 1
2025-01-10 23:20:52,726 DEBUG TRAIN Batch 117/700 loss 0.053663 acc 0.960340 lr 0.00014852 grad_norm 0.413330 rank 2
2025-01-10 23:21:17,065 DEBUG TRAIN Batch 117/800 loss 0.048351 acc 0.970348 lr 0.00014849 grad_norm 0.450008 rank 2
2025-01-10 23:21:17,065 DEBUG TRAIN Batch 117/800 loss 0.063983 acc 0.953014 lr 0.00014849 grad_norm 0.450008 rank 0
2025-01-10 23:21:17,065 DEBUG TRAIN Batch 117/800 loss 0.052589 acc 0.955179 lr 0.00014849 grad_norm 0.450008 rank 1
2025-01-10 23:21:42,128 DEBUG TRAIN Batch 117/900 loss 0.040788 acc 0.971457 lr 0.00014846 grad_norm 0.416790 rank 0
2025-01-10 23:21:42,128 DEBUG TRAIN Batch 117/900 loss 0.037657 acc 0.976667 lr 0.00014846 grad_norm 0.416790 rank 1
2025-01-10 23:21:42,129 DEBUG TRAIN Batch 117/900 loss 0.045696 acc 0.974003 lr 0.00014846 grad_norm 0.416790 rank 2
2025-01-10 23:22:06,867 DEBUG TRAIN Batch 117/1000 loss 0.039581 acc 0.969082 lr 0.00014843 grad_norm 0.404999 rank 1
2025-01-10 23:22:06,867 DEBUG TRAIN Batch 117/1000 loss 0.047300 acc 0.968300 lr 0.00014843 grad_norm 0.404999 rank 2
2025-01-10 23:22:06,867 DEBUG TRAIN Batch 117/1000 loss 0.038267 acc 0.968326 lr 0.00014843 grad_norm 0.404999 rank 0
2025-01-10 23:22:31,230 DEBUG TRAIN Batch 117/1100 loss 0.058880 acc 0.958115 lr 0.00014839 grad_norm 0.447857 rank 0
2025-01-10 23:22:31,231 DEBUG TRAIN Batch 117/1100 loss 0.049890 acc 0.973684 lr 0.00014839 grad_norm 0.447857 rank 1
2025-01-10 23:22:31,231 DEBUG TRAIN Batch 117/1100 loss 0.060517 acc 0.962536 lr 0.00014839 grad_norm 0.447857 rank 2
2025-01-10 23:22:56,767 DEBUG TRAIN Batch 117/1200 loss 0.041977 acc 0.970727 lr 0.00014836 grad_norm 0.428677 rank 0
2025-01-10 23:22:56,768 DEBUG TRAIN Batch 117/1200 loss 0.047451 acc 0.967308 lr 0.00014836 grad_norm 0.428677 rank 1
2025-01-10 23:22:56,768 DEBUG TRAIN Batch 117/1200 loss 0.050220 acc 0.964668 lr 0.00014836 grad_norm 0.428677 rank 2
2025-01-10 23:23:20,899 DEBUG TRAIN Batch 117/1300 loss 0.054272 acc 0.960000 lr 0.00014833 grad_norm 0.415657 rank 0
2025-01-10 23:23:20,899 DEBUG TRAIN Batch 117/1300 loss 0.034512 acc 0.972081 lr 0.00014833 grad_norm 0.415657 rank 2
2025-01-10 23:23:20,899 DEBUG TRAIN Batch 117/1300 loss 0.052849 acc 0.963710 lr 0.00014833 grad_norm 0.415657 rank 1
2025-01-10 23:23:45,667 DEBUG TRAIN Batch 117/1400 loss 0.061416 acc 0.962149 lr 0.00014830 grad_norm 0.462701 rank 0
2025-01-10 23:23:45,667 DEBUG TRAIN Batch 117/1400 loss 0.057853 acc 0.962889 lr 0.00014830 grad_norm 0.462701 rank 1
2025-01-10 23:23:45,668 DEBUG TRAIN Batch 117/1400 loss 0.038484 acc 0.969783 lr 0.00014830 grad_norm 0.462701 rank 2
2025-01-10 23:24:10,149 DEBUG TRAIN Batch 117/1500 loss 0.072215 acc 0.955614 lr 0.00014826 grad_norm 0.443737 rank 0
2025-01-10 23:24:10,150 DEBUG TRAIN Batch 117/1500 loss 0.065094 acc 0.955536 lr 0.00014826 grad_norm 0.443737 rank 1
2025-01-10 23:24:10,150 DEBUG TRAIN Batch 117/1500 loss 0.048775 acc 0.965858 lr 0.00014826 grad_norm 0.443737 rank 2
2025-01-10 23:24:33,961 DEBUG TRAIN Batch 117/1600 loss 0.060324 acc 0.963636 lr 0.00014823 grad_norm 0.476644 rank 2
2025-01-10 23:24:33,961 DEBUG TRAIN Batch 117/1600 loss 0.059476 acc 0.956920 lr 0.00014823 grad_norm 0.476644 rank 0
2025-01-10 23:24:33,962 DEBUG TRAIN Batch 117/1600 loss 0.052367 acc 0.960825 lr 0.00014823 grad_norm 0.476644 rank 1
2025-01-10 23:24:59,099 DEBUG TRAIN Batch 117/1700 loss 0.030417 acc 0.977459 lr 0.00014820 grad_norm 0.389910 rank 1
2025-01-10 23:24:59,099 DEBUG TRAIN Batch 117/1700 loss 0.044126 acc 0.971485 lr 0.00014820 grad_norm 0.389910 rank 0
2025-01-10 23:24:59,099 DEBUG TRAIN Batch 117/1700 loss 0.035161 acc 0.973856 lr 0.00014820 grad_norm 0.389910 rank 2
2025-01-10 23:25:24,284 DEBUG TRAIN Batch 117/1800 loss 0.036756 acc 0.973333 lr 0.00014817 grad_norm 0.409134 rank 0
2025-01-10 23:25:24,284 DEBUG TRAIN Batch 117/1800 loss 0.033343 acc 0.979671 lr 0.00014817 grad_norm 0.409134 rank 1
2025-01-10 23:25:24,285 DEBUG TRAIN Batch 117/1800 loss 0.044786 acc 0.964218 lr 0.00014817 grad_norm 0.409134 rank 2
2025-01-10 23:25:48,692 DEBUG TRAIN Batch 117/1900 loss 0.050249 acc 0.962928 lr 0.00014813 grad_norm 0.431480 rank 0
2025-01-10 23:25:48,693 DEBUG TRAIN Batch 117/1900 loss 0.043434 acc 0.973958 lr 0.00014813 grad_norm 0.431480 rank 1
2025-01-10 23:25:48,693 DEBUG TRAIN Batch 117/1900 loss 0.046616 acc 0.966435 lr 0.00014813 grad_norm 0.431480 rank 2
2025-01-10 23:26:13,077 DEBUG TRAIN Batch 117/2000 loss 0.054857 acc 0.958372 lr 0.00014810 grad_norm 0.401329 rank 0
2025-01-10 23:26:13,078 DEBUG TRAIN Batch 117/2000 loss 0.035058 acc 0.974335 lr 0.00014810 grad_norm 0.401329 rank 1
2025-01-10 23:26:13,078 DEBUG TRAIN Batch 117/2000 loss 0.046355 acc 0.965879 lr 0.00014810 grad_norm 0.401329 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 23:27:27,168 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 23:27:27,169 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 23:27:27,566 INFO Epoch 117 Step 114008 on_batch_end True CV rank 0
2025-01-10 23:27:27,566 INFO Epoch 117 Step 114008 on_batch_end True CV rank 2
2025-01-10 23:27:27,566 INFO Epoch 117 Step 114008 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 23:27:36,764 DEBUG CV Batch 117/100 loss 0.007883 acc 0.997770  rank 2
2025-01-10 23:27:36,809 DEBUG CV Batch 117/100 loss 0.007883 acc 0.997770  rank 0
2025-01-10 23:27:37,301 INFO Epoch 117 Step 114008 CV info lr 0.00014808202367044569 2 rank loss_2.4794735349990478 acc_0.7805041706091479
2025-01-10 23:27:37,340 INFO Epoch 117 Step 114008 CV info lr 0.00014808202367044569 0 rank loss_2.4794735349990478 acc_0.7805041706091479
2025-01-10 23:27:37,579 DEBUG CV Batch 117/100 loss 0.007883 acc 0.997770  rank 1
2025-01-10 23:27:38,123 INFO Epoch 117 Step 114008 CV info lr 0.00014808202367044569 1 rank loss_2.4794735349990478 acc_0.7805041706091479
2025-01-10 23:27:38,691 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_117_whole.pt
2025-01-10 23:27:38,703 INFO Added key: store_based_barrier_key:120 to store for rank: 0
2025-01-10 23:27:38,714 INFO Added key: store_based_barrier_key:120 to store for rank: 1
2025-01-10 23:27:38,714 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:120 with 3 nodes.
2025-01-10 23:27:38,714 INFO Added key: store_based_barrier_key:120 to store for rank: 2
2025-01-10 23:27:38,714 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:120 with 3 nodes.
2025-01-10 23:27:38,715 INFO Epoch 118 TRAIN info lr 0.00014808202367044569 rank 2
2025-01-10 23:27:38,715 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 23:27:38,718 INFO Epoch 118 TRAIN info lr 0.00014808202367044569 rank 1
2025-01-10 23:27:38,718 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 23:27:38,724 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:120 with 3 nodes.
2025-01-10 23:27:38,724 INFO Epoch 118 TRAIN info lr 0.00014808202367044569 rank 0
2025-01-10 23:27:38,725 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 23:28:12,757 DEBUG TRAIN Batch 118/100 loss 0.051825 acc 0.966014 lr 0.00014805 grad_norm 0.394728 rank 0
2025-01-10 23:28:12,757 DEBUG TRAIN Batch 118/100 loss 0.052110 acc 0.965004 lr 0.00014805 grad_norm 0.394728 rank 1
2025-01-10 23:28:12,757 DEBUG TRAIN Batch 118/100 loss 0.033067 acc 0.976583 lr 0.00014805 grad_norm 0.394728 rank 2
2025-01-10 23:28:36,704 DEBUG TRAIN Batch 118/200 loss 0.044256 acc 0.966605 lr 0.00014802 grad_norm 0.415467 rank 1
2025-01-10 23:28:36,704 DEBUG TRAIN Batch 118/200 loss 0.041337 acc 0.968031 lr 0.00014802 grad_norm 0.415467 rank 0
2025-01-10 23:28:36,705 DEBUG TRAIN Batch 118/200 loss 0.036178 acc 0.973848 lr 0.00014802 grad_norm 0.415467 rank 2
2025-01-10 23:29:00,939 DEBUG TRAIN Batch 118/300 loss 0.037169 acc 0.972452 lr 0.00014798 grad_norm 0.401379 rank 2
2025-01-10 23:29:00,939 DEBUG TRAIN Batch 118/300 loss 0.050778 acc 0.963470 lr 0.00014798 grad_norm 0.401379 rank 1
2025-01-10 23:29:00,939 DEBUG TRAIN Batch 118/300 loss 0.049007 acc 0.959576 lr 0.00014798 grad_norm 0.401379 rank 0
2025-01-10 23:29:25,304 DEBUG TRAIN Batch 118/400 loss 0.041387 acc 0.969231 lr 0.00014795 grad_norm 0.433202 rank 0
2025-01-10 23:29:25,304 DEBUG TRAIN Batch 118/400 loss 0.030327 acc 0.981073 lr 0.00014795 grad_norm 0.433202 rank 1
2025-01-10 23:29:25,305 DEBUG TRAIN Batch 118/400 loss 0.050078 acc 0.967742 lr 0.00014795 grad_norm 0.433202 rank 2
2025-01-10 23:29:49,456 DEBUG TRAIN Batch 118/500 loss 0.042204 acc 0.968937 lr 0.00014792 grad_norm 0.395305 rank 1
2025-01-10 23:29:49,456 DEBUG TRAIN Batch 118/500 loss 0.027963 acc 0.981317 lr 0.00014792 grad_norm 0.395305 rank 0
2025-01-10 23:29:49,456 DEBUG TRAIN Batch 118/500 loss 0.034527 acc 0.978605 lr 0.00014792 grad_norm 0.395305 rank 2
2025-01-10 23:30:12,949 DEBUG TRAIN Batch 118/600 loss 0.032865 acc 0.978010 lr 0.00014789 grad_norm 0.391372 rank 0
2025-01-10 23:30:12,949 DEBUG TRAIN Batch 118/600 loss 0.030208 acc 0.981043 lr 0.00014789 grad_norm 0.391372 rank 2
2025-01-10 23:30:12,950 DEBUG TRAIN Batch 118/600 loss 0.042870 acc 0.970425 lr 0.00014789 grad_norm 0.391372 rank 1
2025-01-10 23:30:37,598 DEBUG TRAIN Batch 118/700 loss 0.051256 acc 0.966576 lr 0.00014786 grad_norm 0.417466 rank 0
2025-01-10 23:30:37,599 DEBUG TRAIN Batch 118/700 loss 0.056209 acc 0.961710 lr 0.00014786 grad_norm 0.417466 rank 1
2025-01-10 23:30:37,599 DEBUG TRAIN Batch 118/700 loss 0.032891 acc 0.976916 lr 0.00014786 grad_norm 0.417466 rank 2
2025-01-10 23:31:02,658 DEBUG TRAIN Batch 118/800 loss 0.039760 acc 0.974217 lr 0.00014782 grad_norm 0.422953 rank 0
2025-01-10 23:31:02,659 DEBUG TRAIN Batch 118/800 loss 0.044188 acc 0.967362 lr 0.00014782 grad_norm 0.422953 rank 2
2025-01-10 23:31:02,659 DEBUG TRAIN Batch 118/800 loss 0.063103 acc 0.958333 lr 0.00014782 grad_norm 0.422953 rank 1
2025-01-10 23:31:26,290 DEBUG TRAIN Batch 118/900 loss 0.033032 acc 0.975634 lr 0.00014779 grad_norm 0.432198 rank 0
2025-01-10 23:31:26,290 DEBUG TRAIN Batch 118/900 loss 0.038707 acc 0.968847 lr 0.00014779 grad_norm 0.432198 rank 1
2025-01-10 23:31:26,291 DEBUG TRAIN Batch 118/900 loss 0.048882 acc 0.966342 lr 0.00014779 grad_norm 0.432198 rank 2
2025-01-10 23:31:50,536 DEBUG TRAIN Batch 118/1000 loss 0.062052 acc 0.956637 lr 0.00014776 grad_norm 0.434610 rank 0
2025-01-10 23:31:50,537 DEBUG TRAIN Batch 118/1000 loss 0.046425 acc 0.969091 lr 0.00014776 grad_norm 0.434610 rank 2
2025-01-10 23:31:50,537 DEBUG TRAIN Batch 118/1000 loss 0.051769 acc 0.972274 lr 0.00014776 grad_norm 0.434610 rank 1
2025-01-10 23:32:15,102 DEBUG TRAIN Batch 118/1100 loss 0.061327 acc 0.963908 lr 0.00014773 grad_norm 0.401989 rank 0
2025-01-10 23:32:15,102 DEBUG TRAIN Batch 118/1100 loss 0.033063 acc 0.981339 lr 0.00014773 grad_norm 0.401989 rank 1
2025-01-10 23:32:15,102 DEBUG TRAIN Batch 118/1100 loss 0.026762 acc 0.980437 lr 0.00014773 grad_norm 0.401989 rank 2
2025-01-10 23:32:40,186 DEBUG TRAIN Batch 118/1200 loss 0.039887 acc 0.974805 lr 0.00014769 grad_norm 0.398084 rank 0
2025-01-10 23:32:40,187 DEBUG TRAIN Batch 118/1200 loss 0.043548 acc 0.972872 lr 0.00014769 grad_norm 0.398084 rank 1
2025-01-10 23:32:40,187 DEBUG TRAIN Batch 118/1200 loss 0.043448 acc 0.972926 lr 0.00014769 grad_norm 0.398084 rank 2
2025-01-10 23:33:03,921 DEBUG TRAIN Batch 118/1300 loss 0.037764 acc 0.971216 lr 0.00014766 grad_norm 0.413887 rank 0
2025-01-10 23:33:03,922 DEBUG TRAIN Batch 118/1300 loss 0.052195 acc 0.964539 lr 0.00014766 grad_norm 0.413887 rank 1
2025-01-10 23:33:03,922 DEBUG TRAIN Batch 118/1300 loss 0.028153 acc 0.984663 lr 0.00014766 grad_norm 0.413887 rank 2
2025-01-10 23:33:27,887 DEBUG TRAIN Batch 118/1400 loss 0.036312 acc 0.975866 lr 0.00014763 grad_norm 0.436924 rank 1
2025-01-10 23:33:27,887 DEBUG TRAIN Batch 118/1400 loss 0.037670 acc 0.975342 lr 0.00014763 grad_norm 0.436924 rank 2
2025-01-10 23:33:27,887 DEBUG TRAIN Batch 118/1400 loss 0.051360 acc 0.963158 lr 0.00014763 grad_norm 0.436924 rank 0
2025-01-10 23:33:52,691 DEBUG TRAIN Batch 118/1500 loss 0.040353 acc 0.971223 lr 0.00014760 grad_norm 0.426407 rank 1
2025-01-10 23:33:52,691 DEBUG TRAIN Batch 118/1500 loss 0.064874 acc 0.946593 lr 0.00014760 grad_norm 0.426407 rank 0
2025-01-10 23:33:52,692 DEBUG TRAIN Batch 118/1500 loss 0.028919 acc 0.978458 lr 0.00014760 grad_norm 0.426407 rank 2
2025-01-10 23:34:16,986 DEBUG TRAIN Batch 118/1600 loss 0.049069 acc 0.969697 lr 0.00014757 grad_norm 0.390720 rank 0
2025-01-10 23:34:16,987 DEBUG TRAIN Batch 118/1600 loss 0.038339 acc 0.973072 lr 0.00014757 grad_norm 0.390720 rank 1
2025-01-10 23:34:16,987 DEBUG TRAIN Batch 118/1600 loss 0.034556 acc 0.975149 lr 0.00014757 grad_norm 0.390720 rank 2
2025-01-10 23:34:41,179 DEBUG TRAIN Batch 118/1700 loss 0.040466 acc 0.973496 lr 0.00014753 grad_norm 0.445473 rank 0
2025-01-10 23:34:41,180 DEBUG TRAIN Batch 118/1700 loss 0.044269 acc 0.966805 lr 0.00014753 grad_norm 0.445473 rank 2
2025-01-10 23:34:41,180 DEBUG TRAIN Batch 118/1700 loss 0.051982 acc 0.960514 lr 0.00014753 grad_norm 0.445473 rank 1
2025-01-10 23:35:07,040 DEBUG TRAIN Batch 118/1800 loss 0.042096 acc 0.967930 lr 0.00014750 grad_norm 0.421797 rank 1
2025-01-10 23:35:07,040 DEBUG TRAIN Batch 118/1800 loss 0.040212 acc 0.965473 lr 0.00014750 grad_norm 0.421797 rank 0
2025-01-10 23:35:07,041 DEBUG TRAIN Batch 118/1800 loss 0.021508 acc 0.988136 lr 0.00014750 grad_norm 0.421797 rank 2
2025-01-10 23:35:30,955 DEBUG TRAIN Batch 118/1900 loss 0.053421 acc 0.959633 lr 0.00014747 grad_norm 0.419073 rank 0
2025-01-10 23:35:30,955 DEBUG TRAIN Batch 118/1900 loss 0.041839 acc 0.973492 lr 0.00014747 grad_norm 0.419073 rank 1
2025-01-10 23:35:30,955 DEBUG TRAIN Batch 118/1900 loss 0.024707 acc 0.988006 lr 0.00014747 grad_norm 0.419073 rank 2
2025-01-10 23:35:55,368 DEBUG TRAIN Batch 118/2000 loss 0.044572 acc 0.969442 lr 0.00014744 grad_norm 0.427419 rank 0
2025-01-10 23:35:55,368 DEBUG TRAIN Batch 118/2000 loss 0.042408 acc 0.973864 lr 0.00014744 grad_norm 0.427419 rank 1
2025-01-10 23:35:55,368 DEBUG TRAIN Batch 118/2000 loss 0.033752 acc 0.975734 lr 0.00014744 grad_norm 0.427419 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 23:37:19,215 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 23:37:19,217 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 23:37:19,624 INFO Epoch 118 Step 115054 on_batch_end True CV rank 0
2025-01-10 23:37:19,624 INFO Epoch 118 Step 115054 on_batch_end True CV rank 2
2025-01-10 23:37:19,624 INFO Epoch 118 Step 115054 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 23:37:28,676 DEBUG CV Batch 118/100 loss 0.002386 acc 1.000000  rank 0
2025-01-10 23:37:28,957 DEBUG CV Batch 118/100 loss 0.002386 acc 1.000000  rank 2
2025-01-10 23:37:29,209 INFO Epoch 118 Step 115054 CV info lr 0.00014740735153416783 0 rank loss_2.4824881194003146 acc_0.7799206760368849
2025-01-10 23:37:29,493 INFO Epoch 118 Step 115054 CV info lr 0.00014740735153416783 2 rank loss_2.4824881194003146 acc_0.7799206760368849
2025-01-10 23:37:29,797 DEBUG CV Batch 118/100 loss 0.002386 acc 1.000000  rank 1
2025-01-10 23:37:30,364 INFO Epoch 118 Step 115054 CV info lr 0.00014740735153416783 1 rank loss_2.4824881194003146 acc_0.7799206760368849
2025-01-10 23:37:30,565 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_118_whole.pt
2025-01-10 23:37:30,577 INFO Added key: store_based_barrier_key:121 to store for rank: 0
2025-01-10 23:37:30,587 INFO Added key: store_based_barrier_key:121 to store for rank: 1
2025-01-10 23:37:30,587 INFO Added key: store_based_barrier_key:121 to store for rank: 2
2025-01-10 23:37:30,587 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:121 with 3 nodes.
2025-01-10 23:37:30,587 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:121 with 3 nodes.
2025-01-10 23:37:30,587 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:121 with 3 nodes.
2025-01-10 23:37:30,591 INFO Epoch 119 TRAIN info lr 0.00014740735153416783 rank 2
2025-01-10 23:37:30,592 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 23:37:30,592 INFO Epoch 119 TRAIN info lr 0.00014740735153416783 rank 0
2025-01-10 23:37:30,592 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 23:37:30,592 INFO Epoch 119 TRAIN info lr 0.00014740735153416783 rank 1
2025-01-10 23:37:30,592 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 23:38:01,865 DEBUG TRAIN Batch 119/100 loss 0.039871 acc 0.968815 lr 0.00014738 grad_norm 0.386853 rank 0
2025-01-10 23:38:01,865 DEBUG TRAIN Batch 119/100 loss 0.033141 acc 0.978484 lr 0.00014738 grad_norm 0.386853 rank 1
2025-01-10 23:38:01,865 DEBUG TRAIN Batch 119/100 loss 0.045737 acc 0.976598 lr 0.00014738 grad_norm 0.386853 rank 2
2025-01-10 23:38:25,896 DEBUG TRAIN Batch 119/200 loss 0.053266 acc 0.963834 lr 0.00014734 grad_norm 0.393498 rank 1
2025-01-10 23:38:25,896 DEBUG TRAIN Batch 119/200 loss 0.059157 acc 0.959825 lr 0.00014734 grad_norm 0.393498 rank 0
2025-01-10 23:38:25,896 DEBUG TRAIN Batch 119/200 loss 0.037025 acc 0.974359 lr 0.00014734 grad_norm 0.393498 rank 2
2025-01-10 23:38:49,760 DEBUG TRAIN Batch 119/300 loss 0.044462 acc 0.969828 lr 0.00014731 grad_norm 0.423306 rank 1
2025-01-10 23:38:49,760 DEBUG TRAIN Batch 119/300 loss 0.037458 acc 0.976054 lr 0.00014731 grad_norm 0.423306 rank 0
2025-01-10 23:38:49,760 DEBUG TRAIN Batch 119/300 loss 0.050991 acc 0.965201 lr 0.00014731 grad_norm 0.423306 rank 2
2025-01-10 23:39:13,464 DEBUG TRAIN Batch 119/400 loss 0.046824 acc 0.962090 lr 0.00014728 grad_norm 0.405466 rank 0
2025-01-10 23:39:13,464 DEBUG TRAIN Batch 119/400 loss 0.045215 acc 0.966418 lr 0.00014728 grad_norm 0.405466 rank 1
2025-01-10 23:39:13,465 DEBUG TRAIN Batch 119/400 loss 0.033054 acc 0.979038 lr 0.00014728 grad_norm 0.405466 rank 2
2025-01-10 23:39:37,401 DEBUG TRAIN Batch 119/500 loss 0.037356 acc 0.976542 lr 0.00014725 grad_norm 0.392673 rank 0
2025-01-10 23:39:37,401 DEBUG TRAIN Batch 119/500 loss 0.040300 acc 0.971892 lr 0.00014725 grad_norm 0.392673 rank 2
2025-01-10 23:39:37,401 DEBUG TRAIN Batch 119/500 loss 0.037317 acc 0.974147 lr 0.00014725 grad_norm 0.392673 rank 1
2025-01-10 23:40:01,481 DEBUG TRAIN Batch 119/600 loss 0.057191 acc 0.961165 lr 0.00014722 grad_norm 0.447514 rank 2
2025-01-10 23:40:01,481 DEBUG TRAIN Batch 119/600 loss 0.060018 acc 0.956567 lr 0.00014722 grad_norm 0.447514 rank 0
2025-01-10 23:40:01,481 DEBUG TRAIN Batch 119/600 loss 0.048668 acc 0.969019 lr 0.00014722 grad_norm 0.447514 rank 1
2025-01-10 23:40:26,567 DEBUG TRAIN Batch 119/700 loss 0.049584 acc 0.967332 lr 0.00014718 grad_norm 0.422449 rank 0
2025-01-10 23:40:26,568 DEBUG TRAIN Batch 119/700 loss 0.038617 acc 0.976861 lr 0.00014718 grad_norm 0.422449 rank 2
2025-01-10 23:40:26,571 DEBUG TRAIN Batch 119/700 loss 0.031291 acc 0.980791 lr 0.00014718 grad_norm 0.422449 rank 1
2025-01-10 23:40:50,464 DEBUG TRAIN Batch 119/800 loss 0.033480 acc 0.980270 lr 0.00014715 grad_norm 0.400721 rank 0
2025-01-10 23:40:50,464 DEBUG TRAIN Batch 119/800 loss 0.036076 acc 0.976645 lr 0.00014715 grad_norm 0.400721 rank 2
2025-01-10 23:40:50,464 DEBUG TRAIN Batch 119/800 loss 0.054815 acc 0.963035 lr 0.00014715 grad_norm 0.400721 rank 1
2025-01-10 23:41:14,868 DEBUG TRAIN Batch 119/900 loss 0.049151 acc 0.965004 lr 0.00014712 grad_norm 0.407024 rank 0
2025-01-10 23:41:14,869 DEBUG TRAIN Batch 119/900 loss 0.043323 acc 0.973238 lr 0.00014712 grad_norm 0.407024 rank 2
2025-01-10 23:41:14,869 DEBUG TRAIN Batch 119/900 loss 0.045391 acc 0.967949 lr 0.00014712 grad_norm 0.407024 rank 1
2025-01-10 23:41:40,079 DEBUG TRAIN Batch 119/1000 loss 0.025137 acc 0.984211 lr 0.00014709 grad_norm 0.381132 rank 0
2025-01-10 23:41:40,079 DEBUG TRAIN Batch 119/1000 loss 0.044034 acc 0.968885 lr 0.00014709 grad_norm 0.381132 rank 1
2025-01-10 23:41:40,079 DEBUG TRAIN Batch 119/1000 loss 0.045071 acc 0.969501 lr 0.00014709 grad_norm 0.381132 rank 2
2025-01-10 23:42:03,936 DEBUG TRAIN Batch 119/1100 loss 0.038978 acc 0.972246 lr 0.00014706 grad_norm 0.382785 rank 0
2025-01-10 23:42:03,937 DEBUG TRAIN Batch 119/1100 loss 0.043692 acc 0.972393 lr 0.00014706 grad_norm 0.382785 rank 1
2025-01-10 23:42:03,937 DEBUG TRAIN Batch 119/1100 loss 0.023763 acc 0.983184 lr 0.00014706 grad_norm 0.382785 rank 2
2025-01-10 23:42:29,482 DEBUG TRAIN Batch 119/1200 loss 0.040046 acc 0.970530 lr 0.00014702 grad_norm 0.436229 rank 0
2025-01-10 23:42:29,483 DEBUG TRAIN Batch 119/1200 loss 0.043749 acc 0.970848 lr 0.00014702 grad_norm 0.436229 rank 2
2025-01-10 23:42:29,483 DEBUG TRAIN Batch 119/1200 loss 0.050350 acc 0.965551 lr 0.00014702 grad_norm 0.436229 rank 1
2025-01-10 23:42:53,529 DEBUG TRAIN Batch 119/1300 loss 0.041592 acc 0.972000 lr 0.00014699 grad_norm 0.420965 rank 1
2025-01-10 23:42:53,529 DEBUG TRAIN Batch 119/1300 loss 0.040833 acc 0.971154 lr 0.00014699 grad_norm 0.420965 rank 2
2025-01-10 23:42:53,529 DEBUG TRAIN Batch 119/1300 loss 0.061101 acc 0.960000 lr 0.00014699 grad_norm 0.420965 rank 0
2025-01-10 23:43:17,688 DEBUG TRAIN Batch 119/1400 loss 0.054504 acc 0.959783 lr 0.00014696 grad_norm 0.436673 rank 0
2025-01-10 23:43:17,688 DEBUG TRAIN Batch 119/1400 loss 0.053028 acc 0.965356 lr 0.00014696 grad_norm 0.436673 rank 1
2025-01-10 23:43:17,688 DEBUG TRAIN Batch 119/1400 loss 0.036995 acc 0.976099 lr 0.00014696 grad_norm 0.436673 rank 2
2025-01-10 23:43:42,940 DEBUG TRAIN Batch 119/1500 loss 0.034354 acc 0.982639 lr 0.00014693 grad_norm 0.408149 rank 2
2025-01-10 23:43:42,940 DEBUG TRAIN Batch 119/1500 loss 0.041906 acc 0.968999 lr 0.00014693 grad_norm 0.408149 rank 1
2025-01-10 23:43:42,940 DEBUG TRAIN Batch 119/1500 loss 0.053537 acc 0.967033 lr 0.00014693 grad_norm 0.408149 rank 0
2025-01-10 23:44:08,198 DEBUG TRAIN Batch 119/1600 loss 0.059378 acc 0.957865 lr 0.00014690 grad_norm 0.422244 rank 0
2025-01-10 23:44:08,198 DEBUG TRAIN Batch 119/1600 loss 0.042378 acc 0.976357 lr 0.00014690 grad_norm 0.422244 rank 2
2025-01-10 23:44:08,199 DEBUG TRAIN Batch 119/1600 loss 0.049347 acc 0.961609 lr 0.00014690 grad_norm 0.422244 rank 1
2025-01-10 23:44:31,838 DEBUG TRAIN Batch 119/1700 loss 0.049316 acc 0.964317 lr 0.00014687 grad_norm 0.436430 rank 0
2025-01-10 23:44:31,838 DEBUG TRAIN Batch 119/1700 loss 0.053376 acc 0.967834 lr 0.00014687 grad_norm 0.436430 rank 2
2025-01-10 23:44:31,838 DEBUG TRAIN Batch 119/1700 loss 0.039673 acc 0.980000 lr 0.00014687 grad_norm 0.436430 rank 1
2025-01-10 23:44:56,168 DEBUG TRAIN Batch 119/1800 loss 0.043033 acc 0.963685 lr 0.00014683 grad_norm 0.394537 rank 0
2025-01-10 23:44:56,168 DEBUG TRAIN Batch 119/1800 loss 0.054367 acc 0.960117 lr 0.00014683 grad_norm 0.394537 rank 1
2025-01-10 23:44:56,169 DEBUG TRAIN Batch 119/1800 loss 0.031088 acc 0.976915 lr 0.00014683 grad_norm 0.394537 rank 2
2025-01-10 23:45:20,549 DEBUG TRAIN Batch 119/1900 loss 0.041516 acc 0.978261 lr 0.00014680 grad_norm 0.432940 rank 0
2025-01-10 23:45:20,550 DEBUG TRAIN Batch 119/1900 loss 0.044045 acc 0.968478 lr 0.00014680 grad_norm 0.432940 rank 2
2025-01-10 23:45:20,550 DEBUG TRAIN Batch 119/1900 loss 0.040764 acc 0.971079 lr 0.00014680 grad_norm 0.432940 rank 1
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 23:46:32,421 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-10 23:46:32,423 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 23:46:32,868 INFO Epoch 119 Step 116028 on_batch_end True CV rank 0
2025-01-10 23:46:32,868 INFO Epoch 119 Step 116028 on_batch_end True CV rank 2
2025-01-10 23:46:32,868 INFO Epoch 119 Step 116028 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 23:46:42,228 DEBUG CV Batch 119/100 loss 0.002435 acc 1.000000  rank 0
2025-01-10 23:46:42,233 DEBUG CV Batch 119/100 loss 0.002435 acc 1.000000  rank 2
2025-01-10 23:46:42,763 INFO Epoch 119 Step 116028 CV info lr 0.00014678734023412202 0 rank loss_2.480881769971395 acc_0.7803061834552831
2025-01-10 23:46:42,765 INFO Epoch 119 Step 116028 CV info lr 0.00014678734023412202 2 rank loss_2.480881769971395 acc_0.7803061834552831
2025-01-10 23:46:42,948 DEBUG CV Batch 119/100 loss 0.002435 acc 1.000000  rank 1
2025-01-10 23:46:43,513 INFO Epoch 119 Step 116028 CV info lr 0.00014678734023412202 1 rank loss_2.480881769971395 acc_0.7803061834552831
2025-01-10 23:46:44,089 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_119_whole.pt
2025-01-10 23:46:44,100 INFO Added key: store_based_barrier_key:122 to store for rank: 0
2025-01-10 23:46:44,110 INFO Added key: store_based_barrier_key:122 to store for rank: 1
2025-01-10 23:46:44,111 INFO Added key: store_based_barrier_key:122 to store for rank: 2
2025-01-10 23:46:44,111 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:122 with 3 nodes.
2025-01-10 23:46:44,120 INFO Epoch 120 TRAIN info lr 0.00014678734023412202 rank 2
2025-01-10 23:46:44,120 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 23:46:44,121 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:122 with 3 nodes.
2025-01-10 23:46:44,121 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:122 with 3 nodes.
2025-01-10 23:46:44,126 INFO Epoch 120 TRAIN info lr 0.00014678734023412202 rank 1
2025-01-10 23:46:44,126 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 23:46:44,128 INFO Epoch 120 TRAIN info lr 0.00014678734023412202 rank 0
2025-01-10 23:46:44,128 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 23:47:20,640 DEBUG TRAIN Batch 120/100 loss 0.042163 acc 0.971647 lr 0.00014676 grad_norm 0.405563 rank 2
2025-01-10 23:47:20,640 DEBUG TRAIN Batch 120/100 loss 0.045839 acc 0.962999 lr 0.00014676 grad_norm 0.405563 rank 1
2025-01-10 23:47:20,641 DEBUG TRAIN Batch 120/100 loss 0.037948 acc 0.971193 lr 0.00014676 grad_norm 0.405563 rank 0
2025-01-10 23:47:44,990 DEBUG TRAIN Batch 120/200 loss 0.028841 acc 0.975439 lr 0.00014672 grad_norm 0.432669 rank 2
2025-01-10 23:47:44,991 DEBUG TRAIN Batch 120/200 loss 0.046758 acc 0.965642 lr 0.00014672 grad_norm 0.432669 rank 1
2025-01-10 23:47:44,992 DEBUG TRAIN Batch 120/200 loss 0.047652 acc 0.969811 lr 0.00014672 grad_norm 0.432669 rank 0
2025-01-10 23:48:10,103 DEBUG TRAIN Batch 120/300 loss 0.033282 acc 0.974816 lr 0.00014669 grad_norm 0.392902 rank 1
2025-01-10 23:48:10,103 DEBUG TRAIN Batch 120/300 loss 0.026663 acc 0.978261 lr 0.00014669 grad_norm 0.392902 rank 0
2025-01-10 23:48:10,103 DEBUG TRAIN Batch 120/300 loss 0.030841 acc 0.979133 lr 0.00014669 grad_norm 0.392902 rank 2
2025-01-10 23:48:34,350 DEBUG TRAIN Batch 120/400 loss 0.038747 acc 0.974763 lr 0.00014666 grad_norm 0.422626 rank 0
2025-01-10 23:48:34,351 DEBUG TRAIN Batch 120/400 loss 0.071487 acc 0.952153 lr 0.00014666 grad_norm 0.422626 rank 2
2025-01-10 23:48:34,351 DEBUG TRAIN Batch 120/400 loss 0.052552 acc 0.965272 lr 0.00014666 grad_norm 0.422626 rank 1
2025-01-10 23:48:58,954 DEBUG TRAIN Batch 120/500 loss 0.044370 acc 0.965251 lr 0.00014663 grad_norm 0.400094 rank 2
2025-01-10 23:48:58,954 DEBUG TRAIN Batch 120/500 loss 0.048227 acc 0.971197 lr 0.00014663 grad_norm 0.400094 rank 0
2025-01-10 23:48:58,954 DEBUG TRAIN Batch 120/500 loss 0.042030 acc 0.966851 lr 0.00014663 grad_norm 0.400094 rank 1
2025-01-10 23:49:24,086 DEBUG TRAIN Batch 120/600 loss 0.048799 acc 0.967742 lr 0.00014660 grad_norm 0.417765 rank 1
2025-01-10 23:49:24,086 DEBUG TRAIN Batch 120/600 loss 0.043112 acc 0.971093 lr 0.00014660 grad_norm 0.417765 rank 0
2025-01-10 23:49:24,087 DEBUG TRAIN Batch 120/600 loss 0.047562 acc 0.965760 lr 0.00014660 grad_norm 0.417765 rank 2
2025-01-10 23:49:49,064 DEBUG TRAIN Batch 120/700 loss 0.053002 acc 0.958702 lr 0.00014657 grad_norm 0.440120 rank 0
2025-01-10 23:49:49,064 DEBUG TRAIN Batch 120/700 loss 0.047323 acc 0.973009 lr 0.00014657 grad_norm 0.440120 rank 2
2025-01-10 23:49:49,065 DEBUG TRAIN Batch 120/700 loss 0.051629 acc 0.962547 lr 0.00014657 grad_norm 0.440120 rank 1
2025-01-10 23:50:15,232 DEBUG TRAIN Batch 120/800 loss 0.039362 acc 0.970913 lr 0.00014653 grad_norm 0.400153 rank 2
2025-01-10 23:50:15,232 DEBUG TRAIN Batch 120/800 loss 0.050180 acc 0.966134 lr 0.00014653 grad_norm 0.400153 rank 0
2025-01-10 23:50:15,233 DEBUG TRAIN Batch 120/800 loss 0.048700 acc 0.969244 lr 0.00014653 grad_norm 0.400153 rank 1
2025-01-10 23:50:39,302 DEBUG TRAIN Batch 120/900 loss 0.031218 acc 0.977163 lr 0.00014650 grad_norm 0.403526 rank 0
2025-01-10 23:50:39,302 DEBUG TRAIN Batch 120/900 loss 0.046782 acc 0.964061 lr 0.00014650 grad_norm 0.403526 rank 1
2025-01-10 23:50:39,302 DEBUG TRAIN Batch 120/900 loss 0.035964 acc 0.979920 lr 0.00014650 grad_norm 0.403526 rank 2
2025-01-10 23:51:04,254 DEBUG TRAIN Batch 120/1000 loss 0.039075 acc 0.973123 lr 0.00014647 grad_norm 0.427857 rank 0
2025-01-10 23:51:04,254 DEBUG TRAIN Batch 120/1000 loss 0.054566 acc 0.961879 lr 0.00014647 grad_norm 0.427857 rank 2
2025-01-10 23:51:04,255 DEBUG TRAIN Batch 120/1000 loss 0.051890 acc 0.955923 lr 0.00014647 grad_norm 0.427857 rank 1
2025-01-10 23:51:30,227 DEBUG TRAIN Batch 120/1100 loss 0.051688 acc 0.967679 lr 0.00014644 grad_norm 0.435465 rank 0
2025-01-10 23:51:30,227 DEBUG TRAIN Batch 120/1100 loss 0.043980 acc 0.975435 lr 0.00014644 grad_norm 0.435465 rank 1
2025-01-10 23:51:30,227 DEBUG TRAIN Batch 120/1100 loss 0.034200 acc 0.972136 lr 0.00014644 grad_norm 0.435465 rank 2
2025-01-10 23:51:54,150 DEBUG TRAIN Batch 120/1200 loss 0.046072 acc 0.977738 lr 0.00014641 grad_norm 0.449391 rank 0
2025-01-10 23:51:54,150 DEBUG TRAIN Batch 120/1200 loss 0.035868 acc 0.975118 lr 0.00014641 grad_norm 0.449391 rank 1
2025-01-10 23:51:54,150 DEBUG TRAIN Batch 120/1200 loss 0.044559 acc 0.970070 lr 0.00014641 grad_norm 0.449391 rank 2
2025-01-10 23:52:17,958 DEBUG TRAIN Batch 120/1300 loss 0.035978 acc 0.977362 lr 0.00014638 grad_norm 0.422296 rank 2
2025-01-10 23:52:17,958 DEBUG TRAIN Batch 120/1300 loss 0.048275 acc 0.975482 lr 0.00014638 grad_norm 0.422296 rank 1
2025-01-10 23:52:17,958 DEBUG TRAIN Batch 120/1300 loss 0.047777 acc 0.970430 lr 0.00014638 grad_norm 0.422296 rank 0
2025-01-10 23:52:41,666 DEBUG TRAIN Batch 120/1400 loss 0.043521 acc 0.978723 lr 0.00014635 grad_norm 0.444392 rank 2
2025-01-10 23:52:41,666 DEBUG TRAIN Batch 120/1400 loss 0.052658 acc 0.961538 lr 0.00014635 grad_norm 0.444392 rank 0
2025-01-10 23:52:41,666 DEBUG TRAIN Batch 120/1400 loss 0.039630 acc 0.972387 lr 0.00014635 grad_norm 0.444392 rank 1
2025-01-10 23:53:05,824 DEBUG TRAIN Batch 120/1500 loss 0.052283 acc 0.963039 lr 0.00014632 grad_norm 0.428503 rank 0
2025-01-10 23:53:05,824 DEBUG TRAIN Batch 120/1500 loss 0.051610 acc 0.965302 lr 0.00014632 grad_norm 0.428503 rank 1
2025-01-10 23:53:05,824 DEBUG TRAIN Batch 120/1500 loss 0.043938 acc 0.970919 lr 0.00014632 grad_norm 0.428503 rank 2
2025-01-10 23:53:30,056 DEBUG TRAIN Batch 120/1600 loss 0.054476 acc 0.959164 lr 0.00014628 grad_norm 0.436162 rank 2
2025-01-10 23:53:30,057 DEBUG TRAIN Batch 120/1600 loss 0.027185 acc 0.981941 lr 0.00014628 grad_norm 0.436162 rank 1
2025-01-10 23:53:30,057 DEBUG TRAIN Batch 120/1600 loss 0.049151 acc 0.962963 lr 0.00014628 grad_norm 0.436162 rank 0
2025-01-10 23:53:54,746 DEBUG TRAIN Batch 120/1700 loss 0.048258 acc 0.969891 lr 0.00014625 grad_norm 0.402292 rank 2
2025-01-10 23:53:54,747 DEBUG TRAIN Batch 120/1700 loss 0.039241 acc 0.976534 lr 0.00014625 grad_norm 0.402292 rank 0
2025-01-10 23:53:54,747 DEBUG TRAIN Batch 120/1700 loss 0.052095 acc 0.963262 lr 0.00014625 grad_norm 0.402292 rank 1
2025-01-10 23:54:18,595 DEBUG TRAIN Batch 120/1800 loss 0.032073 acc 0.976693 lr 0.00014622 grad_norm 0.418860 rank 2
2025-01-10 23:54:18,595 DEBUG TRAIN Batch 120/1800 loss 0.036715 acc 0.978316 lr 0.00014622 grad_norm 0.418860 rank 0
2025-01-10 23:54:18,595 DEBUG TRAIN Batch 120/1800 loss 0.048033 acc 0.967164 lr 0.00014622 grad_norm 0.418860 rank 1
2025-01-10 23:54:42,481 DEBUG TRAIN Batch 120/1900 loss 0.033369 acc 0.973180 lr 0.00014619 grad_norm 0.406715 rank 2
2025-01-10 23:54:42,482 DEBUG TRAIN Batch 120/1900 loss 0.037165 acc 0.973196 lr 0.00014619 grad_norm 0.406715 rank 1
2025-01-10 23:54:42,482 DEBUG TRAIN Batch 120/1900 loss 0.039204 acc 0.969312 lr 0.00014619 grad_norm 0.406715 rank 0
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-10 23:56:01,842 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-10 23:56:01,848 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-10 23:56:02,299 INFO Epoch 120 Step 117019 on_batch_end True CV rank 0
2025-01-10 23:56:02,299 INFO Epoch 120 Step 117019 on_batch_end True CV rank 2
2025-01-10 23:56:02,299 INFO Epoch 120 Step 117019 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 23:56:11,615 DEBUG CV Batch 120/100 loss 0.006383 acc 0.998885  rank 0
2025-01-10 23:56:11,631 DEBUG CV Batch 120/100 loss 0.006383 acc 0.998885  rank 2
2025-01-10 23:56:11,976 DEBUG CV Batch 120/100 loss 0.006383 acc 0.998885  rank 1
2025-01-10 23:56:12,156 INFO Epoch 120 Step 117019 CV info lr 0.00014616446897778177 0 rank loss_2.502970207826206 acc_0.7799674285608426
2025-01-10 23:56:12,167 INFO Epoch 120 Step 117019 CV info lr 0.00014616446897778177 2 rank loss_2.502970207826206 acc_0.7799674285608426
2025-01-10 23:56:12,499 INFO Epoch 120 Step 117019 CV info lr 0.00014616446897778177 1 rank loss_2.502970207826206 acc_0.7799674285608426
2025-01-10 23:56:13,480 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_120_whole.pt
2025-01-10 23:56:13,492 INFO Added key: store_based_barrier_key:123 to store for rank: 0
2025-01-10 23:56:13,502 INFO Added key: store_based_barrier_key:123 to store for rank: 2
2025-01-10 23:56:13,502 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:123 with 3 nodes.
2025-01-10 23:56:13,502 INFO Added key: store_based_barrier_key:123 to store for rank: 1
2025-01-10 23:56:13,502 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:123 with 3 nodes.
2025-01-10 23:56:13,502 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:123 with 3 nodes.
2025-01-10 23:56:13,508 INFO Epoch 121 TRAIN info lr 0.00014616446897778177 rank 1
2025-01-10 23:56:13,508 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 23:56:13,509 INFO Epoch 121 TRAIN info lr 0.00014616446897778177 rank 0
2025-01-10 23:56:13,509 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-10 23:56:13,512 INFO Epoch 121 TRAIN info lr 0.00014616446897778177 rank 2
2025-01-10 23:56:13,512 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-10 23:56:44,980 DEBUG TRAIN Batch 121/100 loss 0.042367 acc 0.970435 lr 0.00014613 grad_norm 0.429641 rank 1
2025-01-10 23:56:44,980 DEBUG TRAIN Batch 121/100 loss 0.045311 acc 0.961331 lr 0.00014613 grad_norm 0.429641 rank 2
2025-01-10 23:56:44,980 DEBUG TRAIN Batch 121/100 loss 0.049864 acc 0.961538 lr 0.00014613 grad_norm 0.429641 rank 0
2025-01-10 23:57:08,995 DEBUG TRAIN Batch 121/200 loss 0.051561 acc 0.965517 lr 0.00014610 grad_norm 0.408880 rank 2
2025-01-10 23:57:08,995 DEBUG TRAIN Batch 121/200 loss 0.040219 acc 0.970588 lr 0.00014610 grad_norm 0.408880 rank 1
2025-01-10 23:57:08,995 DEBUG TRAIN Batch 121/200 loss 0.035718 acc 0.976071 lr 0.00014610 grad_norm 0.408880 rank 0
2025-01-10 23:57:33,628 DEBUG TRAIN Batch 121/300 loss 0.047804 acc 0.964627 lr 0.00014607 grad_norm 0.394439 rank 0
2025-01-10 23:57:33,628 DEBUG TRAIN Batch 121/300 loss 0.035856 acc 0.978873 lr 0.00014607 grad_norm 0.394439 rank 1
2025-01-10 23:57:33,629 DEBUG TRAIN Batch 121/300 loss 0.038521 acc 0.974499 lr 0.00014607 grad_norm 0.394439 rank 2
2025-01-10 23:57:57,352 DEBUG TRAIN Batch 121/400 loss 0.029717 acc 0.978818 lr 0.00014604 grad_norm 0.427619 rank 1
2025-01-10 23:57:57,352 DEBUG TRAIN Batch 121/400 loss 0.035802 acc 0.973236 lr 0.00014604 grad_norm 0.427619 rank 2
2025-01-10 23:57:57,353 DEBUG TRAIN Batch 121/400 loss 0.050811 acc 0.967228 lr 0.00014604 grad_norm 0.427619 rank 0
2025-01-10 23:58:21,469 DEBUG TRAIN Batch 121/500 loss 0.049218 acc 0.960945 lr 0.00014601 grad_norm 0.414097 rank 2
2025-01-10 23:58:21,470 DEBUG TRAIN Batch 121/500 loss 0.046315 acc 0.967603 lr 0.00014601 grad_norm 0.414097 rank 1
2025-01-10 23:58:21,470 DEBUG TRAIN Batch 121/500 loss 0.045706 acc 0.968393 lr 0.00014601 grad_norm 0.414097 rank 0
2025-01-10 23:58:45,809 DEBUG TRAIN Batch 121/600 loss 0.044087 acc 0.973207 lr 0.00014598 grad_norm 0.414053 rank 2
2025-01-10 23:58:45,810 DEBUG TRAIN Batch 121/600 loss 0.059752 acc 0.962371 lr 0.00014598 grad_norm 0.414053 rank 1
2025-01-10 23:58:45,810 DEBUG TRAIN Batch 121/600 loss 0.036279 acc 0.974783 lr 0.00014598 grad_norm 0.414053 rank 0
2025-01-10 23:59:09,680 DEBUG TRAIN Batch 121/700 loss 0.042210 acc 0.972873 lr 0.00014595 grad_norm 0.413932 rank 2
2025-01-10 23:59:09,680 DEBUG TRAIN Batch 121/700 loss 0.025001 acc 0.985356 lr 0.00014595 grad_norm 0.413932 rank 0
2025-01-10 23:59:09,680 DEBUG TRAIN Batch 121/700 loss 0.050572 acc 0.969488 lr 0.00014595 grad_norm 0.413932 rank 1
2025-01-10 23:59:33,773 DEBUG TRAIN Batch 121/800 loss 0.045404 acc 0.971485 lr 0.00014592 grad_norm 0.430488 rank 2
2025-01-10 23:59:33,773 DEBUG TRAIN Batch 121/800 loss 0.027528 acc 0.975570 lr 0.00014592 grad_norm 0.430488 rank 0
2025-01-10 23:59:33,774 DEBUG TRAIN Batch 121/800 loss 0.071428 acc 0.958449 lr 0.00014592 grad_norm 0.430488 rank 1
2025-01-10 23:59:57,857 DEBUG TRAIN Batch 121/900 loss 0.052339 acc 0.962230 lr 0.00014588 grad_norm 0.401119 rank 2
2025-01-10 23:59:57,858 DEBUG TRAIN Batch 121/900 loss 0.039078 acc 0.965766 lr 0.00014588 grad_norm 0.401119 rank 0
2025-01-10 23:59:57,858 DEBUG TRAIN Batch 121/900 loss 0.054917 acc 0.969697 lr 0.00014588 grad_norm 0.401119 rank 1
2025-01-11 00:00:21,805 DEBUG TRAIN Batch 121/1000 loss 0.030684 acc 0.980462 lr 0.00014585 grad_norm 0.422100 rank 1
2025-01-11 00:00:21,805 DEBUG TRAIN Batch 121/1000 loss 0.035579 acc 0.970551 lr 0.00014585 grad_norm 0.422100 rank 0
2025-01-11 00:00:21,806 DEBUG TRAIN Batch 121/1000 loss 0.042935 acc 0.974737 lr 0.00014585 grad_norm 0.422100 rank 2
2025-01-11 00:00:45,380 DEBUG TRAIN Batch 121/1100 loss 0.035820 acc 0.973941 lr 0.00014582 grad_norm 0.431758 rank 0
2025-01-11 00:00:45,381 DEBUG TRAIN Batch 121/1100 loss 0.047179 acc 0.967480 lr 0.00014582 grad_norm 0.431758 rank 1
2025-01-11 00:00:45,381 DEBUG TRAIN Batch 121/1100 loss 0.034333 acc 0.975806 lr 0.00014582 grad_norm 0.431758 rank 2
2025-01-11 00:01:10,133 DEBUG TRAIN Batch 121/1200 loss 0.031503 acc 0.978643 lr 0.00014579 grad_norm 0.375059 rank 1
2025-01-11 00:01:10,133 DEBUG TRAIN Batch 121/1200 loss 0.016286 acc 0.988562 lr 0.00014579 grad_norm 0.375059 rank 0
2025-01-11 00:01:10,133 DEBUG TRAIN Batch 121/1200 loss 0.031749 acc 0.980132 lr 0.00014579 grad_norm 0.375059 rank 2
2025-01-11 00:01:34,680 DEBUG TRAIN Batch 121/1300 loss 0.046971 acc 0.964147 lr 0.00014576 grad_norm 0.422410 rank 1
2025-01-11 00:01:34,681 DEBUG TRAIN Batch 121/1300 loss 0.045128 acc 0.971530 lr 0.00014576 grad_norm 0.422410 rank 0
2025-01-11 00:01:34,681 DEBUG TRAIN Batch 121/1300 loss 0.030862 acc 0.978196 lr 0.00014576 grad_norm 0.422410 rank 2
2025-01-11 00:01:58,768 DEBUG TRAIN Batch 121/1400 loss 0.041305 acc 0.968085 lr 0.00014573 grad_norm 0.442433 rank 0
2025-01-11 00:01:58,769 DEBUG TRAIN Batch 121/1400 loss 0.045376 acc 0.965797 lr 0.00014573 grad_norm 0.442433 rank 2
2025-01-11 00:01:58,770 DEBUG TRAIN Batch 121/1400 loss 0.049141 acc 0.970287 lr 0.00014573 grad_norm 0.442433 rank 1
2025-01-11 00:02:22,942 DEBUG TRAIN Batch 121/1500 loss 0.051079 acc 0.962927 lr 0.00014570 grad_norm 0.411044 rank 1
2025-01-11 00:02:22,943 DEBUG TRAIN Batch 121/1500 loss 0.051268 acc 0.962282 lr 0.00014570 grad_norm 0.411044 rank 0
2025-01-11 00:02:22,943 DEBUG TRAIN Batch 121/1500 loss 0.047570 acc 0.972603 lr 0.00014570 grad_norm 0.411044 rank 2
2025-01-11 00:02:47,155 DEBUG TRAIN Batch 121/1600 loss 0.039089 acc 0.970760 lr 0.00014567 grad_norm 0.413714 rank 1
2025-01-11 00:02:47,156 DEBUG TRAIN Batch 121/1600 loss 0.032415 acc 0.977059 lr 0.00014567 grad_norm 0.413714 rank 2
2025-01-11 00:02:47,156 DEBUG TRAIN Batch 121/1600 loss 0.049195 acc 0.968153 lr 0.00014567 grad_norm 0.413714 rank 0
2025-01-11 00:03:11,602 DEBUG TRAIN Batch 121/1700 loss 0.045377 acc 0.968473 lr 0.00014564 grad_norm 0.416406 rank 1
2025-01-11 00:03:11,602 DEBUG TRAIN Batch 121/1700 loss 0.049658 acc 0.970560 lr 0.00014564 grad_norm 0.416406 rank 0
2025-01-11 00:03:11,603 DEBUG TRAIN Batch 121/1700 loss 0.028458 acc 0.980670 lr 0.00014564 grad_norm 0.416406 rank 2
2025-01-11 00:03:34,814 DEBUG TRAIN Batch 121/1800 loss 0.044778 acc 0.968907 lr 0.00014561 grad_norm 0.420534 rank 1
2025-01-11 00:03:34,814 DEBUG TRAIN Batch 121/1800 loss 0.058901 acc 0.958678 lr 0.00014561 grad_norm 0.420534 rank 2
2025-01-11 00:03:34,815 DEBUG TRAIN Batch 121/1800 loss 0.032568 acc 0.981763 lr 0.00014561 grad_norm 0.420534 rank 0
2025-01-11 00:03:58,813 DEBUG TRAIN Batch 121/1900 loss 0.030482 acc 0.983135 lr 0.00014557 grad_norm 0.393851 rank 1
2025-01-11 00:03:58,813 DEBUG TRAIN Batch 121/1900 loss 0.034976 acc 0.975050 lr 0.00014557 grad_norm 0.393851 rank 0
2025-01-11 00:03:58,813 DEBUG TRAIN Batch 121/1900 loss 0.042585 acc 0.969398 lr 0.00014557 grad_norm 0.393851 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 00:05:09,287 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 00:05:09,288 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 00:05:09,763 INFO Epoch 121 Step 117990 on_batch_end True CV rank 0
2025-01-11 00:05:09,763 INFO Epoch 121 Step 117990 on_batch_end True CV rank 2
2025-01-11 00:05:09,764 INFO Epoch 121 Step 117990 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 00:05:18,858 DEBUG CV Batch 121/100 loss 0.003593 acc 1.000000  rank 0
2025-01-11 00:05:18,994 DEBUG CV Batch 121/100 loss 0.003593 acc 1.000000  rank 2
2025-01-11 00:05:19,343 DEBUG CV Batch 121/100 loss 0.003593 acc 1.000000  rank 1
2025-01-11 00:05:19,387 INFO Epoch 121 Step 117990 CV info lr 0.00014556179543826438 0 rank loss_2.5096309424721097 acc_0.7805487567134071
2025-01-11 00:05:19,488 INFO Epoch 121 Step 117990 CV info lr 0.00014556179543826438 2 rank loss_2.5096309424721097 acc_0.7805487567134071
2025-01-11 00:05:19,880 INFO Epoch 121 Step 117990 CV info lr 0.00014556179543826438 1 rank loss_2.5096309424721097 acc_0.7805487567134071
2025-01-11 00:05:20,703 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_121_whole.pt
2025-01-11 00:05:20,725 INFO Added key: store_based_barrier_key:124 to store for rank: 0
2025-01-11 00:05:20,725 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:124 with 3 nodes.
2025-01-11 00:05:20,725 INFO Added key: store_based_barrier_key:124 to store for rank: 2
2025-01-11 00:05:20,725 INFO Added key: store_based_barrier_key:124 to store for rank: 1
2025-01-11 00:05:20,725 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:124 with 3 nodes.
2025-01-11 00:05:20,725 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:124 with 3 nodes.
2025-01-11 00:05:20,733 INFO Epoch 122 TRAIN info lr 0.00014556179543826438 rank 1
2025-01-11 00:05:20,733 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 00:05:20,733 INFO Epoch 122 TRAIN info lr 0.00014556179543826438 rank 2
2025-01-11 00:05:20,733 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 00:05:20,734 INFO Epoch 122 TRAIN info lr 0.00014556179543826438 rank 0
2025-01-11 00:05:20,734 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 00:05:52,163 DEBUG TRAIN Batch 122/100 loss 0.029351 acc 0.978852 lr 0.00014553 grad_norm 0.406208 rank 2
2025-01-11 00:05:52,164 DEBUG TRAIN Batch 122/100 loss 0.058026 acc 0.959854 lr 0.00014553 grad_norm 0.406208 rank 0
2025-01-11 00:05:52,164 DEBUG TRAIN Batch 122/100 loss 0.031794 acc 0.982564 lr 0.00014553 grad_norm 0.406208 rank 1
2025-01-11 00:06:16,037 DEBUG TRAIN Batch 122/200 loss 0.034193 acc 0.974747 lr 0.00014550 grad_norm 0.398122 rank 1
2025-01-11 00:06:16,038 DEBUG TRAIN Batch 122/200 loss 0.033018 acc 0.980371 lr 0.00014550 grad_norm 0.398122 rank 0
2025-01-11 00:06:16,038 DEBUG TRAIN Batch 122/200 loss 0.038999 acc 0.970306 lr 0.00014550 grad_norm 0.398122 rank 2
2025-01-11 00:06:40,342 DEBUG TRAIN Batch 122/300 loss 0.041013 acc 0.973633 lr 0.00014547 grad_norm 0.404026 rank 1
2025-01-11 00:06:40,342 DEBUG TRAIN Batch 122/300 loss 0.034509 acc 0.972097 lr 0.00014547 grad_norm 0.404026 rank 0
2025-01-11 00:06:40,342 DEBUG TRAIN Batch 122/300 loss 0.034931 acc 0.975733 lr 0.00014547 grad_norm 0.404026 rank 2
2025-01-11 00:07:03,774 DEBUG TRAIN Batch 122/400 loss 0.028856 acc 0.980319 lr 0.00014544 grad_norm 0.391356 rank 2
2025-01-11 00:07:03,774 DEBUG TRAIN Batch 122/400 loss 0.031721 acc 0.974843 lr 0.00014544 grad_norm 0.391356 rank 1
2025-01-11 00:07:03,774 DEBUG TRAIN Batch 122/400 loss 0.042116 acc 0.972421 lr 0.00014544 grad_norm 0.391356 rank 0
2025-01-11 00:07:28,415 DEBUG TRAIN Batch 122/500 loss 0.038377 acc 0.970588 lr 0.00014541 grad_norm 0.397479 rank 2
2025-01-11 00:07:28,416 DEBUG TRAIN Batch 122/500 loss 0.023618 acc 0.981513 lr 0.00014541 grad_norm 0.397479 rank 0
2025-01-11 00:07:28,416 DEBUG TRAIN Batch 122/500 loss 0.052447 acc 0.969314 lr 0.00014541 grad_norm 0.397479 rank 1
2025-01-11 00:07:52,396 DEBUG TRAIN Batch 122/600 loss 0.040195 acc 0.974569 lr 0.00014538 grad_norm 0.398466 rank 1
2025-01-11 00:07:52,396 DEBUG TRAIN Batch 122/600 loss 0.036260 acc 0.974586 lr 0.00014538 grad_norm 0.398466 rank 2
2025-01-11 00:07:52,397 DEBUG TRAIN Batch 122/600 loss 0.054056 acc 0.963511 lr 0.00014538 grad_norm 0.398466 rank 0
2025-01-11 00:08:16,722 DEBUG TRAIN Batch 122/700 loss 0.031840 acc 0.980482 lr 0.00014535 grad_norm 0.388624 rank 2
2025-01-11 00:08:16,722 DEBUG TRAIN Batch 122/700 loss 0.042708 acc 0.973573 lr 0.00014535 grad_norm 0.388624 rank 1
2025-01-11 00:08:16,723 DEBUG TRAIN Batch 122/700 loss 0.045329 acc 0.963877 lr 0.00014535 grad_norm 0.388624 rank 0
2025-01-11 00:08:41,334 DEBUG TRAIN Batch 122/800 loss 0.041092 acc 0.977059 lr 0.00014532 grad_norm 0.445053 rank 1
2025-01-11 00:08:41,334 DEBUG TRAIN Batch 122/800 loss 0.053595 acc 0.966990 lr 0.00014532 grad_norm 0.445053 rank 0
2025-01-11 00:08:41,334 DEBUG TRAIN Batch 122/800 loss 0.038413 acc 0.971743 lr 0.00014532 grad_norm 0.445053 rank 2
2025-01-11 00:09:05,802 DEBUG TRAIN Batch 122/900 loss 0.046945 acc 0.966102 lr 0.00014529 grad_norm 0.427295 rank 1
2025-01-11 00:09:05,802 DEBUG TRAIN Batch 122/900 loss 0.043186 acc 0.972112 lr 0.00014529 grad_norm 0.427295 rank 0
2025-01-11 00:09:05,803 DEBUG TRAIN Batch 122/900 loss 0.057252 acc 0.964960 lr 0.00014529 grad_norm 0.427295 rank 2
2025-01-11 00:09:29,677 DEBUG TRAIN Batch 122/1000 loss 0.033953 acc 0.978372 lr 0.00014525 grad_norm 0.407083 rank 0
2025-01-11 00:09:29,678 DEBUG TRAIN Batch 122/1000 loss 0.034754 acc 0.971916 lr 0.00014525 grad_norm 0.407083 rank 2
2025-01-11 00:09:29,679 DEBUG TRAIN Batch 122/1000 loss 0.048468 acc 0.965385 lr 0.00014525 grad_norm 0.407083 rank 1
2025-01-11 00:09:54,004 DEBUG TRAIN Batch 122/1100 loss 0.036980 acc 0.973742 lr 0.00014522 grad_norm 0.445178 rank 2
2025-01-11 00:09:54,005 DEBUG TRAIN Batch 122/1100 loss 0.048610 acc 0.962511 lr 0.00014522 grad_norm 0.445178 rank 1
2025-01-11 00:09:54,005 DEBUG TRAIN Batch 122/1100 loss 0.044877 acc 0.967391 lr 0.00014522 grad_norm 0.445178 rank 0
2025-01-11 00:10:18,790 DEBUG TRAIN Batch 122/1200 loss 0.027631 acc 0.982906 lr 0.00014519 grad_norm 0.416817 rank 2
2025-01-11 00:10:18,790 DEBUG TRAIN Batch 122/1200 loss 0.052337 acc 0.957317 lr 0.00014519 grad_norm 0.416817 rank 1
2025-01-11 00:10:18,790 DEBUG TRAIN Batch 122/1200 loss 0.037167 acc 0.974781 lr 0.00014519 grad_norm 0.416817 rank 0
2025-01-11 00:10:43,386 DEBUG TRAIN Batch 122/1300 loss 0.060037 acc 0.955473 lr 0.00014516 grad_norm 0.420483 rank 1
2025-01-11 00:10:43,386 DEBUG TRAIN Batch 122/1300 loss 0.029615 acc 0.980634 lr 0.00014516 grad_norm 0.420483 rank 0
2025-01-11 00:10:43,386 DEBUG TRAIN Batch 122/1300 loss 0.040882 acc 0.971347 lr 0.00014516 grad_norm 0.420483 rank 2
2025-01-11 00:11:06,802 DEBUG TRAIN Batch 122/1400 loss 0.036115 acc 0.981299 lr 0.00014513 grad_norm 0.387947 rank 1
2025-01-11 00:11:06,802 DEBUG TRAIN Batch 122/1400 loss 0.040359 acc 0.971516 lr 0.00014513 grad_norm 0.387947 rank 2
2025-01-11 00:11:06,803 DEBUG TRAIN Batch 122/1400 loss 0.020305 acc 0.981436 lr 0.00014513 grad_norm 0.387947 rank 0
2025-01-11 00:11:31,454 DEBUG TRAIN Batch 122/1500 loss 0.043979 acc 0.970060 lr 0.00014510 grad_norm 0.416745 rank 1
2025-01-11 00:11:31,455 DEBUG TRAIN Batch 122/1500 loss 0.052982 acc 0.965649 lr 0.00014510 grad_norm 0.416745 rank 0
2025-01-11 00:11:31,455 DEBUG TRAIN Batch 122/1500 loss 0.050737 acc 0.962298 lr 0.00014510 grad_norm 0.416745 rank 2
2025-01-11 00:11:56,196 DEBUG TRAIN Batch 122/1600 loss 0.034575 acc 0.976806 lr 0.00014507 grad_norm 0.432165 rank 2
2025-01-11 00:11:56,196 DEBUG TRAIN Batch 122/1600 loss 0.037824 acc 0.975850 lr 0.00014507 grad_norm 0.432165 rank 1
2025-01-11 00:11:56,197 DEBUG TRAIN Batch 122/1600 loss 0.038781 acc 0.977199 lr 0.00014507 grad_norm 0.432165 rank 0
2025-01-11 00:12:20,272 DEBUG TRAIN Batch 122/1700 loss 0.040166 acc 0.973735 lr 0.00014504 grad_norm 0.404693 rank 1
2025-01-11 00:12:20,273 DEBUG TRAIN Batch 122/1700 loss 0.046568 acc 0.968297 lr 0.00014504 grad_norm 0.404693 rank 2
2025-01-11 00:12:20,273 DEBUG TRAIN Batch 122/1700 loss 0.026380 acc 0.979914 lr 0.00014504 grad_norm 0.404693 rank 0
2025-01-11 00:12:45,078 DEBUG TRAIN Batch 122/1800 loss 0.041816 acc 0.974181 lr 0.00014501 grad_norm 0.388016 rank 1
2025-01-11 00:12:45,078 DEBUG TRAIN Batch 122/1800 loss 0.033269 acc 0.980871 lr 0.00014501 grad_norm 0.388016 rank 2
2025-01-11 00:12:45,078 DEBUG TRAIN Batch 122/1800 loss 0.033064 acc 0.971396 lr 0.00014501 grad_norm 0.388016 rank 0
2025-01-11 00:13:09,498 DEBUG TRAIN Batch 122/1900 loss 0.049174 acc 0.968944 lr 0.00014498 grad_norm 0.429560 rank 1
2025-01-11 00:13:09,498 DEBUG TRAIN Batch 122/1900 loss 0.029178 acc 0.973684 lr 0.00014498 grad_norm 0.429560 rank 2
2025-01-11 00:13:09,498 DEBUG TRAIN Batch 122/1900 loss 0.036275 acc 0.974359 lr 0.00014498 grad_norm 0.429560 rank 0
2025-01-11 00:13:33,410 DEBUG TRAIN Batch 122/2000 loss 0.038748 acc 0.971963 lr 0.00014495 grad_norm 0.400950 rank 0
2025-01-11 00:13:33,410 DEBUG TRAIN Batch 122/2000 loss 0.040535 acc 0.976684 lr 0.00014495 grad_norm 0.400950 rank 2
2025-01-11 00:13:33,413 DEBUG TRAIN Batch 122/2000 loss 0.050130 acc 0.969896 lr 0.00014495 grad_norm 0.400950 rank 1
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 00:14:52,715 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 00:14:52,721 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 00:14:53,194 INFO Epoch 122 Step 119029 on_batch_end True CV rank 1
2025-01-11 00:14:53,194 INFO Epoch 122 Step 119029 on_batch_end True CV rank 0
2025-01-11 00:14:53,194 INFO Epoch 122 Step 119029 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 00:15:02,589 DEBUG CV Batch 122/100 loss 0.016386 acc 0.994426  rank 0
2025-01-11 00:15:02,731 DEBUG CV Batch 122/100 loss 0.016386 acc 0.994426  rank 2
2025-01-11 00:15:03,093 INFO Epoch 122 Step 119029 CV info lr 0.00014492510104795688 0 rank loss_2.513348981336764 acc_0.7809429075895694
2025-01-11 00:15:03,131 DEBUG CV Batch 122/100 loss 0.016386 acc 0.994426  rank 1
2025-01-11 00:15:03,272 INFO Epoch 122 Step 119029 CV info lr 0.00014492510104795688 2 rank loss_2.513348981336764 acc_0.7809429075895694
2025-01-11 00:15:03,669 INFO Epoch 122 Step 119029 CV info lr 0.00014492510104795688 1 rank loss_2.513348981336764 acc_0.7809429075895694
2025-01-11 00:15:04,444 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_122_whole.pt
2025-01-11 00:15:04,466 INFO Added key: store_based_barrier_key:125 to store for rank: 0
2025-01-11 00:15:04,477 INFO Added key: store_based_barrier_key:125 to store for rank: 2
2025-01-11 00:15:04,477 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:125 with 3 nodes.
2025-01-11 00:15:04,477 INFO Added key: store_based_barrier_key:125 to store for rank: 1
2025-01-11 00:15:04,477 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:125 with 3 nodes.
2025-01-11 00:15:04,481 INFO Epoch 123 TRAIN info lr 0.00014492510104795688 rank 1
2025-01-11 00:15:04,481 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 00:15:04,485 INFO Epoch 123 TRAIN info lr 0.00014492510104795688 rank 2
2025-01-11 00:15:04,485 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 00:15:04,487 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:125 with 3 nodes.
2025-01-11 00:15:04,491 INFO Epoch 123 TRAIN info lr 0.00014492510104795688 rank 0
2025-01-11 00:15:04,492 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 00:15:36,880 DEBUG TRAIN Batch 123/100 loss 0.041734 acc 0.971093 lr 0.00014489 grad_norm 0.388738 rank 1
2025-01-11 00:15:36,880 DEBUG TRAIN Batch 123/100 loss 0.028213 acc 0.978166 lr 0.00014489 grad_norm 0.388738 rank 2
2025-01-11 00:15:36,883 DEBUG TRAIN Batch 123/100 loss 0.033841 acc 0.978881 lr 0.00014489 grad_norm 0.388738 rank 0
2025-01-11 00:16:00,788 DEBUG TRAIN Batch 123/200 loss 0.034224 acc 0.982100 lr 0.00014486 grad_norm 0.437501 rank 2
2025-01-11 00:16:00,789 DEBUG TRAIN Batch 123/200 loss 0.036394 acc 0.975962 lr 0.00014486 grad_norm 0.437501 rank 0
2025-01-11 00:16:00,789 DEBUG TRAIN Batch 123/200 loss 0.043582 acc 0.966327 lr 0.00014486 grad_norm 0.437501 rank 1
2025-01-11 00:16:25,125 DEBUG TRAIN Batch 123/300 loss 0.040221 acc 0.975764 lr 0.00014483 grad_norm 0.412158 rank 0
2025-01-11 00:16:25,126 DEBUG TRAIN Batch 123/300 loss 0.035245 acc 0.974318 lr 0.00014483 grad_norm 0.412158 rank 2
2025-01-11 00:16:25,126 DEBUG TRAIN Batch 123/300 loss 0.041632 acc 0.972702 lr 0.00014483 grad_norm 0.412158 rank 1
2025-01-11 00:16:49,227 DEBUG TRAIN Batch 123/400 loss 0.026969 acc 0.982309 lr 0.00014480 grad_norm 0.404263 rank 0
2025-01-11 00:16:49,227 DEBUG TRAIN Batch 123/400 loss 0.041608 acc 0.971795 lr 0.00014480 grad_norm 0.404263 rank 1
2025-01-11 00:16:49,227 DEBUG TRAIN Batch 123/400 loss 0.043242 acc 0.966436 lr 0.00014480 grad_norm 0.404263 rank 2
2025-01-11 00:17:13,196 DEBUG TRAIN Batch 123/500 loss 0.043065 acc 0.968105 lr 0.00014477 grad_norm 0.412455 rank 1
2025-01-11 00:17:13,196 DEBUG TRAIN Batch 123/500 loss 0.032930 acc 0.979063 lr 0.00014477 grad_norm 0.412455 rank 0
2025-01-11 00:17:13,196 DEBUG TRAIN Batch 123/500 loss 0.049293 acc 0.971319 lr 0.00014477 grad_norm 0.412455 rank 2
2025-01-11 00:17:37,450 DEBUG TRAIN Batch 123/600 loss 0.036056 acc 0.974609 lr 0.00014474 grad_norm 0.415557 rank 1
2025-01-11 00:17:37,450 DEBUG TRAIN Batch 123/600 loss 0.059074 acc 0.964878 lr 0.00014474 grad_norm 0.415557 rank 2
2025-01-11 00:17:37,450 DEBUG TRAIN Batch 123/600 loss 0.025395 acc 0.982143 lr 0.00014474 grad_norm 0.415557 rank 0
2025-01-11 00:18:02,792 DEBUG TRAIN Batch 123/700 loss 0.011910 acc 0.991749 lr 0.00014471 grad_norm 0.367574 rank 1
2025-01-11 00:18:02,792 DEBUG TRAIN Batch 123/700 loss 0.032171 acc 0.970509 lr 0.00014471 grad_norm 0.367574 rank 2
2025-01-11 00:18:02,792 DEBUG TRAIN Batch 123/700 loss 0.037079 acc 0.973856 lr 0.00014471 grad_norm 0.367574 rank 0
2025-01-11 00:18:27,333 DEBUG TRAIN Batch 123/800 loss 0.026953 acc 0.982609 lr 0.00014468 grad_norm 0.401202 rank 1
2025-01-11 00:18:27,333 DEBUG TRAIN Batch 123/800 loss 0.040812 acc 0.973659 lr 0.00014468 grad_norm 0.401202 rank 2
2025-01-11 00:18:27,333 DEBUG TRAIN Batch 123/800 loss 0.040657 acc 0.978399 lr 0.00014468 grad_norm 0.401202 rank 0
2025-01-11 00:18:52,065 DEBUG TRAIN Batch 123/900 loss 0.062527 acc 0.946341 lr 0.00014465 grad_norm 0.434068 rank 1
2025-01-11 00:18:52,065 DEBUG TRAIN Batch 123/900 loss 0.043389 acc 0.967546 lr 0.00014465 grad_norm 0.434068 rank 2
2025-01-11 00:18:52,066 DEBUG TRAIN Batch 123/900 loss 0.047495 acc 0.972644 lr 0.00014465 grad_norm 0.434068 rank 0
2025-01-11 00:19:17,017 DEBUG TRAIN Batch 123/1000 loss 0.051404 acc 0.962591 lr 0.00014462 grad_norm 0.411356 rank 2
2025-01-11 00:19:17,018 DEBUG TRAIN Batch 123/1000 loss 0.037155 acc 0.965714 lr 0.00014462 grad_norm 0.411356 rank 1
2025-01-11 00:19:17,018 DEBUG TRAIN Batch 123/1000 loss 0.031711 acc 0.977647 lr 0.00014462 grad_norm 0.411356 rank 0
2025-01-11 00:19:41,627 DEBUG TRAIN Batch 123/1100 loss 0.032741 acc 0.978676 lr 0.00014459 grad_norm 0.414658 rank 1
2025-01-11 00:19:41,627 DEBUG TRAIN Batch 123/1100 loss 0.038790 acc 0.975543 lr 0.00014459 grad_norm 0.414658 rank 2
2025-01-11 00:19:41,627 DEBUG TRAIN Batch 123/1100 loss 0.052758 acc 0.969466 lr 0.00014459 grad_norm 0.414658 rank 0
2025-01-11 00:20:07,409 DEBUG TRAIN Batch 123/1200 loss 0.050839 acc 0.969109 lr 0.00014456 grad_norm 0.411033 rank 1
2025-01-11 00:20:07,409 DEBUG TRAIN Batch 123/1200 loss 0.028304 acc 0.976608 lr 0.00014456 grad_norm 0.411033 rank 0
2025-01-11 00:20:07,409 DEBUG TRAIN Batch 123/1200 loss 0.042469 acc 0.968037 lr 0.00014456 grad_norm 0.411033 rank 2
2025-01-11 00:20:31,236 DEBUG TRAIN Batch 123/1300 loss 0.033221 acc 0.980415 lr 0.00014453 grad_norm 0.422134 rank 2
2025-01-11 00:20:31,236 DEBUG TRAIN Batch 123/1300 loss 0.028182 acc 0.978626 lr 0.00014453 grad_norm 0.422134 rank 1
2025-01-11 00:20:31,236 DEBUG TRAIN Batch 123/1300 loss 0.039540 acc 0.969953 lr 0.00014453 grad_norm 0.422134 rank 0
2025-01-11 00:20:55,582 DEBUG TRAIN Batch 123/1400 loss 0.029041 acc 0.979730 lr 0.00014450 grad_norm 0.401500 rank 1
2025-01-11 00:20:55,582 DEBUG TRAIN Batch 123/1400 loss 0.039931 acc 0.974684 lr 0.00014450 grad_norm 0.401500 rank 2
2025-01-11 00:20:55,582 DEBUG TRAIN Batch 123/1400 loss 0.046845 acc 0.968497 lr 0.00014450 grad_norm 0.401500 rank 0
2025-01-11 00:21:21,749 DEBUG TRAIN Batch 123/1500 loss 0.040303 acc 0.973659 lr 0.00014447 grad_norm 0.403407 rank 2
2025-01-11 00:21:21,749 DEBUG TRAIN Batch 123/1500 loss 0.056157 acc 0.966261 lr 0.00014447 grad_norm 0.403407 rank 0
2025-01-11 00:21:21,750 DEBUG TRAIN Batch 123/1500 loss 0.044431 acc 0.967638 lr 0.00014447 grad_norm 0.403407 rank 1
2025-01-11 00:21:45,771 DEBUG TRAIN Batch 123/1600 loss 0.039812 acc 0.974843 lr 0.00014444 grad_norm 0.422982 rank 1
2025-01-11 00:21:45,771 DEBUG TRAIN Batch 123/1600 loss 0.052071 acc 0.959290 lr 0.00014444 grad_norm 0.422982 rank 2
2025-01-11 00:21:45,771 DEBUG TRAIN Batch 123/1600 loss 0.047348 acc 0.967532 lr 0.00014444 grad_norm 0.422982 rank 0
2025-01-11 00:22:09,630 DEBUG TRAIN Batch 123/1700 loss 0.052739 acc 0.967655 lr 0.00014441 grad_norm 0.415026 rank 1
2025-01-11 00:22:09,630 DEBUG TRAIN Batch 123/1700 loss 0.045389 acc 0.973183 lr 0.00014441 grad_norm 0.415026 rank 2
2025-01-11 00:22:09,630 DEBUG TRAIN Batch 123/1700 loss 0.044446 acc 0.970404 lr 0.00014441 grad_norm 0.415026 rank 0
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 00:23:20,927 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 00:23:20,933 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 00:23:21,337 INFO Epoch 123 Step 119902 on_batch_end True CV rank 0
2025-01-11 00:23:21,337 INFO Epoch 123 Step 119902 on_batch_end True CV rank 1
2025-01-11 00:23:21,337 INFO Epoch 123 Step 119902 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 00:23:30,393 DEBUG CV Batch 123/100 loss 0.006010 acc 0.996656  rank 0
2025-01-11 00:23:30,486 DEBUG CV Batch 123/100 loss 0.006010 acc 0.996656  rank 2
2025-01-11 00:23:30,919 INFO Epoch 123 Step 119902 CV info lr 0.00014439654126139844 0 rank loss_2.5129734984128795 acc_0.7804509807835546
2025-01-11 00:23:30,989 INFO Epoch 123 Step 119902 CV info lr 0.00014439654126139844 2 rank loss_2.5129734984128795 acc_0.7804509807835546
2025-01-11 00:23:31,163 DEBUG CV Batch 123/100 loss 0.006010 acc 0.996656  rank 1
2025-01-11 00:23:31,693 INFO Epoch 123 Step 119902 CV info lr 0.00014439654126139844 1 rank loss_2.5129734984128795 acc_0.7804509807835546
2025-01-11 00:23:32,275 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_123_whole.pt
2025-01-11 00:23:32,287 INFO Added key: store_based_barrier_key:126 to store for rank: 0
2025-01-11 00:23:32,297 INFO Added key: store_based_barrier_key:126 to store for rank: 2
2025-01-11 00:23:32,297 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:126 with 3 nodes.
2025-01-11 00:23:32,297 INFO Added key: store_based_barrier_key:126 to store for rank: 1
2025-01-11 00:23:32,297 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:126 with 3 nodes.
2025-01-11 00:23:32,299 INFO Epoch 124 TRAIN info lr 0.00014439654126139844 rank 2
2025-01-11 00:23:32,299 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 00:23:32,306 INFO Epoch 124 TRAIN info lr 0.00014439654126139844 rank 1
2025-01-11 00:23:32,307 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 00:23:32,307 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:126 with 3 nodes.
2025-01-11 00:23:32,310 INFO Epoch 124 TRAIN info lr 0.00014439654126139844 rank 0
2025-01-11 00:23:32,310 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 00:24:02,673 DEBUG TRAIN Batch 124/100 loss 0.038236 acc 0.978378 lr 0.00014437 grad_norm 0.398704 rank 0
2025-01-11 00:24:02,674 DEBUG TRAIN Batch 124/100 loss 0.050517 acc 0.968664 lr 0.00014437 grad_norm 0.398704 rank 1
2025-01-11 00:24:02,674 DEBUG TRAIN Batch 124/100 loss 0.049758 acc 0.965553 lr 0.00014437 grad_norm 0.398704 rank 2
2025-01-11 00:24:26,814 DEBUG TRAIN Batch 124/200 loss 0.028264 acc 0.973684 lr 0.00014434 grad_norm 0.423459 rank 0
2025-01-11 00:24:26,814 DEBUG TRAIN Batch 124/200 loss 0.049241 acc 0.962786 lr 0.00014434 grad_norm 0.423459 rank 1
2025-01-11 00:24:26,815 DEBUG TRAIN Batch 124/200 loss 0.042461 acc 0.970614 lr 0.00014434 grad_norm 0.423459 rank 2
2025-01-11 00:24:50,169 DEBUG TRAIN Batch 124/300 loss 0.051676 acc 0.966539 lr 0.00014431 grad_norm 0.377315 rank 2
2025-01-11 00:24:50,169 DEBUG TRAIN Batch 124/300 loss 0.031092 acc 0.977757 lr 0.00014431 grad_norm 0.377315 rank 0
2025-01-11 00:24:50,170 DEBUG TRAIN Batch 124/300 loss 0.029819 acc 0.978306 lr 0.00014431 grad_norm 0.377315 rank 1
2025-01-11 00:25:14,059 DEBUG TRAIN Batch 124/400 loss 0.041875 acc 0.967294 lr 0.00014428 grad_norm 0.412749 rank 1
2025-01-11 00:25:14,059 DEBUG TRAIN Batch 124/400 loss 0.043127 acc 0.970677 lr 0.00014428 grad_norm 0.412749 rank 2
2025-01-11 00:25:14,059 DEBUG TRAIN Batch 124/400 loss 0.026429 acc 0.982368 lr 0.00014428 grad_norm 0.412749 rank 0
2025-01-11 00:25:37,935 DEBUG TRAIN Batch 124/500 loss 0.032487 acc 0.980189 lr 0.00014425 grad_norm 0.402359 rank 1
2025-01-11 00:25:37,935 DEBUG TRAIN Batch 124/500 loss 0.033958 acc 0.977186 lr 0.00014425 grad_norm 0.402359 rank 2
2025-01-11 00:25:37,935 DEBUG TRAIN Batch 124/500 loss 0.052467 acc 0.969643 lr 0.00014425 grad_norm 0.402359 rank 0
2025-01-11 00:26:01,878 DEBUG TRAIN Batch 124/600 loss 0.031635 acc 0.979323 lr 0.00014422 grad_norm 0.417586 rank 2
2025-01-11 00:26:01,879 DEBUG TRAIN Batch 124/600 loss 0.040569 acc 0.973545 lr 0.00014422 grad_norm 0.417586 rank 1
2025-01-11 00:26:01,879 DEBUG TRAIN Batch 124/600 loss 0.055844 acc 0.964833 lr 0.00014422 grad_norm 0.417586 rank 0
2025-01-11 00:26:26,017 DEBUG TRAIN Batch 124/700 loss 0.048218 acc 0.969112 lr 0.00014419 grad_norm 0.410380 rank 1
2025-01-11 00:26:26,017 DEBUG TRAIN Batch 124/700 loss 0.045659 acc 0.968592 lr 0.00014419 grad_norm 0.410380 rank 0
2025-01-11 00:26:26,018 DEBUG TRAIN Batch 124/700 loss 0.043710 acc 0.967412 lr 0.00014419 grad_norm 0.410380 rank 2
2025-01-11 00:26:49,860 DEBUG TRAIN Batch 124/800 loss 0.034308 acc 0.976234 lr 0.00014416 grad_norm 0.388195 rank 1
2025-01-11 00:26:49,860 DEBUG TRAIN Batch 124/800 loss 0.036164 acc 0.974900 lr 0.00014416 grad_norm 0.388195 rank 2
2025-01-11 00:26:49,865 DEBUG TRAIN Batch 124/800 loss 0.039602 acc 0.975359 lr 0.00014416 grad_norm 0.388195 rank 0
2025-01-11 00:27:13,944 DEBUG TRAIN Batch 124/900 loss 0.044514 acc 0.967063 lr 0.00014413 grad_norm 0.388996 rank 1
2025-01-11 00:27:13,945 DEBUG TRAIN Batch 124/900 loss 0.022057 acc 0.985455 lr 0.00014413 grad_norm 0.388996 rank 2
2025-01-11 00:27:13,945 DEBUG TRAIN Batch 124/900 loss 0.030383 acc 0.977169 lr 0.00014413 grad_norm 0.388996 rank 0
2025-01-11 00:27:38,098 DEBUG TRAIN Batch 124/1000 loss 0.033990 acc 0.983623 lr 0.00014410 grad_norm 0.396459 rank 1
2025-01-11 00:27:38,099 DEBUG TRAIN Batch 124/1000 loss 0.041900 acc 0.972832 lr 0.00014410 grad_norm 0.396459 rank 2
2025-01-11 00:27:38,099 DEBUG TRAIN Batch 124/1000 loss 0.039258 acc 0.978070 lr 0.00014410 grad_norm 0.396459 rank 0
2025-01-11 00:28:03,581 DEBUG TRAIN Batch 124/1100 loss 0.044793 acc 0.970614 lr 0.00014407 grad_norm 0.404952 rank 1
2025-01-11 00:28:03,581 DEBUG TRAIN Batch 124/1100 loss 0.046498 acc 0.966175 lr 0.00014407 grad_norm 0.404952 rank 0
2025-01-11 00:28:03,582 DEBUG TRAIN Batch 124/1100 loss 0.055801 acc 0.966282 lr 0.00014407 grad_norm 0.404952 rank 2
2025-01-11 00:28:28,227 DEBUG TRAIN Batch 124/1200 loss 0.064771 acc 0.961538 lr 0.00014404 grad_norm 0.430925 rank 1
2025-01-11 00:28:28,228 DEBUG TRAIN Batch 124/1200 loss 0.028786 acc 0.981595 lr 0.00014404 grad_norm 0.430925 rank 0
2025-01-11 00:28:28,228 DEBUG TRAIN Batch 124/1200 loss 0.049898 acc 0.970048 lr 0.00014404 grad_norm 0.430925 rank 2
2025-01-11 00:28:53,206 DEBUG TRAIN Batch 124/1300 loss 0.047138 acc 0.963636 lr 0.00014401 grad_norm 0.394240 rank 1
2025-01-11 00:28:53,206 DEBUG TRAIN Batch 124/1300 loss 0.055778 acc 0.959617 lr 0.00014401 grad_norm 0.394240 rank 2
2025-01-11 00:28:53,207 DEBUG TRAIN Batch 124/1300 loss 0.022096 acc 0.986339 lr 0.00014401 grad_norm 0.394240 rank 0
2025-01-11 00:29:18,377 DEBUG TRAIN Batch 124/1400 loss 0.035095 acc 0.975866 lr 0.00014398 grad_norm 0.400142 rank 1
2025-01-11 00:29:18,377 DEBUG TRAIN Batch 124/1400 loss 0.037755 acc 0.971973 lr 0.00014398 grad_norm 0.400142 rank 0
2025-01-11 00:29:18,377 DEBUG TRAIN Batch 124/1400 loss 0.047280 acc 0.966926 lr 0.00014398 grad_norm 0.400142 rank 2
2025-01-11 00:29:42,919 DEBUG TRAIN Batch 124/1500 loss 0.041296 acc 0.968489 lr 0.00014395 grad_norm 0.424583 rank 0
2025-01-11 00:29:42,919 DEBUG TRAIN Batch 124/1500 loss 0.041605 acc 0.972414 lr 0.00014395 grad_norm 0.424583 rank 1
2025-01-11 00:29:42,920 DEBUG TRAIN Batch 124/1500 loss 0.073159 acc 0.953141 lr 0.00014395 grad_norm 0.424583 rank 2
2025-01-11 00:30:07,835 DEBUG TRAIN Batch 124/1600 loss 0.055119 acc 0.961718 lr 0.00014392 grad_norm 0.403027 rank 1
2025-01-11 00:30:07,835 DEBUG TRAIN Batch 124/1600 loss 0.064781 acc 0.955197 lr 0.00014392 grad_norm 0.403027 rank 2
2025-01-11 00:30:07,836 DEBUG TRAIN Batch 124/1600 loss 0.027705 acc 0.979654 lr 0.00014392 grad_norm 0.403027 rank 0
2025-01-11 00:30:33,184 DEBUG TRAIN Batch 124/1700 loss 0.044365 acc 0.972945 lr 0.00014389 grad_norm 0.429793 rank 2
2025-01-11 00:30:33,184 DEBUG TRAIN Batch 124/1700 loss 0.025081 acc 0.981788 lr 0.00014389 grad_norm 0.429793 rank 0
2025-01-11 00:30:33,184 DEBUG TRAIN Batch 124/1700 loss 0.058928 acc 0.963588 lr 0.00014389 grad_norm 0.429793 rank 1
2025-01-11 00:30:57,237 DEBUG TRAIN Batch 124/1800 loss 0.031768 acc 0.978261 lr 0.00014386 grad_norm 0.429270 rank 0
2025-01-11 00:30:57,237 DEBUG TRAIN Batch 124/1800 loss 0.046891 acc 0.971398 lr 0.00014386 grad_norm 0.429270 rank 1
2025-01-11 00:30:57,237 DEBUG TRAIN Batch 124/1800 loss 0.061803 acc 0.959075 lr 0.00014386 grad_norm 0.429270 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 00:32:13,090 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 00:32:13,092 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 00:32:13,610 INFO Epoch 124 Step 120835 on_batch_end True CV rank 0
2025-01-11 00:32:13,610 INFO Epoch 124 Step 120835 on_batch_end True CV rank 2
2025-01-11 00:32:13,610 INFO Epoch 124 Step 120835 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 00:32:22,859 DEBUG CV Batch 124/100 loss 0.012523 acc 0.996656  rank 2
2025-01-11 00:32:22,894 DEBUG CV Batch 124/100 loss 0.012523 acc 0.996656  rank 0
2025-01-11 00:32:23,290 DEBUG CV Batch 124/100 loss 0.012523 acc 0.996656  rank 1
2025-01-11 00:32:23,383 INFO Epoch 124 Step 120835 CV info lr 0.00014383799846283957 2 rank loss_2.5215869351083886 acc_0.7809398955943292
2025-01-11 00:32:23,436 INFO Epoch 124 Step 120835 CV info lr 0.00014383799846283957 0 rank loss_2.5215869351083886 acc_0.7809398955943292
2025-01-11 00:32:23,857 INFO Epoch 124 Step 120835 CV info lr 0.00014383799846283957 1 rank loss_2.5215869351083886 acc_0.7809398955943292
2025-01-11 00:32:24,785 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_124_whole.pt
2025-01-11 00:32:24,807 INFO Added key: store_based_barrier_key:127 to store for rank: 0
2025-01-11 00:32:24,817 INFO Added key: store_based_barrier_key:127 to store for rank: 2
2025-01-11 00:32:24,817 INFO Added key: store_based_barrier_key:127 to store for rank: 1
2025-01-11 00:32:24,817 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:127 with 3 nodes.
2025-01-11 00:32:24,818 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:127 with 3 nodes.
2025-01-11 00:32:24,820 INFO Epoch 125 TRAIN info lr 0.00014383799846283957 rank 0
2025-01-11 00:32:24,820 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 00:32:24,821 INFO Epoch 125 TRAIN info lr 0.00014383799846283957 rank 1
2025-01-11 00:32:24,821 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 00:32:24,827 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:127 with 3 nodes.
2025-01-11 00:32:24,827 INFO Epoch 125 TRAIN info lr 0.00014383799846283957 rank 2
2025-01-11 00:32:24,827 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 00:32:55,914 DEBUG TRAIN Batch 125/100 loss 0.036664 acc 0.972856 lr 0.00014381 grad_norm 0.427527 rank 0
2025-01-11 00:32:55,914 DEBUG TRAIN Batch 125/100 loss 0.043131 acc 0.969665 lr 0.00014381 grad_norm 0.427527 rank 1
2025-01-11 00:32:55,914 DEBUG TRAIN Batch 125/100 loss 0.042183 acc 0.980208 lr 0.00014381 grad_norm 0.427527 rank 2
2025-01-11 00:33:19,828 DEBUG TRAIN Batch 125/200 loss 0.042722 acc 0.974739 lr 0.00014378 grad_norm 0.396435 rank 1
2025-01-11 00:33:19,828 DEBUG TRAIN Batch 125/200 loss 0.032036 acc 0.975980 lr 0.00014378 grad_norm 0.396435 rank 2
2025-01-11 00:33:19,829 DEBUG TRAIN Batch 125/200 loss 0.042184 acc 0.966455 lr 0.00014378 grad_norm 0.396435 rank 0
2025-01-11 00:33:43,036 DEBUG TRAIN Batch 125/300 loss 0.043745 acc 0.970250 lr 0.00014375 grad_norm 0.413947 rank 1
2025-01-11 00:33:43,036 DEBUG TRAIN Batch 125/300 loss 0.047407 acc 0.962489 lr 0.00014375 grad_norm 0.413947 rank 0
2025-01-11 00:33:43,036 DEBUG TRAIN Batch 125/300 loss 0.033621 acc 0.975143 lr 0.00014375 grad_norm 0.413947 rank 2
2025-01-11 00:34:06,460 DEBUG TRAIN Batch 125/400 loss 0.036621 acc 0.972169 lr 0.00014372 grad_norm 0.403552 rank 0
2025-01-11 00:34:06,460 DEBUG TRAIN Batch 125/400 loss 0.044674 acc 0.969874 lr 0.00014372 grad_norm 0.403552 rank 1
2025-01-11 00:34:06,461 DEBUG TRAIN Batch 125/400 loss 0.053450 acc 0.960501 lr 0.00014372 grad_norm 0.403552 rank 2
2025-01-11 00:34:30,730 DEBUG TRAIN Batch 125/500 loss 0.051110 acc 0.964416 lr 0.00014369 grad_norm 0.402421 rank 0
2025-01-11 00:34:30,730 DEBUG TRAIN Batch 125/500 loss 0.054172 acc 0.966395 lr 0.00014369 grad_norm 0.402421 rank 1
2025-01-11 00:34:30,731 DEBUG TRAIN Batch 125/500 loss 0.047330 acc 0.969379 lr 0.00014369 grad_norm 0.402421 rank 2
2025-01-11 00:34:53,941 DEBUG TRAIN Batch 125/600 loss 0.045588 acc 0.970999 lr 0.00014366 grad_norm 0.411010 rank 1
2025-01-11 00:34:53,941 DEBUG TRAIN Batch 125/600 loss 0.050788 acc 0.964318 lr 0.00014366 grad_norm 0.411010 rank 0
2025-01-11 00:34:53,942 DEBUG TRAIN Batch 125/600 loss 0.026599 acc 0.981839 lr 0.00014366 grad_norm 0.411010 rank 2
2025-01-11 00:35:17,554 DEBUG TRAIN Batch 125/700 loss 0.042231 acc 0.972364 lr 0.00014363 grad_norm 0.403207 rank 1
2025-01-11 00:35:17,554 DEBUG TRAIN Batch 125/700 loss 0.052593 acc 0.972101 lr 0.00014363 grad_norm 0.403207 rank 0
2025-01-11 00:35:17,555 DEBUG TRAIN Batch 125/700 loss 0.040245 acc 0.970974 lr 0.00014363 grad_norm 0.403207 rank 2
2025-01-11 00:35:40,766 DEBUG TRAIN Batch 125/800 loss 0.031352 acc 0.983670 lr 0.00014360 grad_norm 0.389430 rank 0
2025-01-11 00:35:40,766 DEBUG TRAIN Batch 125/800 loss 0.035556 acc 0.975798 lr 0.00014360 grad_norm 0.389430 rank 1
2025-01-11 00:35:40,766 DEBUG TRAIN Batch 125/800 loss 0.034180 acc 0.977695 lr 0.00014360 grad_norm 0.389430 rank 2
2025-01-11 00:36:04,601 DEBUG TRAIN Batch 125/900 loss 0.047858 acc 0.968085 lr 0.00014357 grad_norm 0.453534 rank 1
2025-01-11 00:36:04,602 DEBUG TRAIN Batch 125/900 loss 0.035520 acc 0.974257 lr 0.00014357 grad_norm 0.453534 rank 0
2025-01-11 00:36:04,602 DEBUG TRAIN Batch 125/900 loss 0.047694 acc 0.966418 lr 0.00014357 grad_norm 0.453534 rank 2
2025-01-11 00:36:28,325 DEBUG TRAIN Batch 125/1000 loss 0.047435 acc 0.971963 lr 0.00014354 grad_norm 0.423332 rank 1
2025-01-11 00:36:28,325 DEBUG TRAIN Batch 125/1000 loss 0.040924 acc 0.970727 lr 0.00014354 grad_norm 0.423332 rank 0
2025-01-11 00:36:28,326 DEBUG TRAIN Batch 125/1000 loss 0.056206 acc 0.960784 lr 0.00014354 grad_norm 0.423332 rank 2
2025-01-11 00:36:51,915 DEBUG TRAIN Batch 125/1100 loss 0.042570 acc 0.971888 lr 0.00014351 grad_norm 0.389623 rank 1
2025-01-11 00:36:51,915 DEBUG TRAIN Batch 125/1100 loss 0.029742 acc 0.971631 lr 0.00014351 grad_norm 0.389623 rank 2
2025-01-11 00:36:51,915 DEBUG TRAIN Batch 125/1100 loss 0.035719 acc 0.974522 lr 0.00014351 grad_norm 0.389623 rank 0
2025-01-11 00:37:15,830 DEBUG TRAIN Batch 125/1200 loss 0.044303 acc 0.969466 lr 0.00014348 grad_norm 0.399658 rank 0
2025-01-11 00:37:15,830 DEBUG TRAIN Batch 125/1200 loss 0.035674 acc 0.979123 lr 0.00014348 grad_norm 0.399658 rank 1
2025-01-11 00:37:15,831 DEBUG TRAIN Batch 125/1200 loss 0.047971 acc 0.962466 lr 0.00014348 grad_norm 0.399658 rank 2
2025-01-11 00:37:40,057 DEBUG TRAIN Batch 125/1300 loss 0.041900 acc 0.975345 lr 0.00014345 grad_norm 0.403311 rank 0
2025-01-11 00:37:40,057 DEBUG TRAIN Batch 125/1300 loss 0.044876 acc 0.963470 lr 0.00014345 grad_norm 0.403311 rank 1
2025-01-11 00:37:40,058 DEBUG TRAIN Batch 125/1300 loss 0.040069 acc 0.971767 lr 0.00014345 grad_norm 0.403311 rank 2
2025-01-11 00:38:05,080 DEBUG TRAIN Batch 125/1400 loss 0.044026 acc 0.973684 lr 0.00014342 grad_norm 0.417036 rank 2
2025-01-11 00:38:05,081 DEBUG TRAIN Batch 125/1400 loss 0.048520 acc 0.967334 lr 0.00014342 grad_norm 0.417036 rank 0
2025-01-11 00:38:05,081 DEBUG TRAIN Batch 125/1400 loss 0.039478 acc 0.973607 lr 0.00014342 grad_norm 0.417036 rank 1
2025-01-11 00:38:28,472 DEBUG TRAIN Batch 125/1500 loss 0.045383 acc 0.967010 lr 0.00014339 grad_norm 0.413347 rank 0
2025-01-11 00:38:28,473 DEBUG TRAIN Batch 125/1500 loss 0.046429 acc 0.969247 lr 0.00014339 grad_norm 0.413347 rank 1
2025-01-11 00:38:28,473 DEBUG TRAIN Batch 125/1500 loss 0.027818 acc 0.979370 lr 0.00014339 grad_norm 0.413347 rank 2
2025-01-11 00:38:52,705 DEBUG TRAIN Batch 125/1600 loss 0.048990 acc 0.972590 lr 0.00014336 grad_norm 0.447096 rank 0
2025-01-11 00:38:52,705 DEBUG TRAIN Batch 125/1600 loss 0.056286 acc 0.965392 lr 0.00014336 grad_norm 0.447096 rank 1
2025-01-11 00:38:52,706 DEBUG TRAIN Batch 125/1600 loss 0.050425 acc 0.957257 lr 0.00014336 grad_norm 0.447096 rank 2
2025-01-11 00:39:18,614 DEBUG TRAIN Batch 125/1700 loss 0.052360 acc 0.965686 lr 0.00014333 grad_norm 0.415656 rank 1
2025-01-11 00:39:18,615 DEBUG TRAIN Batch 125/1700 loss 0.042300 acc 0.967709 lr 0.00014333 grad_norm 0.415656 rank 0
2025-01-11 00:39:18,615 DEBUG TRAIN Batch 125/1700 loss 0.031517 acc 0.979167 lr 0.00014333 grad_norm 0.415656 rank 2
2025-01-11 00:39:42,931 DEBUG TRAIN Batch 125/1800 loss 0.032359 acc 0.981295 lr 0.00014331 grad_norm 0.450054 rank 0
2025-01-11 00:39:42,932 DEBUG TRAIN Batch 125/1800 loss 0.052626 acc 0.965517 lr 0.00014331 grad_norm 0.450054 rank 1
2025-01-11 00:39:42,932 DEBUG TRAIN Batch 125/1800 loss 0.050486 acc 0.964286 lr 0.00014331 grad_norm 0.450054 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 00:40:59,773 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 00:40:59,774 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 00:41:00,264 INFO Epoch 125 Step 121769 on_batch_end True CV rank 0
2025-01-11 00:41:00,264 INFO Epoch 125 Step 121769 on_batch_end True CV rank 1
2025-01-11 00:41:00,264 INFO Epoch 125 Step 121769 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 00:41:09,294 DEBUG CV Batch 125/100 loss 0.002482 acc 1.000000  rank 0
2025-01-11 00:41:09,638 DEBUG CV Batch 125/100 loss 0.002482 acc 1.000000  rank 2
2025-01-11 00:41:09,800 DEBUG CV Batch 125/100 loss 0.002482 acc 1.000000  rank 1
2025-01-11 00:41:09,814 INFO Epoch 125 Step 121769 CV info lr 0.00014328529909756962 0 rank loss_2.5171929521712357 acc_0.7817394095554686
2025-01-11 00:41:10,169 INFO Epoch 125 Step 121769 CV info lr 0.00014328529909756962 2 rank loss_2.5171929521712357 acc_0.7817394095554686
2025-01-11 00:41:10,337 INFO Epoch 125 Step 121769 CV info lr 0.00014328529909756962 1 rank loss_2.5171929521712357 acc_0.7817394095554686
2025-01-11 00:41:11,115 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_125_whole.pt
2025-01-11 00:41:11,137 INFO Added key: store_based_barrier_key:128 to store for rank: 0
2025-01-11 00:41:11,137 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:128 with 3 nodes.
2025-01-11 00:41:11,137 INFO Added key: store_based_barrier_key:128 to store for rank: 2
2025-01-11 00:41:11,137 INFO Added key: store_based_barrier_key:128 to store for rank: 1
2025-01-11 00:41:11,138 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:128 with 3 nodes.
2025-01-11 00:41:11,138 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:128 with 3 nodes.
2025-01-11 00:41:11,142 INFO Epoch 126 TRAIN info lr 0.00014328529909756962 rank 0
2025-01-11 00:41:11,142 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 00:41:11,146 INFO Epoch 126 TRAIN info lr 0.00014328529909756962 rank 2
2025-01-11 00:41:11,146 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 00:41:11,147 INFO Epoch 126 TRAIN info lr 0.00014328529909756962 rank 1
2025-01-11 00:41:11,147 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 00:41:45,362 DEBUG TRAIN Batch 126/100 loss 0.039371 acc 0.971845 lr 0.00014326 grad_norm 0.401247 rank 2
2025-01-11 00:41:45,362 DEBUG TRAIN Batch 126/100 loss 0.040462 acc 0.978637 lr 0.00014326 grad_norm 0.401247 rank 1
2025-01-11 00:41:45,362 DEBUG TRAIN Batch 126/100 loss 0.027386 acc 0.984016 lr 0.00014326 grad_norm 0.401247 rank 0
2025-01-11 00:42:09,603 DEBUG TRAIN Batch 126/200 loss 0.040029 acc 0.972302 lr 0.00014323 grad_norm 0.394000 rank 2
2025-01-11 00:42:09,603 DEBUG TRAIN Batch 126/200 loss 0.045795 acc 0.958182 lr 0.00014323 grad_norm 0.394000 rank 1
2025-01-11 00:42:09,604 DEBUG TRAIN Batch 126/200 loss 0.019602 acc 0.985965 lr 0.00014323 grad_norm 0.394000 rank 0
2025-01-11 00:42:34,439 DEBUG TRAIN Batch 126/300 loss 0.033701 acc 0.969125 lr 0.00014320 grad_norm 0.426065 rank 2
2025-01-11 00:42:34,439 DEBUG TRAIN Batch 126/300 loss 0.043562 acc 0.966151 lr 0.00014320 grad_norm 0.426065 rank 1
2025-01-11 00:42:34,439 DEBUG TRAIN Batch 126/300 loss 0.037559 acc 0.974884 lr 0.00014320 grad_norm 0.426065 rank 0
2025-01-11 00:42:58,701 DEBUG TRAIN Batch 126/400 loss 0.032554 acc 0.981214 lr 0.00014317 grad_norm 0.400275 rank 0
2025-01-11 00:42:58,702 DEBUG TRAIN Batch 126/400 loss 0.033092 acc 0.980088 lr 0.00014317 grad_norm 0.400275 rank 1
2025-01-11 00:42:58,702 DEBUG TRAIN Batch 126/400 loss 0.047737 acc 0.968095 lr 0.00014317 grad_norm 0.400275 rank 2
2025-01-11 00:43:22,625 DEBUG TRAIN Batch 126/500 loss 0.041143 acc 0.966355 lr 0.00014314 grad_norm 0.407011 rank 1
2025-01-11 00:43:22,625 DEBUG TRAIN Batch 126/500 loss 0.039452 acc 0.970885 lr 0.00014314 grad_norm 0.407011 rank 2
2025-01-11 00:43:22,626 DEBUG TRAIN Batch 126/500 loss 0.026392 acc 0.981622 lr 0.00014314 grad_norm 0.407011 rank 0
2025-01-11 00:43:46,640 DEBUG TRAIN Batch 126/600 loss 0.043451 acc 0.969885 lr 0.00014311 grad_norm 0.393963 rank 1
2025-01-11 00:43:46,640 DEBUG TRAIN Batch 126/600 loss 0.029278 acc 0.983951 lr 0.00014311 grad_norm 0.393963 rank 0
2025-01-11 00:43:46,641 DEBUG TRAIN Batch 126/600 loss 0.046032 acc 0.970385 lr 0.00014311 grad_norm 0.393963 rank 2
2025-01-11 00:44:11,009 DEBUG TRAIN Batch 126/700 loss 0.041554 acc 0.970707 lr 0.00014308 grad_norm 0.436113 rank 0
2025-01-11 00:44:11,009 DEBUG TRAIN Batch 126/700 loss 0.050323 acc 0.962038 lr 0.00014308 grad_norm 0.436113 rank 1
2025-01-11 00:44:11,010 DEBUG TRAIN Batch 126/700 loss 0.039302 acc 0.971690 lr 0.00014308 grad_norm 0.436113 rank 2
2025-01-11 00:44:36,091 DEBUG TRAIN Batch 126/800 loss 0.045630 acc 0.969863 lr 0.00014305 grad_norm 0.426022 rank 2
2025-01-11 00:44:36,092 DEBUG TRAIN Batch 126/800 loss 0.021367 acc 0.986686 lr 0.00014305 grad_norm 0.426022 rank 0
2025-01-11 00:44:36,092 DEBUG TRAIN Batch 126/800 loss 0.051397 acc 0.966820 lr 0.00014305 grad_norm 0.426022 rank 1
2025-01-11 00:45:00,198 DEBUG TRAIN Batch 126/900 loss 0.023784 acc 0.985311 lr 0.00014302 grad_norm 0.389261 rank 2
2025-01-11 00:45:00,198 DEBUG TRAIN Batch 126/900 loss 0.035439 acc 0.976359 lr 0.00014302 grad_norm 0.389261 rank 1
2025-01-11 00:45:00,198 DEBUG TRAIN Batch 126/900 loss 0.042936 acc 0.968548 lr 0.00014302 grad_norm 0.389261 rank 0
2025-01-11 00:45:23,590 DEBUG TRAIN Batch 126/1000 loss 0.025853 acc 0.981151 lr 0.00014299 grad_norm 0.363673 rank 0
2025-01-11 00:45:23,590 DEBUG TRAIN Batch 126/1000 loss 0.019333 acc 0.992670 lr 0.00014299 grad_norm 0.363673 rank 1
2025-01-11 00:45:23,590 DEBUG TRAIN Batch 126/1000 loss 0.028183 acc 0.986258 lr 0.00014299 grad_norm 0.363673 rank 2
2025-01-11 00:45:48,300 DEBUG TRAIN Batch 126/1100 loss 0.041889 acc 0.966990 lr 0.00014296 grad_norm 0.442929 rank 0
2025-01-11 00:45:48,300 DEBUG TRAIN Batch 126/1100 loss 0.045893 acc 0.966837 lr 0.00014296 grad_norm 0.442929 rank 1
2025-01-11 00:45:48,301 DEBUG TRAIN Batch 126/1100 loss 0.043085 acc 0.968288 lr 0.00014296 grad_norm 0.442929 rank 2
2025-01-11 00:46:12,637 DEBUG TRAIN Batch 126/1200 loss 0.045332 acc 0.968107 lr 0.00014293 grad_norm 0.419567 rank 1
2025-01-11 00:46:12,637 DEBUG TRAIN Batch 126/1200 loss 0.037808 acc 0.970109 lr 0.00014293 grad_norm 0.419567 rank 2
2025-01-11 00:46:12,637 DEBUG TRAIN Batch 126/1200 loss 0.025779 acc 0.980066 lr 0.00014293 grad_norm 0.419567 rank 0
2025-01-11 00:46:36,701 DEBUG TRAIN Batch 126/1300 loss 0.044135 acc 0.972615 lr 0.00014290 grad_norm 0.412249 rank 0
2025-01-11 00:46:36,701 DEBUG TRAIN Batch 126/1300 loss 0.042628 acc 0.971074 lr 0.00014290 grad_norm 0.412249 rank 1
2025-01-11 00:46:36,702 DEBUG TRAIN Batch 126/1300 loss 0.047657 acc 0.963336 lr 0.00014290 grad_norm 0.412249 rank 2
2025-01-11 00:47:01,160 DEBUG TRAIN Batch 126/1400 loss 0.044796 acc 0.963429 lr 0.00014288 grad_norm 0.435997 rank 0
2025-01-11 00:47:01,160 DEBUG TRAIN Batch 126/1400 loss 0.037166 acc 0.973166 lr 0.00014288 grad_norm 0.435997 rank 1
2025-01-11 00:47:01,160 DEBUG TRAIN Batch 126/1400 loss 0.045568 acc 0.958951 lr 0.00014288 grad_norm 0.435997 rank 2
2025-01-11 00:47:26,336 DEBUG TRAIN Batch 126/1500 loss 0.043148 acc 0.971816 lr 0.00014285 grad_norm 0.414184 rank 1
2025-01-11 00:47:26,336 DEBUG TRAIN Batch 126/1500 loss 0.045719 acc 0.969891 lr 0.00014285 grad_norm 0.414184 rank 2
2025-01-11 00:47:26,336 DEBUG TRAIN Batch 126/1500 loss 0.040236 acc 0.972634 lr 0.00014285 grad_norm 0.414184 rank 0
2025-01-11 00:47:50,800 DEBUG TRAIN Batch 126/1600 loss 0.042207 acc 0.971129 lr 0.00014282 grad_norm 0.396824 rank 1
2025-01-11 00:47:50,800 DEBUG TRAIN Batch 126/1600 loss 0.054525 acc 0.968907 lr 0.00014282 grad_norm 0.396824 rank 2
2025-01-11 00:47:50,802 DEBUG TRAIN Batch 126/1600 loss 0.031875 acc 0.975359 lr 0.00014282 grad_norm 0.396824 rank 0
2025-01-11 00:48:16,084 DEBUG TRAIN Batch 126/1700 loss 0.046382 acc 0.969565 lr 0.00014279 grad_norm 0.374859 rank 1
2025-01-11 00:48:16,084 DEBUG TRAIN Batch 126/1700 loss 0.022471 acc 0.985987 lr 0.00014279 grad_norm 0.374859 rank 0
2025-01-11 00:48:16,087 DEBUG TRAIN Batch 126/1700 loss 0.032850 acc 0.976932 lr 0.00014279 grad_norm 0.374859 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 00:49:24,533 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 00:49:24,534 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 00:49:25,027 INFO Epoch 126 Step 122636 on_batch_end True CV rank 0
2025-01-11 00:49:25,027 INFO Epoch 126 Step 122636 on_batch_end True CV rank 1
2025-01-11 00:49:25,027 INFO Epoch 126 Step 122636 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 00:49:34,081 DEBUG CV Batch 126/100 loss 0.009196 acc 0.995541  rank 0
2025-01-11 00:49:34,373 DEBUG CV Batch 126/100 loss 0.009196 acc 0.995541  rank 2
2025-01-11 00:49:34,617 INFO Epoch 126 Step 122636 CV info lr 0.00014277790853419882 0 rank loss_2.536109953493507 acc_0.7813665415895613
2025-01-11 00:49:34,752 DEBUG CV Batch 126/100 loss 0.009196 acc 0.995541  rank 1
2025-01-11 00:49:34,902 INFO Epoch 126 Step 122636 CV info lr 0.00014277790853419882 2 rank loss_2.536109953493507 acc_0.7813665415895613
2025-01-11 00:49:35,300 INFO Epoch 126 Step 122636 CV info lr 0.00014277790853419882 1 rank loss_2.536109953493507 acc_0.7813665415895613
2025-01-11 00:49:35,948 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_126_whole.pt
2025-01-11 00:49:35,970 INFO Added key: store_based_barrier_key:129 to store for rank: 0
2025-01-11 00:49:35,980 INFO Added key: store_based_barrier_key:129 to store for rank: 2
2025-01-11 00:49:35,981 INFO Added key: store_based_barrier_key:129 to store for rank: 1
2025-01-11 00:49:35,981 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:129 with 3 nodes.
2025-01-11 00:49:35,988 INFO Epoch 127 TRAIN info lr 0.00014277790853419882 rank 1
2025-01-11 00:49:35,988 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 00:49:35,991 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:129 with 3 nodes.
2025-01-11 00:49:35,991 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:129 with 3 nodes.
2025-01-11 00:49:35,996 INFO Epoch 127 TRAIN info lr 0.00014277790853419882 rank 2
2025-01-11 00:49:35,996 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 00:49:36,001 INFO Epoch 127 TRAIN info lr 0.00014277790853419882 rank 0
2025-01-11 00:49:36,001 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 00:50:10,277 DEBUG TRAIN Batch 127/100 loss 0.030669 acc 0.978196 lr 0.00014275 grad_norm 0.388237 rank 2
2025-01-11 00:50:10,277 DEBUG TRAIN Batch 127/100 loss 0.034816 acc 0.975026 lr 0.00014275 grad_norm 0.388237 rank 1
2025-01-11 00:50:10,278 DEBUG TRAIN Batch 127/100 loss 0.044174 acc 0.967043 lr 0.00014275 grad_norm 0.388237 rank 0
2025-01-11 00:50:34,574 DEBUG TRAIN Batch 127/200 loss 0.035064 acc 0.978558 lr 0.00014272 grad_norm 0.377018 rank 2
2025-01-11 00:50:34,575 DEBUG TRAIN Batch 127/200 loss 0.036357 acc 0.975439 lr 0.00014272 grad_norm 0.377018 rank 0
2025-01-11 00:50:34,575 DEBUG TRAIN Batch 127/200 loss 0.039573 acc 0.972711 lr 0.00014272 grad_norm 0.377018 rank 1
2025-01-11 00:50:59,543 DEBUG TRAIN Batch 127/300 loss 0.037773 acc 0.976190 lr 0.00014269 grad_norm 0.394329 rank 0
2025-01-11 00:50:59,543 DEBUG TRAIN Batch 127/300 loss 0.037753 acc 0.970392 lr 0.00014269 grad_norm 0.394329 rank 1
2025-01-11 00:50:59,600 DEBUG TRAIN Batch 127/300 loss 0.040180 acc 0.972222 lr 0.00014269 grad_norm 0.394329 rank 2
2025-01-11 00:51:23,646 DEBUG TRAIN Batch 127/400 loss 0.056196 acc 0.966702 lr 0.00014266 grad_norm 0.421370 rank 0
2025-01-11 00:51:23,646 DEBUG TRAIN Batch 127/400 loss 0.037241 acc 0.971282 lr 0.00014266 grad_norm 0.421370 rank 1
2025-01-11 00:51:23,647 DEBUG TRAIN Batch 127/400 loss 0.030961 acc 0.978704 lr 0.00014266 grad_norm 0.421370 rank 2
2025-01-11 00:51:47,976 DEBUG TRAIN Batch 127/500 loss 0.044098 acc 0.973913 lr 0.00014263 grad_norm 0.397176 rank 1
2025-01-11 00:51:47,976 DEBUG TRAIN Batch 127/500 loss 0.037323 acc 0.974026 lr 0.00014263 grad_norm 0.397176 rank 2
2025-01-11 00:51:47,976 DEBUG TRAIN Batch 127/500 loss 0.040698 acc 0.973503 lr 0.00014263 grad_norm 0.397176 rank 0
2025-01-11 00:52:12,231 DEBUG TRAIN Batch 127/600 loss 0.034466 acc 0.975191 lr 0.00014260 grad_norm 0.392613 rank 1
2025-01-11 00:52:12,231 DEBUG TRAIN Batch 127/600 loss 0.040380 acc 0.974061 lr 0.00014260 grad_norm 0.392613 rank 0
2025-01-11 00:52:12,232 DEBUG TRAIN Batch 127/600 loss 0.034952 acc 0.981614 lr 0.00014260 grad_norm 0.392613 rank 2
2025-01-11 00:52:36,539 DEBUG TRAIN Batch 127/700 loss 0.033987 acc 0.979392 lr 0.00014257 grad_norm 0.359617 rank 0
2025-01-11 00:52:36,539 DEBUG TRAIN Batch 127/700 loss 0.034908 acc 0.971942 lr 0.00014257 grad_norm 0.359617 rank 2
2025-01-11 00:52:36,539 DEBUG TRAIN Batch 127/700 loss 0.040031 acc 0.967910 lr 0.00014257 grad_norm 0.359617 rank 1
2025-01-11 00:53:01,285 DEBUG TRAIN Batch 127/800 loss 0.045683 acc 0.968868 lr 0.00014255 grad_norm 0.408608 rank 2
2025-01-11 00:53:01,285 DEBUG TRAIN Batch 127/800 loss 0.034569 acc 0.980962 lr 0.00014255 grad_norm 0.408608 rank 0
2025-01-11 00:53:01,285 DEBUG TRAIN Batch 127/800 loss 0.048138 acc 0.970106 lr 0.00014255 grad_norm 0.408608 rank 1
2025-01-11 00:53:24,963 DEBUG TRAIN Batch 127/900 loss 0.052427 acc 0.968182 lr 0.00014252 grad_norm 0.425242 rank 1
2025-01-11 00:53:24,963 DEBUG TRAIN Batch 127/900 loss 0.050240 acc 0.965481 lr 0.00014252 grad_norm 0.425242 rank 2
2025-01-11 00:53:24,964 DEBUG TRAIN Batch 127/900 loss 0.024159 acc 0.983516 lr 0.00014252 grad_norm 0.425242 rank 0
2025-01-11 00:53:48,871 DEBUG TRAIN Batch 127/1000 loss 0.032583 acc 0.982398 lr 0.00014249 grad_norm 0.407287 rank 2
2025-01-11 00:53:48,871 DEBUG TRAIN Batch 127/1000 loss 0.043300 acc 0.968962 lr 0.00014249 grad_norm 0.407287 rank 1
2025-01-11 00:53:48,871 DEBUG TRAIN Batch 127/1000 loss 0.044326 acc 0.969407 lr 0.00014249 grad_norm 0.407287 rank 0
2025-01-11 00:54:13,611 DEBUG TRAIN Batch 127/1100 loss 0.021285 acc 0.983631 lr 0.00014246 grad_norm 0.427844 rank 2
2025-01-11 00:54:13,611 DEBUG TRAIN Batch 127/1100 loss 0.040781 acc 0.974330 lr 0.00014246 grad_norm 0.427844 rank 0
2025-01-11 00:54:13,611 DEBUG TRAIN Batch 127/1100 loss 0.044990 acc 0.965753 lr 0.00014246 grad_norm 0.427844 rank 1
2025-01-11 00:54:37,755 DEBUG TRAIN Batch 127/1200 loss 0.043758 acc 0.966549 lr 0.00014243 grad_norm 0.409277 rank 2
2025-01-11 00:54:37,756 DEBUG TRAIN Batch 127/1200 loss 0.053038 acc 0.957129 lr 0.00014243 grad_norm 0.409277 rank 1
2025-01-11 00:54:37,756 DEBUG TRAIN Batch 127/1200 loss 0.032612 acc 0.978281 lr 0.00014243 grad_norm 0.409277 rank 0
2025-01-11 00:55:01,507 DEBUG TRAIN Batch 127/1300 loss 0.031902 acc 0.974099 lr 0.00014240 grad_norm 0.403403 rank 0
2025-01-11 00:55:01,508 DEBUG TRAIN Batch 127/1300 loss 0.042746 acc 0.967828 lr 0.00014240 grad_norm 0.403403 rank 2
2025-01-11 00:55:01,508 DEBUG TRAIN Batch 127/1300 loss 0.035076 acc 0.974522 lr 0.00014240 grad_norm 0.403403 rank 1
2025-01-11 00:55:25,863 DEBUG TRAIN Batch 127/1400 loss 0.035529 acc 0.976136 lr 0.00014237 grad_norm 0.413043 rank 0
2025-01-11 00:55:25,864 DEBUG TRAIN Batch 127/1400 loss 0.058221 acc 0.959649 lr 0.00014237 grad_norm 0.413043 rank 2
2025-01-11 00:55:25,864 DEBUG TRAIN Batch 127/1400 loss 0.030518 acc 0.977754 lr 0.00014237 grad_norm 0.413043 rank 1
2025-01-11 00:55:49,928 DEBUG TRAIN Batch 127/1500 loss 0.046192 acc 0.974283 lr 0.00014234 grad_norm 0.418727 rank 0
2025-01-11 00:55:49,928 DEBUG TRAIN Batch 127/1500 loss 0.041837 acc 0.970950 lr 0.00014234 grad_norm 0.418727 rank 1
2025-01-11 00:55:49,928 DEBUG TRAIN Batch 127/1500 loss 0.024646 acc 0.983173 lr 0.00014234 grad_norm 0.418727 rank 2
2025-01-11 00:56:13,845 DEBUG TRAIN Batch 127/1600 loss 0.049393 acc 0.964932 lr 0.00014231 grad_norm 0.412766 rank 2
2025-01-11 00:56:13,845 DEBUG TRAIN Batch 127/1600 loss 0.034883 acc 0.976789 lr 0.00014231 grad_norm 0.412766 rank 0
2025-01-11 00:56:13,846 DEBUG TRAIN Batch 127/1600 loss 0.063227 acc 0.953111 lr 0.00014231 grad_norm 0.412766 rank 1
2025-01-11 00:56:37,697 DEBUG TRAIN Batch 127/1700 loss 0.056894 acc 0.961005 lr 0.00014229 grad_norm 0.424138 rank 2
2025-01-11 00:56:37,698 DEBUG TRAIN Batch 127/1700 loss 0.058580 acc 0.958296 lr 0.00014229 grad_norm 0.424138 rank 1
2025-01-11 00:56:37,699 DEBUG TRAIN Batch 127/1700 loss 0.042035 acc 0.969163 lr 0.00014229 grad_norm 0.424138 rank 0
2025-01-11 00:57:02,780 DEBUG TRAIN Batch 127/1800 loss 0.056350 acc 0.961727 lr 0.00014226 grad_norm 0.441245 rank 1
2025-01-11 00:57:02,780 DEBUG TRAIN Batch 127/1800 loss 0.053480 acc 0.968783 lr 0.00014226 grad_norm 0.441245 rank 2
2025-01-11 00:57:02,781 DEBUG TRAIN Batch 127/1800 loss 0.037750 acc 0.969072 lr 0.00014226 grad_norm 0.441245 rank 0
2025-01-11 00:57:26,480 DEBUG TRAIN Batch 127/1900 loss 0.048144 acc 0.963274 lr 0.00014223 grad_norm 0.437039 rank 1
2025-01-11 00:57:26,480 DEBUG TRAIN Batch 127/1900 loss 0.049901 acc 0.966070 lr 0.00014223 grad_norm 0.437039 rank 2
2025-01-11 00:57:26,481 DEBUG TRAIN Batch 127/1900 loss 0.050478 acc 0.962424 lr 0.00014223 grad_norm 0.437039 rank 0
2025-01-11 00:57:50,362 DEBUG TRAIN Batch 127/2000 loss 0.063820 acc 0.959532 lr 0.00014220 grad_norm 0.427945 rank 2
2025-01-11 00:57:50,363 DEBUG TRAIN Batch 127/2000 loss 0.049067 acc 0.969529 lr 0.00014220 grad_norm 0.427945 rank 1
2025-01-11 00:57:50,363 DEBUG TRAIN Batch 127/2000 loss 0.042267 acc 0.973869 lr 0.00014220 grad_norm 0.427945 rank 0
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 00:58:57,697 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 00:58:57,700 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 00:58:58,086 INFO Epoch 127 Step 123651 on_batch_end True CV rank 2
2025-01-11 00:58:58,086 INFO Epoch 127 Step 123651 on_batch_end True CV rank 1
2025-01-11 00:58:58,086 INFO Epoch 127 Step 123651 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 00:59:07,272 DEBUG CV Batch 127/100 loss 0.009436 acc 0.996656  rank 0
2025-01-11 00:59:07,333 DEBUG CV Batch 127/100 loss 0.009436 acc 0.996656  rank 2
2025-01-11 00:59:07,799 INFO Epoch 127 Step 123651 CV info lr 0.00014219069856297376 0 rank loss_2.532200026185213 acc_0.7811934564981544
2025-01-11 00:59:07,855 INFO Epoch 127 Step 123651 CV info lr 0.00014219069856297376 2 rank loss_2.532200026185213 acc_0.7811934564981544
2025-01-11 00:59:07,914 DEBUG CV Batch 127/100 loss 0.009436 acc 0.996656  rank 1
2025-01-11 00:59:08,431 INFO Epoch 127 Step 123651 CV info lr 0.00014219069856297376 1 rank loss_2.532200026185213 acc_0.7811934564981544
2025-01-11 00:59:09,131 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_127_whole.pt
2025-01-11 00:59:09,153 INFO Added key: store_based_barrier_key:130 to store for rank: 0
2025-01-11 00:59:09,153 INFO Added key: store_based_barrier_key:130 to store for rank: 1
2025-01-11 00:59:09,153 INFO Added key: store_based_barrier_key:130 to store for rank: 2
2025-01-11 00:59:09,154 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:130 with 3 nodes.
2025-01-11 00:59:09,154 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:130 with 3 nodes.
2025-01-11 00:59:09,154 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:130 with 3 nodes.
2025-01-11 00:59:09,154 INFO Epoch 128 TRAIN info lr 0.00014219069856297376 rank 0
2025-01-11 00:59:09,154 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 00:59:09,157 INFO Epoch 128 TRAIN info lr 0.00014219069856297376 rank 2
2025-01-11 00:59:09,157 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 00:59:09,157 INFO Epoch 128 TRAIN info lr 0.00014219069856297376 rank 1
2025-01-11 00:59:09,157 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 00:59:42,600 DEBUG TRAIN Batch 128/100 loss 0.034651 acc 0.976496 lr 0.00014216 grad_norm 0.388115 rank 1
2025-01-11 00:59:42,601 DEBUG TRAIN Batch 128/100 loss 0.026649 acc 0.979636 lr 0.00014216 grad_norm 0.388115 rank 0
2025-01-11 00:59:42,601 DEBUG TRAIN Batch 128/100 loss 0.052361 acc 0.964384 lr 0.00014216 grad_norm 0.388115 rank 2
2025-01-11 01:00:07,000 DEBUG TRAIN Batch 128/200 loss 0.034466 acc 0.981322 lr 0.00014213 grad_norm 0.419979 rank 1
2025-01-11 01:00:07,000 DEBUG TRAIN Batch 128/200 loss 0.050211 acc 0.965328 lr 0.00014213 grad_norm 0.419979 rank 0
2025-01-11 01:00:07,000 DEBUG TRAIN Batch 128/200 loss 0.032293 acc 0.977823 lr 0.00014213 grad_norm 0.419979 rank 2
2025-01-11 01:00:32,014 DEBUG TRAIN Batch 128/300 loss 0.054704 acc 0.961400 lr 0.00014210 grad_norm 0.386169 rank 2
2025-01-11 01:00:32,014 DEBUG TRAIN Batch 128/300 loss 0.032161 acc 0.978605 lr 0.00014210 grad_norm 0.386169 rank 0
2025-01-11 01:00:32,014 DEBUG TRAIN Batch 128/300 loss 0.041787 acc 0.975866 lr 0.00014210 grad_norm 0.386169 rank 1
2025-01-11 01:00:56,513 DEBUG TRAIN Batch 128/400 loss 0.032755 acc 0.978701 lr 0.00014208 grad_norm 0.395258 rank 2
2025-01-11 01:00:56,513 DEBUG TRAIN Batch 128/400 loss 0.033831 acc 0.978261 lr 0.00014208 grad_norm 0.395258 rank 0
2025-01-11 01:00:56,514 DEBUG TRAIN Batch 128/400 loss 0.031976 acc 0.973988 lr 0.00014208 grad_norm 0.395258 rank 1
2025-01-11 01:01:20,575 DEBUG TRAIN Batch 128/500 loss 0.039615 acc 0.975296 lr 0.00014205 grad_norm 0.412016 rank 0
2025-01-11 01:01:20,575 DEBUG TRAIN Batch 128/500 loss 0.028939 acc 0.986802 lr 0.00014205 grad_norm 0.412016 rank 1
2025-01-11 01:01:20,575 DEBUG TRAIN Batch 128/500 loss 0.050110 acc 0.964356 lr 0.00014205 grad_norm 0.412016 rank 2
2025-01-11 01:01:45,286 DEBUG TRAIN Batch 128/600 loss 0.036789 acc 0.973985 lr 0.00014202 grad_norm 0.416885 rank 0
2025-01-11 01:01:45,287 DEBUG TRAIN Batch 128/600 loss 0.044628 acc 0.968015 lr 0.00014202 grad_norm 0.416885 rank 2
2025-01-11 01:01:45,290 DEBUG TRAIN Batch 128/600 loss 0.023996 acc 0.987639 lr 0.00014202 grad_norm 0.416885 rank 1
2025-01-11 01:02:09,524 DEBUG TRAIN Batch 128/700 loss 0.038440 acc 0.976264 lr 0.00014199 grad_norm 0.389939 rank 0
2025-01-11 01:02:09,524 DEBUG TRAIN Batch 128/700 loss 0.043767 acc 0.969352 lr 0.00014199 grad_norm 0.389939 rank 2
2025-01-11 01:02:09,524 DEBUG TRAIN Batch 128/700 loss 0.042090 acc 0.973023 lr 0.00014199 grad_norm 0.389939 rank 1
2025-01-11 01:02:33,492 DEBUG TRAIN Batch 128/800 loss 0.042815 acc 0.970307 lr 0.00014196 grad_norm 0.389806 rank 2
2025-01-11 01:02:33,493 DEBUG TRAIN Batch 128/800 loss 0.041825 acc 0.971804 lr 0.00014196 grad_norm 0.389806 rank 0
2025-01-11 01:02:33,493 DEBUG TRAIN Batch 128/800 loss 0.033289 acc 0.975758 lr 0.00014196 grad_norm 0.389806 rank 1
2025-01-11 01:02:57,593 DEBUG TRAIN Batch 128/900 loss 0.049282 acc 0.967480 lr 0.00014193 grad_norm 0.408840 rank 2
2025-01-11 01:02:57,593 DEBUG TRAIN Batch 128/900 loss 0.038711 acc 0.975283 lr 0.00014193 grad_norm 0.408840 rank 0
2025-01-11 01:02:57,594 DEBUG TRAIN Batch 128/900 loss 0.040361 acc 0.970090 lr 0.00014193 grad_norm 0.408840 rank 1
2025-01-11 01:03:21,633 DEBUG TRAIN Batch 128/1000 loss 0.035115 acc 0.975723 lr 0.00014190 grad_norm 0.391157 rank 0
2025-01-11 01:03:21,633 DEBUG TRAIN Batch 128/1000 loss 0.041591 acc 0.973198 lr 0.00014190 grad_norm 0.391157 rank 1
2025-01-11 01:03:21,634 DEBUG TRAIN Batch 128/1000 loss 0.025868 acc 0.978986 lr 0.00014190 grad_norm 0.391157 rank 2
2025-01-11 01:03:45,982 DEBUG TRAIN Batch 128/1100 loss 0.044778 acc 0.968777 lr 0.00014188 grad_norm 0.416387 rank 0
2025-01-11 01:03:45,982 DEBUG TRAIN Batch 128/1100 loss 0.039030 acc 0.970854 lr 0.00014188 grad_norm 0.416387 rank 1
2025-01-11 01:03:45,982 DEBUG TRAIN Batch 128/1100 loss 0.052907 acc 0.965458 lr 0.00014188 grad_norm 0.416387 rank 2
2025-01-11 01:04:09,676 DEBUG TRAIN Batch 128/1200 loss 0.040832 acc 0.976679 lr 0.00014185 grad_norm 0.382062 rank 0
2025-01-11 01:04:09,676 DEBUG TRAIN Batch 128/1200 loss 0.040210 acc 0.971459 lr 0.00014185 grad_norm 0.382062 rank 1
2025-01-11 01:04:09,676 DEBUG TRAIN Batch 128/1200 loss 0.033566 acc 0.975657 lr 0.00014185 grad_norm 0.382062 rank 2
2025-01-11 01:04:33,520 DEBUG TRAIN Batch 128/1300 loss 0.050426 acc 0.964192 lr 0.00014182 grad_norm 0.407568 rank 0
2025-01-11 01:04:33,521 DEBUG TRAIN Batch 128/1300 loss 0.047661 acc 0.969244 lr 0.00014182 grad_norm 0.407568 rank 2
2025-01-11 01:04:33,521 DEBUG TRAIN Batch 128/1300 loss 0.046285 acc 0.971910 lr 0.00014182 grad_norm 0.407568 rank 1
2025-01-11 01:04:57,447 DEBUG TRAIN Batch 128/1400 loss 0.032315 acc 0.980645 lr 0.00014179 grad_norm 0.390639 rank 0
2025-01-11 01:04:57,448 DEBUG TRAIN Batch 128/1400 loss 0.043239 acc 0.976531 lr 0.00014179 grad_norm 0.390639 rank 1
2025-01-11 01:04:57,448 DEBUG TRAIN Batch 128/1400 loss 0.034924 acc 0.975348 lr 0.00014179 grad_norm 0.390639 rank 2
2025-01-11 01:05:21,852 DEBUG TRAIN Batch 128/1500 loss 0.037548 acc 0.971338 lr 0.00014176 grad_norm 0.397563 rank 1
2025-01-11 01:05:21,852 DEBUG TRAIN Batch 128/1500 loss 0.030793 acc 0.985830 lr 0.00014176 grad_norm 0.397563 rank 0
2025-01-11 01:05:21,852 DEBUG TRAIN Batch 128/1500 loss 0.039800 acc 0.972603 lr 0.00014176 grad_norm 0.397563 rank 2
2025-01-11 01:05:46,161 DEBUG TRAIN Batch 128/1600 loss 0.042866 acc 0.964894 lr 0.00014173 grad_norm 0.437454 rank 2
2025-01-11 01:05:46,161 DEBUG TRAIN Batch 128/1600 loss 0.035806 acc 0.974221 lr 0.00014173 grad_norm 0.437454 rank 0
2025-01-11 01:05:46,161 DEBUG TRAIN Batch 128/1600 loss 0.046635 acc 0.971899 lr 0.00014173 grad_norm 0.437454 rank 1
2025-01-11 01:06:09,632 DEBUG TRAIN Batch 128/1700 loss 0.041937 acc 0.970588 lr 0.00014170 grad_norm 0.409079 rank 1
2025-01-11 01:06:09,632 DEBUG TRAIN Batch 128/1700 loss 0.024229 acc 0.985491 lr 0.00014170 grad_norm 0.409079 rank 2
2025-01-11 01:06:09,632 DEBUG TRAIN Batch 128/1700 loss 0.043736 acc 0.974561 lr 0.00014170 grad_norm 0.409079 rank 0
2025-01-11 01:06:34,014 DEBUG TRAIN Batch 128/1800 loss 0.036434 acc 0.975632 lr 0.00014168 grad_norm 0.407721 rank 1
2025-01-11 01:06:34,014 DEBUG TRAIN Batch 128/1800 loss 0.039205 acc 0.977074 lr 0.00014168 grad_norm 0.407721 rank 2
2025-01-11 01:06:34,014 DEBUG TRAIN Batch 128/1800 loss 0.042892 acc 0.973205 lr 0.00014168 grad_norm 0.407721 rank 0
2025-01-11 01:06:58,338 DEBUG TRAIN Batch 128/1900 loss 0.037198 acc 0.969481 lr 0.00014165 grad_norm 0.410883 rank 0
2025-01-11 01:06:58,339 DEBUG TRAIN Batch 128/1900 loss 0.025566 acc 0.988034 lr 0.00014165 grad_norm 0.410883 rank 2
2025-01-11 01:06:58,340 DEBUG TRAIN Batch 128/1900 loss 0.037788 acc 0.968518 lr 0.00014165 grad_norm 0.410883 rank 1
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 01:08:08,104 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 01:08:08,108 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 01:08:08,566 INFO Epoch 128 Step 124622 on_batch_end True CV rank 1
2025-01-11 01:08:08,566 INFO Epoch 128 Step 124622 on_batch_end True CV rank 0
2025-01-11 01:08:08,566 INFO Epoch 128 Step 124622 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 01:08:17,671 DEBUG CV Batch 128/100 loss 0.002093 acc 1.000000  rank 2
2025-01-11 01:08:17,811 DEBUG CV Batch 128/100 loss 0.002093 acc 1.000000  rank 0
2025-01-11 01:08:18,193 INFO Epoch 128 Step 124622 CV info lr 0.00014163567151767063 2 rank loss_2.5548397714224658 acc_0.7806381932214687
2025-01-11 01:08:18,336 INFO Epoch 128 Step 124622 CV info lr 0.00014163567151767063 0 rank loss_2.5548397714224658 acc_0.7806381932214687
2025-01-11 01:08:18,544 DEBUG CV Batch 128/100 loss 0.002093 acc 1.000000  rank 1
2025-01-11 01:08:19,068 INFO Epoch 128 Step 124622 CV info lr 0.00014163567151767063 1 rank loss_2.5548397714224658 acc_0.7806381932214687
2025-01-11 01:08:19,632 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_128_whole.pt
2025-01-11 01:08:19,654 INFO Added key: store_based_barrier_key:131 to store for rank: 0
2025-01-11 01:08:19,654 INFO Added key: store_based_barrier_key:131 to store for rank: 2
2025-01-11 01:08:19,654 INFO Added key: store_based_barrier_key:131 to store for rank: 1
2025-01-11 01:08:19,654 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:131 with 3 nodes.
2025-01-11 01:08:19,654 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:131 with 3 nodes.
2025-01-11 01:08:19,655 INFO Epoch 129 TRAIN info lr 0.00014163567151767063 rank 1
2025-01-11 01:08:19,655 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 01:08:19,661 INFO Epoch 129 TRAIN info lr 0.00014163567151767063 rank 2
2025-01-11 01:08:19,661 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 01:08:19,664 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:131 with 3 nodes.
2025-01-11 01:08:19,665 INFO Epoch 129 TRAIN info lr 0.00014163567151767063 rank 0
2025-01-11 01:08:19,665 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 01:08:50,971 DEBUG TRAIN Batch 129/100 loss 0.029226 acc 0.978373 lr 0.00014161 grad_norm 0.378026 rank 2
2025-01-11 01:08:50,972 DEBUG TRAIN Batch 129/100 loss 0.041425 acc 0.973604 lr 0.00014161 grad_norm 0.378026 rank 0
2025-01-11 01:08:50,972 DEBUG TRAIN Batch 129/100 loss 0.031217 acc 0.983957 lr 0.00014161 grad_norm 0.378026 rank 1
2025-01-11 01:09:15,181 DEBUG TRAIN Batch 129/200 loss 0.035191 acc 0.973992 lr 0.00014158 grad_norm 0.414348 rank 2
2025-01-11 01:09:15,181 DEBUG TRAIN Batch 129/200 loss 0.040766 acc 0.969582 lr 0.00014158 grad_norm 0.414348 rank 0
2025-01-11 01:09:15,182 DEBUG TRAIN Batch 129/200 loss 0.033647 acc 0.976644 lr 0.00014158 grad_norm 0.414348 rank 1
2025-01-11 01:09:38,922 DEBUG TRAIN Batch 129/300 loss 0.031154 acc 0.978967 lr 0.00014155 grad_norm 0.387079 rank 1
2025-01-11 01:09:38,923 DEBUG TRAIN Batch 129/300 loss 0.037868 acc 0.975892 lr 0.00014155 grad_norm 0.387079 rank 0
2025-01-11 01:09:38,923 DEBUG TRAIN Batch 129/300 loss 0.038621 acc 0.969608 lr 0.00014155 grad_norm 0.387079 rank 2
2025-01-11 01:10:02,767 DEBUG TRAIN Batch 129/400 loss 0.034080 acc 0.978903 lr 0.00014152 grad_norm 0.361464 rank 0
2025-01-11 01:10:02,767 DEBUG TRAIN Batch 129/400 loss 0.037982 acc 0.980372 lr 0.00014152 grad_norm 0.361464 rank 1
2025-01-11 01:10:02,768 DEBUG TRAIN Batch 129/400 loss 0.031812 acc 0.979859 lr 0.00014152 grad_norm 0.361464 rank 2
2025-01-11 01:10:27,163 DEBUG TRAIN Batch 129/500 loss 0.038154 acc 0.975045 lr 0.00014149 grad_norm 0.393038 rank 0
2025-01-11 01:10:27,164 DEBUG TRAIN Batch 129/500 loss 0.030272 acc 0.980076 lr 0.00014149 grad_norm 0.393038 rank 1
2025-01-11 01:10:27,164 DEBUG TRAIN Batch 129/500 loss 0.047436 acc 0.970054 lr 0.00014149 grad_norm 0.393038 rank 2
2025-01-11 01:10:50,609 DEBUG TRAIN Batch 129/600 loss 0.052844 acc 0.967910 lr 0.00014147 grad_norm 0.442065 rank 2
2025-01-11 01:10:50,609 DEBUG TRAIN Batch 129/600 loss 0.048797 acc 0.965887 lr 0.00014147 grad_norm 0.442065 rank 1
2025-01-11 01:10:50,609 DEBUG TRAIN Batch 129/600 loss 0.048776 acc 0.966667 lr 0.00014147 grad_norm 0.442065 rank 0
2025-01-11 01:11:15,286 DEBUG TRAIN Batch 129/700 loss 0.031964 acc 0.976308 lr 0.00014144 grad_norm 0.401172 rank 1
2025-01-11 01:11:15,286 DEBUG TRAIN Batch 129/700 loss 0.034050 acc 0.979894 lr 0.00014144 grad_norm 0.401172 rank 0
2025-01-11 01:11:15,286 DEBUG TRAIN Batch 129/700 loss 0.029546 acc 0.979104 lr 0.00014144 grad_norm 0.401172 rank 2
2025-01-11 01:11:39,303 DEBUG TRAIN Batch 129/800 loss 0.041335 acc 0.966014 lr 0.00014141 grad_norm 0.426237 rank 1
2025-01-11 01:11:39,303 DEBUG TRAIN Batch 129/800 loss 0.034361 acc 0.980208 lr 0.00014141 grad_norm 0.426237 rank 2
2025-01-11 01:11:39,303 DEBUG TRAIN Batch 129/800 loss 0.054080 acc 0.957492 lr 0.00014141 grad_norm 0.426237 rank 0
2025-01-11 01:12:04,063 DEBUG TRAIN Batch 129/900 loss 0.044765 acc 0.967243 lr 0.00014138 grad_norm 0.380754 rank 0
2025-01-11 01:12:04,063 DEBUG TRAIN Batch 129/900 loss 0.044921 acc 0.969271 lr 0.00014138 grad_norm 0.380754 rank 1
2025-01-11 01:12:04,064 DEBUG TRAIN Batch 129/900 loss 0.038740 acc 0.975893 lr 0.00014138 grad_norm 0.380754 rank 2
2025-01-11 01:12:27,958 DEBUG TRAIN Batch 129/1000 loss 0.036436 acc 0.974330 lr 0.00014135 grad_norm 0.386304 rank 1
2025-01-11 01:12:27,958 DEBUG TRAIN Batch 129/1000 loss 0.046597 acc 0.971856 lr 0.00014135 grad_norm 0.386304 rank 0
2025-01-11 01:12:27,959 DEBUG TRAIN Batch 129/1000 loss 0.038918 acc 0.973137 lr 0.00014135 grad_norm 0.386304 rank 2
2025-01-11 01:12:52,778 DEBUG TRAIN Batch 129/1100 loss 0.049140 acc 0.968553 lr 0.00014132 grad_norm 0.416799 rank 1
2025-01-11 01:12:52,779 DEBUG TRAIN Batch 129/1100 loss 0.041803 acc 0.971664 lr 0.00014132 grad_norm 0.416799 rank 2
2025-01-11 01:12:52,779 DEBUG TRAIN Batch 129/1100 loss 0.050068 acc 0.964472 lr 0.00014132 grad_norm 0.416799 rank 0
2025-01-11 01:13:17,075 DEBUG TRAIN Batch 129/1200 loss 0.036998 acc 0.970135 lr 0.00014130 grad_norm 0.410273 rank 1
2025-01-11 01:13:17,076 DEBUG TRAIN Batch 129/1200 loss 0.027251 acc 0.984407 lr 0.00014130 grad_norm 0.410273 rank 2
2025-01-11 01:13:17,076 DEBUG TRAIN Batch 129/1200 loss 0.044914 acc 0.967290 lr 0.00014130 grad_norm 0.410273 rank 0
2025-01-11 01:13:41,284 DEBUG TRAIN Batch 129/1300 loss 0.031119 acc 0.974110 lr 0.00014127 grad_norm 0.412806 rank 0
2025-01-11 01:13:41,284 DEBUG TRAIN Batch 129/1300 loss 0.047307 acc 0.961938 lr 0.00014127 grad_norm 0.412806 rank 1
2025-01-11 01:13:41,284 DEBUG TRAIN Batch 129/1300 loss 0.027432 acc 0.977539 lr 0.00014127 grad_norm 0.412806 rank 2
2025-01-11 01:14:05,477 DEBUG TRAIN Batch 129/1400 loss 0.034615 acc 0.975184 lr 0.00014124 grad_norm 0.384595 rank 0
2025-01-11 01:14:05,477 DEBUG TRAIN Batch 129/1400 loss 0.036542 acc 0.978402 lr 0.00014124 grad_norm 0.384595 rank 1
2025-01-11 01:14:05,478 DEBUG TRAIN Batch 129/1400 loss 0.036260 acc 0.978745 lr 0.00014124 grad_norm 0.384595 rank 2
2025-01-11 01:14:29,802 DEBUG TRAIN Batch 129/1500 loss 0.059335 acc 0.965608 lr 0.00014121 grad_norm 0.409290 rank 2
2025-01-11 01:14:29,802 DEBUG TRAIN Batch 129/1500 loss 0.041996 acc 0.970260 lr 0.00014121 grad_norm 0.409290 rank 1
2025-01-11 01:14:29,805 DEBUG TRAIN Batch 129/1500 loss 0.026811 acc 0.981799 lr 0.00014121 grad_norm 0.409290 rank 0
2025-01-11 01:14:53,310 DEBUG TRAIN Batch 129/1600 loss 0.039843 acc 0.973581 lr 0.00014118 grad_norm 0.415230 rank 1
2025-01-11 01:14:53,310 DEBUG TRAIN Batch 129/1600 loss 0.050511 acc 0.970362 lr 0.00014118 grad_norm 0.415230 rank 2
2025-01-11 01:14:53,311 DEBUG TRAIN Batch 129/1600 loss 0.035612 acc 0.975541 lr 0.00014118 grad_norm 0.415230 rank 0
2025-01-11 01:15:17,222 DEBUG TRAIN Batch 129/1700 loss 0.035961 acc 0.977169 lr 0.00014116 grad_norm 0.428435 rank 2
2025-01-11 01:15:17,223 DEBUG TRAIN Batch 129/1700 loss 0.054584 acc 0.963277 lr 0.00014116 grad_norm 0.428435 rank 0
2025-01-11 01:15:17,223 DEBUG TRAIN Batch 129/1700 loss 0.026626 acc 0.977742 lr 0.00014116 grad_norm 0.428435 rank 1
2025-01-11 01:15:42,093 DEBUG TRAIN Batch 129/1800 loss 0.046173 acc 0.965858 lr 0.00014113 grad_norm 0.395722 rank 0
2025-01-11 01:15:42,093 DEBUG TRAIN Batch 129/1800 loss 0.027141 acc 0.982301 lr 0.00014113 grad_norm 0.395722 rank 2
2025-01-11 01:15:42,094 DEBUG TRAIN Batch 129/1800 loss 0.048880 acc 0.962652 lr 0.00014113 grad_norm 0.395722 rank 1
2025-01-11 01:16:06,667 DEBUG TRAIN Batch 129/1900 loss 0.054070 acc 0.965993 lr 0.00014110 grad_norm 0.438544 rank 0
2025-01-11 01:16:06,668 DEBUG TRAIN Batch 129/1900 loss 0.050131 acc 0.962065 lr 0.00014110 grad_norm 0.438544 rank 1
2025-01-11 01:16:06,668 DEBUG TRAIN Batch 129/1900 loss 0.028132 acc 0.979487 lr 0.00014110 grad_norm 0.438544 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 01:17:23,071 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 01:17:23,078 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 01:17:23,515 INFO Epoch 129 Step 125606 on_batch_end True CV rank 0
2025-01-11 01:17:23,515 INFO Epoch 129 Step 125606 on_batch_end True CV rank 2
2025-01-11 01:17:23,516 INFO Epoch 129 Step 125606 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 01:17:32,728 DEBUG CV Batch 129/100 loss 0.006304 acc 0.998885  rank 0
2025-01-11 01:17:33,275 INFO Epoch 129 Step 125606 CV info lr 0.000141079792295756 0 rank loss_2.57421926192974 acc_0.7789790562370367
2025-01-11 01:17:33,296 DEBUG CV Batch 129/100 loss 0.006304 acc 0.998885  rank 2
2025-01-11 01:17:33,621 DEBUG CV Batch 129/100 loss 0.006304 acc 0.998885  rank 1
2025-01-11 01:17:33,832 INFO Epoch 129 Step 125606 CV info lr 0.000141079792295756 2 rank loss_2.57421926192974 acc_0.7789790562370367
2025-01-11 01:17:34,189 INFO Epoch 129 Step 125606 CV info lr 0.000141079792295756 1 rank loss_2.57421926192974 acc_0.7789790562370367
2025-01-11 01:17:34,602 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_129_whole.pt
2025-01-11 01:17:34,613 INFO Added key: store_based_barrier_key:132 to store for rank: 0
2025-01-11 01:17:34,623 INFO Added key: store_based_barrier_key:132 to store for rank: 2
2025-01-11 01:17:34,624 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:132 with 3 nodes.
2025-01-11 01:17:34,624 INFO Added key: store_based_barrier_key:132 to store for rank: 1
2025-01-11 01:17:34,624 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:132 with 3 nodes.
2025-01-11 01:17:34,628 INFO Epoch 130 TRAIN info lr 0.000141079792295756 rank 1
2025-01-11 01:17:34,628 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 01:17:34,632 INFO Epoch 130 TRAIN info lr 0.000141079792295756 rank 2
2025-01-11 01:17:34,632 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 01:17:34,634 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:132 with 3 nodes.
2025-01-11 01:17:34,644 INFO Epoch 130 TRAIN info lr 0.000141079792295756 rank 0
2025-01-11 01:17:34,644 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 01:18:06,017 DEBUG TRAIN Batch 130/100 loss 0.042444 acc 0.966701 lr 0.00014105 grad_norm 0.398368 rank 0
2025-01-11 01:18:06,018 DEBUG TRAIN Batch 130/100 loss 0.037956 acc 0.983607 lr 0.00014105 grad_norm 0.398368 rank 2
2025-01-11 01:18:06,018 DEBUG TRAIN Batch 130/100 loss 0.035639 acc 0.977564 lr 0.00014105 grad_norm 0.398368 rank 1
2025-01-11 01:18:29,921 DEBUG TRAIN Batch 130/200 loss 0.060296 acc 0.958261 lr 0.00014102 grad_norm 0.414967 rank 2
2025-01-11 01:18:29,921 DEBUG TRAIN Batch 130/200 loss 0.049499 acc 0.966179 lr 0.00014102 grad_norm 0.414967 rank 1
2025-01-11 01:18:29,921 DEBUG TRAIN Batch 130/200 loss 0.033843 acc 0.980600 lr 0.00014102 grad_norm 0.414967 rank 0
2025-01-11 01:18:53,929 DEBUG TRAIN Batch 130/300 loss 0.028612 acc 0.977539 lr 0.00014100 grad_norm 0.381777 rank 0
2025-01-11 01:18:53,929 DEBUG TRAIN Batch 130/300 loss 0.039687 acc 0.982213 lr 0.00014100 grad_norm 0.381777 rank 2
2025-01-11 01:18:53,929 DEBUG TRAIN Batch 130/300 loss 0.036621 acc 0.972897 lr 0.00014100 grad_norm 0.381777 rank 1
2025-01-11 01:19:17,607 DEBUG TRAIN Batch 130/400 loss 0.033730 acc 0.982310 lr 0.00014097 grad_norm 0.394934 rank 0
2025-01-11 01:19:17,608 DEBUG TRAIN Batch 130/400 loss 0.038823 acc 0.972013 lr 0.00014097 grad_norm 0.394934 rank 2
2025-01-11 01:19:17,608 DEBUG TRAIN Batch 130/400 loss 0.035480 acc 0.973790 lr 0.00014097 grad_norm 0.394934 rank 1
2025-01-11 01:19:41,781 DEBUG TRAIN Batch 130/500 loss 0.040486 acc 0.972878 lr 0.00014094 grad_norm 0.335134 rank 0
2025-01-11 01:19:41,781 DEBUG TRAIN Batch 130/500 loss 0.042726 acc 0.966934 lr 0.00014094 grad_norm 0.335134 rank 1
2025-01-11 01:19:41,782 DEBUG TRAIN Batch 130/500 loss 0.025325 acc 0.986934 lr 0.00014094 grad_norm 0.335134 rank 2
2025-01-11 01:20:05,875 DEBUG TRAIN Batch 130/600 loss 0.039351 acc 0.973031 lr 0.00014091 grad_norm 0.428193 rank 1
2025-01-11 01:20:05,875 DEBUG TRAIN Batch 130/600 loss 0.041655 acc 0.971591 lr 0.00014091 grad_norm 0.428193 rank 0
2025-01-11 01:20:05,875 DEBUG TRAIN Batch 130/600 loss 0.038814 acc 0.972617 lr 0.00014091 grad_norm 0.428193 rank 2
2025-01-11 01:20:31,021 DEBUG TRAIN Batch 130/700 loss 0.025936 acc 0.982475 lr 0.00014088 grad_norm 0.387604 rank 2
2025-01-11 01:20:31,021 DEBUG TRAIN Batch 130/700 loss 0.045771 acc 0.968858 lr 0.00014088 grad_norm 0.387604 rank 1
2025-01-11 01:20:31,021 DEBUG TRAIN Batch 130/700 loss 0.034369 acc 0.981413 lr 0.00014088 grad_norm 0.387604 rank 0
2025-01-11 01:20:56,030 DEBUG TRAIN Batch 130/800 loss 0.059176 acc 0.959472 lr 0.00014086 grad_norm 0.394742 rank 0
2025-01-11 01:20:56,031 DEBUG TRAIN Batch 130/800 loss 0.026777 acc 0.982059 lr 0.00014086 grad_norm 0.394742 rank 1
2025-01-11 01:20:56,031 DEBUG TRAIN Batch 130/800 loss 0.031323 acc 0.983434 lr 0.00014086 grad_norm 0.394742 rank 2
2025-01-11 01:21:21,496 DEBUG TRAIN Batch 130/900 loss 0.043127 acc 0.973048 lr 0.00014083 grad_norm 0.394649 rank 0
2025-01-11 01:21:21,497 DEBUG TRAIN Batch 130/900 loss 0.035626 acc 0.977654 lr 0.00014083 grad_norm 0.394649 rank 1
2025-01-11 01:21:21,497 DEBUG TRAIN Batch 130/900 loss 0.033774 acc 0.980493 lr 0.00014083 grad_norm 0.394649 rank 2
2025-01-11 01:21:46,384 DEBUG TRAIN Batch 130/1000 loss 0.053224 acc 0.968504 lr 0.00014080 grad_norm 0.406606 rank 2
2025-01-11 01:21:46,383 DEBUG TRAIN Batch 130/1000 loss 0.046515 acc 0.971756 lr 0.00014080 grad_norm 0.406606 rank 1
2025-01-11 01:21:46,384 DEBUG TRAIN Batch 130/1000 loss 0.033819 acc 0.977718 lr 0.00014080 grad_norm 0.406606 rank 0
2025-01-11 01:22:11,048 DEBUG TRAIN Batch 130/1100 loss 0.027013 acc 0.980971 lr 0.00014077 grad_norm 0.390568 rank 0
2025-01-11 01:22:11,048 DEBUG TRAIN Batch 130/1100 loss 0.015869 acc 0.994881 lr 0.00014077 grad_norm 0.390568 rank 2
2025-01-11 01:22:11,049 DEBUG TRAIN Batch 130/1100 loss 0.042714 acc 0.971645 lr 0.00014077 grad_norm 0.390568 rank 1
2025-01-11 01:22:37,051 DEBUG TRAIN Batch 130/1200 loss 0.041269 acc 0.966997 lr 0.00014074 grad_norm 0.393188 rank 2
2025-01-11 01:22:37,051 DEBUG TRAIN Batch 130/1200 loss 0.030841 acc 0.979323 lr 0.00014074 grad_norm 0.393188 rank 0
2025-01-11 01:22:37,051 DEBUG TRAIN Batch 130/1200 loss 0.040858 acc 0.968750 lr 0.00014074 grad_norm 0.393188 rank 1
2025-01-11 01:23:00,918 DEBUG TRAIN Batch 130/1300 loss 0.036316 acc 0.974708 lr 0.00014072 grad_norm 0.402865 rank 0
2025-01-11 01:23:00,918 DEBUG TRAIN Batch 130/1300 loss 0.033989 acc 0.972279 lr 0.00014072 grad_norm 0.402865 rank 1
2025-01-11 01:23:00,918 DEBUG TRAIN Batch 130/1300 loss 0.034150 acc 0.978571 lr 0.00014072 grad_norm 0.402865 rank 2
2025-01-11 01:23:25,127 DEBUG TRAIN Batch 130/1400 loss 0.036163 acc 0.974661 lr 0.00014069 grad_norm 0.387550 rank 1
2025-01-11 01:23:25,127 DEBUG TRAIN Batch 130/1400 loss 0.028452 acc 0.978923 lr 0.00014069 grad_norm 0.387550 rank 0
2025-01-11 01:23:25,127 DEBUG TRAIN Batch 130/1400 loss 0.037414 acc 0.979186 lr 0.00014069 grad_norm 0.387550 rank 2
2025-01-11 01:23:50,634 DEBUG TRAIN Batch 130/1500 loss 0.039047 acc 0.970097 lr 0.00014066 grad_norm 0.396158 rank 1
2025-01-11 01:23:50,634 DEBUG TRAIN Batch 130/1500 loss 0.046894 acc 0.965278 lr 0.00014066 grad_norm 0.396158 rank 0
2025-01-11 01:23:50,635 DEBUG TRAIN Batch 130/1500 loss 0.044547 acc 0.966934 lr 0.00014066 grad_norm 0.396158 rank 2
2025-01-11 01:24:14,572 DEBUG TRAIN Batch 130/1600 loss 0.043761 acc 0.963295 lr 0.00014063 grad_norm 0.416928 rank 0
2025-01-11 01:24:14,573 DEBUG TRAIN Batch 130/1600 loss 0.035104 acc 0.982036 lr 0.00014063 grad_norm 0.416928 rank 1
2025-01-11 01:24:14,573 DEBUG TRAIN Batch 130/1600 loss 0.031310 acc 0.976217 lr 0.00014063 grad_norm 0.416928 rank 2
2025-01-11 01:24:38,334 DEBUG TRAIN Batch 130/1700 loss 0.028837 acc 0.976879 lr 0.00014060 grad_norm 0.376119 rank 0
2025-01-11 01:24:38,334 DEBUG TRAIN Batch 130/1700 loss 0.038436 acc 0.975659 lr 0.00014060 grad_norm 0.376119 rank 1
2025-01-11 01:24:38,334 DEBUG TRAIN Batch 130/1700 loss 0.040563 acc 0.971275 lr 0.00014060 grad_norm 0.376119 rank 2
2025-01-11 01:25:01,998 DEBUG TRAIN Batch 130/1800 loss 0.035235 acc 0.977022 lr 0.00014058 grad_norm 0.407778 rank 0
2025-01-11 01:25:01,999 DEBUG TRAIN Batch 130/1800 loss 0.040971 acc 0.969961 lr 0.00014058 grad_norm 0.407778 rank 1
2025-01-11 01:25:01,999 DEBUG TRAIN Batch 130/1800 loss 0.041378 acc 0.973783 lr 0.00014058 grad_norm 0.407778 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 01:26:25,619 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 01:26:25,621 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 01:26:26,030 INFO Epoch 130 Step 126555 on_batch_end True CV rank 0
2025-01-11 01:26:26,030 INFO Epoch 130 Step 126555 on_batch_end True CV rank 2
2025-01-11 01:26:26,030 INFO Epoch 130 Step 126555 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 01:26:35,453 DEBUG CV Batch 130/100 loss 0.007994 acc 0.996656  rank 0
2025-01-11 01:26:35,555 DEBUG CV Batch 130/100 loss 0.007994 acc 0.996656  rank 2
2025-01-11 01:26:35,847 DEBUG CV Batch 130/100 loss 0.007994 acc 0.996656  rank 1
2025-01-11 01:26:35,992 INFO Epoch 130 Step 126555 CV info lr 0.00014054983828661147 0 rank loss_2.563303167605977 acc_0.7797039742009682
2025-01-11 01:26:36,096 INFO Epoch 130 Step 126555 CV info lr 0.00014054983828661147 2 rank loss_2.563303167605977 acc_0.7797039742009682
2025-01-11 01:26:36,387 INFO Epoch 130 Step 126555 CV info lr 0.00014054983828661147 1 rank loss_2.563303167605977 acc_0.7797039742009682
2025-01-11 01:26:37,359 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_130_whole.pt
2025-01-11 01:26:37,380 INFO Added key: store_based_barrier_key:133 to store for rank: 0
2025-01-11 01:26:37,381 INFO Added key: store_based_barrier_key:133 to store for rank: 2
2025-01-11 01:26:37,381 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:133 with 3 nodes.
2025-01-11 01:26:37,381 INFO Added key: store_based_barrier_key:133 to store for rank: 1
2025-01-11 01:26:37,382 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:133 with 3 nodes.
2025-01-11 01:26:37,383 INFO Epoch 131 TRAIN info lr 0.00014054983828661147 rank 2
2025-01-11 01:26:37,383 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 01:26:37,386 INFO Epoch 131 TRAIN info lr 0.00014054983828661147 rank 1
2025-01-11 01:26:37,386 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 01:26:37,391 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:133 with 3 nodes.
2025-01-11 01:26:37,398 INFO Epoch 131 TRAIN info lr 0.00014054983828661147 rank 0
2025-01-11 01:26:37,398 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 01:27:11,930 DEBUG TRAIN Batch 131/100 loss 0.042278 acc 0.969368 lr 0.00014052 grad_norm 0.393058 rank 0
2025-01-11 01:27:11,930 DEBUG TRAIN Batch 131/100 loss 0.029728 acc 0.979317 lr 0.00014052 grad_norm 0.393058 rank 1
2025-01-11 01:27:11,930 DEBUG TRAIN Batch 131/100 loss 0.043138 acc 0.969259 lr 0.00014052 grad_norm 0.393058 rank 2
2025-01-11 01:27:36,266 DEBUG TRAIN Batch 131/200 loss 0.038470 acc 0.979540 lr 0.00014049 grad_norm 0.439329 rank 1
2025-01-11 01:27:36,266 DEBUG TRAIN Batch 131/200 loss 0.026876 acc 0.983852 lr 0.00014049 grad_norm 0.439329 rank 2
2025-01-11 01:27:36,266 DEBUG TRAIN Batch 131/200 loss 0.041385 acc 0.976371 lr 0.00014049 grad_norm 0.439329 rank 0
2025-01-11 01:28:00,791 DEBUG TRAIN Batch 131/300 loss 0.042704 acc 0.971372 lr 0.00014047 grad_norm 0.382531 rank 1
2025-01-11 01:28:00,792 DEBUG TRAIN Batch 131/300 loss 0.034486 acc 0.974453 lr 0.00014047 grad_norm 0.382531 rank 2
2025-01-11 01:28:00,792 DEBUG TRAIN Batch 131/300 loss 0.035155 acc 0.974935 lr 0.00014047 grad_norm 0.382531 rank 0
2025-01-11 01:28:25,832 DEBUG TRAIN Batch 131/400 loss 0.026314 acc 0.986359 lr 0.00014044 grad_norm 0.395580 rank 1
2025-01-11 01:28:25,832 DEBUG TRAIN Batch 131/400 loss 0.033938 acc 0.980695 lr 0.00014044 grad_norm 0.395580 rank 2
2025-01-11 01:28:25,832 DEBUG TRAIN Batch 131/400 loss 0.056370 acc 0.966057 lr 0.00014044 grad_norm 0.395580 rank 0
2025-01-11 01:28:49,920 DEBUG TRAIN Batch 131/500 loss 0.032367 acc 0.974977 lr 0.00014041 grad_norm 0.383067 rank 0
2025-01-11 01:28:49,920 DEBUG TRAIN Batch 131/500 loss 0.033389 acc 0.975330 lr 0.00014041 grad_norm 0.383067 rank 1
2025-01-11 01:28:49,921 DEBUG TRAIN Batch 131/500 loss 0.027953 acc 0.978763 lr 0.00014041 grad_norm 0.383067 rank 2
2025-01-11 01:29:13,762 DEBUG TRAIN Batch 131/600 loss 0.042435 acc 0.971028 lr 0.00014038 grad_norm 0.381412 rank 1
2025-01-11 01:29:13,763 DEBUG TRAIN Batch 131/600 loss 0.036632 acc 0.975287 lr 0.00014038 grad_norm 0.381412 rank 2
2025-01-11 01:29:13,763 DEBUG TRAIN Batch 131/600 loss 0.047019 acc 0.966730 lr 0.00014038 grad_norm 0.381412 rank 0
2025-01-11 01:29:38,232 DEBUG TRAIN Batch 131/700 loss 0.025900 acc 0.983856 lr 0.00014036 grad_norm 0.383937 rank 1
2025-01-11 01:29:38,233 DEBUG TRAIN Batch 131/700 loss 0.035992 acc 0.974063 lr 0.00014036 grad_norm 0.383937 rank 0
2025-01-11 01:29:38,234 DEBUG TRAIN Batch 131/700 loss 0.052769 acc 0.965682 lr 0.00014036 grad_norm 0.383937 rank 2
2025-01-11 01:30:02,666 DEBUG TRAIN Batch 131/800 loss 0.033706 acc 0.977528 lr 0.00014033 grad_norm 0.407057 rank 1
2025-01-11 01:30:02,666 DEBUG TRAIN Batch 131/800 loss 0.038544 acc 0.972053 lr 0.00014033 grad_norm 0.407057 rank 0
2025-01-11 01:30:02,667 DEBUG TRAIN Batch 131/800 loss 0.038059 acc 0.976119 lr 0.00014033 grad_norm 0.407057 rank 2
2025-01-11 01:30:26,746 DEBUG TRAIN Batch 131/900 loss 0.038775 acc 0.975610 lr 0.00014030 grad_norm 0.407214 rank 1
2025-01-11 01:30:26,747 DEBUG TRAIN Batch 131/900 loss 0.061376 acc 0.960685 lr 0.00014030 grad_norm 0.407214 rank 2
2025-01-11 01:30:26,747 DEBUG TRAIN Batch 131/900 loss 0.044171 acc 0.968691 lr 0.00014030 grad_norm 0.407214 rank 0
2025-01-11 01:30:51,288 DEBUG TRAIN Batch 131/1000 loss 0.043259 acc 0.963360 lr 0.00014027 grad_norm 0.406367 rank 2
2025-01-11 01:30:51,288 DEBUG TRAIN Batch 131/1000 loss 0.028372 acc 0.980769 lr 0.00014027 grad_norm 0.406367 rank 1
2025-01-11 01:30:51,288 DEBUG TRAIN Batch 131/1000 loss 0.048326 acc 0.965821 lr 0.00014027 grad_norm 0.406367 rank 0
2025-01-11 01:31:15,085 DEBUG TRAIN Batch 131/1100 loss 0.030588 acc 0.975162 lr 0.00014025 grad_norm 0.411990 rank 2
2025-01-11 01:31:15,085 DEBUG TRAIN Batch 131/1100 loss 0.042624 acc 0.968610 lr 0.00014025 grad_norm 0.411990 rank 0
2025-01-11 01:31:15,085 DEBUG TRAIN Batch 131/1100 loss 0.053622 acc 0.960311 lr 0.00014025 grad_norm 0.411990 rank 1
2025-01-11 01:31:39,135 DEBUG TRAIN Batch 131/1200 loss 0.032296 acc 0.974849 lr 0.00014022 grad_norm 0.431328 rank 1
2025-01-11 01:31:39,135 DEBUG TRAIN Batch 131/1200 loss 0.038841 acc 0.971154 lr 0.00014022 grad_norm 0.431328 rank 2
2025-01-11 01:31:39,136 DEBUG TRAIN Batch 131/1200 loss 0.043297 acc 0.970766 lr 0.00014022 grad_norm 0.431328 rank 0
2025-01-11 01:32:04,114 DEBUG TRAIN Batch 131/1300 loss 0.052296 acc 0.964539 lr 0.00014019 grad_norm 0.417274 rank 2
2025-01-11 01:32:04,114 DEBUG TRAIN Batch 131/1300 loss 0.044523 acc 0.970883 lr 0.00014019 grad_norm 0.417274 rank 1
2025-01-11 01:32:04,114 DEBUG TRAIN Batch 131/1300 loss 0.041960 acc 0.970334 lr 0.00014019 grad_norm 0.417274 rank 0
2025-01-11 01:32:28,308 DEBUG TRAIN Batch 131/1400 loss 0.038945 acc 0.973510 lr 0.00014016 grad_norm 0.402106 rank 1
2025-01-11 01:32:28,308 DEBUG TRAIN Batch 131/1400 loss 0.039989 acc 0.969388 lr 0.00014016 grad_norm 0.402106 rank 0
2025-01-11 01:32:28,310 DEBUG TRAIN Batch 131/1400 loss 0.032067 acc 0.975945 lr 0.00014016 grad_norm 0.402106 rank 2
2025-01-11 01:32:53,880 DEBUG TRAIN Batch 131/1500 loss 0.037915 acc 0.970874 lr 0.00014014 grad_norm 0.414582 rank 2
2025-01-11 01:32:53,881 DEBUG TRAIN Batch 131/1500 loss 0.033341 acc 0.980000 lr 0.00014014 grad_norm 0.414582 rank 1
2025-01-11 01:32:53,881 DEBUG TRAIN Batch 131/1500 loss 0.057550 acc 0.961676 lr 0.00014014 grad_norm 0.414582 rank 0
2025-01-11 01:33:17,842 DEBUG TRAIN Batch 131/1600 loss 0.033584 acc 0.978261 lr 0.00014011 grad_norm 0.385835 rank 2
2025-01-11 01:33:17,842 DEBUG TRAIN Batch 131/1600 loss 0.047517 acc 0.963776 lr 0.00014011 grad_norm 0.385835 rank 1
2025-01-11 01:33:17,843 DEBUG TRAIN Batch 131/1600 loss 0.040324 acc 0.974695 lr 0.00014011 grad_norm 0.385835 rank 0
2025-01-11 01:33:42,082 DEBUG TRAIN Batch 131/1700 loss 0.033462 acc 0.972616 lr 0.00014008 grad_norm 0.405504 rank 2
2025-01-11 01:33:42,082 DEBUG TRAIN Batch 131/1700 loss 0.045812 acc 0.972894 lr 0.00014008 grad_norm 0.405504 rank 1
2025-01-11 01:33:42,082 DEBUG TRAIN Batch 131/1700 loss 0.050062 acc 0.971400 lr 0.00014008 grad_norm 0.405504 rank 0
2025-01-11 01:34:07,699 DEBUG TRAIN Batch 131/1800 loss 0.031300 acc 0.983186 lr 0.00014005 grad_norm 0.428236 rank 1
2025-01-11 01:34:07,699 DEBUG TRAIN Batch 131/1800 loss 0.029913 acc 0.977880 lr 0.00014005 grad_norm 0.428236 rank 2
2025-01-11 01:34:07,700 DEBUG TRAIN Batch 131/1800 loss 0.042684 acc 0.968597 lr 0.00014005 grad_norm 0.428236 rank 0
2025-01-11 01:34:31,324 DEBUG TRAIN Batch 131/1900 loss 0.041066 acc 0.973661 lr 0.00014003 grad_norm 0.402022 rank 1
2025-01-11 01:34:31,325 DEBUG TRAIN Batch 131/1900 loss 0.035309 acc 0.977644 lr 0.00014003 grad_norm 0.402022 rank 2
2025-01-11 01:34:31,325 DEBUG TRAIN Batch 131/1900 loss 0.054066 acc 0.968269 lr 0.00014003 grad_norm 0.402022 rank 0
2025-01-11 01:34:54,807 DEBUG TRAIN Batch 131/2000 loss 0.041648 acc 0.974003 lr 0.00014000 grad_norm 0.402752 rank 1
2025-01-11 01:34:54,807 DEBUG TRAIN Batch 131/2000 loss 0.027560 acc 0.983333 lr 0.00014000 grad_norm 0.402752 rank 2
2025-01-11 01:34:54,808 DEBUG TRAIN Batch 131/2000 loss 0.039541 acc 0.972775 lr 0.00014000 grad_norm 0.402752 rank 0
2025-01-11 01:35:18,480 DEBUG TRAIN Batch 131/2100 loss 0.035787 acc 0.973953 lr 0.00013997 grad_norm 0.415880 rank 2
2025-01-11 01:35:18,480 DEBUG TRAIN Batch 131/2100 loss 0.051573 acc 0.966071 lr 0.00013997 grad_norm 0.415880 rank 1
2025-01-11 01:35:18,480 DEBUG TRAIN Batch 131/2100 loss 0.031543 acc 0.977798 lr 0.00013997 grad_norm 0.415880 rank 0
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 01:36:25,161 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 01:36:25,165 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 01:36:25,557 INFO Epoch 131 Step 127619 on_batch_end True CV rank 1
2025-01-11 01:36:25,557 INFO Epoch 131 Step 127619 on_batch_end True CV rank 2
2025-01-11 01:36:25,557 INFO Epoch 131 Step 127619 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 01:36:35,006 DEBUG CV Batch 131/100 loss 0.008540 acc 0.995541  rank 0
2025-01-11 01:36:35,064 DEBUG CV Batch 131/100 loss 0.008540 acc 0.995541  rank 2
2025-01-11 01:36:35,258 DEBUG CV Batch 131/100 loss 0.008540 acc 0.995541  rank 1
2025-01-11 01:36:35,502 INFO Epoch 131 Step 127619 CV info lr 0.00013996270770581397 0 rank loss_2.5614444173524245 acc_0.779514198109769
2025-01-11 01:36:35,612 INFO Epoch 131 Step 127619 CV info lr 0.00013996270770581397 2 rank loss_2.5614444173524245 acc_0.779514198109769
2025-01-11 01:36:35,776 INFO Epoch 131 Step 127619 CV info lr 0.00013996270770581397 1 rank loss_2.5614444173524245 acc_0.779514198109769
2025-01-11 01:36:36,834 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_131_whole.pt
2025-01-11 01:36:36,855 INFO Added key: store_based_barrier_key:134 to store for rank: 0
2025-01-11 01:36:36,866 INFO Added key: store_based_barrier_key:134 to store for rank: 2
2025-01-11 01:36:36,866 INFO Added key: store_based_barrier_key:134 to store for rank: 1
2025-01-11 01:36:36,866 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:134 with 3 nodes.
2025-01-11 01:36:36,867 INFO Epoch 132 TRAIN info lr 0.00013996270770581397 rank 1
2025-01-11 01:36:36,867 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 01:36:36,876 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:134 with 3 nodes.
2025-01-11 01:36:36,876 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:134 with 3 nodes.
2025-01-11 01:36:36,877 INFO Epoch 132 TRAIN info lr 0.00013996270770581397 rank 0
2025-01-11 01:36:36,877 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 01:36:36,886 INFO Epoch 132 TRAIN info lr 0.00013996270770581397 rank 2
2025-01-11 01:36:36,886 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 01:37:12,502 DEBUG TRAIN Batch 132/100 loss 0.049910 acc 0.971311 lr 0.00013994 grad_norm 0.384748 rank 1
2025-01-11 01:37:12,502 DEBUG TRAIN Batch 132/100 loss 0.044150 acc 0.968966 lr 0.00013994 grad_norm 0.384748 rank 2
2025-01-11 01:37:12,502 DEBUG TRAIN Batch 132/100 loss 0.041914 acc 0.976449 lr 0.00013994 grad_norm 0.384748 rank 0
2025-01-11 01:37:36,644 DEBUG TRAIN Batch 132/200 loss 0.043833 acc 0.970557 lr 0.00013991 grad_norm 0.403102 rank 0
2025-01-11 01:37:36,644 DEBUG TRAIN Batch 132/200 loss 0.045790 acc 0.969828 lr 0.00013991 grad_norm 0.403102 rank 1
2025-01-11 01:37:36,644 DEBUG TRAIN Batch 132/200 loss 0.033397 acc 0.981595 lr 0.00013991 grad_norm 0.403102 rank 2
2025-01-11 01:38:01,957 DEBUG TRAIN Batch 132/300 loss 0.035624 acc 0.975466 lr 0.00013988 grad_norm 0.388259 rank 1
2025-01-11 01:38:01,958 DEBUG TRAIN Batch 132/300 loss 0.047710 acc 0.966486 lr 0.00013988 grad_norm 0.388259 rank 0
2025-01-11 01:38:01,958 DEBUG TRAIN Batch 132/300 loss 0.044030 acc 0.967742 lr 0.00013988 grad_norm 0.388259 rank 2
2025-01-11 01:38:26,307 DEBUG TRAIN Batch 132/400 loss 0.037029 acc 0.979894 lr 0.00013985 grad_norm 0.436601 rank 1
2025-01-11 01:38:26,307 DEBUG TRAIN Batch 132/400 loss 0.033446 acc 0.970982 lr 0.00013985 grad_norm 0.436601 rank 0
2025-01-11 01:38:26,307 DEBUG TRAIN Batch 132/400 loss 0.051150 acc 0.957764 lr 0.00013985 grad_norm 0.436601 rank 2
2025-01-11 01:38:50,336 DEBUG TRAIN Batch 132/500 loss 0.036817 acc 0.973974 lr 0.00013983 grad_norm 0.398709 rank 0
2025-01-11 01:38:50,338 DEBUG TRAIN Batch 132/500 loss 0.035012 acc 0.976145 lr 0.00013983 grad_norm 0.398709 rank 1
2025-01-11 01:38:50,338 DEBUG TRAIN Batch 132/500 loss 0.041599 acc 0.971857 lr 0.00013983 grad_norm 0.398709 rank 2
2025-01-11 01:39:14,609 DEBUG TRAIN Batch 132/600 loss 0.044207 acc 0.968720 lr 0.00013980 grad_norm 0.399956 rank 1
2025-01-11 01:39:14,610 DEBUG TRAIN Batch 132/600 loss 0.042208 acc 0.971028 lr 0.00013980 grad_norm 0.399956 rank 0
2025-01-11 01:39:14,610 DEBUG TRAIN Batch 132/600 loss 0.038174 acc 0.976534 lr 0.00013980 grad_norm 0.399956 rank 2
2025-01-11 01:39:39,007 DEBUG TRAIN Batch 132/700 loss 0.029021 acc 0.980431 lr 0.00013977 grad_norm 0.363774 rank 2
2025-01-11 01:39:39,007 DEBUG TRAIN Batch 132/700 loss 0.035481 acc 0.976834 lr 0.00013977 grad_norm 0.363774 rank 1
2025-01-11 01:39:39,007 DEBUG TRAIN Batch 132/700 loss 0.020851 acc 0.985393 lr 0.00013977 grad_norm 0.363774 rank 0
2025-01-11 01:40:02,983 DEBUG TRAIN Batch 132/800 loss 0.045837 acc 0.967280 lr 0.00013974 grad_norm 0.410642 rank 0
2025-01-11 01:40:02,983 DEBUG TRAIN Batch 132/800 loss 0.040346 acc 0.972281 lr 0.00013974 grad_norm 0.410642 rank 1
2025-01-11 01:40:02,984 DEBUG TRAIN Batch 132/800 loss 0.040679 acc 0.969349 lr 0.00013974 grad_norm 0.410642 rank 2
2025-01-11 01:40:27,128 DEBUG TRAIN Batch 132/900 loss 0.047210 acc 0.967949 lr 0.00013972 grad_norm 0.387271 rank 0
2025-01-11 01:40:27,128 DEBUG TRAIN Batch 132/900 loss 0.024966 acc 0.985075 lr 0.00013972 grad_norm 0.387271 rank 1
2025-01-11 01:40:27,128 DEBUG TRAIN Batch 132/900 loss 0.032537 acc 0.976471 lr 0.00013972 grad_norm 0.387271 rank 2
2025-01-11 01:40:50,725 DEBUG TRAIN Batch 132/1000 loss 0.034733 acc 0.976087 lr 0.00013969 grad_norm 0.406632 rank 0
2025-01-11 01:40:50,726 DEBUG TRAIN Batch 132/1000 loss 0.037466 acc 0.975510 lr 0.00013969 grad_norm 0.406632 rank 1
2025-01-11 01:40:50,726 DEBUG TRAIN Batch 132/1000 loss 0.035886 acc 0.972193 lr 0.00013969 grad_norm 0.406632 rank 2
2025-01-11 01:41:14,605 DEBUG TRAIN Batch 132/1100 loss 0.039126 acc 0.968421 lr 0.00013966 grad_norm 0.428447 rank 2
2025-01-11 01:41:14,605 DEBUG TRAIN Batch 132/1100 loss 0.037444 acc 0.975581 lr 0.00013966 grad_norm 0.428447 rank 0
2025-01-11 01:41:14,605 DEBUG TRAIN Batch 132/1100 loss 0.034566 acc 0.972900 lr 0.00013966 grad_norm 0.428447 rank 1
2025-01-11 01:41:38,777 DEBUG TRAIN Batch 132/1200 loss 0.042040 acc 0.971349 lr 0.00013963 grad_norm 0.389821 rank 2
2025-01-11 01:41:38,777 DEBUG TRAIN Batch 132/1200 loss 0.012644 acc 0.990625 lr 0.00013963 grad_norm 0.389821 rank 0
2025-01-11 01:41:38,777 DEBUG TRAIN Batch 132/1200 loss 0.023708 acc 0.984581 lr 0.00013963 grad_norm 0.389821 rank 1
2025-01-11 01:42:03,503 DEBUG TRAIN Batch 132/1300 loss 0.044373 acc 0.969991 lr 0.00013961 grad_norm 0.422552 rank 0
2025-01-11 01:42:03,505 DEBUG TRAIN Batch 132/1300 loss 0.046941 acc 0.967123 lr 0.00013961 grad_norm 0.422552 rank 2
2025-01-11 01:42:03,505 DEBUG TRAIN Batch 132/1300 loss 0.046210 acc 0.963523 lr 0.00013961 grad_norm 0.422552 rank 1
2025-01-11 01:42:27,371 DEBUG TRAIN Batch 132/1400 loss 0.039805 acc 0.973529 lr 0.00013958 grad_norm 0.404377 rank 1
2025-01-11 01:42:27,371 DEBUG TRAIN Batch 132/1400 loss 0.030024 acc 0.977799 lr 0.00013958 grad_norm 0.404377 rank 2
2025-01-11 01:42:27,371 DEBUG TRAIN Batch 132/1400 loss 0.042489 acc 0.969286 lr 0.00013958 grad_norm 0.404377 rank 0
2025-01-11 01:42:51,608 DEBUG TRAIN Batch 132/1500 loss 0.032695 acc 0.977505 lr 0.00013955 grad_norm 0.416956 rank 1
2025-01-11 01:42:51,608 DEBUG TRAIN Batch 132/1500 loss 0.039945 acc 0.973631 lr 0.00013955 grad_norm 0.416956 rank 2
2025-01-11 01:42:51,608 DEBUG TRAIN Batch 132/1500 loss 0.045218 acc 0.970642 lr 0.00013955 grad_norm 0.416956 rank 0
2025-01-11 01:43:16,550 DEBUG TRAIN Batch 132/1600 loss 0.048941 acc 0.978056 lr 0.00013953 grad_norm 0.435416 rank 1
2025-01-11 01:43:16,551 DEBUG TRAIN Batch 132/1600 loss 0.035284 acc 0.973384 lr 0.00013953 grad_norm 0.435416 rank 2
2025-01-11 01:43:16,551 DEBUG TRAIN Batch 132/1600 loss 0.028679 acc 0.974290 lr 0.00013953 grad_norm 0.435416 rank 0
2025-01-11 01:43:41,650 DEBUG TRAIN Batch 132/1700 loss 0.037402 acc 0.969457 lr 0.00013950 grad_norm 0.409620 rank 1
2025-01-11 01:43:41,651 DEBUG TRAIN Batch 132/1700 loss 0.038541 acc 0.975410 lr 0.00013950 grad_norm 0.409620 rank 0
2025-01-11 01:43:41,651 DEBUG TRAIN Batch 132/1700 loss 0.040434 acc 0.968932 lr 0.00013950 grad_norm 0.409620 rank 2
2025-01-11 01:44:06,612 DEBUG TRAIN Batch 132/1800 loss 0.035081 acc 0.978769 lr 0.00013947 grad_norm 0.391854 rank 1
2025-01-11 01:44:06,612 DEBUG TRAIN Batch 132/1800 loss 0.036299 acc 0.976393 lr 0.00013947 grad_norm 0.391854 rank 2
2025-01-11 01:44:06,612 DEBUG TRAIN Batch 132/1800 loss 0.047428 acc 0.964995 lr 0.00013947 grad_norm 0.391854 rank 0
2025-01-11 01:44:31,287 DEBUG TRAIN Batch 132/1900 loss 0.022926 acc 0.983384 lr 0.00013944 grad_norm 0.394347 rank 1
2025-01-11 01:44:31,287 DEBUG TRAIN Batch 132/1900 loss 0.036825 acc 0.974129 lr 0.00013944 grad_norm 0.394347 rank 2
2025-01-11 01:44:31,288 DEBUG TRAIN Batch 132/1900 loss 0.048859 acc 0.969099 lr 0.00013944 grad_norm 0.394347 rank 0
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 01:45:54,301 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 01:45:54,301 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 01:45:54,747 INFO Epoch 132 Step 128614 on_batch_end True CV rank 0
2025-01-11 01:45:54,747 INFO Epoch 132 Step 128614 on_batch_end True CV rank 2
2025-01-11 01:45:54,747 INFO Epoch 132 Step 128614 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 01:46:04,184 DEBUG CV Batch 132/100 loss 0.004598 acc 0.997770  rank 0
2025-01-11 01:46:04,212 DEBUG CV Batch 132/100 loss 0.004598 acc 0.997770  rank 2
2025-01-11 01:46:04,599 DEBUG CV Batch 132/100 loss 0.004598 acc 0.997770  rank 1
2025-01-11 01:46:04,699 INFO Epoch 132 Step 128614 CV info lr 0.00013942025786777598 0 rank loss_2.5572161435559617 acc_0.7806630568546161
2025-01-11 01:46:04,766 INFO Epoch 132 Step 128614 CV info lr 0.00013942025786777598 2 rank loss_2.5572161435559617 acc_0.7806630568546161
2025-01-11 01:46:05,140 INFO Epoch 132 Step 128614 CV info lr 0.00013942025786777598 1 rank loss_2.5572161435559617 acc_0.7806630568546161
2025-01-11 01:46:06,045 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_132_whole.pt
2025-01-11 01:46:06,057 INFO Added key: store_based_barrier_key:135 to store for rank: 0
2025-01-11 01:46:06,067 INFO Added key: store_based_barrier_key:135 to store for rank: 1
2025-01-11 01:46:06,067 INFO Added key: store_based_barrier_key:135 to store for rank: 2
2025-01-11 01:46:06,067 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:135 with 3 nodes.
2025-01-11 01:46:06,067 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:135 with 3 nodes.
2025-01-11 01:46:06,069 INFO Epoch 133 TRAIN info lr 0.00013942025786777598 rank 1
2025-01-11 01:46:06,069 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 01:46:06,073 INFO Epoch 133 TRAIN info lr 0.00013942025786777598 rank 2
2025-01-11 01:46:06,073 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 01:46:06,077 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:135 with 3 nodes.
2025-01-11 01:46:06,080 INFO Epoch 133 TRAIN info lr 0.00013942025786777598 rank 0
2025-01-11 01:46:06,080 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 01:46:36,674 DEBUG TRAIN Batch 133/100 loss 0.032812 acc 0.978899 lr 0.00013939 grad_norm 0.413686 rank 0
2025-01-11 01:46:36,675 DEBUG TRAIN Batch 133/100 loss 0.047431 acc 0.966935 lr 0.00013939 grad_norm 0.413686 rank 1
2025-01-11 01:46:36,676 DEBUG TRAIN Batch 133/100 loss 0.046572 acc 0.972013 lr 0.00013939 grad_norm 0.413686 rank 2
2025-01-11 01:47:00,532 DEBUG TRAIN Batch 133/200 loss 0.044636 acc 0.965451 lr 0.00013937 grad_norm 0.405049 rank 0
2025-01-11 01:47:00,532 DEBUG TRAIN Batch 133/200 loss 0.031460 acc 0.979981 lr 0.00013937 grad_norm 0.405049 rank 1
2025-01-11 01:47:00,533 DEBUG TRAIN Batch 133/200 loss 0.023252 acc 0.986301 lr 0.00013937 grad_norm 0.405049 rank 2
2025-01-11 01:47:24,028 DEBUG TRAIN Batch 133/300 loss 0.029724 acc 0.975045 lr 0.00013934 grad_norm 0.392128 rank 1
2025-01-11 01:47:24,029 DEBUG TRAIN Batch 133/300 loss 0.044481 acc 0.965291 lr 0.00013934 grad_norm 0.392128 rank 2
2025-01-11 01:47:24,029 DEBUG TRAIN Batch 133/300 loss 0.029098 acc 0.986185 lr 0.00013934 grad_norm 0.392128 rank 0
2025-01-11 01:47:47,702 DEBUG TRAIN Batch 133/400 loss 0.031856 acc 0.973333 lr 0.00013931 grad_norm 0.389541 rank 1
2025-01-11 01:47:47,702 DEBUG TRAIN Batch 133/400 loss 0.043488 acc 0.973046 lr 0.00013931 grad_norm 0.389541 rank 0
2025-01-11 01:47:47,702 DEBUG TRAIN Batch 133/400 loss 0.043518 acc 0.976167 lr 0.00013931 grad_norm 0.389541 rank 2
2025-01-11 01:48:11,520 DEBUG TRAIN Batch 133/500 loss 0.041102 acc 0.968623 lr 0.00013928 grad_norm 0.410677 rank 0
2025-01-11 01:48:11,520 DEBUG TRAIN Batch 133/500 loss 0.025650 acc 0.979766 lr 0.00013928 grad_norm 0.410677 rank 1
2025-01-11 01:48:11,520 DEBUG TRAIN Batch 133/500 loss 0.053404 acc 0.961271 lr 0.00013928 grad_norm 0.410677 rank 2
2025-01-11 01:48:34,650 DEBUG TRAIN Batch 133/600 loss 0.047120 acc 0.971698 lr 0.00013926 grad_norm 0.404750 rank 0
2025-01-11 01:48:34,650 DEBUG TRAIN Batch 133/600 loss 0.037944 acc 0.978261 lr 0.00013926 grad_norm 0.404750 rank 1
2025-01-11 01:48:34,650 DEBUG TRAIN Batch 133/600 loss 0.028601 acc 0.980132 lr 0.00013926 grad_norm 0.404750 rank 2
2025-01-11 01:48:58,568 DEBUG TRAIN Batch 133/700 loss 0.050792 acc 0.967828 lr 0.00013923 grad_norm 0.358525 rank 2
2025-01-11 01:48:58,568 DEBUG TRAIN Batch 133/700 loss 0.018494 acc 0.986041 lr 0.00013923 grad_norm 0.358525 rank 1
2025-01-11 01:48:58,569 DEBUG TRAIN Batch 133/700 loss 0.038951 acc 0.968224 lr 0.00013923 grad_norm 0.358525 rank 0
2025-01-11 01:49:21,764 DEBUG TRAIN Batch 133/800 loss 0.039391 acc 0.977033 lr 0.00013920 grad_norm 0.374120 rank 2
2025-01-11 01:49:21,764 DEBUG TRAIN Batch 133/800 loss 0.031273 acc 0.980847 lr 0.00013920 grad_norm 0.374120 rank 0
2025-01-11 01:49:21,764 DEBUG TRAIN Batch 133/800 loss 0.045403 acc 0.971767 lr 0.00013920 grad_norm 0.374120 rank 1
2025-01-11 01:49:45,639 DEBUG TRAIN Batch 133/900 loss 0.033193 acc 0.978373 lr 0.00013918 grad_norm 0.386155 rank 2
2025-01-11 01:49:45,640 DEBUG TRAIN Batch 133/900 loss 0.039748 acc 0.971154 lr 0.00013918 grad_norm 0.386155 rank 0
2025-01-11 01:49:45,640 DEBUG TRAIN Batch 133/900 loss 0.026451 acc 0.983607 lr 0.00013918 grad_norm 0.386155 rank 1
2025-01-11 01:50:10,388 DEBUG TRAIN Batch 133/1000 loss 0.032496 acc 0.973320 lr 0.00013915 grad_norm 0.397061 rank 1
2025-01-11 01:50:10,388 DEBUG TRAIN Batch 133/1000 loss 0.036940 acc 0.973533 lr 0.00013915 grad_norm 0.397061 rank 2
2025-01-11 01:50:10,388 DEBUG TRAIN Batch 133/1000 loss 0.037006 acc 0.976765 lr 0.00013915 grad_norm 0.397061 rank 0
2025-01-11 01:50:33,887 DEBUG TRAIN Batch 133/1100 loss 0.029778 acc 0.982541 lr 0.00013912 grad_norm 0.383241 rank 1
2025-01-11 01:50:33,888 DEBUG TRAIN Batch 133/1100 loss 0.043520 acc 0.969754 lr 0.00013912 grad_norm 0.383241 rank 0
2025-01-11 01:50:33,888 DEBUG TRAIN Batch 133/1100 loss 0.029267 acc 0.973346 lr 0.00013912 grad_norm 0.383241 rank 2
2025-01-11 01:50:57,363 DEBUG TRAIN Batch 133/1200 loss 0.030059 acc 0.978148 lr 0.00013910 grad_norm 0.403070 rank 1
2025-01-11 01:50:57,363 DEBUG TRAIN Batch 133/1200 loss 0.037750 acc 0.970894 lr 0.00013910 grad_norm 0.403070 rank 0
2025-01-11 01:50:57,363 DEBUG TRAIN Batch 133/1200 loss 0.043720 acc 0.972247 lr 0.00013910 grad_norm 0.403070 rank 2
2025-01-11 01:51:21,910 DEBUG TRAIN Batch 133/1300 loss 0.036019 acc 0.978162 lr 0.00013907 grad_norm 0.389863 rank 1
2025-01-11 01:51:21,910 DEBUG TRAIN Batch 133/1300 loss 0.027408 acc 0.976791 lr 0.00013907 grad_norm 0.389863 rank 2
2025-01-11 01:51:21,910 DEBUG TRAIN Batch 133/1300 loss 0.034645 acc 0.977805 lr 0.00013907 grad_norm 0.389863 rank 0
2025-01-11 01:51:46,541 DEBUG TRAIN Batch 133/1400 loss 0.044869 acc 0.969585 lr 0.00013904 grad_norm 0.414248 rank 0
2025-01-11 01:51:46,541 DEBUG TRAIN Batch 133/1400 loss 0.039947 acc 0.972252 lr 0.00013904 grad_norm 0.414248 rank 2
2025-01-11 01:51:46,542 DEBUG TRAIN Batch 133/1400 loss 0.041950 acc 0.972370 lr 0.00013904 grad_norm 0.414248 rank 1
2025-01-11 01:52:11,105 DEBUG TRAIN Batch 133/1500 loss 0.055547 acc 0.963093 lr 0.00013902 grad_norm 0.452161 rank 1
2025-01-11 01:52:11,106 DEBUG TRAIN Batch 133/1500 loss 0.034511 acc 0.972222 lr 0.00013902 grad_norm 0.452161 rank 0
2025-01-11 01:52:11,106 DEBUG TRAIN Batch 133/1500 loss 0.026222 acc 0.978151 lr 0.00013902 grad_norm 0.452161 rank 2
2025-01-11 01:52:35,511 DEBUG TRAIN Batch 133/1600 loss 0.044746 acc 0.969325 lr 0.00013899 grad_norm 0.426658 rank 0
2025-01-11 01:52:35,511 DEBUG TRAIN Batch 133/1600 loss 0.039239 acc 0.970560 lr 0.00013899 grad_norm 0.426658 rank 1
2025-01-11 01:52:35,512 DEBUG TRAIN Batch 133/1600 loss 0.036279 acc 0.976190 lr 0.00013899 grad_norm 0.426658 rank 2
2025-01-11 01:53:00,158 DEBUG TRAIN Batch 133/1700 loss 0.054156 acc 0.964220 lr 0.00013896 grad_norm 0.414830 rank 0
2025-01-11 01:53:00,158 DEBUG TRAIN Batch 133/1700 loss 0.036298 acc 0.978320 lr 0.00013896 grad_norm 0.414830 rank 1
2025-01-11 01:53:00,159 DEBUG TRAIN Batch 133/1700 loss 0.028986 acc 0.978008 lr 0.00013896 grad_norm 0.414830 rank 2
2025-01-11 01:53:25,604 DEBUG TRAIN Batch 133/1800 loss 0.039323 acc 0.974212 lr 0.00013893 grad_norm 0.417088 rank 1
2025-01-11 01:53:25,604 DEBUG TRAIN Batch 133/1800 loss 0.039708 acc 0.971888 lr 0.00013893 grad_norm 0.417088 rank 0
2025-01-11 01:53:25,605 DEBUG TRAIN Batch 133/1800 loss 0.040268 acc 0.973297 lr 0.00013893 grad_norm 0.417088 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 01:54:25,629 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 01:54:25,630 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 01:54:26,055 INFO Epoch 133 Step 129514 on_batch_end True CV rank 2
2025-01-11 01:54:26,055 INFO Epoch 133 Step 129514 on_batch_end True CV rank 0
2025-01-11 01:54:26,055 INFO Epoch 133 Step 129514 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 01:54:34,884 DEBUG CV Batch 133/100 loss 0.006983 acc 0.996656  rank 0
2025-01-11 01:54:35,393 INFO Epoch 133 Step 129514 CV info lr 0.00013893499379747935 0 rank loss_2.5580851642661036 acc_0.7792915420835478
2025-01-11 01:54:35,416 DEBUG CV Batch 133/100 loss 0.006983 acc 0.996656  rank 2
2025-01-11 01:54:35,895 DEBUG CV Batch 133/100 loss 0.006983 acc 0.996656  rank 1
2025-01-11 01:54:35,947 INFO Epoch 133 Step 129514 CV info lr 0.00013893499379747935 2 rank loss_2.5580851642661036 acc_0.7792915420835478
2025-01-11 01:54:36,435 INFO Epoch 133 Step 129514 CV info lr 0.00013893499379747935 1 rank loss_2.5580851642661036 acc_0.7792915420835478
2025-01-11 01:54:36,676 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_133_whole.pt
2025-01-11 01:54:36,698 INFO Added key: store_based_barrier_key:136 to store for rank: 0
2025-01-11 01:54:36,699 INFO Added key: store_based_barrier_key:136 to store for rank: 2
2025-01-11 01:54:36,699 INFO Added key: store_based_barrier_key:136 to store for rank: 1
2025-01-11 01:54:36,699 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:136 with 3 nodes.
2025-01-11 01:54:36,699 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:136 with 3 nodes.
2025-01-11 01:54:36,701 INFO Epoch 134 TRAIN info lr 0.00013893499379747935 rank 2
2025-01-11 01:54:36,701 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 01:54:36,703 INFO Epoch 134 TRAIN info lr 0.00013893499379747935 rank 1
2025-01-11 01:54:36,703 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 01:54:36,709 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:136 with 3 nodes.
2025-01-11 01:54:36,710 INFO Epoch 134 TRAIN info lr 0.00013893499379747935 rank 0
2025-01-11 01:54:36,711 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 01:55:10,263 DEBUG TRAIN Batch 134/100 loss 0.039679 acc 0.973027 lr 0.00013891 grad_norm 0.420323 rank 0
2025-01-11 01:55:10,263 DEBUG TRAIN Batch 134/100 loss 0.061084 acc 0.964361 lr 0.00013891 grad_norm 0.420323 rank 1
2025-01-11 01:55:10,264 DEBUG TRAIN Batch 134/100 loss 0.032164 acc 0.979571 lr 0.00013891 grad_norm 0.420323 rank 2
2025-01-11 01:55:34,242 DEBUG TRAIN Batch 134/200 loss 0.047876 acc 0.970280 lr 0.00013888 grad_norm 0.401258 rank 1
2025-01-11 01:55:34,243 DEBUG TRAIN Batch 134/200 loss 0.036526 acc 0.977327 lr 0.00013888 grad_norm 0.401258 rank 0
2025-01-11 01:55:34,243 DEBUG TRAIN Batch 134/200 loss 0.042382 acc 0.969271 lr 0.00013888 grad_norm 0.401258 rank 2
2025-01-11 01:55:58,396 DEBUG TRAIN Batch 134/300 loss 0.041611 acc 0.969112 lr 0.00013885 grad_norm 0.399530 rank 1
2025-01-11 01:55:58,397 DEBUG TRAIN Batch 134/300 loss 0.029507 acc 0.975466 lr 0.00013885 grad_norm 0.399530 rank 0
2025-01-11 01:55:58,398 DEBUG TRAIN Batch 134/300 loss 0.037268 acc 0.977099 lr 0.00013885 grad_norm 0.399530 rank 2
2025-01-11 01:56:22,732 DEBUG TRAIN Batch 134/400 loss 0.038830 acc 0.980044 lr 0.00013883 grad_norm 0.403268 rank 2
2025-01-11 01:56:22,732 DEBUG TRAIN Batch 134/400 loss 0.025792 acc 0.981771 lr 0.00013883 grad_norm 0.403268 rank 0
2025-01-11 01:56:22,733 DEBUG TRAIN Batch 134/400 loss 0.036663 acc 0.974948 lr 0.00013883 grad_norm 0.403268 rank 1
2025-01-11 01:56:47,069 DEBUG TRAIN Batch 134/500 loss 0.045934 acc 0.969486 lr 0.00013880 grad_norm 0.436013 rank 2
2025-01-11 01:56:47,070 DEBUG TRAIN Batch 134/500 loss 0.033739 acc 0.976289 lr 0.00013880 grad_norm 0.436013 rank 0
2025-01-11 01:56:47,070 DEBUG TRAIN Batch 134/500 loss 0.047225 acc 0.960623 lr 0.00013880 grad_norm 0.436013 rank 1
2025-01-11 01:57:10,929 DEBUG TRAIN Batch 134/600 loss 0.029553 acc 0.976134 lr 0.00013877 grad_norm 0.418651 rank 0
2025-01-11 01:57:10,929 DEBUG TRAIN Batch 134/600 loss 0.037083 acc 0.977352 lr 0.00013877 grad_norm 0.418651 rank 1
2025-01-11 01:57:10,929 DEBUG TRAIN Batch 134/600 loss 0.039507 acc 0.976313 lr 0.00013877 grad_norm 0.418651 rank 2
2025-01-11 01:57:35,459 DEBUG TRAIN Batch 134/700 loss 0.034480 acc 0.981326 lr 0.00013875 grad_norm 0.404290 rank 0
2025-01-11 01:57:35,459 DEBUG TRAIN Batch 134/700 loss 0.031153 acc 0.980447 lr 0.00013875 grad_norm 0.404290 rank 1
2025-01-11 01:57:35,459 DEBUG TRAIN Batch 134/700 loss 0.026713 acc 0.977134 lr 0.00013875 grad_norm 0.404290 rank 2
2025-01-11 01:57:59,368 DEBUG TRAIN Batch 134/800 loss 0.018021 acc 0.989766 lr 0.00013872 grad_norm 0.340385 rank 0
2025-01-11 01:57:59,369 DEBUG TRAIN Batch 134/800 loss 0.018384 acc 0.990467 lr 0.00013872 grad_norm 0.340385 rank 1
2025-01-11 01:57:59,369 DEBUG TRAIN Batch 134/800 loss 0.039127 acc 0.976399 lr 0.00013872 grad_norm 0.340385 rank 2
2025-01-11 01:58:23,447 DEBUG TRAIN Batch 134/900 loss 0.047407 acc 0.969539 lr 0.00013869 grad_norm 0.411668 rank 0
2025-01-11 01:58:23,447 DEBUG TRAIN Batch 134/900 loss 0.033382 acc 0.975562 lr 0.00013869 grad_norm 0.411668 rank 1
2025-01-11 01:58:23,447 DEBUG TRAIN Batch 134/900 loss 0.042622 acc 0.971292 lr 0.00013869 grad_norm 0.411668 rank 2
2025-01-11 01:58:47,625 DEBUG TRAIN Batch 134/1000 loss 0.040163 acc 0.974907 lr 0.00013867 grad_norm 0.409156 rank 0
2025-01-11 01:58:47,625 DEBUG TRAIN Batch 134/1000 loss 0.038993 acc 0.973850 lr 0.00013867 grad_norm 0.409156 rank 1
2025-01-11 01:58:47,626 DEBUG TRAIN Batch 134/1000 loss 0.043419 acc 0.969835 lr 0.00013867 grad_norm 0.409156 rank 2
2025-01-11 01:59:12,049 DEBUG TRAIN Batch 134/1100 loss 0.038963 acc 0.974120 lr 0.00013864 grad_norm 0.405347 rank 1
2025-01-11 01:59:12,049 DEBUG TRAIN Batch 134/1100 loss 0.038987 acc 0.969854 lr 0.00013864 grad_norm 0.405347 rank 0
2025-01-11 01:59:12,049 DEBUG TRAIN Batch 134/1100 loss 0.031026 acc 0.975724 lr 0.00013864 grad_norm 0.405347 rank 2
2025-01-11 01:59:35,742 DEBUG TRAIN Batch 134/1200 loss 0.042794 acc 0.973714 lr 0.00013861 grad_norm 0.395563 rank 0
2025-01-11 01:59:35,742 DEBUG TRAIN Batch 134/1200 loss 0.039059 acc 0.975879 lr 0.00013861 grad_norm 0.395563 rank 2
2025-01-11 01:59:35,742 DEBUG TRAIN Batch 134/1200 loss 0.032239 acc 0.977974 lr 0.00013861 grad_norm 0.395563 rank 1
2025-01-11 01:59:59,375 DEBUG TRAIN Batch 134/1300 loss 0.029495 acc 0.983402 lr 0.00013859 grad_norm 0.410705 rank 1
2025-01-11 01:59:59,375 DEBUG TRAIN Batch 134/1300 loss 0.032008 acc 0.978453 lr 0.00013859 grad_norm 0.410705 rank 2
2025-01-11 01:59:59,375 DEBUG TRAIN Batch 134/1300 loss 0.044542 acc 0.962929 lr 0.00013859 grad_norm 0.410705 rank 0
2025-01-11 02:00:23,368 DEBUG TRAIN Batch 134/1400 loss 0.043377 acc 0.968460 lr 0.00013856 grad_norm 0.393499 rank 0
2025-01-11 02:00:23,369 DEBUG TRAIN Batch 134/1400 loss 0.026756 acc 0.980934 lr 0.00013856 grad_norm 0.393499 rank 1
2025-01-11 02:00:23,369 DEBUG TRAIN Batch 134/1400 loss 0.043000 acc 0.973636 lr 0.00013856 grad_norm 0.393499 rank 2
2025-01-11 02:00:46,974 DEBUG TRAIN Batch 134/1500 loss 0.031801 acc 0.977408 lr 0.00013853 grad_norm 0.389075 rank 0
2025-01-11 02:00:46,974 DEBUG TRAIN Batch 134/1500 loss 0.032384 acc 0.979339 lr 0.00013853 grad_norm 0.389075 rank 1
2025-01-11 02:00:46,975 DEBUG TRAIN Batch 134/1500 loss 0.038055 acc 0.971698 lr 0.00013853 grad_norm 0.389075 rank 2
2025-01-11 02:01:11,060 DEBUG TRAIN Batch 134/1600 loss 0.028004 acc 0.980322 lr 0.00013851 grad_norm 0.395035 rank 0
2025-01-11 02:01:11,060 DEBUG TRAIN Batch 134/1600 loss 0.019016 acc 0.986982 lr 0.00013851 grad_norm 0.395035 rank 1
2025-01-11 02:01:11,060 DEBUG TRAIN Batch 134/1600 loss 0.032171 acc 0.972678 lr 0.00013851 grad_norm 0.395035 rank 2
2025-01-11 02:01:34,635 DEBUG TRAIN Batch 134/1700 loss 0.042837 acc 0.964651 lr 0.00013848 grad_norm 0.392574 rank 0
2025-01-11 02:01:34,635 DEBUG TRAIN Batch 134/1700 loss 0.039775 acc 0.970213 lr 0.00013848 grad_norm 0.392574 rank 1
2025-01-11 02:01:34,636 DEBUG TRAIN Batch 134/1700 loss 0.027202 acc 0.982011 lr 0.00013848 grad_norm 0.392574 rank 2
2025-01-11 02:01:59,538 DEBUG TRAIN Batch 134/1800 loss 0.042945 acc 0.972538 lr 0.00013845 grad_norm 0.416219 rank 0
2025-01-11 02:01:59,538 DEBUG TRAIN Batch 134/1800 loss 0.038528 acc 0.970310 lr 0.00013845 grad_norm 0.416219 rank 2
2025-01-11 02:01:59,539 DEBUG TRAIN Batch 134/1800 loss 0.051798 acc 0.961931 lr 0.00013845 grad_norm 0.416219 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 02:03:00,032 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 02:03:00,042 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 02:03:00,472 INFO Epoch 134 Step 130415 on_batch_end True CV rank 1
2025-01-11 02:03:00,472 INFO Epoch 134 Step 130415 on_batch_end True CV rank 0
2025-01-11 02:03:00,472 INFO Epoch 134 Step 130415 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 02:03:09,374 DEBUG CV Batch 134/100 loss 0.007727 acc 0.996656  rank 0
2025-01-11 02:03:09,879 INFO Epoch 134 Step 130415 CV info lr 0.00013845423089261147 0 rank loss_2.573959186031093 acc_0.780130406220754
2025-01-11 02:03:09,899 DEBUG CV Batch 134/100 loss 0.007727 acc 0.996656  rank 2
2025-01-11 02:03:10,056 DEBUG CV Batch 134/100 loss 0.007727 acc 0.996656  rank 1
2025-01-11 02:03:10,431 INFO Epoch 134 Step 130415 CV info lr 0.00013845423089261147 2 rank loss_2.573959186031093 acc_0.780130406220754
2025-01-11 02:03:10,590 INFO Epoch 134 Step 130415 CV info lr 0.00013845423089261147 1 rank loss_2.573959186031093 acc_0.780130406220754
2025-01-11 02:03:11,122 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_134_whole.pt
2025-01-11 02:03:11,144 INFO Added key: store_based_barrier_key:137 to store for rank: 0
2025-01-11 02:03:11,144 INFO Added key: store_based_barrier_key:137 to store for rank: 1
2025-01-11 02:03:11,144 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:137 with 3 nodes.
2025-01-11 02:03:11,144 INFO Added key: store_based_barrier_key:137 to store for rank: 2
2025-01-11 02:03:11,145 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:137 with 3 nodes.
2025-01-11 02:03:11,149 INFO Epoch 135 TRAIN info lr 0.00013845423089261147 rank 1
2025-01-11 02:03:11,149 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 02:03:11,149 INFO Epoch 135 TRAIN info lr 0.00013845423089261147 rank 2
2025-01-11 02:03:11,149 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 02:03:11,154 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:137 with 3 nodes.
2025-01-11 02:03:11,156 INFO Epoch 135 TRAIN info lr 0.00013845423089261147 rank 0
2025-01-11 02:03:11,156 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 02:03:41,864 DEBUG TRAIN Batch 135/100 loss 0.032750 acc 0.972860 lr 0.00013843 grad_norm 0.361508 rank 1
2025-01-11 02:03:41,864 DEBUG TRAIN Batch 135/100 loss 0.039568 acc 0.978417 lr 0.00013843 grad_norm 0.361508 rank 2
2025-01-11 02:03:41,864 DEBUG TRAIN Batch 135/100 loss 0.027781 acc 0.980769 lr 0.00013843 grad_norm 0.361508 rank 0
2025-01-11 02:04:05,186 DEBUG TRAIN Batch 135/200 loss 0.032593 acc 0.981865 lr 0.00013840 grad_norm 0.372478 rank 2
2025-01-11 02:04:05,186 DEBUG TRAIN Batch 135/200 loss 0.040521 acc 0.972401 lr 0.00013840 grad_norm 0.372478 rank 0
2025-01-11 02:04:05,186 DEBUG TRAIN Batch 135/200 loss 0.032726 acc 0.977186 lr 0.00013840 grad_norm 0.372478 rank 1
2025-01-11 02:04:28,647 DEBUG TRAIN Batch 135/300 loss 0.039203 acc 0.976355 lr 0.00013837 grad_norm 0.399627 rank 2
2025-01-11 02:04:28,647 DEBUG TRAIN Batch 135/300 loss 0.034483 acc 0.968836 lr 0.00013837 grad_norm 0.399627 rank 0
2025-01-11 02:04:28,648 DEBUG TRAIN Batch 135/300 loss 0.035816 acc 0.976614 lr 0.00013837 grad_norm 0.399627 rank 1
2025-01-11 02:04:52,581 DEBUG TRAIN Batch 135/400 loss 0.030159 acc 0.975052 lr 0.00013835 grad_norm 0.424892 rank 0
2025-01-11 02:04:52,581 DEBUG TRAIN Batch 135/400 loss 0.029950 acc 0.980167 lr 0.00013835 grad_norm 0.424892 rank 1
2025-01-11 02:04:52,581 DEBUG TRAIN Batch 135/400 loss 0.060083 acc 0.956609 lr 0.00013835 grad_norm 0.424892 rank 2
2025-01-11 02:05:16,979 DEBUG TRAIN Batch 135/500 loss 0.030540 acc 0.981801 lr 0.00013832 grad_norm 0.392206 rank 0
2025-01-11 02:05:16,979 DEBUG TRAIN Batch 135/500 loss 0.026725 acc 0.982775 lr 0.00013832 grad_norm 0.392206 rank 1
2025-01-11 02:05:16,979 DEBUG TRAIN Batch 135/500 loss 0.033312 acc 0.975763 lr 0.00013832 grad_norm 0.392206 rank 2
2025-01-11 02:05:41,032 DEBUG TRAIN Batch 135/600 loss 0.039405 acc 0.973262 lr 0.00013830 grad_norm 0.436343 rank 0
2025-01-11 02:05:41,032 DEBUG TRAIN Batch 135/600 loss 0.034546 acc 0.974886 lr 0.00013830 grad_norm 0.436343 rank 1
2025-01-11 02:05:41,033 DEBUG TRAIN Batch 135/600 loss 0.032604 acc 0.974088 lr 0.00013830 grad_norm 0.436343 rank 2
2025-01-11 02:06:06,281 DEBUG TRAIN Batch 135/700 loss 0.033347 acc 0.974628 lr 0.00013827 grad_norm 0.374496 rank 2
2025-01-11 02:06:06,281 DEBUG TRAIN Batch 135/700 loss 0.042757 acc 0.973279 lr 0.00013827 grad_norm 0.374496 rank 0
2025-01-11 02:06:06,281 DEBUG TRAIN Batch 135/700 loss 0.038032 acc 0.971920 lr 0.00013827 grad_norm 0.374496 rank 1
2025-01-11 02:06:30,619 DEBUG TRAIN Batch 135/800 loss 0.027715 acc 0.983376 lr 0.00013824 grad_norm 0.387720 rank 0
2025-01-11 02:06:30,619 DEBUG TRAIN Batch 135/800 loss 0.033825 acc 0.976471 lr 0.00013824 grad_norm 0.387720 rank 1
2025-01-11 02:06:30,619 DEBUG TRAIN Batch 135/800 loss 0.040523 acc 0.975758 lr 0.00013824 grad_norm 0.387720 rank 2
2025-01-11 02:06:54,804 DEBUG TRAIN Batch 135/900 loss 0.032801 acc 0.972586 lr 0.00013822 grad_norm 0.406866 rank 1
2025-01-11 02:06:54,805 DEBUG TRAIN Batch 135/900 loss 0.050783 acc 0.963866 lr 0.00013822 grad_norm 0.406866 rank 0
2025-01-11 02:06:54,805 DEBUG TRAIN Batch 135/900 loss 0.037149 acc 0.972522 lr 0.00013822 grad_norm 0.406866 rank 2
2025-01-11 02:07:19,706 DEBUG TRAIN Batch 135/1000 loss 0.037913 acc 0.975477 lr 0.00013819 grad_norm 0.417756 rank 1
2025-01-11 02:07:19,707 DEBUG TRAIN Batch 135/1000 loss 0.046785 acc 0.969182 lr 0.00013819 grad_norm 0.417756 rank 0
2025-01-11 02:07:19,707 DEBUG TRAIN Batch 135/1000 loss 0.031228 acc 0.979878 lr 0.00013819 grad_norm 0.417756 rank 2
2025-01-11 02:07:44,475 DEBUG TRAIN Batch 135/1100 loss 0.048375 acc 0.964457 lr 0.00013816 grad_norm 0.388957 rank 0
2025-01-11 02:07:44,475 DEBUG TRAIN Batch 135/1100 loss 0.021389 acc 0.982301 lr 0.00013816 grad_norm 0.388957 rank 1
2025-01-11 02:07:44,475 DEBUG TRAIN Batch 135/1100 loss 0.040808 acc 0.969945 lr 0.00013816 grad_norm 0.388957 rank 2
2025-01-11 02:08:08,495 DEBUG TRAIN Batch 135/1200 loss 0.058484 acc 0.961868 lr 0.00013814 grad_norm 0.423861 rank 1
2025-01-11 02:08:08,496 DEBUG TRAIN Batch 135/1200 loss 0.035584 acc 0.976274 lr 0.00013814 grad_norm 0.423861 rank 2
2025-01-11 02:08:08,497 DEBUG TRAIN Batch 135/1200 loss 0.026617 acc 0.981111 lr 0.00013814 grad_norm 0.423861 rank 0
2025-01-11 02:08:33,801 DEBUG TRAIN Batch 135/1300 loss 0.037491 acc 0.972789 lr 0.00013811 grad_norm 0.402968 rank 2
2025-01-11 02:08:33,801 DEBUG TRAIN Batch 135/1300 loss 0.058681 acc 0.957533 lr 0.00013811 grad_norm 0.402968 rank 0
2025-01-11 02:08:33,801 DEBUG TRAIN Batch 135/1300 loss 0.043166 acc 0.967713 lr 0.00013811 grad_norm 0.402968 rank 1
2025-01-11 02:08:58,096 DEBUG TRAIN Batch 135/1400 loss 0.023949 acc 0.986708 lr 0.00013808 grad_norm 0.382861 rank 2
2025-01-11 02:08:58,096 DEBUG TRAIN Batch 135/1400 loss 0.037756 acc 0.971344 lr 0.00013808 grad_norm 0.382861 rank 1
2025-01-11 02:08:58,096 DEBUG TRAIN Batch 135/1400 loss 0.040610 acc 0.973612 lr 0.00013808 grad_norm 0.382861 rank 0
2025-01-11 02:09:21,517 DEBUG TRAIN Batch 135/1500 loss 0.035787 acc 0.972702 lr 0.00013806 grad_norm 0.412158 rank 1
2025-01-11 02:09:21,518 DEBUG TRAIN Batch 135/1500 loss 0.040991 acc 0.969553 lr 0.00013806 grad_norm 0.412158 rank 0
2025-01-11 02:09:21,518 DEBUG TRAIN Batch 135/1500 loss 0.043830 acc 0.964318 lr 0.00013806 grad_norm 0.412158 rank 2
2025-01-11 02:09:45,601 DEBUG TRAIN Batch 135/1600 loss 0.029343 acc 0.975560 lr 0.00013803 grad_norm 0.395241 rank 0
2025-01-11 02:09:45,601 DEBUG TRAIN Batch 135/1600 loss 0.048077 acc 0.962929 lr 0.00013803 grad_norm 0.395241 rank 1
2025-01-11 02:09:45,601 DEBUG TRAIN Batch 135/1600 loss 0.036978 acc 0.975546 lr 0.00013803 grad_norm 0.395241 rank 2
2025-01-11 02:10:08,957 DEBUG TRAIN Batch 135/1700 loss 0.039420 acc 0.970264 lr 0.00013801 grad_norm 0.394335 rank 2
2025-01-11 02:10:08,957 DEBUG TRAIN Batch 135/1700 loss 0.034295 acc 0.972831 lr 0.00013801 grad_norm 0.394335 rank 0
2025-01-11 02:10:08,957 DEBUG TRAIN Batch 135/1700 loss 0.037442 acc 0.977143 lr 0.00013801 grad_norm 0.394335 rank 1
2025-01-11 02:10:32,890 DEBUG TRAIN Batch 135/1800 loss 0.048783 acc 0.961872 lr 0.00013798 grad_norm 0.415378 rank 2
2025-01-11 02:10:32,890 DEBUG TRAIN Batch 135/1800 loss 0.030730 acc 0.977584 lr 0.00013798 grad_norm 0.415378 rank 0
2025-01-11 02:10:32,890 DEBUG TRAIN Batch 135/1800 loss 0.039338 acc 0.976848 lr 0.00013798 grad_norm 0.415378 rank 1
2025-01-11 02:10:56,157 DEBUG TRAIN Batch 135/1900 loss 0.041407 acc 0.973103 lr 0.00013795 grad_norm 0.412304 rank 2
2025-01-11 02:10:56,157 DEBUG TRAIN Batch 135/1900 loss 0.041206 acc 0.973359 lr 0.00013795 grad_norm 0.412304 rank 1
2025-01-11 02:10:56,158 DEBUG TRAIN Batch 135/1900 loss 0.037286 acc 0.972043 lr 0.00013795 grad_norm 0.412304 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 02:12:02,533 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 02:12:02,536 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 02:12:02,966 INFO Epoch 135 Step 131378 on_batch_end True CV rank 0
2025-01-11 02:12:02,966 INFO Epoch 135 Step 131378 on_batch_end True CV rank 2
2025-01-11 02:12:02,966 INFO Epoch 135 Step 131378 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 02:12:12,022 DEBUG CV Batch 135/100 loss 0.005831 acc 0.997770  rank 0
2025-01-11 02:12:12,393 DEBUG CV Batch 135/100 loss 0.005831 acc 0.997770  rank 2
2025-01-11 02:12:12,538 INFO Epoch 135 Step 131378 CV info lr 0.00013794586322988272 0 rank loss_2.5786217994438565 acc_0.7805388590745759
2025-01-11 02:12:12,621 DEBUG CV Batch 135/100 loss 0.005831 acc 0.997770  rank 1
2025-01-11 02:12:12,931 INFO Epoch 135 Step 131378 CV info lr 0.00013794586322988272 2 rank loss_2.5786217994438565 acc_0.7805388590745759
2025-01-11 02:12:13,162 INFO Epoch 135 Step 131378 CV info lr 0.00013794586322988272 1 rank loss_2.5786217994438565 acc_0.7805388590745759
2025-01-11 02:12:13,836 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_135_whole.pt
2025-01-11 02:12:13,847 INFO Added key: store_based_barrier_key:138 to store for rank: 0
2025-01-11 02:12:13,857 INFO Added key: store_based_barrier_key:138 to store for rank: 2
2025-01-11 02:12:13,858 INFO Added key: store_based_barrier_key:138 to store for rank: 1
2025-01-11 02:12:13,858 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:138 with 3 nodes.
2025-01-11 02:12:13,863 INFO Epoch 136 TRAIN info lr 0.00013794586322988272 rank 1
2025-01-11 02:12:13,863 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 02:12:13,867 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:138 with 3 nodes.
2025-01-11 02:12:13,868 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:138 with 3 nodes.
2025-01-11 02:12:13,871 INFO Epoch 136 TRAIN info lr 0.00013794586322988272 rank 2
2025-01-11 02:12:13,871 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 02:12:13,872 INFO Epoch 136 TRAIN info lr 0.00013794586322988272 rank 0
2025-01-11 02:12:13,872 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 02:12:44,716 DEBUG TRAIN Batch 136/100 loss 0.029547 acc 0.977390 lr 0.00013792 grad_norm 0.384142 rank 2
2025-01-11 02:12:44,716 DEBUG TRAIN Batch 136/100 loss 0.040184 acc 0.970681 lr 0.00013792 grad_norm 0.384142 rank 0
2025-01-11 02:12:44,716 DEBUG TRAIN Batch 136/100 loss 0.033998 acc 0.980126 lr 0.00013792 grad_norm 0.384142 rank 1
2025-01-11 02:13:08,600 DEBUG TRAIN Batch 136/200 loss 0.030981 acc 0.981203 lr 0.00013789 grad_norm 0.388163 rank 1
2025-01-11 02:13:08,601 DEBUG TRAIN Batch 136/200 loss 0.034777 acc 0.977041 lr 0.00013789 grad_norm 0.388163 rank 0
2025-01-11 02:13:08,601 DEBUG TRAIN Batch 136/200 loss 0.039361 acc 0.971631 lr 0.00013789 grad_norm 0.388163 rank 2
2025-01-11 02:13:31,972 DEBUG TRAIN Batch 136/300 loss 0.040426 acc 0.976099 lr 0.00013787 grad_norm 0.405852 rank 1
2025-01-11 02:13:31,973 DEBUG TRAIN Batch 136/300 loss 0.033689 acc 0.978826 lr 0.00013787 grad_norm 0.405852 rank 0
2025-01-11 02:13:31,973 DEBUG TRAIN Batch 136/300 loss 0.033684 acc 0.978474 lr 0.00013787 grad_norm 0.405852 rank 2
2025-01-11 02:13:55,421 DEBUG TRAIN Batch 136/400 loss 0.043004 acc 0.969697 lr 0.00013784 grad_norm 0.408907 rank 1
2025-01-11 02:13:55,421 DEBUG TRAIN Batch 136/400 loss 0.036889 acc 0.968444 lr 0.00013784 grad_norm 0.408907 rank 0
2025-01-11 02:13:55,422 DEBUG TRAIN Batch 136/400 loss 0.029494 acc 0.982202 lr 0.00013784 grad_norm 0.408907 rank 2
2025-01-11 02:14:19,662 DEBUG TRAIN Batch 136/500 loss 0.032185 acc 0.979249 lr 0.00013781 grad_norm 0.379019 rank 1
2025-01-11 02:14:19,662 DEBUG TRAIN Batch 136/500 loss 0.041966 acc 0.970909 lr 0.00013781 grad_norm 0.379019 rank 2
2025-01-11 02:14:19,662 DEBUG TRAIN Batch 136/500 loss 0.041734 acc 0.969973 lr 0.00013781 grad_norm 0.379019 rank 0
2025-01-11 02:14:43,081 DEBUG TRAIN Batch 136/600 loss 0.044105 acc 0.970425 lr 0.00013779 grad_norm 0.425954 rank 1
2025-01-11 02:14:43,081 DEBUG TRAIN Batch 136/600 loss 0.037930 acc 0.969555 lr 0.00013779 grad_norm 0.425954 rank 0
2025-01-11 02:14:43,081 DEBUG TRAIN Batch 136/600 loss 0.036209 acc 0.979843 lr 0.00013779 grad_norm 0.425954 rank 2
2025-01-11 02:15:06,785 DEBUG TRAIN Batch 136/700 loss 0.033138 acc 0.975904 lr 0.00013776 grad_norm 0.352799 rank 2
2025-01-11 02:15:06,786 DEBUG TRAIN Batch 136/700 loss 0.027960 acc 0.975799 lr 0.00013776 grad_norm 0.352799 rank 0
2025-01-11 02:15:06,786 DEBUG TRAIN Batch 136/700 loss 0.029084 acc 0.978178 lr 0.00013776 grad_norm 0.352799 rank 1
2025-01-11 02:15:30,131 DEBUG TRAIN Batch 136/800 loss 0.046681 acc 0.968411 lr 0.00013774 grad_norm 0.404914 rank 1
2025-01-11 02:15:30,131 DEBUG TRAIN Batch 136/800 loss 0.026499 acc 0.977633 lr 0.00013774 grad_norm 0.404914 rank 0
2025-01-11 02:15:30,132 DEBUG TRAIN Batch 136/800 loss 0.036059 acc 0.974978 lr 0.00013774 grad_norm 0.404914 rank 2
2025-01-11 02:15:54,207 DEBUG TRAIN Batch 136/900 loss 0.036596 acc 0.967043 lr 0.00013771 grad_norm 0.369339 rank 1
2025-01-11 02:15:54,208 DEBUG TRAIN Batch 136/900 loss 0.026480 acc 0.980496 lr 0.00013771 grad_norm 0.369339 rank 2
2025-01-11 02:15:54,208 DEBUG TRAIN Batch 136/900 loss 0.041986 acc 0.977332 lr 0.00013771 grad_norm 0.369339 rank 0
2025-01-11 02:16:17,998 DEBUG TRAIN Batch 136/1000 loss 0.036329 acc 0.970716 lr 0.00013768 grad_norm 0.377926 rank 0
2025-01-11 02:16:17,998 DEBUG TRAIN Batch 136/1000 loss 0.020768 acc 0.986330 lr 0.00013768 grad_norm 0.377926 rank 1
2025-01-11 02:16:17,999 DEBUG TRAIN Batch 136/1000 loss 0.031090 acc 0.983407 lr 0.00013768 grad_norm 0.377926 rank 2
2025-01-11 02:16:42,389 DEBUG TRAIN Batch 136/1100 loss 0.030024 acc 0.973813 lr 0.00013766 grad_norm 0.420795 rank 0
2025-01-11 02:16:42,389 DEBUG TRAIN Batch 136/1100 loss 0.019432 acc 0.986471 lr 0.00013766 grad_norm 0.420795 rank 1
2025-01-11 02:16:42,390 DEBUG TRAIN Batch 136/1100 loss 0.047462 acc 0.966990 lr 0.00013766 grad_norm 0.420795 rank 2
2025-01-11 02:17:06,783 DEBUG TRAIN Batch 136/1200 loss 0.029599 acc 0.981162 lr 0.00013763 grad_norm 0.377595 rank 1
2025-01-11 02:17:06,783 DEBUG TRAIN Batch 136/1200 loss 0.035456 acc 0.976570 lr 0.00013763 grad_norm 0.377595 rank 0
2025-01-11 02:17:06,784 DEBUG TRAIN Batch 136/1200 loss 0.027515 acc 0.977174 lr 0.00013763 grad_norm 0.377595 rank 2
2025-01-11 02:17:31,362 DEBUG TRAIN Batch 136/1300 loss 0.057137 acc 0.959276 lr 0.00013761 grad_norm 0.413659 rank 1
2025-01-11 02:17:31,362 DEBUG TRAIN Batch 136/1300 loss 0.037139 acc 0.977273 lr 0.00013761 grad_norm 0.413659 rank 2
2025-01-11 02:17:31,362 DEBUG TRAIN Batch 136/1300 loss 0.040731 acc 0.978648 lr 0.00013761 grad_norm 0.413659 rank 0
2025-01-11 02:17:56,419 DEBUG TRAIN Batch 136/1400 loss 0.042152 acc 0.970988 lr 0.00013758 grad_norm 0.396641 rank 2
2025-01-11 02:17:56,419 DEBUG TRAIN Batch 136/1400 loss 0.040419 acc 0.975000 lr 0.00013758 grad_norm 0.396641 rank 0
2025-01-11 02:17:56,422 DEBUG TRAIN Batch 136/1400 loss 0.041504 acc 0.972801 lr 0.00013758 grad_norm 0.396641 rank 1
2025-01-11 02:18:21,367 DEBUG TRAIN Batch 136/1500 loss 0.035156 acc 0.974628 lr 0.00013755 grad_norm 0.420542 rank 1
2025-01-11 02:18:21,368 DEBUG TRAIN Batch 136/1500 loss 0.027979 acc 0.976667 lr 0.00013755 grad_norm 0.420542 rank 0
2025-01-11 02:18:21,368 DEBUG TRAIN Batch 136/1500 loss 0.054570 acc 0.953575 lr 0.00013755 grad_norm 0.420542 rank 2
2025-01-11 02:18:46,658 DEBUG TRAIN Batch 136/1600 loss 0.034120 acc 0.976522 lr 0.00013753 grad_norm 0.393802 rank 0
2025-01-11 02:18:46,658 DEBUG TRAIN Batch 136/1600 loss 0.047556 acc 0.965819 lr 0.00013753 grad_norm 0.393802 rank 1
2025-01-11 02:18:46,659 DEBUG TRAIN Batch 136/1600 loss 0.037280 acc 0.971246 lr 0.00013753 grad_norm 0.393802 rank 2
2025-01-11 02:19:11,643 DEBUG TRAIN Batch 136/1700 loss 0.056497 acc 0.961191 lr 0.00013750 grad_norm 0.402950 rank 1
2025-01-11 02:19:11,644 DEBUG TRAIN Batch 136/1700 loss 0.039750 acc 0.975000 lr 0.00013750 grad_norm 0.402950 rank 2
2025-01-11 02:19:11,644 DEBUG TRAIN Batch 136/1700 loss 0.030182 acc 0.978852 lr 0.00013750 grad_norm 0.402950 rank 0
2025-01-11 02:19:36,155 DEBUG TRAIN Batch 136/1800 loss 0.041154 acc 0.977561 lr 0.00013748 grad_norm 0.416530 rank 1
2025-01-11 02:19:36,156 DEBUG TRAIN Batch 136/1800 loss 0.031933 acc 0.978196 lr 0.00013748 grad_norm 0.416530 rank 0
2025-01-11 02:19:36,156 DEBUG TRAIN Batch 136/1800 loss 0.059466 acc 0.963504 lr 0.00013748 grad_norm 0.416530 rank 2
2025-01-11 02:20:00,062 DEBUG TRAIN Batch 136/1900 loss 0.039087 acc 0.965874 lr 0.00013745 grad_norm 0.430124 rank 0
2025-01-11 02:20:00,062 DEBUG TRAIN Batch 136/1900 loss 0.048070 acc 0.971190 lr 0.00013745 grad_norm 0.430124 rank 2
2025-01-11 02:20:00,063 DEBUG TRAIN Batch 136/1900 loss 0.033243 acc 0.973291 lr 0.00013745 grad_norm 0.430124 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 02:21:09,119 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 02:21:09,126 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 02:21:09,553 INFO Epoch 136 Step 132346 on_batch_end True CV rank 1
2025-01-11 02:21:09,553 INFO Epoch 136 Step 132346 on_batch_end True CV rank 0
2025-01-11 02:21:09,553 INFO Epoch 136 Step 132346 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 02:21:18,620 DEBUG CV Batch 136/100 loss 0.014292 acc 0.995541  rank 0
2025-01-11 02:21:18,836 DEBUG CV Batch 136/100 loss 0.014292 acc 0.995541  rank 2
2025-01-11 02:21:18,996 DEBUG CV Batch 136/100 loss 0.014292 acc 0.995541  rank 1
2025-01-11 02:21:19,115 INFO Epoch 136 Step 132346 CV info lr 0.00013744045822874698 0 rank loss_2.5756893909486265 acc_0.780536991331661
2025-01-11 02:21:19,387 INFO Epoch 136 Step 132346 CV info lr 0.00013744045822874698 2 rank loss_2.5756893909486265 acc_0.780536991331661
2025-01-11 02:21:19,530 INFO Epoch 136 Step 132346 CV info lr 0.00013744045822874698 1 rank loss_2.5756893909486265 acc_0.780536991331661
2025-01-11 02:21:20,422 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_136_whole.pt
2025-01-11 02:21:20,433 INFO Added key: store_based_barrier_key:139 to store for rank: 0
2025-01-11 02:21:20,444 INFO Added key: store_based_barrier_key:139 to store for rank: 2
2025-01-11 02:21:20,444 INFO Added key: store_based_barrier_key:139 to store for rank: 1
2025-01-11 02:21:20,444 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:139 with 3 nodes.
2025-01-11 02:21:20,444 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:139 with 3 nodes.
2025-01-11 02:21:20,447 INFO Epoch 137 TRAIN info lr 0.00013744045822874698 rank 1
2025-01-11 02:21:20,447 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 02:21:20,450 INFO Epoch 137 TRAIN info lr 0.00013744045822874698 rank 2
2025-01-11 02:21:20,450 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 02:21:20,454 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:139 with 3 nodes.
2025-01-11 02:21:20,457 INFO Epoch 137 TRAIN info lr 0.00013744045822874698 rank 0
2025-01-11 02:21:20,457 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 02:21:51,911 DEBUG TRAIN Batch 137/100 loss 0.021692 acc 0.984227 lr 0.00013741 grad_norm 0.343708 rank 0
2025-01-11 02:21:51,911 DEBUG TRAIN Batch 137/100 loss 0.031424 acc 0.977195 lr 0.00013741 grad_norm 0.343708 rank 2
2025-01-11 02:21:51,912 DEBUG TRAIN Batch 137/100 loss 0.037813 acc 0.977390 lr 0.00013741 grad_norm 0.343708 rank 1
2025-01-11 02:22:15,813 DEBUG TRAIN Batch 137/200 loss 0.028928 acc 0.974326 lr 0.00013739 grad_norm 0.387638 rank 1
2025-01-11 02:22:15,813 DEBUG TRAIN Batch 137/200 loss 0.031385 acc 0.972821 lr 0.00013739 grad_norm 0.387638 rank 0
2025-01-11 02:22:15,814 DEBUG TRAIN Batch 137/200 loss 0.040332 acc 0.967811 lr 0.00013739 grad_norm 0.387638 rank 2
2025-01-11 02:22:40,713 DEBUG TRAIN Batch 137/300 loss 0.048798 acc 0.963532 lr 0.00013736 grad_norm 0.416458 rank 1
2025-01-11 02:22:40,714 DEBUG TRAIN Batch 137/300 loss 0.048918 acc 0.966236 lr 0.00013736 grad_norm 0.416458 rank 0
2025-01-11 02:22:40,714 DEBUG TRAIN Batch 137/300 loss 0.036383 acc 0.972826 lr 0.00013736 grad_norm 0.416458 rank 2
2025-01-11 02:23:04,503 DEBUG TRAIN Batch 137/400 loss 0.040608 acc 0.964738 lr 0.00013734 grad_norm 0.377641 rank 2
2025-01-11 02:23:04,503 DEBUG TRAIN Batch 137/400 loss 0.025143 acc 0.983571 lr 0.00013734 grad_norm 0.377641 rank 0
2025-01-11 02:23:04,504 DEBUG TRAIN Batch 137/400 loss 0.050562 acc 0.967403 lr 0.00013734 grad_norm 0.377641 rank 1
2025-01-11 02:23:28,826 DEBUG TRAIN Batch 137/500 loss 0.037693 acc 0.975161 lr 0.00013731 grad_norm 0.383921 rank 0
2025-01-11 02:23:28,826 DEBUG TRAIN Batch 137/500 loss 0.031132 acc 0.975104 lr 0.00013731 grad_norm 0.383921 rank 2
2025-01-11 02:23:28,827 DEBUG TRAIN Batch 137/500 loss 0.035375 acc 0.975543 lr 0.00013731 grad_norm 0.383921 rank 1
2025-01-11 02:23:53,193 DEBUG TRAIN Batch 137/600 loss 0.027589 acc 0.983670 lr 0.00013728 grad_norm 0.367791 rank 0
2025-01-11 02:23:53,194 DEBUG TRAIN Batch 137/600 loss 0.045430 acc 0.967623 lr 0.00013728 grad_norm 0.367791 rank 2
2025-01-11 02:23:53,194 DEBUG TRAIN Batch 137/600 loss 0.039006 acc 0.973588 lr 0.00013728 grad_norm 0.367791 rank 1
2025-01-11 02:24:17,041 DEBUG TRAIN Batch 137/700 loss 0.055245 acc 0.964476 lr 0.00013726 grad_norm 0.397189 rank 1
2025-01-11 02:24:17,041 DEBUG TRAIN Batch 137/700 loss 0.030607 acc 0.974038 lr 0.00013726 grad_norm 0.397189 rank 2
2025-01-11 02:24:17,041 DEBUG TRAIN Batch 137/700 loss 0.032570 acc 0.980653 lr 0.00013726 grad_norm 0.397189 rank 0
2025-01-11 02:24:40,965 DEBUG TRAIN Batch 137/800 loss 0.054307 acc 0.958640 lr 0.00013723 grad_norm 0.401573 rank 1
2025-01-11 02:24:40,965 DEBUG TRAIN Batch 137/800 loss 0.049267 acc 0.965686 lr 0.00013723 grad_norm 0.401573 rank 2
2025-01-11 02:24:40,966 DEBUG TRAIN Batch 137/800 loss 0.036175 acc 0.980601 lr 0.00013723 grad_norm 0.401573 rank 0
2025-01-11 02:25:04,598 DEBUG TRAIN Batch 137/900 loss 0.030776 acc 0.974359 lr 0.00013721 grad_norm 0.393413 rank 0
2025-01-11 02:25:04,598 DEBUG TRAIN Batch 137/900 loss 0.034752 acc 0.979736 lr 0.00013721 grad_norm 0.393413 rank 1
2025-01-11 02:25:04,598 DEBUG TRAIN Batch 137/900 loss 0.037322 acc 0.973188 lr 0.00013721 grad_norm 0.393413 rank 2
2025-01-11 02:25:29,700 DEBUG TRAIN Batch 137/1000 loss 0.042576 acc 0.972274 lr 0.00013718 grad_norm 0.366834 rank 2
2025-01-11 02:25:29,700 DEBUG TRAIN Batch 137/1000 loss 0.041056 acc 0.975207 lr 0.00013718 grad_norm 0.366834 rank 1
2025-01-11 02:25:29,700 DEBUG TRAIN Batch 137/1000 loss 0.032824 acc 0.982353 lr 0.00013718 grad_norm 0.366834 rank 0
2025-01-11 02:25:53,965 DEBUG TRAIN Batch 137/1100 loss 0.031225 acc 0.977528 lr 0.00013716 grad_norm 0.420496 rank 1
2025-01-11 02:25:53,965 DEBUG TRAIN Batch 137/1100 loss 0.042454 acc 0.969466 lr 0.00013716 grad_norm 0.420496 rank 2
2025-01-11 02:25:53,966 DEBUG TRAIN Batch 137/1100 loss 0.027351 acc 0.981720 lr 0.00013716 grad_norm 0.420496 rank 0
2025-01-11 02:26:18,390 DEBUG TRAIN Batch 137/1200 loss 0.036775 acc 0.974576 lr 0.00013713 grad_norm 0.435447 rank 1
2025-01-11 02:26:18,391 DEBUG TRAIN Batch 137/1200 loss 0.038868 acc 0.974199 lr 0.00013713 grad_norm 0.435447 rank 2
2025-01-11 02:26:18,391 DEBUG TRAIN Batch 137/1200 loss 0.042976 acc 0.970179 lr 0.00013713 grad_norm 0.435447 rank 0
2025-01-11 02:26:43,463 DEBUG TRAIN Batch 137/1300 loss 0.029951 acc 0.978723 lr 0.00013710 grad_norm 0.394164 rank 0
2025-01-11 02:26:43,463 DEBUG TRAIN Batch 137/1300 loss 0.030441 acc 0.978289 lr 0.00013710 grad_norm 0.394164 rank 1
2025-01-11 02:26:43,464 DEBUG TRAIN Batch 137/1300 loss 0.022079 acc 0.985169 lr 0.00013710 grad_norm 0.394164 rank 2
2025-01-11 02:27:07,531 DEBUG TRAIN Batch 137/1400 loss 0.047092 acc 0.968124 lr 0.00013708 grad_norm 0.387194 rank 2
2025-01-11 02:27:07,532 DEBUG TRAIN Batch 137/1400 loss 0.035844 acc 0.973735 lr 0.00013708 grad_norm 0.387194 rank 1
2025-01-11 02:27:07,532 DEBUG TRAIN Batch 137/1400 loss 0.040299 acc 0.965065 lr 0.00013708 grad_norm 0.387194 rank 0
2025-01-11 02:27:32,384 DEBUG TRAIN Batch 137/1500 loss 0.021034 acc 0.990000 lr 0.00013705 grad_norm 0.396347 rank 0
2025-01-11 02:27:32,385 DEBUG TRAIN Batch 137/1500 loss 0.057704 acc 0.966539 lr 0.00013705 grad_norm 0.396347 rank 2
2025-01-11 02:27:32,385 DEBUG TRAIN Batch 137/1500 loss 0.044967 acc 0.969142 lr 0.00013705 grad_norm 0.396347 rank 1
2025-01-11 02:27:57,002 DEBUG TRAIN Batch 137/1600 loss 0.041720 acc 0.973711 lr 0.00013703 grad_norm 0.388342 rank 1
2025-01-11 02:27:57,002 DEBUG TRAIN Batch 137/1600 loss 0.041225 acc 0.974052 lr 0.00013703 grad_norm 0.388342 rank 0
2025-01-11 02:27:57,002 DEBUG TRAIN Batch 137/1600 loss 0.031703 acc 0.981928 lr 0.00013703 grad_norm 0.388342 rank 2
2025-01-11 02:28:21,843 DEBUG TRAIN Batch 137/1700 loss 0.040091 acc 0.974186 lr 0.00013700 grad_norm 0.439358 rank 0
2025-01-11 02:28:21,843 DEBUG TRAIN Batch 137/1700 loss 0.030599 acc 0.982620 lr 0.00013700 grad_norm 0.439358 rank 1
2025-01-11 02:28:21,844 DEBUG TRAIN Batch 137/1700 loss 0.041160 acc 0.969595 lr 0.00013700 grad_norm 0.439358 rank 2
2025-01-11 02:28:47,404 DEBUG TRAIN Batch 137/1800 loss 0.051741 acc 0.963458 lr 0.00013698 grad_norm 0.393714 rank 1
2025-01-11 02:28:47,404 DEBUG TRAIN Batch 137/1800 loss 0.032000 acc 0.980276 lr 0.00013698 grad_norm 0.393714 rank 0
2025-01-11 02:28:47,405 DEBUG TRAIN Batch 137/1800 loss 0.027595 acc 0.978743 lr 0.00013698 grad_norm 0.393714 rank 2
2025-01-11 02:29:10,504 DEBUG TRAIN Batch 137/1900 loss 0.046851 acc 0.968976 lr 0.00013695 grad_norm 0.417142 rank 0
2025-01-11 02:29:10,505 DEBUG TRAIN Batch 137/1900 loss 0.042861 acc 0.970909 lr 0.00013695 grad_norm 0.417142 rank 2
2025-01-11 02:29:10,505 DEBUG TRAIN Batch 137/1900 loss 0.037718 acc 0.978882 lr 0.00013695 grad_norm 0.417142 rank 1
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 02:30:13,479 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 02:30:13,481 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 02:30:13,880 INFO Epoch 137 Step 133302 on_batch_end True CV rank 0
2025-01-11 02:30:13,880 INFO Epoch 137 Step 133302 on_batch_end True CV rank 2
2025-01-11 02:30:13,880 INFO Epoch 137 Step 133302 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 02:30:22,942 DEBUG CV Batch 137/100 loss 0.005261 acc 0.998885  rank 0
2025-01-11 02:30:23,137 DEBUG CV Batch 137/100 loss 0.005261 acc 0.998885  rank 2
2025-01-11 02:30:23,472 INFO Epoch 137 Step 133302 CV info lr 0.00013694673156272166 0 rank loss_2.5737679731458214 acc_0.7794801068671963
2025-01-11 02:30:23,664 INFO Epoch 137 Step 133302 CV info lr 0.00013694673156272166 2 rank loss_2.5737679731458214 acc_0.7794801068671963
2025-01-11 02:30:23,712 DEBUG CV Batch 137/100 loss 0.005261 acc 0.998885  rank 1
2025-01-11 02:30:24,262 INFO Epoch 137 Step 133302 CV info lr 0.00013694673156272166 1 rank loss_2.5737679731458214 acc_0.7794801068671963
2025-01-11 02:30:24,765 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_137_whole.pt
2025-01-11 02:30:24,787 INFO Added key: store_based_barrier_key:140 to store for rank: 0
2025-01-11 02:30:24,787 INFO Added key: store_based_barrier_key:140 to store for rank: 2
2025-01-11 02:30:24,787 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:140 with 3 nodes.
2025-01-11 02:30:24,787 INFO Added key: store_based_barrier_key:140 to store for rank: 1
2025-01-11 02:30:24,788 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:140 with 3 nodes.
2025-01-11 02:30:24,794 INFO Epoch 138 TRAIN info lr 0.00013694673156272166 rank 2
2025-01-11 02:30:24,794 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 02:30:24,796 INFO Epoch 138 TRAIN info lr 0.00013694673156272166 rank 1
2025-01-11 02:30:24,796 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 02:30:24,797 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:140 with 3 nodes.
2025-01-11 02:30:24,805 INFO Epoch 138 TRAIN info lr 0.00013694673156272166 rank 0
2025-01-11 02:30:24,805 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 02:30:54,846 DEBUG TRAIN Batch 138/100 loss 0.027779 acc 0.978484 lr 0.00013692 grad_norm 0.364193 rank 2
2025-01-11 02:30:54,847 DEBUG TRAIN Batch 138/100 loss 0.035390 acc 0.976657 lr 0.00013692 grad_norm 0.364193 rank 0
2025-01-11 02:30:54,847 DEBUG TRAIN Batch 138/100 loss 0.032977 acc 0.978723 lr 0.00013692 grad_norm 0.364193 rank 1
2025-01-11 02:31:18,670 DEBUG TRAIN Batch 138/200 loss 0.037902 acc 0.976631 lr 0.00013690 grad_norm 0.384526 rank 1
2025-01-11 02:31:18,670 DEBUG TRAIN Batch 138/200 loss 0.031573 acc 0.978464 lr 0.00013690 grad_norm 0.384526 rank 0
2025-01-11 02:31:18,671 DEBUG TRAIN Batch 138/200 loss 0.018327 acc 0.992500 lr 0.00013690 grad_norm 0.384526 rank 2
2025-01-11 02:31:42,041 DEBUG TRAIN Batch 138/300 loss 0.047829 acc 0.970958 lr 0.00013687 grad_norm 0.399627 rank 1
2025-01-11 02:31:42,042 DEBUG TRAIN Batch 138/300 loss 0.044808 acc 0.963208 lr 0.00013687 grad_norm 0.399627 rank 0
2025-01-11 02:31:42,042 DEBUG TRAIN Batch 138/300 loss 0.042608 acc 0.975562 lr 0.00013687 grad_norm 0.399627 rank 2
2025-01-11 02:32:05,874 DEBUG TRAIN Batch 138/400 loss 0.019768 acc 0.985656 lr 0.00013684 grad_norm 0.358045 rank 2
2025-01-11 02:32:05,874 DEBUG TRAIN Batch 138/400 loss 0.040558 acc 0.965919 lr 0.00013684 grad_norm 0.358045 rank 0
2025-01-11 02:32:05,875 DEBUG TRAIN Batch 138/400 loss 0.018325 acc 0.986828 lr 0.00013684 grad_norm 0.358045 rank 1
2025-01-11 02:32:29,983 DEBUG TRAIN Batch 138/500 loss 0.049017 acc 0.964192 lr 0.00013682 grad_norm 0.398345 rank 1
2025-01-11 02:32:29,983 DEBUG TRAIN Batch 138/500 loss 0.053722 acc 0.962694 lr 0.00013682 grad_norm 0.398345 rank 0
2025-01-11 02:32:29,983 DEBUG TRAIN Batch 138/500 loss 0.042054 acc 0.976784 lr 0.00013682 grad_norm 0.398345 rank 2
2025-01-11 02:32:53,795 DEBUG TRAIN Batch 138/600 loss 0.049229 acc 0.968224 lr 0.00013679 grad_norm 0.434765 rank 1
2025-01-11 02:32:53,796 DEBUG TRAIN Batch 138/600 loss 0.060341 acc 0.961062 lr 0.00013679 grad_norm 0.434765 rank 0
2025-01-11 02:32:53,796 DEBUG TRAIN Batch 138/600 loss 0.046056 acc 0.969314 lr 0.00013679 grad_norm 0.434765 rank 2
2025-01-11 02:33:18,426 DEBUG TRAIN Batch 138/700 loss 0.041630 acc 0.970228 lr 0.00013677 grad_norm 0.379225 rank 1
2025-01-11 02:33:18,427 DEBUG TRAIN Batch 138/700 loss 0.038151 acc 0.975215 lr 0.00013677 grad_norm 0.379225 rank 0
2025-01-11 02:33:18,427 DEBUG TRAIN Batch 138/700 loss 0.034333 acc 0.974848 lr 0.00013677 grad_norm 0.379225 rank 2
2025-01-11 02:33:41,851 DEBUG TRAIN Batch 138/800 loss 0.038614 acc 0.972420 lr 0.00013674 grad_norm 0.381810 rank 1
2025-01-11 02:33:41,852 DEBUG TRAIN Batch 138/800 loss 0.043417 acc 0.970864 lr 0.00013674 grad_norm 0.381810 rank 0
2025-01-11 02:33:41,852 DEBUG TRAIN Batch 138/800 loss 0.032698 acc 0.980553 lr 0.00013674 grad_norm 0.381810 rank 2
2025-01-11 02:34:06,453 DEBUG TRAIN Batch 138/900 loss 0.031595 acc 0.979907 lr 0.00013672 grad_norm 0.387955 rank 1
2025-01-11 02:34:06,453 DEBUG TRAIN Batch 138/900 loss 0.049098 acc 0.964098 lr 0.00013672 grad_norm 0.387955 rank 0
2025-01-11 02:34:06,453 DEBUG TRAIN Batch 138/900 loss 0.025201 acc 0.984834 lr 0.00013672 grad_norm 0.387955 rank 2
2025-01-11 02:34:31,405 DEBUG TRAIN Batch 138/1000 loss 0.042037 acc 0.970425 lr 0.00013669 grad_norm 0.390436 rank 1
2025-01-11 02:34:31,405 DEBUG TRAIN Batch 138/1000 loss 0.034632 acc 0.977558 lr 0.00013669 grad_norm 0.390436 rank 2
2025-01-11 02:34:31,405 DEBUG TRAIN Batch 138/1000 loss 0.044105 acc 0.967000 lr 0.00013669 grad_norm 0.390436 rank 0
2025-01-11 02:34:56,415 DEBUG TRAIN Batch 138/1100 loss 0.042795 acc 0.972197 lr 0.00013667 grad_norm 0.409884 rank 1
2025-01-11 02:34:56,415 DEBUG TRAIN Batch 138/1100 loss 0.050658 acc 0.965517 lr 0.00013667 grad_norm 0.409884 rank 0
2025-01-11 02:34:56,416 DEBUG TRAIN Batch 138/1100 loss 0.029416 acc 0.979298 lr 0.00013667 grad_norm 0.409884 rank 2
2025-01-11 02:35:20,920 DEBUG TRAIN Batch 138/1200 loss 0.039841 acc 0.975518 lr 0.00013664 grad_norm 0.396058 rank 0
2025-01-11 02:35:20,920 DEBUG TRAIN Batch 138/1200 loss 0.046429 acc 0.969014 lr 0.00013664 grad_norm 0.396058 rank 2
2025-01-11 02:35:20,923 DEBUG TRAIN Batch 138/1200 loss 0.026966 acc 0.978962 lr 0.00013664 grad_norm 0.396058 rank 1
2025-01-11 02:35:45,286 DEBUG TRAIN Batch 138/1300 loss 0.038405 acc 0.977509 lr 0.00013661 grad_norm 0.382040 rank 0
2025-01-11 02:35:45,287 DEBUG TRAIN Batch 138/1300 loss 0.026973 acc 0.983087 lr 0.00013661 grad_norm 0.382040 rank 2
2025-01-11 02:35:45,425 DEBUG TRAIN Batch 138/1300 loss 0.041900 acc 0.969398 lr 0.00013661 grad_norm 0.382040 rank 1
2025-01-11 02:36:10,512 DEBUG TRAIN Batch 138/1400 loss 0.042727 acc 0.972810 lr 0.00013659 grad_norm 0.569228 rank 0
2025-01-11 02:36:10,512 DEBUG TRAIN Batch 138/1400 loss 0.040016 acc 0.972222 lr 0.00013659 grad_norm 0.569228 rank 1
2025-01-11 02:36:10,512 DEBUG TRAIN Batch 138/1400 loss 0.035056 acc 0.978947 lr 0.00013659 grad_norm 0.569228 rank 2
2025-01-11 02:36:34,702 DEBUG TRAIN Batch 138/1500 loss 0.032977 acc 0.975092 lr 0.00013656 grad_norm 0.350196 rank 1
2025-01-11 02:36:34,703 DEBUG TRAIN Batch 138/1500 loss 0.036348 acc 0.974592 lr 0.00013656 grad_norm 0.350196 rank 2
2025-01-11 02:36:34,703 DEBUG TRAIN Batch 138/1500 loss 0.039022 acc 0.975941 lr 0.00013656 grad_norm 0.350196 rank 0
2025-01-11 02:36:58,740 DEBUG TRAIN Batch 138/1600 loss 0.029539 acc 0.976864 lr 0.00013654 grad_norm 0.377360 rank 2
2025-01-11 02:36:58,740 DEBUG TRAIN Batch 138/1600 loss 0.031714 acc 0.981707 lr 0.00013654 grad_norm 0.377360 rank 1
2025-01-11 02:36:58,740 DEBUG TRAIN Batch 138/1600 loss 0.028837 acc 0.983111 lr 0.00013654 grad_norm 0.377360 rank 0
2025-01-11 02:37:23,588 DEBUG TRAIN Batch 138/1700 loss 0.037646 acc 0.970448 lr 0.00013651 grad_norm 0.405935 rank 1
2025-01-11 02:37:23,588 DEBUG TRAIN Batch 138/1700 loss 0.030358 acc 0.976168 lr 0.00013651 grad_norm 0.405935 rank 0
2025-01-11 02:37:23,589 DEBUG TRAIN Batch 138/1700 loss 0.025241 acc 0.979633 lr 0.00013651 grad_norm 0.405935 rank 2
2025-01-11 02:37:47,872 DEBUG TRAIN Batch 138/1800 loss 0.035165 acc 0.976873 lr 0.00013649 grad_norm 0.411432 rank 1
2025-01-11 02:37:47,872 DEBUG TRAIN Batch 138/1800 loss 0.033727 acc 0.976583 lr 0.00013649 grad_norm 0.411432 rank 0
2025-01-11 02:37:47,872 DEBUG TRAIN Batch 138/1800 loss 0.028695 acc 0.978587 lr 0.00013649 grad_norm 0.411432 rank 2
2025-01-11 02:38:12,612 DEBUG TRAIN Batch 138/1900 loss 0.049158 acc 0.970457 lr 0.00013646 grad_norm 0.421212 rank 1
2025-01-11 02:38:12,612 DEBUG TRAIN Batch 138/1900 loss 0.034173 acc 0.972877 lr 0.00013646 grad_norm 0.421212 rank 0
2025-01-11 02:38:12,612 DEBUG TRAIN Batch 138/1900 loss 0.041841 acc 0.971656 lr 0.00013646 grad_norm 0.421212 rank 2
2025-01-11 02:38:36,945 DEBUG TRAIN Batch 138/2000 loss 0.030330 acc 0.976693 lr 0.00013644 grad_norm 0.413192 rank 1
2025-01-11 02:38:36,945 DEBUG TRAIN Batch 138/2000 loss 0.044527 acc 0.970297 lr 0.00013644 grad_norm 0.413192 rank 0
2025-01-11 02:38:36,945 DEBUG TRAIN Batch 138/2000 loss 0.040088 acc 0.972737 lr 0.00013644 grad_norm 0.413192 rank 2
2025-01-11 02:39:01,486 DEBUG TRAIN Batch 138/2100 loss 0.027975 acc 0.983278 lr 0.00013641 grad_norm 0.401449 rank 0
2025-01-11 02:39:01,486 DEBUG TRAIN Batch 138/2100 loss 0.035116 acc 0.974805 lr 0.00013641 grad_norm 0.401449 rank 2
2025-01-11 02:39:01,486 DEBUG TRAIN Batch 138/2100 loss 0.019340 acc 0.986196 lr 0.00013641 grad_norm 0.401449 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 02:40:05,889 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59990ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 02:40:05,902 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 02:40:06,271 INFO Epoch 138 Step 134361 on_batch_end True CV rank 0
2025-01-11 02:40:06,271 INFO Epoch 138 Step 134361 on_batch_end True CV rank 1
2025-01-11 02:40:06,271 INFO Epoch 138 Step 134361 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 02:40:15,283 DEBUG CV Batch 138/100 loss 0.008850 acc 0.996656  rank 0
2025-01-11 02:40:15,769 INFO Epoch 138 Step 134361 CV info lr 0.00013640597387875512 0 rank loss_2.566483709565721 acc_0.7804183739057758
2025-01-11 02:40:15,804 DEBUG CV Batch 138/100 loss 0.008850 acc 0.996656  rank 2
2025-01-11 02:40:15,957 DEBUG CV Batch 138/100 loss 0.008850 acc 0.996656  rank 1
2025-01-11 02:40:16,359 INFO Epoch 138 Step 134361 CV info lr 0.00013640597387875512 2 rank loss_2.566483709565721 acc_0.7804183739057758
2025-01-11 02:40:16,510 INFO Epoch 138 Step 134361 CV info lr 0.00013640597387875512 1 rank loss_2.566483709565721 acc_0.7804183739057758
2025-01-11 02:40:17,055 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_138_whole.pt
2025-01-11 02:40:17,067 INFO Added key: store_based_barrier_key:141 to store for rank: 0
2025-01-11 02:40:17,078 INFO Added key: store_based_barrier_key:141 to store for rank: 1
2025-01-11 02:40:17,078 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:141 with 3 nodes.
2025-01-11 02:40:17,078 INFO Added key: store_based_barrier_key:141 to store for rank: 2
2025-01-11 02:40:17,078 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:141 with 3 nodes.
2025-01-11 02:40:17,080 INFO Epoch 139 TRAIN info lr 0.00013640597387875512 rank 2
2025-01-11 02:40:17,080 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 02:40:17,082 INFO Epoch 139 TRAIN info lr 0.00013640597387875512 rank 1
2025-01-11 02:40:17,082 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 02:40:17,088 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:141 with 3 nodes.
2025-01-11 02:40:17,092 INFO Epoch 139 TRAIN info lr 0.00013640597387875512 rank 0
2025-01-11 02:40:17,093 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 02:40:49,788 DEBUG TRAIN Batch 139/100 loss 0.036568 acc 0.972801 lr 0.00013638 grad_norm 0.396272 rank 2
2025-01-11 02:40:49,788 DEBUG TRAIN Batch 139/100 loss 0.041125 acc 0.975427 lr 0.00013638 grad_norm 0.396272 rank 1
2025-01-11 02:40:49,789 DEBUG TRAIN Batch 139/100 loss 0.040220 acc 0.976215 lr 0.00013638 grad_norm 0.396272 rank 0
2025-01-11 02:41:13,714 DEBUG TRAIN Batch 139/200 loss 0.051291 acc 0.967800 lr 0.00013636 grad_norm 0.440230 rank 1
2025-01-11 02:41:13,714 DEBUG TRAIN Batch 139/200 loss 0.034628 acc 0.977500 lr 0.00013636 grad_norm 0.440230 rank 0
2025-01-11 02:41:13,715 DEBUG TRAIN Batch 139/200 loss 0.038766 acc 0.971816 lr 0.00013636 grad_norm 0.440230 rank 2
2025-01-11 02:41:38,280 DEBUG TRAIN Batch 139/300 loss 0.040427 acc 0.970093 lr 0.00013633 grad_norm 0.395617 rank 1
2025-01-11 02:41:38,281 DEBUG TRAIN Batch 139/300 loss 0.046413 acc 0.966576 lr 0.00013633 grad_norm 0.395617 rank 2
2025-01-11 02:41:38,281 DEBUG TRAIN Batch 139/300 loss 0.033285 acc 0.980257 lr 0.00013633 grad_norm 0.395617 rank 0
2025-01-11 02:42:01,964 DEBUG TRAIN Batch 139/400 loss 0.027360 acc 0.980198 lr 0.00013630 grad_norm 0.401078 rank 2
2025-01-11 02:42:01,964 DEBUG TRAIN Batch 139/400 loss 0.042369 acc 0.974280 lr 0.00013630 grad_norm 0.401078 rank 1
2025-01-11 02:42:01,964 DEBUG TRAIN Batch 139/400 loss 0.034318 acc 0.972458 lr 0.00013630 grad_norm 0.401078 rank 0
2025-01-11 02:42:26,038 DEBUG TRAIN Batch 139/500 loss 0.031310 acc 0.976141 lr 0.00013628 grad_norm 0.394442 rank 1
2025-01-11 02:42:26,038 DEBUG TRAIN Batch 139/500 loss 0.036839 acc 0.976679 lr 0.00013628 grad_norm 0.394442 rank 0
2025-01-11 02:42:26,038 DEBUG TRAIN Batch 139/500 loss 0.042988 acc 0.970942 lr 0.00013628 grad_norm 0.394442 rank 2
2025-01-11 02:42:50,555 DEBUG TRAIN Batch 139/600 loss 0.042324 acc 0.971223 lr 0.00013625 grad_norm 0.366312 rank 1
2025-01-11 02:42:50,556 DEBUG TRAIN Batch 139/600 loss 0.029714 acc 0.979129 lr 0.00013625 grad_norm 0.366312 rank 0
2025-01-11 02:42:50,556 DEBUG TRAIN Batch 139/600 loss 0.028956 acc 0.979167 lr 0.00013625 grad_norm 0.366312 rank 2
2025-01-11 02:43:14,724 DEBUG TRAIN Batch 139/700 loss 0.050166 acc 0.966698 lr 0.00013623 grad_norm 0.396481 rank 1
2025-01-11 02:43:14,724 DEBUG TRAIN Batch 139/700 loss 0.020379 acc 0.985849 lr 0.00013623 grad_norm 0.396481 rank 0
2025-01-11 02:43:14,725 DEBUG TRAIN Batch 139/700 loss 0.031530 acc 0.982437 lr 0.00013623 grad_norm 0.396481 rank 2
2025-01-11 02:43:39,184 DEBUG TRAIN Batch 139/800 loss 0.030507 acc 0.979008 lr 0.00013620 grad_norm 0.394943 rank 1
2025-01-11 02:43:39,184 DEBUG TRAIN Batch 139/800 loss 0.035920 acc 0.973022 lr 0.00013620 grad_norm 0.394943 rank 0
2025-01-11 02:43:39,184 DEBUG TRAIN Batch 139/800 loss 0.033760 acc 0.971370 lr 0.00013620 grad_norm 0.394943 rank 2
2025-01-11 02:44:03,009 DEBUG TRAIN Batch 139/900 loss 0.023175 acc 0.981461 lr 0.00013618 grad_norm 0.408990 rank 1
2025-01-11 02:44:03,010 DEBUG TRAIN Batch 139/900 loss 0.030855 acc 0.977839 lr 0.00013618 grad_norm 0.408990 rank 2
2025-01-11 02:44:03,010 DEBUG TRAIN Batch 139/900 loss 0.049242 acc 0.970435 lr 0.00013618 grad_norm 0.408990 rank 0
2025-01-11 02:44:26,875 DEBUG TRAIN Batch 139/1000 loss 0.029671 acc 0.978175 lr 0.00013615 grad_norm 0.385816 rank 0
2025-01-11 02:44:26,875 DEBUG TRAIN Batch 139/1000 loss 0.040364 acc 0.968680 lr 0.00013615 grad_norm 0.385816 rank 1
2025-01-11 02:44:26,875 DEBUG TRAIN Batch 139/1000 loss 0.033804 acc 0.974147 lr 0.00013615 grad_norm 0.385816 rank 2
2025-01-11 02:44:51,026 DEBUG TRAIN Batch 139/1100 loss 0.033494 acc 0.975124 lr 0.00013613 grad_norm 0.430053 rank 2
2025-01-11 02:44:51,026 DEBUG TRAIN Batch 139/1100 loss 0.032714 acc 0.976153 lr 0.00013613 grad_norm 0.430053 rank 1
2025-01-11 02:44:51,026 DEBUG TRAIN Batch 139/1100 loss 0.033332 acc 0.974863 lr 0.00013613 grad_norm 0.430053 rank 0
2025-01-11 02:45:15,307 DEBUG TRAIN Batch 139/1200 loss 0.042154 acc 0.971831 lr 0.00013610 grad_norm 0.390865 rank 2
2025-01-11 02:45:15,307 DEBUG TRAIN Batch 139/1200 loss 0.040728 acc 0.969342 lr 0.00013610 grad_norm 0.390865 rank 0
2025-01-11 02:45:15,307 DEBUG TRAIN Batch 139/1200 loss 0.036132 acc 0.973936 lr 0.00013610 grad_norm 0.390865 rank 1
2025-01-11 02:45:38,886 DEBUG TRAIN Batch 139/1300 loss 0.045225 acc 0.970134 lr 0.00013608 grad_norm 0.408494 rank 1
2025-01-11 02:45:38,886 DEBUG TRAIN Batch 139/1300 loss 0.035226 acc 0.976693 lr 0.00013608 grad_norm 0.408494 rank 0
2025-01-11 02:45:38,887 DEBUG TRAIN Batch 139/1300 loss 0.040344 acc 0.970120 lr 0.00013608 grad_norm 0.408494 rank 2
2025-01-11 02:46:02,377 DEBUG TRAIN Batch 139/1400 loss 0.037028 acc 0.972381 lr 0.00013605 grad_norm 0.370341 rank 0
2025-01-11 02:46:02,378 DEBUG TRAIN Batch 139/1400 loss 0.036392 acc 0.976364 lr 0.00013605 grad_norm 0.370341 rank 2
2025-01-11 02:46:02,378 DEBUG TRAIN Batch 139/1400 loss 0.033596 acc 0.974592 lr 0.00013605 grad_norm 0.370341 rank 1
2025-01-11 02:46:25,981 DEBUG TRAIN Batch 139/1500 loss 0.043094 acc 0.972973 lr 0.00013603 grad_norm 0.394512 rank 1
2025-01-11 02:46:25,982 DEBUG TRAIN Batch 139/1500 loss 0.028110 acc 0.985185 lr 0.00013603 grad_norm 0.394512 rank 2
2025-01-11 02:46:25,982 DEBUG TRAIN Batch 139/1500 loss 0.042674 acc 0.971190 lr 0.00013603 grad_norm 0.394512 rank 0
2025-01-11 02:46:49,660 DEBUG TRAIN Batch 139/1600 loss 0.041949 acc 0.974261 lr 0.00013600 grad_norm 0.394088 rank 2
2025-01-11 02:46:49,661 DEBUG TRAIN Batch 139/1600 loss 0.032924 acc 0.975758 lr 0.00013600 grad_norm 0.394088 rank 1
2025-01-11 02:46:49,661 DEBUG TRAIN Batch 139/1600 loss 0.035096 acc 0.975928 lr 0.00013600 grad_norm 0.394088 rank 0
2025-01-11 02:47:13,437 DEBUG TRAIN Batch 139/1700 loss 0.035964 acc 0.977055 lr 0.00013598 grad_norm 0.373317 rank 2
2025-01-11 02:47:13,437 DEBUG TRAIN Batch 139/1700 loss 0.033404 acc 0.978102 lr 0.00013598 grad_norm 0.373317 rank 0
2025-01-11 02:47:13,438 DEBUG TRAIN Batch 139/1700 loss 0.023783 acc 0.983373 lr 0.00013598 grad_norm 0.373317 rank 1
2025-01-11 02:47:38,170 DEBUG TRAIN Batch 139/1800 loss 0.039719 acc 0.972692 lr 0.00013595 grad_norm 0.428060 rank 0
2025-01-11 02:47:38,170 DEBUG TRAIN Batch 139/1800 loss 0.052273 acc 0.966425 lr 0.00013595 grad_norm 0.428060 rank 2
2025-01-11 02:47:38,170 DEBUG TRAIN Batch 139/1800 loss 0.035226 acc 0.971690 lr 0.00013595 grad_norm 0.428060 rank 1
2025-01-11 02:48:02,895 DEBUG TRAIN Batch 139/1900 loss 0.033131 acc 0.976017 lr 0.00013593 grad_norm 0.400227 rank 0
2025-01-11 02:48:02,895 DEBUG TRAIN Batch 139/1900 loss 0.035278 acc 0.966455 lr 0.00013593 grad_norm 0.400227 rank 2
2025-01-11 02:48:02,895 DEBUG TRAIN Batch 139/1900 loss 0.022214 acc 0.982343 lr 0.00013593 grad_norm 0.400227 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 02:49:11,321 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 02:49:11,326 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 02:49:11,756 INFO Epoch 139 Step 135328 on_batch_end True CV rank 1
2025-01-11 02:49:11,756 INFO Epoch 139 Step 135328 on_batch_end True CV rank 2
2025-01-11 02:49:11,756 INFO Epoch 139 Step 135328 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 02:49:20,989 DEBUG CV Batch 139/100 loss 0.008699 acc 0.995541  rank 0
2025-01-11 02:49:21,294 DEBUG CV Batch 139/100 loss 0.008699 acc 0.995541  rank 2
2025-01-11 02:49:21,475 INFO Epoch 139 Step 135328 CV info lr 0.0001359177487635188 0 rank loss_2.5917405122951065 acc_0.7805304359971431
2025-01-11 02:49:21,553 DEBUG CV Batch 139/100 loss 0.008699 acc 0.995541  rank 1
2025-01-11 02:49:21,850 INFO Epoch 139 Step 135328 CV info lr 0.0001359177487635188 2 rank loss_2.5917405122951065 acc_0.7805304359971431
2025-01-11 02:49:22,120 INFO Epoch 139 Step 135328 CV info lr 0.0001359177487635188 1 rank loss_2.5917405122951065 acc_0.7805304359971431
2025-01-11 02:49:22,773 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_139_whole.pt
2025-01-11 02:49:22,795 INFO Added key: store_based_barrier_key:142 to store for rank: 0
2025-01-11 02:49:22,795 INFO Added key: store_based_barrier_key:142 to store for rank: 1
2025-01-11 02:49:22,795 INFO Added key: store_based_barrier_key:142 to store for rank: 2
2025-01-11 02:49:22,795 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:142 with 3 nodes.
2025-01-11 02:49:22,795 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:142 with 3 nodes.
2025-01-11 02:49:22,803 INFO Epoch 140 TRAIN info lr 0.0001359177487635188 rank 2
2025-01-11 02:49:22,803 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 02:49:22,804 INFO Epoch 140 TRAIN info lr 0.0001359177487635188 rank 1
2025-01-11 02:49:22,804 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 02:49:22,805 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:142 with 3 nodes.
2025-01-11 02:49:22,810 INFO Epoch 140 TRAIN info lr 0.0001359177487635188 rank 0
2025-01-11 02:49:22,810 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 02:49:55,739 DEBUG TRAIN Batch 140/100 loss 0.043090 acc 0.974385 lr 0.00013589 grad_norm 0.387128 rank 0
2025-01-11 02:49:55,739 DEBUG TRAIN Batch 140/100 loss 0.025704 acc 0.982759 lr 0.00013589 grad_norm 0.387128 rank 1
2025-01-11 02:49:55,739 DEBUG TRAIN Batch 140/100 loss 0.041425 acc 0.969052 lr 0.00013589 grad_norm 0.387128 rank 2
2025-01-11 02:50:19,829 DEBUG TRAIN Batch 140/200 loss 0.038968 acc 0.975893 lr 0.00013587 grad_norm 0.392647 rank 0
2025-01-11 02:50:19,830 DEBUG TRAIN Batch 140/200 loss 0.024996 acc 0.984576 lr 0.00013587 grad_norm 0.392647 rank 1
2025-01-11 02:50:19,830 DEBUG TRAIN Batch 140/200 loss 0.044756 acc 0.968893 lr 0.00013587 grad_norm 0.392647 rank 2
2025-01-11 02:50:43,830 DEBUG TRAIN Batch 140/300 loss 0.029395 acc 0.977969 lr 0.00013584 grad_norm 0.391854 rank 0
2025-01-11 02:50:43,830 DEBUG TRAIN Batch 140/300 loss 0.049122 acc 0.971279 lr 0.00013584 grad_norm 0.391854 rank 2
2025-01-11 02:50:43,831 DEBUG TRAIN Batch 140/300 loss 0.031280 acc 0.977046 lr 0.00013584 grad_norm 0.391854 rank 1
2025-01-11 02:51:07,913 DEBUG TRAIN Batch 140/400 loss 0.033846 acc 0.974558 lr 0.00013582 grad_norm 0.394189 rank 0
2025-01-11 02:51:07,913 DEBUG TRAIN Batch 140/400 loss 0.033003 acc 0.976457 lr 0.00013582 grad_norm 0.394189 rank 1
2025-01-11 02:51:07,913 DEBUG TRAIN Batch 140/400 loss 0.039495 acc 0.972949 lr 0.00013582 grad_norm 0.394189 rank 2
2025-01-11 02:51:32,169 DEBUG TRAIN Batch 140/500 loss 0.043216 acc 0.969081 lr 0.00013579 grad_norm 0.413236 rank 0
2025-01-11 02:51:32,169 DEBUG TRAIN Batch 140/500 loss 0.033476 acc 0.978125 lr 0.00013579 grad_norm 0.413236 rank 1
2025-01-11 02:51:32,170 DEBUG TRAIN Batch 140/500 loss 0.040452 acc 0.972973 lr 0.00013579 grad_norm 0.413236 rank 2
2025-01-11 02:51:56,145 DEBUG TRAIN Batch 140/600 loss 0.034336 acc 0.975108 lr 0.00013577 grad_norm 0.363584 rank 2
2025-01-11 02:51:56,145 DEBUG TRAIN Batch 140/600 loss 0.031781 acc 0.976977 lr 0.00013577 grad_norm 0.363584 rank 0
2025-01-11 02:51:56,146 DEBUG TRAIN Batch 140/600 loss 0.024982 acc 0.982328 lr 0.00013577 grad_norm 0.363584 rank 1
2025-01-11 02:52:21,145 DEBUG TRAIN Batch 140/700 loss 0.019652 acc 0.988543 lr 0.00013574 grad_norm 0.363179 rank 2
2025-01-11 02:52:21,145 DEBUG TRAIN Batch 140/700 loss 0.024599 acc 0.984262 lr 0.00013574 grad_norm 0.363179 rank 0
2025-01-11 02:52:21,146 DEBUG TRAIN Batch 140/700 loss 0.030997 acc 0.976378 lr 0.00013574 grad_norm 0.363179 rank 1
2025-01-11 02:52:45,442 DEBUG TRAIN Batch 140/800 loss 0.039853 acc 0.967742 lr 0.00013572 grad_norm 0.388928 rank 0
2025-01-11 02:52:45,442 DEBUG TRAIN Batch 140/800 loss 0.043561 acc 0.970909 lr 0.00013572 grad_norm 0.388928 rank 1
2025-01-11 02:52:45,442 DEBUG TRAIN Batch 140/800 loss 0.020765 acc 0.987572 lr 0.00013572 grad_norm 0.388928 rank 2
2025-01-11 02:53:08,853 DEBUG TRAIN Batch 140/900 loss 0.036726 acc 0.974561 lr 0.00013569 grad_norm 0.378871 rank 2
2025-01-11 02:53:08,853 DEBUG TRAIN Batch 140/900 loss 0.028223 acc 0.981964 lr 0.00013569 grad_norm 0.378871 rank 1
2025-01-11 02:53:08,853 DEBUG TRAIN Batch 140/900 loss 0.038951 acc 0.977927 lr 0.00013569 grad_norm 0.378871 rank 0
2025-01-11 02:53:33,023 DEBUG TRAIN Batch 140/1000 loss 0.036953 acc 0.977174 lr 0.00013567 grad_norm 0.411480 rank 2
2025-01-11 02:53:33,023 DEBUG TRAIN Batch 140/1000 loss 0.049348 acc 0.970054 lr 0.00013567 grad_norm 0.411480 rank 0
2025-01-11 02:53:33,023 DEBUG TRAIN Batch 140/1000 loss 0.038451 acc 0.971296 lr 0.00013567 grad_norm 0.411480 rank 1
2025-01-11 02:53:57,353 DEBUG TRAIN Batch 140/1100 loss 0.026480 acc 0.982869 lr 0.00013564 grad_norm 0.431923 rank 0
2025-01-11 02:53:57,353 DEBUG TRAIN Batch 140/1100 loss 0.048564 acc 0.969608 lr 0.00013564 grad_norm 0.431923 rank 1
2025-01-11 02:53:57,354 DEBUG TRAIN Batch 140/1100 loss 0.042517 acc 0.973333 lr 0.00013564 grad_norm 0.431923 rank 2
2025-01-11 02:54:21,410 DEBUG TRAIN Batch 140/1200 loss 0.048026 acc 0.968015 lr 0.00013562 grad_norm 0.393404 rank 2
2025-01-11 02:54:21,410 DEBUG TRAIN Batch 140/1200 loss 0.040601 acc 0.969054 lr 0.00013562 grad_norm 0.393404 rank 0
2025-01-11 02:54:21,411 DEBUG TRAIN Batch 140/1200 loss 0.034041 acc 0.978899 lr 0.00013562 grad_norm 0.393404 rank 1
2025-01-11 02:54:45,004 DEBUG TRAIN Batch 140/1300 loss 0.036977 acc 0.977778 lr 0.00013559 grad_norm 0.394696 rank 1
2025-01-11 02:54:45,004 DEBUG TRAIN Batch 140/1300 loss 0.035512 acc 0.972279 lr 0.00013559 grad_norm 0.394696 rank 0
2025-01-11 02:54:45,005 DEBUG TRAIN Batch 140/1300 loss 0.038791 acc 0.979186 lr 0.00013559 grad_norm 0.394696 rank 2
2025-01-11 02:55:09,363 DEBUG TRAIN Batch 140/1400 loss 0.044696 acc 0.969589 lr 0.00013557 grad_norm 0.423538 rank 1
2025-01-11 02:55:09,364 DEBUG TRAIN Batch 140/1400 loss 0.048178 acc 0.973735 lr 0.00013557 grad_norm 0.423538 rank 2
2025-01-11 02:55:09,364 DEBUG TRAIN Batch 140/1400 loss 0.037666 acc 0.973874 lr 0.00013557 grad_norm 0.423538 rank 0
2025-01-11 02:55:33,095 DEBUG TRAIN Batch 140/1500 loss 0.030231 acc 0.977518 lr 0.00013554 grad_norm 0.412135 rank 2
2025-01-11 02:55:33,095 DEBUG TRAIN Batch 140/1500 loss 0.042356 acc 0.972376 lr 0.00013554 grad_norm 0.412135 rank 0
2025-01-11 02:55:33,095 DEBUG TRAIN Batch 140/1500 loss 0.036147 acc 0.972336 lr 0.00013554 grad_norm 0.412135 rank 1
2025-01-11 02:55:57,229 DEBUG TRAIN Batch 140/1600 loss 0.027647 acc 0.979798 lr 0.00013552 grad_norm 0.371861 rank 1
2025-01-11 02:55:57,229 DEBUG TRAIN Batch 140/1600 loss 0.037479 acc 0.968779 lr 0.00013552 grad_norm 0.371861 rank 0
2025-01-11 02:55:57,229 DEBUG TRAIN Batch 140/1600 loss 0.033145 acc 0.976765 lr 0.00013552 grad_norm 0.371861 rank 2
2025-01-11 02:56:21,183 DEBUG TRAIN Batch 140/1700 loss 0.029615 acc 0.984520 lr 0.00013549 grad_norm 0.403820 rank 2
2025-01-11 02:56:21,183 DEBUG TRAIN Batch 140/1700 loss 0.051697 acc 0.960452 lr 0.00013549 grad_norm 0.403820 rank 1
2025-01-11 02:56:21,183 DEBUG TRAIN Batch 140/1700 loss 0.041904 acc 0.976827 lr 0.00013549 grad_norm 0.403820 rank 0
2025-01-11 02:56:46,291 DEBUG TRAIN Batch 140/1800 loss 0.028337 acc 0.977679 lr 0.00013547 grad_norm 0.428838 rank 2
2025-01-11 02:56:46,291 DEBUG TRAIN Batch 140/1800 loss 0.039771 acc 0.971545 lr 0.00013547 grad_norm 0.428838 rank 1
2025-01-11 02:56:46,291 DEBUG TRAIN Batch 140/1800 loss 0.041570 acc 0.974329 lr 0.00013547 grad_norm 0.428838 rank 0
2025-01-11 02:57:12,275 DEBUG TRAIN Batch 140/1900 loss 0.036853 acc 0.972632 lr 0.00013544 grad_norm 0.379021 rank 0
2025-01-11 02:57:12,275 DEBUG TRAIN Batch 140/1900 loss 0.042802 acc 0.972359 lr 0.00013544 grad_norm 0.379021 rank 1
2025-01-11 02:57:12,275 DEBUG TRAIN Batch 140/1900 loss 0.027492 acc 0.983920 lr 0.00013544 grad_norm 0.379021 rank 2
2025-01-11 02:57:36,294 DEBUG TRAIN Batch 140/2000 loss 0.039745 acc 0.966543 lr 0.00013542 grad_norm 0.447069 rank 2
2025-01-11 02:57:36,294 DEBUG TRAIN Batch 140/2000 loss 0.048431 acc 0.972897 lr 0.00013542 grad_norm 0.447069 rank 1
2025-01-11 02:57:36,294 DEBUG TRAIN Batch 140/2000 loss 0.040492 acc 0.974880 lr 0.00013542 grad_norm 0.447069 rank 0
2025-01-11 02:58:00,682 DEBUG TRAIN Batch 140/2100 loss 0.031216 acc 0.977077 lr 0.00013539 grad_norm 0.442993 rank 0
2025-01-11 02:58:00,682 DEBUG TRAIN Batch 140/2100 loss 0.042915 acc 0.978846 lr 0.00013539 grad_norm 0.442993 rank 1
2025-01-11 02:58:00,683 DEBUG TRAIN Batch 140/2100 loss 0.063657 acc 0.960000 lr 0.00013539 grad_norm 0.442993 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 02:59:17,421 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59979ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 02:59:17,444 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 02:59:17,761 INFO Epoch 140 Step 136410 on_batch_end True CV rank 1
2025-01-11 02:59:17,761 INFO Epoch 140 Step 136410 on_batch_end True CV rank 0
2025-01-11 02:59:17,761 INFO Epoch 140 Step 136410 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 02:59:26,670 DEBUG CV Batch 140/100 loss 0.011889 acc 0.996656  rank 0
2025-01-11 02:59:27,091 DEBUG CV Batch 140/100 loss 0.011889 acc 0.996656  rank 2
2025-01-11 02:59:27,192 INFO Epoch 140 Step 136410 CV info lr 0.00013537762783640805 0 rank loss_2.585679917934804 acc_0.7815450705718576
2025-01-11 02:59:27,255 DEBUG CV Batch 140/100 loss 0.011889 acc 0.996656  rank 1
2025-01-11 02:59:27,636 INFO Epoch 140 Step 136410 CV info lr 0.00013537762783640805 2 rank loss_2.585679917934804 acc_0.7815450705718576
2025-01-11 02:59:27,789 INFO Epoch 140 Step 136410 CV info lr 0.00013537762783640805 1 rank loss_2.585679917934804 acc_0.7815450705718576
2025-01-11 02:59:28,481 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_140_whole.pt
2025-01-11 02:59:28,503 INFO Added key: store_based_barrier_key:143 to store for rank: 0
2025-01-11 02:59:28,513 INFO Added key: store_based_barrier_key:143 to store for rank: 2
2025-01-11 02:59:28,514 INFO Added key: store_based_barrier_key:143 to store for rank: 1
2025-01-11 02:59:28,514 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:143 with 3 nodes.
2025-01-11 02:59:28,519 INFO Epoch 141 TRAIN info lr 0.00013537762783640805 rank 1
2025-01-11 02:59:28,519 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 02:59:28,523 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:143 with 3 nodes.
2025-01-11 02:59:28,524 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:143 with 3 nodes.
2025-01-11 02:59:28,524 INFO Epoch 141 TRAIN info lr 0.00013537762783640805 rank 2
2025-01-11 02:59:28,524 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 02:59:28,526 INFO Epoch 141 TRAIN info lr 0.00013537762783640805 rank 0
2025-01-11 02:59:28,526 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 03:00:00,900 DEBUG TRAIN Batch 141/100 loss 0.023912 acc 0.988323 lr 0.00013535 grad_norm 0.378607 rank 2
2025-01-11 03:00:00,900 DEBUG TRAIN Batch 141/100 loss 0.030171 acc 0.981215 lr 0.00013535 grad_norm 0.378607 rank 0
2025-01-11 03:00:00,900 DEBUG TRAIN Batch 141/100 loss 0.038997 acc 0.967380 lr 0.00013535 grad_norm 0.378607 rank 1
2025-01-11 03:00:24,480 DEBUG TRAIN Batch 141/200 loss 0.033429 acc 0.975703 lr 0.00013533 grad_norm 0.385722 rank 2
2025-01-11 03:00:24,480 DEBUG TRAIN Batch 141/200 loss 0.039166 acc 0.970377 lr 0.00013533 grad_norm 0.385722 rank 1
2025-01-11 03:00:24,480 DEBUG TRAIN Batch 141/200 loss 0.018875 acc 0.988318 lr 0.00013533 grad_norm 0.385722 rank 0
2025-01-11 03:00:48,449 DEBUG TRAIN Batch 141/300 loss 0.028037 acc 0.978022 lr 0.00013530 grad_norm 0.406416 rank 0
2025-01-11 03:00:48,449 DEBUG TRAIN Batch 141/300 loss 0.040439 acc 0.974516 lr 0.00013530 grad_norm 0.406416 rank 1
2025-01-11 03:00:48,449 DEBUG TRAIN Batch 141/300 loss 0.032514 acc 0.978763 lr 0.00013530 grad_norm 0.406416 rank 2
2025-01-11 03:01:12,733 DEBUG TRAIN Batch 141/400 loss 0.025212 acc 0.982514 lr 0.00013528 grad_norm 0.376781 rank 1
2025-01-11 03:01:12,733 DEBUG TRAIN Batch 141/400 loss 0.039661 acc 0.971116 lr 0.00013528 grad_norm 0.376781 rank 0
2025-01-11 03:01:12,733 DEBUG TRAIN Batch 141/400 loss 0.036384 acc 0.975258 lr 0.00013528 grad_norm 0.376781 rank 2
2025-01-11 03:01:36,734 DEBUG TRAIN Batch 141/500 loss 0.037432 acc 0.971790 lr 0.00013525 grad_norm 0.382387 rank 1
2025-01-11 03:01:36,735 DEBUG TRAIN Batch 141/500 loss 0.046032 acc 0.966403 lr 0.00013525 grad_norm 0.382387 rank 0
2025-01-11 03:01:36,735 DEBUG TRAIN Batch 141/500 loss 0.034859 acc 0.978474 lr 0.00013525 grad_norm 0.382387 rank 2
2025-01-11 03:02:00,381 DEBUG TRAIN Batch 141/600 loss 0.042922 acc 0.964815 lr 0.00013523 grad_norm 0.431671 rank 1
2025-01-11 03:02:00,381 DEBUG TRAIN Batch 141/600 loss 0.043566 acc 0.975130 lr 0.00013523 grad_norm 0.431671 rank 0
2025-01-11 03:02:00,382 DEBUG TRAIN Batch 141/600 loss 0.049605 acc 0.970044 lr 0.00013523 grad_norm 0.431671 rank 2
2025-01-11 03:02:25,019 DEBUG TRAIN Batch 141/700 loss 0.036836 acc 0.975108 lr 0.00013520 grad_norm 0.402158 rank 1
2025-01-11 03:02:25,019 DEBUG TRAIN Batch 141/700 loss 0.041057 acc 0.972145 lr 0.00013520 grad_norm 0.402158 rank 2
2025-01-11 03:02:25,020 DEBUG TRAIN Batch 141/700 loss 0.020803 acc 0.981612 lr 0.00013520 grad_norm 0.402158 rank 0
2025-01-11 03:02:48,623 DEBUG TRAIN Batch 141/800 loss 0.037776 acc 0.975869 lr 0.00013518 grad_norm 0.399171 rank 2
2025-01-11 03:02:48,623 DEBUG TRAIN Batch 141/800 loss 0.028537 acc 0.982273 lr 0.00013518 grad_norm 0.399171 rank 1
2025-01-11 03:02:48,623 DEBUG TRAIN Batch 141/800 loss 0.041185 acc 0.970588 lr 0.00013518 grad_norm 0.399171 rank 0
2025-01-11 03:03:12,685 DEBUG TRAIN Batch 141/900 loss 0.046773 acc 0.966116 lr 0.00013515 grad_norm 0.408423 rank 2
2025-01-11 03:03:12,685 DEBUG TRAIN Batch 141/900 loss 0.053482 acc 0.971453 lr 0.00013515 grad_norm 0.408423 rank 0
2025-01-11 03:03:12,685 DEBUG TRAIN Batch 141/900 loss 0.044222 acc 0.963973 lr 0.00013515 grad_norm 0.408423 rank 1
2025-01-11 03:03:36,343 DEBUG TRAIN Batch 141/1000 loss 0.025880 acc 0.981785 lr 0.00013513 grad_norm 0.390771 rank 2
2025-01-11 03:03:36,344 DEBUG TRAIN Batch 141/1000 loss 0.031109 acc 0.978821 lr 0.00013513 grad_norm 0.390771 rank 0
2025-01-11 03:03:36,344 DEBUG TRAIN Batch 141/1000 loss 0.043325 acc 0.968927 lr 0.00013513 grad_norm 0.390771 rank 1
2025-01-11 03:03:59,992 DEBUG TRAIN Batch 141/1100 loss 0.039799 acc 0.967472 lr 0.00013511 grad_norm 0.400995 rank 1
2025-01-11 03:03:59,992 DEBUG TRAIN Batch 141/1100 loss 0.041387 acc 0.974860 lr 0.00013511 grad_norm 0.400995 rank 2
2025-01-11 03:03:59,993 DEBUG TRAIN Batch 141/1100 loss 0.042219 acc 0.969697 lr 0.00013511 grad_norm 0.400995 rank 0
2025-01-11 03:04:23,332 DEBUG TRAIN Batch 141/1200 loss 0.037661 acc 0.974153 lr 0.00013508 grad_norm 0.360807 rank 1
2025-01-11 03:04:23,332 DEBUG TRAIN Batch 141/1200 loss 0.042291 acc 0.972097 lr 0.00013508 grad_norm 0.360807 rank 0
2025-01-11 03:04:23,333 DEBUG TRAIN Batch 141/1200 loss 0.029479 acc 0.983319 lr 0.00013508 grad_norm 0.360807 rank 2
2025-01-11 03:04:46,918 DEBUG TRAIN Batch 141/1300 loss 0.036277 acc 0.976143 lr 0.00013506 grad_norm 0.372251 rank 1
2025-01-11 03:04:46,918 DEBUG TRAIN Batch 141/1300 loss 0.033483 acc 0.975610 lr 0.00013506 grad_norm 0.372251 rank 0
2025-01-11 03:04:46,918 DEBUG TRAIN Batch 141/1300 loss 0.037015 acc 0.973753 lr 0.00013506 grad_norm 0.372251 rank 2
2025-01-11 03:05:11,478 DEBUG TRAIN Batch 141/1400 loss 0.033361 acc 0.975639 lr 0.00013503 grad_norm 0.396835 rank 1
2025-01-11 03:05:11,478 DEBUG TRAIN Batch 141/1400 loss 0.034461 acc 0.979270 lr 0.00013503 grad_norm 0.396835 rank 2
2025-01-11 03:05:11,478 DEBUG TRAIN Batch 141/1400 loss 0.030943 acc 0.974528 lr 0.00013503 grad_norm 0.396835 rank 0
2025-01-11 03:05:36,161 DEBUG TRAIN Batch 141/1500 loss 0.018633 acc 0.991857 lr 0.00013501 grad_norm 0.395938 rank 2
2025-01-11 03:05:36,161 DEBUG TRAIN Batch 141/1500 loss 0.047896 acc 0.968722 lr 0.00013501 grad_norm 0.395938 rank 0
2025-01-11 03:05:36,161 DEBUG TRAIN Batch 141/1500 loss 0.041708 acc 0.973612 lr 0.00013501 grad_norm 0.395938 rank 1
2025-01-11 03:05:59,738 DEBUG TRAIN Batch 141/1600 loss 0.037460 acc 0.977574 lr 0.00013498 grad_norm 0.436038 rank 0
2025-01-11 03:05:59,738 DEBUG TRAIN Batch 141/1600 loss 0.037830 acc 0.976766 lr 0.00013498 grad_norm 0.436038 rank 1
2025-01-11 03:05:59,738 DEBUG TRAIN Batch 141/1600 loss 0.033055 acc 0.972384 lr 0.00013498 grad_norm 0.436038 rank 2
2025-01-11 03:06:24,210 DEBUG TRAIN Batch 141/1700 loss 0.034447 acc 0.979167 lr 0.00013496 grad_norm 0.399294 rank 0
2025-01-11 03:06:24,210 DEBUG TRAIN Batch 141/1700 loss 0.022758 acc 0.982100 lr 0.00013496 grad_norm 0.399294 rank 2
2025-01-11 03:06:24,211 DEBUG TRAIN Batch 141/1700 loss 0.050781 acc 0.965517 lr 0.00013496 grad_norm 0.399294 rank 1
2025-01-11 03:06:49,125 DEBUG TRAIN Batch 141/1800 loss 0.044490 acc 0.972167 lr 0.00013493 grad_norm 0.399355 rank 1
2025-01-11 03:06:49,125 DEBUG TRAIN Batch 141/1800 loss 0.050094 acc 0.963922 lr 0.00013493 grad_norm 0.399355 rank 0
2025-01-11 03:06:49,125 DEBUG TRAIN Batch 141/1800 loss 0.023004 acc 0.984060 lr 0.00013493 grad_norm 0.399355 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 03:07:53,247 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 03:07:53,247 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 03:07:53,733 INFO Epoch 141 Step 137318 on_batch_end True CV rank 0
2025-01-11 03:07:53,733 INFO Epoch 141 Step 137318 on_batch_end True CV rank 2
2025-01-11 03:07:53,733 INFO Epoch 141 Step 137318 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 03:08:03,043 DEBUG CV Batch 141/100 loss 0.003075 acc 0.998885  rank 0
2025-01-11 03:08:03,285 DEBUG CV Batch 141/100 loss 0.003075 acc 0.998885  rank 2
2025-01-11 03:08:03,562 INFO Epoch 141 Step 137318 CV info lr 0.00013492930072644182 0 rank loss_2.5865939122072232 acc_0.7807611295005732
2025-01-11 03:08:03,600 DEBUG CV Batch 141/100 loss 0.003075 acc 0.998885  rank 1
2025-01-11 03:08:03,845 INFO Epoch 141 Step 137318 CV info lr 0.00013492930072644182 2 rank loss_2.5865939122072232 acc_0.7807611295005732
2025-01-11 03:08:04,161 INFO Epoch 141 Step 137318 CV info lr 0.00013492930072644182 1 rank loss_2.5865939122072232 acc_0.7807611295005732
2025-01-11 03:08:05,011 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_141_whole.pt
2025-01-11 03:08:05,033 INFO Added key: store_based_barrier_key:144 to store for rank: 0
2025-01-11 03:08:05,033 INFO Added key: store_based_barrier_key:144 to store for rank: 2
2025-01-11 03:08:05,033 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:144 with 3 nodes.
2025-01-11 03:08:05,033 INFO Added key: store_based_barrier_key:144 to store for rank: 1
2025-01-11 03:08:05,034 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:144 with 3 nodes.
2025-01-11 03:08:05,036 INFO Epoch 142 TRAIN info lr 0.00013492930072644182 rank 1
2025-01-11 03:08:05,036 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 03:08:05,043 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:144 with 3 nodes.
2025-01-11 03:08:05,043 INFO Epoch 142 TRAIN info lr 0.00013492930072644182 rank 2
2025-01-11 03:08:05,043 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 03:08:05,046 INFO Epoch 142 TRAIN info lr 0.00013492930072644182 rank 0
2025-01-11 03:08:05,046 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 03:08:38,807 DEBUG TRAIN Batch 142/100 loss 0.062149 acc 0.966935 lr 0.00013490 grad_norm 0.371724 rank 0
2025-01-11 03:08:38,807 DEBUG TRAIN Batch 142/100 loss 0.023444 acc 0.985958 lr 0.00013490 grad_norm 0.371724 rank 1
2025-01-11 03:08:38,807 DEBUG TRAIN Batch 142/100 loss 0.028298 acc 0.982997 lr 0.00013490 grad_norm 0.371724 rank 2
2025-01-11 03:09:02,743 DEBUG TRAIN Batch 142/200 loss 0.050537 acc 0.967320 lr 0.00013488 grad_norm 0.349521 rank 0
2025-01-11 03:09:02,743 DEBUG TRAIN Batch 142/200 loss 0.016997 acc 0.985882 lr 0.00013488 grad_norm 0.349521 rank 1
2025-01-11 03:09:02,744 DEBUG TRAIN Batch 142/200 loss 0.015593 acc 0.988608 lr 0.00013488 grad_norm 0.349521 rank 2
2025-01-11 03:09:27,136 DEBUG TRAIN Batch 142/300 loss 0.028976 acc 0.981430 lr 0.00013486 grad_norm 0.381664 rank 1
2025-01-11 03:09:27,136 DEBUG TRAIN Batch 142/300 loss 0.029928 acc 0.973251 lr 0.00013486 grad_norm 0.381664 rank 0
2025-01-11 03:09:27,137 DEBUG TRAIN Batch 142/300 loss 0.023458 acc 0.986830 lr 0.00013486 grad_norm 0.381664 rank 2
2025-01-11 03:09:51,150 DEBUG TRAIN Batch 142/400 loss 0.031246 acc 0.980882 lr 0.00013483 grad_norm 0.382668 rank 1
2025-01-11 03:09:51,150 DEBUG TRAIN Batch 142/400 loss 0.017758 acc 0.987830 lr 0.00013483 grad_norm 0.382668 rank 0
2025-01-11 03:09:51,151 DEBUG TRAIN Batch 142/400 loss 0.031427 acc 0.979487 lr 0.00013483 grad_norm 0.382668 rank 2
2025-01-11 03:10:15,394 DEBUG TRAIN Batch 142/500 loss 0.036308 acc 0.968220 lr 0.00013481 grad_norm 0.405023 rank 0
2025-01-11 03:10:15,394 DEBUG TRAIN Batch 142/500 loss 0.035851 acc 0.973060 lr 0.00013481 grad_norm 0.405023 rank 1
2025-01-11 03:10:15,395 DEBUG TRAIN Batch 142/500 loss 0.037746 acc 0.969072 lr 0.00013481 grad_norm 0.405023 rank 2
2025-01-11 03:10:38,900 DEBUG TRAIN Batch 142/600 loss 0.036771 acc 0.980304 lr 0.00013478 grad_norm 0.377165 rank 2
2025-01-11 03:10:38,900 DEBUG TRAIN Batch 142/600 loss 0.047669 acc 0.966912 lr 0.00013478 grad_norm 0.377165 rank 1
2025-01-11 03:10:38,901 DEBUG TRAIN Batch 142/600 loss 0.029109 acc 0.980874 lr 0.00013478 grad_norm 0.377165 rank 0
2025-01-11 03:11:03,136 DEBUG TRAIN Batch 142/700 loss 0.029615 acc 0.982828 lr 0.00013476 grad_norm 0.379219 rank 1
2025-01-11 03:11:03,137 DEBUG TRAIN Batch 142/700 loss 0.034278 acc 0.974619 lr 0.00013476 grad_norm 0.379219 rank 0
2025-01-11 03:11:03,137 DEBUG TRAIN Batch 142/700 loss 0.035004 acc 0.981079 lr 0.00013476 grad_norm 0.379219 rank 2
2025-01-11 03:11:27,495 DEBUG TRAIN Batch 142/800 loss 0.034582 acc 0.974212 lr 0.00013473 grad_norm 0.383933 rank 1
2025-01-11 03:11:27,495 DEBUG TRAIN Batch 142/800 loss 0.035155 acc 0.971458 lr 0.00013473 grad_norm 0.383933 rank 2
2025-01-11 03:11:27,496 DEBUG TRAIN Batch 142/800 loss 0.040308 acc 0.974384 lr 0.00013473 grad_norm 0.383933 rank 0
2025-01-11 03:11:51,638 DEBUG TRAIN Batch 142/900 loss 0.030213 acc 0.978208 lr 0.00013471 grad_norm 0.395508 rank 2
2025-01-11 03:11:51,638 DEBUG TRAIN Batch 142/900 loss 0.024143 acc 0.983114 lr 0.00013471 grad_norm 0.395508 rank 1
2025-01-11 03:11:51,638 DEBUG TRAIN Batch 142/900 loss 0.042215 acc 0.966084 lr 0.00013471 grad_norm 0.395508 rank 0
2025-01-11 03:12:15,086 DEBUG TRAIN Batch 142/1000 loss 0.044184 acc 0.973732 lr 0.00013468 grad_norm 0.373216 rank 1
2025-01-11 03:12:15,087 DEBUG TRAIN Batch 142/1000 loss 0.038339 acc 0.975733 lr 0.00013468 grad_norm 0.373216 rank 0
2025-01-11 03:12:15,090 DEBUG TRAIN Batch 142/1000 loss 0.031825 acc 0.976281 lr 0.00013468 grad_norm 0.373216 rank 2
2025-01-11 03:12:38,858 DEBUG TRAIN Batch 142/1100 loss 0.039912 acc 0.971668 lr 0.00013466 grad_norm 0.401508 rank 1
2025-01-11 03:12:38,858 DEBUG TRAIN Batch 142/1100 loss 0.033211 acc 0.974104 lr 0.00013466 grad_norm 0.401508 rank 0
2025-01-11 03:12:38,859 DEBUG TRAIN Batch 142/1100 loss 0.041879 acc 0.971098 lr 0.00013466 grad_norm 0.401508 rank 2
2025-01-11 03:13:02,671 DEBUG TRAIN Batch 142/1200 loss 0.032408 acc 0.980989 lr 0.00013464 grad_norm 0.390728 rank 0
2025-01-11 03:13:02,671 DEBUG TRAIN Batch 142/1200 loss 0.043384 acc 0.967003 lr 0.00013464 grad_norm 0.390728 rank 1
2025-01-11 03:13:02,671 DEBUG TRAIN Batch 142/1200 loss 0.032569 acc 0.979042 lr 0.00013464 grad_norm 0.390728 rank 2
2025-01-11 03:13:26,726 DEBUG TRAIN Batch 142/1300 loss 0.043553 acc 0.975893 lr 0.00013461 grad_norm 0.389590 rank 0
2025-01-11 03:13:26,726 DEBUG TRAIN Batch 142/1300 loss 0.031361 acc 0.971719 lr 0.00013461 grad_norm 0.389590 rank 1
2025-01-11 03:13:26,726 DEBUG TRAIN Batch 142/1300 loss 0.040914 acc 0.970270 lr 0.00013461 grad_norm 0.389590 rank 2
2025-01-11 03:13:52,390 DEBUG TRAIN Batch 142/1400 loss 0.041252 acc 0.964738 lr 0.00013459 grad_norm 0.437515 rank 1
2025-01-11 03:13:52,390 DEBUG TRAIN Batch 142/1400 loss 0.036394 acc 0.970852 lr 0.00013459 grad_norm 0.437515 rank 0
2025-01-11 03:13:52,390 DEBUG TRAIN Batch 142/1400 loss 0.024352 acc 0.986301 lr 0.00013459 grad_norm 0.437515 rank 2
2025-01-11 03:14:16,848 DEBUG TRAIN Batch 142/1500 loss 0.046978 acc 0.970044 lr 0.00013456 grad_norm 0.392111 rank 2
2025-01-11 03:14:16,848 DEBUG TRAIN Batch 142/1500 loss 0.027214 acc 0.980924 lr 0.00013456 grad_norm 0.392111 rank 0
2025-01-11 03:14:16,848 DEBUG TRAIN Batch 142/1500 loss 0.050316 acc 0.962835 lr 0.00013456 grad_norm 0.392111 rank 1
2025-01-11 03:14:41,830 DEBUG TRAIN Batch 142/1600 loss 0.051562 acc 0.964395 lr 0.00013454 grad_norm 0.430978 rank 1
2025-01-11 03:14:41,830 DEBUG TRAIN Batch 142/1600 loss 0.027278 acc 0.983459 lr 0.00013454 grad_norm 0.430978 rank 0
2025-01-11 03:14:41,831 DEBUG TRAIN Batch 142/1600 loss 0.040193 acc 0.970476 lr 0.00013454 grad_norm 0.430978 rank 2
2025-01-11 03:15:07,833 DEBUG TRAIN Batch 142/1700 loss 0.043174 acc 0.963801 lr 0.00013451 grad_norm 0.407825 rank 1
2025-01-11 03:15:07,833 DEBUG TRAIN Batch 142/1700 loss 0.038826 acc 0.974879 lr 0.00013451 grad_norm 0.407825 rank 0
2025-01-11 03:15:07,834 DEBUG TRAIN Batch 142/1700 loss 0.038761 acc 0.970018 lr 0.00013451 grad_norm 0.407825 rank 2
2025-01-11 03:15:31,149 DEBUG TRAIN Batch 142/1800 loss 0.037424 acc 0.979144 lr 0.00013449 grad_norm 0.394930 rank 0
2025-01-11 03:15:31,149 DEBUG TRAIN Batch 142/1800 loss 0.043831 acc 0.974063 lr 0.00013449 grad_norm 0.394930 rank 1
2025-01-11 03:15:31,149 DEBUG TRAIN Batch 142/1800 loss 0.035172 acc 0.980162 lr 0.00013449 grad_norm 0.394930 rank 2
2025-01-11 03:15:54,967 DEBUG TRAIN Batch 142/1900 loss 0.029700 acc 0.983491 lr 0.00013446 grad_norm 0.438117 rank 1
2025-01-11 03:15:54,967 DEBUG TRAIN Batch 142/1900 loss 0.050362 acc 0.962025 lr 0.00013446 grad_norm 0.438117 rank 0
2025-01-11 03:15:54,967 DEBUG TRAIN Batch 142/1900 loss 0.043624 acc 0.973658 lr 0.00013446 grad_norm 0.438117 rank 2
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 03:17:11,109 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 03:17:11,112 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 03:17:11,526 INFO Epoch 142 Step 138302 on_batch_end True CV rank 1
2025-01-11 03:17:11,526 INFO Epoch 142 Step 138302 on_batch_end True CV rank 0
2025-01-11 03:17:11,526 INFO Epoch 142 Step 138302 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 03:17:20,810 DEBUG CV Batch 142/100 loss 0.008154 acc 0.997770  rank 0
2025-01-11 03:17:20,938 DEBUG CV Batch 142/100 loss 0.008154 acc 0.997770  rank 2
2025-01-11 03:17:21,085 DEBUG CV Batch 142/100 loss 0.008154 acc 0.997770  rank 1
2025-01-11 03:17:21,327 INFO Epoch 142 Step 138302 CV info lr 0.0001344484420378242 0 rank loss_2.592569922482015 acc_0.7814307709534963
2025-01-11 03:17:21,460 INFO Epoch 142 Step 138302 CV info lr 0.0001344484420378242 2 rank loss_2.592569922482015 acc_0.7814307709534963
2025-01-11 03:17:21,617 INFO Epoch 142 Step 138302 CV info lr 0.0001344484420378242 1 rank loss_2.592569922482015 acc_0.7814307709534963
2025-01-11 03:17:22,621 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_142_whole.pt
2025-01-11 03:17:22,643 INFO Added key: store_based_barrier_key:145 to store for rank: 0
2025-01-11 03:17:22,643 INFO Added key: store_based_barrier_key:145 to store for rank: 1
2025-01-11 03:17:22,643 INFO Added key: store_based_barrier_key:145 to store for rank: 2
2025-01-11 03:17:22,644 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:145 with 3 nodes.
2025-01-11 03:17:22,644 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:145 with 3 nodes.
2025-01-11 03:17:22,645 INFO Epoch 143 TRAIN info lr 0.0001344484420378242 rank 2
2025-01-11 03:17:22,645 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 03:17:22,647 INFO Epoch 143 TRAIN info lr 0.0001344484420378242 rank 1
2025-01-11 03:17:22,647 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 03:17:22,654 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:145 with 3 nodes.
2025-01-11 03:17:22,664 INFO Epoch 143 TRAIN info lr 0.0001344484420378242 rank 0
2025-01-11 03:17:22,664 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 03:17:55,786 DEBUG TRAIN Batch 143/100 loss 0.039517 acc 0.971856 lr 0.00013442 grad_norm 0.387046 rank 1
2025-01-11 03:17:55,786 DEBUG TRAIN Batch 143/100 loss 0.033050 acc 0.971638 lr 0.00013442 grad_norm 0.387046 rank 2
2025-01-11 03:17:55,786 DEBUG TRAIN Batch 143/100 loss 0.026178 acc 0.980208 lr 0.00013442 grad_norm 0.387046 rank 0
2025-01-11 03:18:19,900 DEBUG TRAIN Batch 143/200 loss 0.027043 acc 0.974448 lr 0.00013440 grad_norm 0.392064 rank 1
2025-01-11 03:18:19,901 DEBUG TRAIN Batch 143/200 loss 0.045513 acc 0.966994 lr 0.00013440 grad_norm 0.392064 rank 0
2025-01-11 03:18:19,901 DEBUG TRAIN Batch 143/200 loss 0.044269 acc 0.970163 lr 0.00013440 grad_norm 0.392064 rank 2
2025-01-11 03:18:44,115 DEBUG TRAIN Batch 143/300 loss 0.038472 acc 0.977498 lr 0.00013438 grad_norm 0.364567 rank 1
2025-01-11 03:18:44,115 DEBUG TRAIN Batch 143/300 loss 0.031162 acc 0.979592 lr 0.00013438 grad_norm 0.364567 rank 2
2025-01-11 03:18:44,115 DEBUG TRAIN Batch 143/300 loss 0.037483 acc 0.970164 lr 0.00013438 grad_norm 0.364567 rank 0
2025-01-11 03:19:08,433 DEBUG TRAIN Batch 143/400 loss 0.051747 acc 0.965116 lr 0.00013435 grad_norm 0.372208 rank 1
2025-01-11 03:19:08,433 DEBUG TRAIN Batch 143/400 loss 0.039487 acc 0.968421 lr 0.00013435 grad_norm 0.372208 rank 2
2025-01-11 03:19:08,433 DEBUG TRAIN Batch 143/400 loss 0.025759 acc 0.981092 lr 0.00013435 grad_norm 0.372208 rank 0
2025-01-11 03:19:32,631 DEBUG TRAIN Batch 143/500 loss 0.035255 acc 0.971510 lr 0.00013433 grad_norm 0.374712 rank 1
2025-01-11 03:19:32,631 DEBUG TRAIN Batch 143/500 loss 0.033349 acc 0.975096 lr 0.00013433 grad_norm 0.374712 rank 0
2025-01-11 03:19:32,631 DEBUG TRAIN Batch 143/500 loss 0.029909 acc 0.982379 lr 0.00013433 grad_norm 0.374712 rank 2
2025-01-11 03:19:56,616 DEBUG TRAIN Batch 143/600 loss 0.024155 acc 0.986386 lr 0.00013430 grad_norm 0.396242 rank 1
2025-01-11 03:19:56,616 DEBUG TRAIN Batch 143/600 loss 0.039051 acc 0.973381 lr 0.00013430 grad_norm 0.396242 rank 0
2025-01-11 03:19:56,616 DEBUG TRAIN Batch 143/600 loss 0.037237 acc 0.972590 lr 0.00013430 grad_norm 0.396242 rank 2
2025-01-11 03:20:20,787 DEBUG TRAIN Batch 143/700 loss 0.036281 acc 0.978395 lr 0.00013428 grad_norm 0.384138 rank 1
2025-01-11 03:20:20,787 DEBUG TRAIN Batch 143/700 loss 0.033856 acc 0.977982 lr 0.00013428 grad_norm 0.384138 rank 2
2025-01-11 03:20:20,787 DEBUG TRAIN Batch 143/700 loss 0.036382 acc 0.977131 lr 0.00013428 grad_norm 0.384138 rank 0
2025-01-11 03:20:45,438 DEBUG TRAIN Batch 143/800 loss 0.027323 acc 0.980372 lr 0.00013425 grad_norm 0.361160 rank 0
2025-01-11 03:20:45,438 DEBUG TRAIN Batch 143/800 loss 0.039524 acc 0.974359 lr 0.00013425 grad_norm 0.361160 rank 1
2025-01-11 03:20:45,441 DEBUG TRAIN Batch 143/800 loss 0.037958 acc 0.977586 lr 0.00013425 grad_norm 0.361160 rank 2
2025-01-11 03:21:09,257 DEBUG TRAIN Batch 143/900 loss 0.037705 acc 0.969444 lr 0.00013423 grad_norm 0.387526 rank 1
2025-01-11 03:21:09,258 DEBUG TRAIN Batch 143/900 loss 0.042151 acc 0.977273 lr 0.00013423 grad_norm 0.387526 rank 2
2025-01-11 03:21:09,258 DEBUG TRAIN Batch 143/900 loss 0.033788 acc 0.977193 lr 0.00013423 grad_norm 0.387526 rank 0
2025-01-11 03:21:33,313 DEBUG TRAIN Batch 143/1000 loss 0.047108 acc 0.964746 lr 0.00013421 grad_norm 0.423956 rank 1
2025-01-11 03:21:33,314 DEBUG TRAIN Batch 143/1000 loss 0.036485 acc 0.973384 lr 0.00013421 grad_norm 0.423956 rank 0
2025-01-11 03:21:33,314 DEBUG TRAIN Batch 143/1000 loss 0.041551 acc 0.969035 lr 0.00013421 grad_norm 0.423956 rank 2
2025-01-11 03:21:57,352 DEBUG TRAIN Batch 143/1100 loss 0.038846 acc 0.971944 lr 0.00013418 grad_norm 0.390017 rank 1
2025-01-11 03:21:57,352 DEBUG TRAIN Batch 143/1100 loss 0.046113 acc 0.966595 lr 0.00013418 grad_norm 0.390017 rank 2
2025-01-11 03:21:57,352 DEBUG TRAIN Batch 143/1100 loss 0.026605 acc 0.984881 lr 0.00013418 grad_norm 0.390017 rank 0
2025-01-11 03:22:22,072 DEBUG TRAIN Batch 143/1200 loss 0.029376 acc 0.980437 lr 0.00013416 grad_norm 0.383914 rank 1
2025-01-11 03:22:22,072 DEBUG TRAIN Batch 143/1200 loss 0.046280 acc 0.968170 lr 0.00013416 grad_norm 0.383914 rank 2
2025-01-11 03:22:22,072 DEBUG TRAIN Batch 143/1200 loss 0.038504 acc 0.970164 lr 0.00013416 grad_norm 0.383914 rank 0
2025-01-11 03:22:45,909 DEBUG TRAIN Batch 143/1300 loss 0.045963 acc 0.963222 lr 0.00013413 grad_norm 0.395733 rank 1
2025-01-11 03:22:45,909 DEBUG TRAIN Batch 143/1300 loss 0.041155 acc 0.971963 lr 0.00013413 grad_norm 0.395733 rank 2
2025-01-11 03:22:45,909 DEBUG TRAIN Batch 143/1300 loss 0.051052 acc 0.969775 lr 0.00013413 grad_norm 0.395733 rank 0
2025-01-11 03:23:10,569 DEBUG TRAIN Batch 143/1400 loss 0.047243 acc 0.972169 lr 0.00013411 grad_norm 0.411287 rank 2
2025-01-11 03:23:10,569 DEBUG TRAIN Batch 143/1400 loss 0.041875 acc 0.972949 lr 0.00013411 grad_norm 0.411287 rank 0
2025-01-11 03:23:10,570 DEBUG TRAIN Batch 143/1400 loss 0.042491 acc 0.968360 lr 0.00013411 grad_norm 0.411287 rank 1
2025-01-11 03:23:34,336 DEBUG TRAIN Batch 143/1500 loss 0.021233 acc 0.983854 lr 0.00013409 grad_norm 0.375334 rank 1
2025-01-11 03:23:34,336 DEBUG TRAIN Batch 143/1500 loss 0.026147 acc 0.983271 lr 0.00013409 grad_norm 0.375334 rank 0
2025-01-11 03:23:34,336 DEBUG TRAIN Batch 143/1500 loss 0.036863 acc 0.975281 lr 0.00013409 grad_norm 0.375334 rank 2
2025-01-11 03:23:58,386 DEBUG TRAIN Batch 143/1600 loss 0.046180 acc 0.972872 lr 0.00013406 grad_norm 0.425553 rank 0
2025-01-11 03:23:58,386 DEBUG TRAIN Batch 143/1600 loss 0.030693 acc 0.979766 lr 0.00013406 grad_norm 0.425553 rank 1
2025-01-11 03:23:58,386 DEBUG TRAIN Batch 143/1600 loss 0.050204 acc 0.964539 lr 0.00013406 grad_norm 0.425553 rank 2
2025-01-11 03:24:23,555 DEBUG TRAIN Batch 143/1700 loss 0.011010 acc 0.989779 lr 0.00013404 grad_norm 0.372606 rank 1
2025-01-11 03:24:23,556 DEBUG TRAIN Batch 143/1700 loss 0.040229 acc 0.968254 lr 0.00013404 grad_norm 0.372606 rank 0
2025-01-11 03:24:23,556 DEBUG TRAIN Batch 143/1700 loss 0.037784 acc 0.967022 lr 0.00013404 grad_norm 0.372606 rank 2
2025-01-11 03:24:46,934 DEBUG TRAIN Batch 143/1800 loss 0.056546 acc 0.962832 lr 0.00013401 grad_norm 0.391611 rank 0
2025-01-11 03:24:46,935 DEBUG TRAIN Batch 143/1800 loss 0.020614 acc 0.986405 lr 0.00013401 grad_norm 0.391611 rank 1
2025-01-11 03:24:46,935 DEBUG TRAIN Batch 143/1800 loss 0.035718 acc 0.978051 lr 0.00013401 grad_norm 0.391611 rank 2
2025-01-11 03:25:10,760 DEBUG TRAIN Batch 143/1900 loss 0.042224 acc 0.966895 lr 0.00013399 grad_norm 0.399187 rank 0
2025-01-11 03:25:10,760 DEBUG TRAIN Batch 143/1900 loss 0.028691 acc 0.985195 lr 0.00013399 grad_norm 0.399187 rank 1
2025-01-11 03:25:10,760 DEBUG TRAIN Batch 143/1900 loss 0.038391 acc 0.976092 lr 0.00013399 grad_norm 0.399187 rank 2
2025-01-11 03:25:35,642 DEBUG TRAIN Batch 143/2000 loss 0.030322 acc 0.977083 lr 0.00013396 grad_norm 0.372863 rank 1
2025-01-11 03:25:35,642 DEBUG TRAIN Batch 143/2000 loss 0.026670 acc 0.978238 lr 0.00013396 grad_norm 0.372863 rank 2
2025-01-11 03:25:35,642 DEBUG TRAIN Batch 143/2000 loss 0.037730 acc 0.973684 lr 0.00013396 grad_norm 0.372863 rank 0
2025-01-11 03:25:59,610 DEBUG TRAIN Batch 143/2100 loss 0.037604 acc 0.978281 lr 0.00013394 grad_norm 0.387297 rank 0
2025-01-11 03:25:59,611 DEBUG TRAIN Batch 143/2100 loss 0.030723 acc 0.981265 lr 0.00013394 grad_norm 0.387297 rank 1
2025-01-11 03:25:59,611 DEBUG TRAIN Batch 143/2100 loss 0.032573 acc 0.981132 lr 0.00013394 grad_norm 0.387297 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 03:27:02,533 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 03:27:02,535 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 03:27:02,955 INFO Epoch 143 Step 139358 on_batch_end True CV rank 1
2025-01-11 03:27:02,955 INFO Epoch 143 Step 139358 on_batch_end True CV rank 0
2025-01-11 03:27:02,955 INFO Epoch 143 Step 139358 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 03:27:12,258 DEBUG CV Batch 143/100 loss 0.007242 acc 0.997770  rank 0
2025-01-11 03:27:12,502 DEBUG CV Batch 143/100 loss 0.007242 acc 0.997770  rank 2
2025-01-11 03:27:12,711 DEBUG CV Batch 143/100 loss 0.007242 acc 0.997770  rank 1
2025-01-11 03:27:12,758 INFO Epoch 143 Step 139358 CV info lr 0.00013393807470628167 0 rank loss_2.601687948898312 acc_0.7816182520044478
2025-01-11 03:27:13,047 INFO Epoch 143 Step 139358 CV info lr 0.00013393807470628167 2 rank loss_2.601687948898312 acc_0.7816182520044478
2025-01-11 03:27:13,251 INFO Epoch 143 Step 139358 CV info lr 0.00013393807470628167 1 rank loss_2.601687948898312 acc_0.7816182520044478
2025-01-11 03:27:14,042 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_143_whole.pt
2025-01-11 03:27:14,064 INFO Added key: store_based_barrier_key:146 to store for rank: 0
2025-01-11 03:27:14,074 INFO Added key: store_based_barrier_key:146 to store for rank: 2
2025-01-11 03:27:14,074 INFO Added key: store_based_barrier_key:146 to store for rank: 1
2025-01-11 03:27:14,075 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:146 with 3 nodes.
2025-01-11 03:27:14,081 INFO Epoch 144 TRAIN info lr 0.00013393807470628167 rank 1
2025-01-11 03:27:14,081 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 03:27:14,084 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:146 with 3 nodes.
2025-01-11 03:27:14,085 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:146 with 3 nodes.
2025-01-11 03:27:14,085 INFO Epoch 144 TRAIN info lr 0.00013393807470628167 rank 2
2025-01-11 03:27:14,085 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 03:27:14,088 INFO Epoch 144 TRAIN info lr 0.00013393807470628167 rank 0
2025-01-11 03:27:14,088 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 03:27:47,498 DEBUG TRAIN Batch 144/100 loss 0.027734 acc 0.980726 lr 0.00013391 grad_norm 0.364138 rank 2
2025-01-11 03:27:47,498 DEBUG TRAIN Batch 144/100 loss 0.039576 acc 0.978089 lr 0.00013391 grad_norm 0.364138 rank 0
2025-01-11 03:27:47,498 DEBUG TRAIN Batch 144/100 loss 0.029879 acc 0.982473 lr 0.00013391 grad_norm 0.364138 rank 1
2025-01-11 03:28:11,213 DEBUG TRAIN Batch 144/200 loss 0.031503 acc 0.977477 lr 0.00013389 grad_norm 0.408035 rank 1
2025-01-11 03:28:11,214 DEBUG TRAIN Batch 144/200 loss 0.041563 acc 0.964830 lr 0.00013389 grad_norm 0.408035 rank 2
2025-01-11 03:28:11,214 DEBUG TRAIN Batch 144/200 loss 0.034288 acc 0.979651 lr 0.00013389 grad_norm 0.408035 rank 0
2025-01-11 03:28:35,225 DEBUG TRAIN Batch 144/300 loss 0.027422 acc 0.978109 lr 0.00013387 grad_norm 0.410986 rank 0
2025-01-11 03:28:35,225 DEBUG TRAIN Batch 144/300 loss 0.027131 acc 0.981308 lr 0.00013387 grad_norm 0.410986 rank 2
2025-01-11 03:28:35,226 DEBUG TRAIN Batch 144/300 loss 0.042726 acc 0.973173 lr 0.00013387 grad_norm 0.410986 rank 1
2025-01-11 03:28:59,152 DEBUG TRAIN Batch 144/400 loss 0.011656 acc 0.991803 lr 0.00013384 grad_norm 0.372321 rank 0
2025-01-11 03:28:59,152 DEBUG TRAIN Batch 144/400 loss 0.027940 acc 0.976096 lr 0.00013384 grad_norm 0.372321 rank 1
2025-01-11 03:28:59,152 DEBUG TRAIN Batch 144/400 loss 0.038109 acc 0.972115 lr 0.00013384 grad_norm 0.372321 rank 2
2025-01-11 03:29:23,077 DEBUG TRAIN Batch 144/500 loss 0.036404 acc 0.976428 lr 0.00013382 grad_norm 0.395343 rank 1
2025-01-11 03:29:23,077 DEBUG TRAIN Batch 144/500 loss 0.039063 acc 0.973661 lr 0.00013382 grad_norm 0.395343 rank 0
2025-01-11 03:29:23,077 DEBUG TRAIN Batch 144/500 loss 0.032440 acc 0.978220 lr 0.00013382 grad_norm 0.395343 rank 2
2025-01-11 03:29:46,758 DEBUG TRAIN Batch 144/600 loss 0.023241 acc 0.980173 lr 0.00013379 grad_norm 0.370102 rank 0
2025-01-11 03:29:46,758 DEBUG TRAIN Batch 144/600 loss 0.022503 acc 0.986622 lr 0.00013379 grad_norm 0.370102 rank 1
2025-01-11 03:29:46,759 DEBUG TRAIN Batch 144/600 loss 0.029185 acc 0.975232 lr 0.00013379 grad_norm 0.370102 rank 2
2025-01-11 03:30:11,518 DEBUG TRAIN Batch 144/700 loss 0.030344 acc 0.979927 lr 0.00013377 grad_norm 0.381263 rank 0
2025-01-11 03:30:11,518 DEBUG TRAIN Batch 144/700 loss 0.029155 acc 0.979592 lr 0.00013377 grad_norm 0.381263 rank 1
2025-01-11 03:30:11,519 DEBUG TRAIN Batch 144/700 loss 0.024790 acc 0.987805 lr 0.00013377 grad_norm 0.381263 rank 2
2025-01-11 03:30:36,266 DEBUG TRAIN Batch 144/800 loss 0.034266 acc 0.974542 lr 0.00013375 grad_norm 0.391236 rank 1
2025-01-11 03:30:36,266 DEBUG TRAIN Batch 144/800 loss 0.028434 acc 0.977092 lr 0.00013375 grad_norm 0.391236 rank 0
2025-01-11 03:30:36,266 DEBUG TRAIN Batch 144/800 loss 0.030227 acc 0.979487 lr 0.00013375 grad_norm 0.391236 rank 2
2025-01-11 03:31:00,049 DEBUG TRAIN Batch 144/900 loss 0.037569 acc 0.967294 lr 0.00013372 grad_norm 0.364217 rank 2
2025-01-11 03:31:00,049 DEBUG TRAIN Batch 144/900 loss 0.031950 acc 0.977954 lr 0.00013372 grad_norm 0.364217 rank 0
2025-01-11 03:31:00,050 DEBUG TRAIN Batch 144/900 loss 0.036346 acc 0.977022 lr 0.00013372 grad_norm 0.364217 rank 1
2025-01-11 03:31:24,176 DEBUG TRAIN Batch 144/1000 loss 0.036426 acc 0.971505 lr 0.00013370 grad_norm 0.394743 rank 2
2025-01-11 03:31:24,176 DEBUG TRAIN Batch 144/1000 loss 0.030889 acc 0.980331 lr 0.00013370 grad_norm 0.394743 rank 1
2025-01-11 03:31:24,176 DEBUG TRAIN Batch 144/1000 loss 0.028694 acc 0.980498 lr 0.00013370 grad_norm 0.394743 rank 0
2025-01-11 03:31:48,381 DEBUG TRAIN Batch 144/1100 loss 0.036106 acc 0.982938 lr 0.00013367 grad_norm 0.371225 rank 1
2025-01-11 03:31:48,382 DEBUG TRAIN Batch 144/1100 loss 0.036540 acc 0.977407 lr 0.00013367 grad_norm 0.371225 rank 0
2025-01-11 03:31:48,382 DEBUG TRAIN Batch 144/1100 loss 0.028860 acc 0.986006 lr 0.00013367 grad_norm 0.371225 rank 2
2025-01-11 03:32:12,067 DEBUG TRAIN Batch 144/1200 loss 0.025835 acc 0.982724 lr 0.00013365 grad_norm 0.372927 rank 0
2025-01-11 03:32:12,067 DEBUG TRAIN Batch 144/1200 loss 0.042388 acc 0.975133 lr 0.00013365 grad_norm 0.372927 rank 1
2025-01-11 03:32:12,067 DEBUG TRAIN Batch 144/1200 loss 0.029005 acc 0.974286 lr 0.00013365 grad_norm 0.372927 rank 2
2025-01-11 03:32:35,378 DEBUG TRAIN Batch 144/1300 loss 0.044426 acc 0.972222 lr 0.00013363 grad_norm 0.382370 rank 0
2025-01-11 03:32:35,378 DEBUG TRAIN Batch 144/1300 loss 0.022994 acc 0.982759 lr 0.00013363 grad_norm 0.382370 rank 1
2025-01-11 03:32:35,379 DEBUG TRAIN Batch 144/1300 loss 0.031744 acc 0.979610 lr 0.00013363 grad_norm 0.382370 rank 2
2025-01-11 03:32:59,294 DEBUG TRAIN Batch 144/1400 loss 0.051582 acc 0.968511 lr 0.00013360 grad_norm 0.387084 rank 0
2025-01-11 03:32:59,294 DEBUG TRAIN Batch 144/1400 loss 0.039950 acc 0.979346 lr 0.00013360 grad_norm 0.387084 rank 1
2025-01-11 03:32:59,294 DEBUG TRAIN Batch 144/1400 loss 0.030730 acc 0.983425 lr 0.00013360 grad_norm 0.387084 rank 2
2025-01-11 03:33:23,635 DEBUG TRAIN Batch 144/1500 loss 0.025155 acc 0.983657 lr 0.00013358 grad_norm 0.365486 rank 1
2025-01-11 03:33:23,635 DEBUG TRAIN Batch 144/1500 loss 0.039098 acc 0.977113 lr 0.00013358 grad_norm 0.365486 rank 0
2025-01-11 03:33:23,636 DEBUG TRAIN Batch 144/1500 loss 0.013147 acc 0.990115 lr 0.00013358 grad_norm 0.365486 rank 2
2025-01-11 03:33:46,978 DEBUG TRAIN Batch 144/1600 loss 0.031474 acc 0.979129 lr 0.00013356 grad_norm 0.368878 rank 0
2025-01-11 03:33:46,978 DEBUG TRAIN Batch 144/1600 loss 0.033677 acc 0.974237 lr 0.00013356 grad_norm 0.368878 rank 1
2025-01-11 03:33:46,979 DEBUG TRAIN Batch 144/1600 loss 0.023014 acc 0.984267 lr 0.00013356 grad_norm 0.368878 rank 2
2025-01-11 03:34:10,727 DEBUG TRAIN Batch 144/1700 loss 0.035064 acc 0.973090 lr 0.00013353 grad_norm 0.391060 rank 0
2025-01-11 03:34:10,727 DEBUG TRAIN Batch 144/1700 loss 0.040330 acc 0.970268 lr 0.00013353 grad_norm 0.391060 rank 1
2025-01-11 03:34:10,727 DEBUG TRAIN Batch 144/1700 loss 0.035766 acc 0.976534 lr 0.00013353 grad_norm 0.391060 rank 2
2025-01-11 03:34:34,621 DEBUG TRAIN Batch 144/1800 loss 0.040736 acc 0.973767 lr 0.00013351 grad_norm 0.387153 rank 1
2025-01-11 03:34:34,621 DEBUG TRAIN Batch 144/1800 loss 0.044818 acc 0.975057 lr 0.00013351 grad_norm 0.387153 rank 0
2025-01-11 03:34:34,622 DEBUG TRAIN Batch 144/1800 loss 0.025236 acc 0.982422 lr 0.00013351 grad_norm 0.387153 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 03:35:35,680 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 03:35:35,680 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 03:35:36,092 INFO Epoch 144 Step 140260 on_batch_end True CV rank 2
2025-01-11 03:35:36,092 INFO Epoch 144 Step 140260 on_batch_end True CV rank 1
2025-01-11 03:35:36,092 INFO Epoch 144 Step 140260 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 03:35:45,054 DEBUG CV Batch 144/100 loss 0.003240 acc 0.998885  rank 0
2025-01-11 03:35:45,304 DEBUG CV Batch 144/100 loss 0.003240 acc 0.998885  rank 2
2025-01-11 03:35:45,525 INFO Epoch 144 Step 140260 CV info lr 0.00013350670794604524 0 rank loss_2.605470710111835 acc_0.7802138959890917
2025-01-11 03:35:45,625 DEBUG CV Batch 144/100 loss 0.003240 acc 0.998885  rank 1
2025-01-11 03:35:45,854 INFO Epoch 144 Step 140260 CV info lr 0.00013350670794604524 2 rank loss_2.605470710111835 acc_0.7802138959890917
2025-01-11 03:35:46,162 INFO Epoch 144 Step 140260 CV info lr 0.00013350670794604524 1 rank loss_2.605470710111835 acc_0.7802138959890917
2025-01-11 03:35:46,784 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_144_whole.pt
2025-01-11 03:35:46,805 INFO Added key: store_based_barrier_key:147 to store for rank: 0
2025-01-11 03:35:46,816 INFO Added key: store_based_barrier_key:147 to store for rank: 2
2025-01-11 03:35:46,816 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:147 with 3 nodes.
2025-01-11 03:35:46,816 INFO Added key: store_based_barrier_key:147 to store for rank: 1
2025-01-11 03:35:46,816 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:147 with 3 nodes.
2025-01-11 03:35:46,818 INFO Epoch 145 TRAIN info lr 0.00013350670794604524 rank 2
2025-01-11 03:35:46,818 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 03:35:46,821 INFO Epoch 145 TRAIN info lr 0.00013350670794604524 rank 1
2025-01-11 03:35:46,821 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 03:35:46,826 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:147 with 3 nodes.
2025-01-11 03:35:46,834 INFO Epoch 145 TRAIN info lr 0.00013350670794604524 rank 0
2025-01-11 03:35:46,834 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 03:36:17,286 DEBUG TRAIN Batch 145/100 loss 0.034267 acc 0.979614 lr 0.00013348 grad_norm 0.402667 rank 0
2025-01-11 03:36:17,287 DEBUG TRAIN Batch 145/100 loss 0.049591 acc 0.971185 lr 0.00013348 grad_norm 0.402667 rank 2
2025-01-11 03:36:17,287 DEBUG TRAIN Batch 145/100 loss 0.032722 acc 0.976769 lr 0.00013348 grad_norm 0.402667 rank 1
2025-01-11 03:36:41,106 DEBUG TRAIN Batch 145/200 loss 0.039660 acc 0.968066 lr 0.00013346 grad_norm 0.376317 rank 0
2025-01-11 03:36:41,106 DEBUG TRAIN Batch 145/200 loss 0.024080 acc 0.981973 lr 0.00013346 grad_norm 0.376317 rank 1
2025-01-11 03:36:41,106 DEBUG TRAIN Batch 145/200 loss 0.027861 acc 0.976970 lr 0.00013346 grad_norm 0.376317 rank 2
2025-01-11 03:37:04,773 DEBUG TRAIN Batch 145/300 loss 0.037006 acc 0.972897 lr 0.00013344 grad_norm 0.365812 rank 0
2025-01-11 03:37:04,773 DEBUG TRAIN Batch 145/300 loss 0.025127 acc 0.985348 lr 0.00013344 grad_norm 0.365812 rank 1
2025-01-11 03:37:04,773 DEBUG TRAIN Batch 145/300 loss 0.036837 acc 0.973684 lr 0.00013344 grad_norm 0.365812 rank 2
2025-01-11 03:37:28,351 DEBUG TRAIN Batch 145/400 loss 0.028011 acc 0.976812 lr 0.00013341 grad_norm 0.372177 rank 1
2025-01-11 03:37:28,352 DEBUG TRAIN Batch 145/400 loss 0.038713 acc 0.971455 lr 0.00013341 grad_norm 0.372177 rank 2
2025-01-11 03:37:28,352 DEBUG TRAIN Batch 145/400 loss 0.027654 acc 0.983522 lr 0.00013341 grad_norm 0.372177 rank 0
2025-01-11 03:37:52,542 DEBUG TRAIN Batch 145/500 loss 0.028451 acc 0.982863 lr 0.00013339 grad_norm 0.354404 rank 0
2025-01-11 03:37:52,543 DEBUG TRAIN Batch 145/500 loss 0.035829 acc 0.974545 lr 0.00013339 grad_norm 0.354404 rank 2
2025-01-11 03:37:52,546 DEBUG TRAIN Batch 145/500 loss 0.031456 acc 0.977482 lr 0.00013339 grad_norm 0.354404 rank 1
2025-01-11 03:38:16,176 DEBUG TRAIN Batch 145/600 loss 0.041970 acc 0.969271 lr 0.00013336 grad_norm 0.368156 rank 1
2025-01-11 03:38:16,176 DEBUG TRAIN Batch 145/600 loss 0.026415 acc 0.984496 lr 0.00013336 grad_norm 0.368156 rank 2
2025-01-11 03:38:16,176 DEBUG TRAIN Batch 145/600 loss 0.031512 acc 0.980769 lr 0.00013336 grad_norm 0.368156 rank 0
2025-01-11 03:38:39,981 DEBUG TRAIN Batch 145/700 loss 0.032302 acc 0.976585 lr 0.00013334 grad_norm 0.381973 rank 2
2025-01-11 03:38:39,981 DEBUG TRAIN Batch 145/700 loss 0.029460 acc 0.977465 lr 0.00013334 grad_norm 0.381973 rank 1
2025-01-11 03:38:39,981 DEBUG TRAIN Batch 145/700 loss 0.041166 acc 0.967099 lr 0.00013334 grad_norm 0.381973 rank 0
2025-01-11 03:39:03,195 DEBUG TRAIN Batch 145/800 loss 0.030770 acc 0.982318 lr 0.00013332 grad_norm 0.382064 rank 2
2025-01-11 03:39:03,195 DEBUG TRAIN Batch 145/800 loss 0.029467 acc 0.983957 lr 0.00013332 grad_norm 0.382064 rank 1
2025-01-11 03:39:03,195 DEBUG TRAIN Batch 145/800 loss 0.036936 acc 0.973333 lr 0.00013332 grad_norm 0.382064 rank 0
2025-01-11 03:39:27,098 DEBUG TRAIN Batch 145/900 loss 0.032334 acc 0.979437 lr 0.00013329 grad_norm 0.418321 rank 2
2025-01-11 03:39:27,099 DEBUG TRAIN Batch 145/900 loss 0.023745 acc 0.987640 lr 0.00013329 grad_norm 0.418321 rank 0
2025-01-11 03:39:27,099 DEBUG TRAIN Batch 145/900 loss 0.048859 acc 0.969194 lr 0.00013329 grad_norm 0.418321 rank 1
2025-01-11 03:39:51,037 DEBUG TRAIN Batch 145/1000 loss 0.028654 acc 0.972414 lr 0.00013327 grad_norm 0.393021 rank 2
2025-01-11 03:39:51,038 DEBUG TRAIN Batch 145/1000 loss 0.040624 acc 0.970723 lr 0.00013327 grad_norm 0.393021 rank 0
2025-01-11 03:39:51,038 DEBUG TRAIN Batch 145/1000 loss 0.021108 acc 0.983395 lr 0.00013327 grad_norm 0.393021 rank 1
2025-01-11 03:40:15,254 DEBUG TRAIN Batch 145/1100 loss 0.049710 acc 0.965041 lr 0.00013325 grad_norm 0.402941 rank 2
2025-01-11 03:40:15,254 DEBUG TRAIN Batch 145/1100 loss 0.041601 acc 0.973498 lr 0.00013325 grad_norm 0.402941 rank 1
2025-01-11 03:40:15,255 DEBUG TRAIN Batch 145/1100 loss 0.032166 acc 0.977626 lr 0.00013325 grad_norm 0.402941 rank 0
2025-01-11 03:40:39,297 DEBUG TRAIN Batch 145/1200 loss 0.041013 acc 0.972197 lr 0.00013322 grad_norm 0.372548 rank 0
2025-01-11 03:40:39,298 DEBUG TRAIN Batch 145/1200 loss 0.025380 acc 0.983153 lr 0.00013322 grad_norm 0.372548 rank 2
2025-01-11 03:40:39,298 DEBUG TRAIN Batch 145/1200 loss 0.036767 acc 0.979186 lr 0.00013322 grad_norm 0.372548 rank 1
2025-01-11 03:41:03,746 DEBUG TRAIN Batch 145/1300 loss 0.034965 acc 0.977707 lr 0.00013320 grad_norm 0.414931 rank 0
2025-01-11 03:41:03,746 DEBUG TRAIN Batch 145/1300 loss 0.021902 acc 0.985390 lr 0.00013320 grad_norm 0.414931 rank 2
2025-01-11 03:41:03,746 DEBUG TRAIN Batch 145/1300 loss 0.046944 acc 0.972371 lr 0.00013320 grad_norm 0.414931 rank 1
2025-01-11 03:41:28,475 DEBUG TRAIN Batch 145/1400 loss 0.030177 acc 0.979945 lr 0.00013317 grad_norm 0.375731 rank 1
2025-01-11 03:41:28,475 DEBUG TRAIN Batch 145/1400 loss 0.045840 acc 0.968095 lr 0.00013317 grad_norm 0.375731 rank 0
2025-01-11 03:41:28,476 DEBUG TRAIN Batch 145/1400 loss 0.032958 acc 0.978125 lr 0.00013317 grad_norm 0.375731 rank 2
2025-01-11 03:41:52,114 DEBUG TRAIN Batch 145/1500 loss 0.057460 acc 0.964671 lr 0.00013315 grad_norm 0.404397 rank 1
2025-01-11 03:41:52,115 DEBUG TRAIN Batch 145/1500 loss 0.029797 acc 0.978044 lr 0.00013315 grad_norm 0.404397 rank 2
2025-01-11 03:41:52,115 DEBUG TRAIN Batch 145/1500 loss 0.040630 acc 0.971067 lr 0.00013315 grad_norm 0.404397 rank 0
2025-01-11 03:42:16,563 DEBUG TRAIN Batch 145/1600 loss 0.019651 acc 0.984823 lr 0.00013313 grad_norm 0.392463 rank 0
2025-01-11 03:42:16,563 DEBUG TRAIN Batch 145/1600 loss 0.019095 acc 0.986971 lr 0.00013313 grad_norm 0.392463 rank 1
2025-01-11 03:42:16,563 DEBUG TRAIN Batch 145/1600 loss 0.022474 acc 0.987059 lr 0.00013313 grad_norm 0.392463 rank 2
2025-01-11 03:42:41,377 DEBUG TRAIN Batch 145/1700 loss 0.031980 acc 0.981595 lr 0.00013310 grad_norm 0.382840 rank 1
2025-01-11 03:42:41,377 DEBUG TRAIN Batch 145/1700 loss 0.036785 acc 0.973817 lr 0.00013310 grad_norm 0.382840 rank 0
2025-01-11 03:42:41,378 DEBUG TRAIN Batch 145/1700 loss 0.039765 acc 0.970480 lr 0.00013310 grad_norm 0.382840 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 03:44:02,124 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 03:44:02,125 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 03:44:02,592 INFO Epoch 145 Step 141151 on_batch_end True CV rank 1
2025-01-11 03:44:02,592 INFO Epoch 145 Step 141151 on_batch_end True CV rank 0
2025-01-11 03:44:02,592 INFO Epoch 145 Step 141151 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 03:44:11,728 DEBUG CV Batch 145/100 loss 0.000770 acc 1.000000  rank 0
2025-01-11 03:44:11,882 DEBUG CV Batch 145/100 loss 0.000770 acc 1.000000  rank 2
2025-01-11 03:44:12,242 DEBUG CV Batch 145/100 loss 0.000770 acc 1.000000  rank 1
2025-01-11 03:44:12,268 INFO Epoch 145 Step 141151 CV info lr 0.0001330846677432036 0 rank loss_2.619428070034605 acc_0.7793585196660276
2025-01-11 03:44:12,403 INFO Epoch 145 Step 141151 CV info lr 0.0001330846677432036 2 rank loss_2.619428070034605 acc_0.7793585196660276
2025-01-11 03:44:12,788 INFO Epoch 145 Step 141151 CV info lr 0.0001330846677432036 1 rank loss_2.619428070034605 acc_0.7793585196660276
2025-01-11 03:44:13,550 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_145_whole.pt
2025-01-11 03:44:13,572 INFO Added key: store_based_barrier_key:148 to store for rank: 0
2025-01-11 03:44:13,572 INFO Added key: store_based_barrier_key:148 to store for rank: 1
2025-01-11 03:44:13,572 INFO Added key: store_based_barrier_key:148 to store for rank: 2
2025-01-11 03:44:13,572 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:148 with 3 nodes.
2025-01-11 03:44:13,572 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:148 with 3 nodes.
2025-01-11 03:44:13,574 INFO Epoch 146 TRAIN info lr 0.0001330846677432036 rank 2
2025-01-11 03:44:13,574 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 03:44:13,574 INFO Epoch 146 TRAIN info lr 0.0001330846677432036 rank 1
2025-01-11 03:44:13,574 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 03:44:13,582 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:148 with 3 nodes.
2025-01-11 03:44:13,583 INFO Epoch 146 TRAIN info lr 0.0001330846677432036 rank 0
2025-01-11 03:44:13,583 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 03:44:49,828 DEBUG TRAIN Batch 146/100 loss 0.030488 acc 0.976744 lr 0.00013306 grad_norm 0.370896 rank 1
2025-01-11 03:44:49,828 DEBUG TRAIN Batch 146/100 loss 0.036928 acc 0.975806 lr 0.00013306 grad_norm 0.370896 rank 2
2025-01-11 03:44:49,828 DEBUG TRAIN Batch 146/100 loss 0.040004 acc 0.970343 lr 0.00013306 grad_norm 0.370896 rank 0
2025-01-11 03:45:14,008 DEBUG TRAIN Batch 146/200 loss 0.025136 acc 0.981413 lr 0.00013304 grad_norm 0.391647 rank 1
2025-01-11 03:45:14,008 DEBUG TRAIN Batch 146/200 loss 0.030755 acc 0.982293 lr 0.00013304 grad_norm 0.391647 rank 0
2025-01-11 03:45:14,009 DEBUG TRAIN Batch 146/200 loss 0.024821 acc 0.982028 lr 0.00013304 grad_norm 0.391647 rank 2
2025-01-11 03:45:38,432 DEBUG TRAIN Batch 146/300 loss 0.036023 acc 0.972917 lr 0.00013301 grad_norm 0.394283 rank 0
2025-01-11 03:45:38,433 DEBUG TRAIN Batch 146/300 loss 0.030412 acc 0.977713 lr 0.00013301 grad_norm 0.394283 rank 2
2025-01-11 03:45:38,433 DEBUG TRAIN Batch 146/300 loss 0.038149 acc 0.974194 lr 0.00013301 grad_norm 0.394283 rank 1
2025-01-11 03:46:02,162 DEBUG TRAIN Batch 146/400 loss 0.025367 acc 0.982222 lr 0.00013299 grad_norm 0.381245 rank 2
2025-01-11 03:46:02,162 DEBUG TRAIN Batch 146/400 loss 0.031948 acc 0.982161 lr 0.00013299 grad_norm 0.381245 rank 0
2025-01-11 03:46:02,162 DEBUG TRAIN Batch 146/400 loss 0.029690 acc 0.979612 lr 0.00013299 grad_norm 0.381245 rank 1
2025-01-11 03:46:26,774 DEBUG TRAIN Batch 146/500 loss 0.028736 acc 0.981463 lr 0.00013297 grad_norm 0.381112 rank 1
2025-01-11 03:46:26,774 DEBUG TRAIN Batch 146/500 loss 0.038550 acc 0.975543 lr 0.00013297 grad_norm 0.381112 rank 0
2025-01-11 03:46:26,774 DEBUG TRAIN Batch 146/500 loss 0.019065 acc 0.982456 lr 0.00013297 grad_norm 0.381112 rank 2
2025-01-11 03:46:51,703 DEBUG TRAIN Batch 146/600 loss 0.032677 acc 0.981678 lr 0.00013294 grad_norm 0.361085 rank 0
2025-01-11 03:46:51,704 DEBUG TRAIN Batch 146/600 loss 0.038235 acc 0.973610 lr 0.00013294 grad_norm 0.361085 rank 2
2025-01-11 03:46:51,704 DEBUG TRAIN Batch 146/600 loss 0.032462 acc 0.977273 lr 0.00013294 grad_norm 0.361085 rank 1
2025-01-11 03:47:15,211 DEBUG TRAIN Batch 146/700 loss 0.043415 acc 0.976695 lr 0.00013292 grad_norm 0.401720 rank 1
2025-01-11 03:47:15,211 DEBUG TRAIN Batch 146/700 loss 0.032673 acc 0.980639 lr 0.00013292 grad_norm 0.401720 rank 0
2025-01-11 03:47:15,212 DEBUG TRAIN Batch 146/700 loss 0.042706 acc 0.971513 lr 0.00013292 grad_norm 0.401720 rank 2
2025-01-11 03:47:40,379 DEBUG TRAIN Batch 146/800 loss 0.034671 acc 0.974038 lr 0.00013290 grad_norm 0.367759 rank 0
2025-01-11 03:47:40,379 DEBUG TRAIN Batch 146/800 loss 0.034882 acc 0.975538 lr 0.00013290 grad_norm 0.367759 rank 1
2025-01-11 03:47:40,379 DEBUG TRAIN Batch 146/800 loss 0.028495 acc 0.977211 lr 0.00013290 grad_norm 0.367759 rank 2
2025-01-11 03:48:04,057 DEBUG TRAIN Batch 146/900 loss 0.023936 acc 0.982347 lr 0.00013287 grad_norm 0.380358 rank 1
2025-01-11 03:48:04,057 DEBUG TRAIN Batch 146/900 loss 0.034819 acc 0.981972 lr 0.00013287 grad_norm 0.380358 rank 2
2025-01-11 03:48:04,059 DEBUG TRAIN Batch 146/900 loss 0.024589 acc 0.981174 lr 0.00013287 grad_norm 0.380358 rank 0
2025-01-11 03:48:28,101 DEBUG TRAIN Batch 146/1000 loss 0.026176 acc 0.986234 lr 0.00013285 grad_norm 0.370194 rank 1
2025-01-11 03:48:28,101 DEBUG TRAIN Batch 146/1000 loss 0.027226 acc 0.978261 lr 0.00013285 grad_norm 0.370194 rank 2
2025-01-11 03:48:28,101 DEBUG TRAIN Batch 146/1000 loss 0.024476 acc 0.984848 lr 0.00013285 grad_norm 0.370194 rank 0
2025-01-11 03:48:53,220 DEBUG TRAIN Batch 146/1100 loss 0.035335 acc 0.980924 lr 0.00013283 grad_norm 0.373688 rank 1
2025-01-11 03:48:53,220 DEBUG TRAIN Batch 146/1100 loss 0.035412 acc 0.977106 lr 0.00013283 grad_norm 0.373688 rank 2
2025-01-11 03:48:53,221 DEBUG TRAIN Batch 146/1100 loss 0.025042 acc 0.981328 lr 0.00013283 grad_norm 0.373688 rank 0
2025-01-11 03:49:17,017 DEBUG TRAIN Batch 146/1200 loss 0.039054 acc 0.976326 lr 0.00013280 grad_norm 0.375524 rank 0
2025-01-11 03:49:17,017 DEBUG TRAIN Batch 146/1200 loss 0.032144 acc 0.978122 lr 0.00013280 grad_norm 0.375524 rank 1
2025-01-11 03:49:17,018 DEBUG TRAIN Batch 146/1200 loss 0.029781 acc 0.981132 lr 0.00013280 grad_norm 0.375524 rank 2
2025-01-11 03:49:41,531 DEBUG TRAIN Batch 146/1300 loss 0.015775 acc 0.987097 lr 0.00013278 grad_norm 0.368220 rank 1
2025-01-11 03:49:41,532 DEBUG TRAIN Batch 146/1300 loss 0.032580 acc 0.979981 lr 0.00013278 grad_norm 0.368220 rank 2
2025-01-11 03:49:41,532 DEBUG TRAIN Batch 146/1300 loss 0.041990 acc 0.966292 lr 0.00013278 grad_norm 0.368220 rank 0
2025-01-11 03:50:05,574 DEBUG TRAIN Batch 146/1400 loss 0.029967 acc 0.977798 lr 0.00013276 grad_norm 0.360570 rank 1
2025-01-11 03:50:05,575 DEBUG TRAIN Batch 146/1400 loss 0.027724 acc 0.978723 lr 0.00013276 grad_norm 0.360570 rank 0
2025-01-11 03:50:05,575 DEBUG TRAIN Batch 146/1400 loss 0.023954 acc 0.986416 lr 0.00013276 grad_norm 0.360570 rank 2
2025-01-11 03:50:29,704 DEBUG TRAIN Batch 146/1500 loss 0.033080 acc 0.979268 lr 0.00013273 grad_norm 0.412545 rank 1
2025-01-11 03:50:29,704 DEBUG TRAIN Batch 146/1500 loss 0.046181 acc 0.969805 lr 0.00013273 grad_norm 0.412545 rank 0
2025-01-11 03:50:29,704 DEBUG TRAIN Batch 146/1500 loss 0.035543 acc 0.976190 lr 0.00013273 grad_norm 0.412545 rank 2
2025-01-11 03:50:53,728 DEBUG TRAIN Batch 146/1600 loss 0.026119 acc 0.980207 lr 0.00013271 grad_norm 0.379022 rank 1
2025-01-11 03:50:53,728 DEBUG TRAIN Batch 146/1600 loss 0.054318 acc 0.965766 lr 0.00013271 grad_norm 0.379022 rank 2
2025-01-11 03:50:53,728 DEBUG TRAIN Batch 146/1600 loss 0.032238 acc 0.976767 lr 0.00013271 grad_norm 0.379022 rank 0
2025-01-11 03:51:18,192 DEBUG TRAIN Batch 146/1700 loss 0.027936 acc 0.979343 lr 0.00013269 grad_norm 0.416432 rank 1
2025-01-11 03:51:18,192 DEBUG TRAIN Batch 146/1700 loss 0.034390 acc 0.971910 lr 0.00013269 grad_norm 0.416432 rank 2
2025-01-11 03:51:18,193 DEBUG TRAIN Batch 146/1700 loss 0.026521 acc 0.984356 lr 0.00013269 grad_norm 0.416432 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 03:52:41,469 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 03:52:41,474 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 03:52:41,897 INFO Epoch 146 Step 142049 on_batch_end True CV rank 1
2025-01-11 03:52:41,897 INFO Epoch 146 Step 142049 on_batch_end True CV rank 0
2025-01-11 03:52:41,897 INFO Epoch 146 Step 142049 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 03:52:50,794 DEBUG CV Batch 146/100 loss 0.003292 acc 0.998885  rank 0
2025-01-11 03:52:51,281 INFO Epoch 146 Step 142049 CV info lr 0.00013266333598611394 0 rank loss_2.614060087006676 acc_0.7797041281796339
2025-01-11 03:52:51,298 DEBUG CV Batch 146/100 loss 0.003292 acc 0.998885  rank 2
2025-01-11 03:52:51,464 DEBUG CV Batch 146/100 loss 0.003292 acc 0.998885  rank 1
2025-01-11 03:52:51,846 INFO Epoch 146 Step 142049 CV info lr 0.00013266333598611394 2 rank loss_2.614060087006676 acc_0.7797041281796339
2025-01-11 03:52:52,002 INFO Epoch 146 Step 142049 CV info lr 0.00013266333598611394 1 rank loss_2.614060087006676 acc_0.7797041281796339
2025-01-11 03:52:52,550 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_146_whole.pt
2025-01-11 03:52:52,571 INFO Added key: store_based_barrier_key:149 to store for rank: 0
2025-01-11 03:52:52,582 INFO Added key: store_based_barrier_key:149 to store for rank: 2
2025-01-11 03:52:52,582 INFO Added key: store_based_barrier_key:149 to store for rank: 1
2025-01-11 03:52:52,582 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:149 with 3 nodes.
2025-01-11 03:52:52,582 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:149 with 3 nodes.
2025-01-11 03:52:52,584 INFO Epoch 147 TRAIN info lr 0.00013266333598611394 rank 2
2025-01-11 03:52:52,584 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 03:52:52,592 INFO Epoch 147 TRAIN info lr 0.00013266333598611394 rank 1
2025-01-11 03:52:52,592 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:149 with 3 nodes.
2025-01-11 03:52:52,592 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 03:52:52,594 INFO Epoch 147 TRAIN info lr 0.00013266333598611394 rank 0
2025-01-11 03:52:52,594 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 03:53:26,125 DEBUG TRAIN Batch 147/100 loss 0.030113 acc 0.981634 lr 0.00013264 grad_norm 0.354257 rank 0
2025-01-11 03:53:26,125 DEBUG TRAIN Batch 147/100 loss 0.037011 acc 0.973869 lr 0.00013264 grad_norm 0.354257 rank 2
2025-01-11 03:53:26,125 DEBUG TRAIN Batch 147/100 loss 0.025717 acc 0.982285 lr 0.00013264 grad_norm 0.354257 rank 1
2025-01-11 03:53:49,927 DEBUG TRAIN Batch 147/200 loss 0.040969 acc 0.970233 lr 0.00013262 grad_norm 0.382867 rank 1
2025-01-11 03:53:49,928 DEBUG TRAIN Batch 147/200 loss 0.025571 acc 0.980804 lr 0.00013262 grad_norm 0.382867 rank 0
2025-01-11 03:53:49,928 DEBUG TRAIN Batch 147/200 loss 0.021979 acc 0.985879 lr 0.00013262 grad_norm 0.382867 rank 2
2025-01-11 03:54:14,028 DEBUG TRAIN Batch 147/300 loss 0.026024 acc 0.981409 lr 0.00013259 grad_norm 0.368923 rank 2
2025-01-11 03:54:14,028 DEBUG TRAIN Batch 147/300 loss 0.045858 acc 0.969973 lr 0.00013259 grad_norm 0.368923 rank 0
2025-01-11 03:54:14,029 DEBUG TRAIN Batch 147/300 loss 0.034854 acc 0.975543 lr 0.00013259 grad_norm 0.368923 rank 1
2025-01-11 03:54:37,983 DEBUG TRAIN Batch 147/400 loss 0.037035 acc 0.971831 lr 0.00013257 grad_norm 0.396853 rank 1
2025-01-11 03:54:37,983 DEBUG TRAIN Batch 147/400 loss 0.024273 acc 0.981896 lr 0.00013257 grad_norm 0.396853 rank 2
2025-01-11 03:54:37,984 DEBUG TRAIN Batch 147/400 loss 0.039931 acc 0.975198 lr 0.00013257 grad_norm 0.396853 rank 0
2025-01-11 03:55:01,815 DEBUG TRAIN Batch 147/500 loss 0.045876 acc 0.966314 lr 0.00013255 grad_norm 0.371481 rank 2
2025-01-11 03:55:01,816 DEBUG TRAIN Batch 147/500 loss 0.035859 acc 0.974261 lr 0.00013255 grad_norm 0.371481 rank 1
2025-01-11 03:55:01,816 DEBUG TRAIN Batch 147/500 loss 0.028329 acc 0.983204 lr 0.00013255 grad_norm 0.371481 rank 0
2025-01-11 03:55:25,781 DEBUG TRAIN Batch 147/600 loss 0.026551 acc 0.979592 lr 0.00013252 grad_norm 0.379455 rank 0
2025-01-11 03:55:25,782 DEBUG TRAIN Batch 147/600 loss 0.026288 acc 0.977444 lr 0.00013252 grad_norm 0.379455 rank 2
2025-01-11 03:55:25,782 DEBUG TRAIN Batch 147/600 loss 0.035524 acc 0.978992 lr 0.00013252 grad_norm 0.379455 rank 1
2025-01-11 03:55:49,757 DEBUG TRAIN Batch 147/700 loss 0.039563 acc 0.972687 lr 0.00013250 grad_norm 0.377427 rank 1
2025-01-11 03:55:49,757 DEBUG TRAIN Batch 147/700 loss 0.034255 acc 0.976471 lr 0.00013250 grad_norm 0.377427 rank 0
2025-01-11 03:55:49,758 DEBUG TRAIN Batch 147/700 loss 0.026963 acc 0.978082 lr 0.00013250 grad_norm 0.377427 rank 2
2025-01-11 03:56:14,103 DEBUG TRAIN Batch 147/800 loss 0.037643 acc 0.976809 lr 0.00013248 grad_norm 0.396202 rank 0
2025-01-11 03:56:14,103 DEBUG TRAIN Batch 147/800 loss 0.040018 acc 0.973594 lr 0.00013248 grad_norm 0.396202 rank 1
2025-01-11 03:56:14,103 DEBUG TRAIN Batch 147/800 loss 0.037021 acc 0.972502 lr 0.00013248 grad_norm 0.396202 rank 2
2025-01-11 03:56:38,159 DEBUG TRAIN Batch 147/900 loss 0.025887 acc 0.982808 lr 0.00013245 grad_norm 0.366316 rank 1
2025-01-11 03:56:38,159 DEBUG TRAIN Batch 147/900 loss 0.029951 acc 0.979775 lr 0.00013245 grad_norm 0.366316 rank 2
2025-01-11 03:56:38,159 DEBUG TRAIN Batch 147/900 loss 0.026638 acc 0.980237 lr 0.00013245 grad_norm 0.366316 rank 0
2025-01-11 03:57:02,508 DEBUG TRAIN Batch 147/1000 loss 0.041466 acc 0.966429 lr 0.00013243 grad_norm 0.373403 rank 1
2025-01-11 03:57:02,509 DEBUG TRAIN Batch 147/1000 loss 0.027694 acc 0.980707 lr 0.00013243 grad_norm 0.373403 rank 0
2025-01-11 03:57:02,509 DEBUG TRAIN Batch 147/1000 loss 0.027495 acc 0.984043 lr 0.00013243 grad_norm 0.373403 rank 2
2025-01-11 03:57:26,409 DEBUG TRAIN Batch 147/1100 loss 0.025217 acc 0.982578 lr 0.00013241 grad_norm 0.397998 rank 1
2025-01-11 03:57:26,410 DEBUG TRAIN Batch 147/1100 loss 0.032945 acc 0.979129 lr 0.00013241 grad_norm 0.397998 rank 2
2025-01-11 03:57:26,411 DEBUG TRAIN Batch 147/1100 loss 0.034483 acc 0.971398 lr 0.00013241 grad_norm 0.397998 rank 0
2025-01-11 03:57:50,214 DEBUG TRAIN Batch 147/1200 loss 0.037180 acc 0.972145 lr 0.00013238 grad_norm 0.405620 rank 1
2025-01-11 03:57:50,215 DEBUG TRAIN Batch 147/1200 loss 0.047095 acc 0.963470 lr 0.00013238 grad_norm 0.405620 rank 0
2025-01-11 03:57:50,215 DEBUG TRAIN Batch 147/1200 loss 0.033296 acc 0.976319 lr 0.00013238 grad_norm 0.405620 rank 2
2025-01-11 03:58:14,733 DEBUG TRAIN Batch 147/1300 loss 0.050978 acc 0.962600 lr 0.00013236 grad_norm 0.385443 rank 1
2025-01-11 03:58:14,733 DEBUG TRAIN Batch 147/1300 loss 0.024904 acc 0.982283 lr 0.00013236 grad_norm 0.385443 rank 0
2025-01-11 03:58:14,741 DEBUG TRAIN Batch 147/1300 loss 0.030088 acc 0.979846 lr 0.00013236 grad_norm 0.385443 rank 2
2025-01-11 03:58:38,320 DEBUG TRAIN Batch 147/1400 loss 0.034413 acc 0.981502 lr 0.00013234 grad_norm 0.399650 rank 0
2025-01-11 03:58:38,320 DEBUG TRAIN Batch 147/1400 loss 0.037654 acc 0.971899 lr 0.00013234 grad_norm 0.399650 rank 1
2025-01-11 03:58:38,321 DEBUG TRAIN Batch 147/1400 loss 0.038496 acc 0.974312 lr 0.00013234 grad_norm 0.399650 rank 2
2025-01-11 03:59:02,894 DEBUG TRAIN Batch 147/1500 loss 0.051366 acc 0.963940 lr 0.00013231 grad_norm 0.382746 rank 1
2025-01-11 03:59:02,894 DEBUG TRAIN Batch 147/1500 loss 0.036646 acc 0.974650 lr 0.00013231 grad_norm 0.382746 rank 0
2025-01-11 03:59:02,894 DEBUG TRAIN Batch 147/1500 loss 0.029542 acc 0.983296 lr 0.00013231 grad_norm 0.382746 rank 2
2025-01-11 03:59:26,981 DEBUG TRAIN Batch 147/1600 loss 0.044841 acc 0.968268 lr 0.00013229 grad_norm 0.381395 rank 1
2025-01-11 03:59:26,981 DEBUG TRAIN Batch 147/1600 loss 0.029575 acc 0.983917 lr 0.00013229 grad_norm 0.381395 rank 0
2025-01-11 03:59:26,981 DEBUG TRAIN Batch 147/1600 loss 0.038173 acc 0.968553 lr 0.00013229 grad_norm 0.381395 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 04:00:32,944 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 04:00:32,944 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 04:00:33,427 INFO Epoch 147 Step 142861 on_batch_end True CV rank 2
2025-01-11 04:00:33,427 INFO Epoch 147 Step 142861 on_batch_end True CV rank 0
2025-01-11 04:00:33,427 INFO Epoch 147 Step 142861 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 04:00:42,403 DEBUG CV Batch 147/100 loss 0.002052 acc 1.000000  rank 0
2025-01-11 04:00:42,710 DEBUG CV Batch 147/100 loss 0.002052 acc 1.000000  rank 2
2025-01-11 04:00:42,933 INFO Epoch 147 Step 142861 CV info lr 0.00013228577970725788 0 rank loss_2.6218904175322293 acc_0.7809745509896362
2025-01-11 04:00:43,045 DEBUG CV Batch 147/100 loss 0.002052 acc 1.000000  rank 1
2025-01-11 04:00:43,234 INFO Epoch 147 Step 142861 CV info lr 0.00013228577970725788 2 rank loss_2.6218904175322293 acc_0.7809745509896362
2025-01-11 04:00:43,574 INFO Epoch 147 Step 142861 CV info lr 0.00013228577970725788 1 rank loss_2.6218904175322293 acc_0.7809745509896362
2025-01-11 04:00:44,238 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_147_whole.pt
2025-01-11 04:00:44,250 INFO Added key: store_based_barrier_key:150 to store for rank: 0
2025-01-11 04:00:44,260 INFO Added key: store_based_barrier_key:150 to store for rank: 2
2025-01-11 04:00:44,261 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:150 with 3 nodes.
2025-01-11 04:00:44,261 INFO Added key: store_based_barrier_key:150 to store for rank: 1
2025-01-11 04:00:44,261 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:150 with 3 nodes.
2025-01-11 04:00:44,263 INFO Epoch 148 TRAIN info lr 0.00013228577970725788 rank 1
2025-01-11 04:00:44,263 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 04:00:44,269 INFO Epoch 148 TRAIN info lr 0.00013228577970725788 rank 2
2025-01-11 04:00:44,269 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 04:00:44,270 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:150 with 3 nodes.
2025-01-11 04:00:44,271 INFO Epoch 148 TRAIN info lr 0.00013228577970725788 rank 0
2025-01-11 04:00:44,271 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 04:01:18,119 DEBUG TRAIN Batch 148/100 loss 0.026240 acc 0.984244 lr 0.00013226 grad_norm 0.362916 rank 1
2025-01-11 04:01:18,120 DEBUG TRAIN Batch 148/100 loss 0.030770 acc 0.977507 lr 0.00013226 grad_norm 0.362916 rank 2
2025-01-11 04:01:18,120 DEBUG TRAIN Batch 148/100 loss 0.025924 acc 0.978585 lr 0.00013226 grad_norm 0.362916 rank 0
2025-01-11 04:01:42,007 DEBUG TRAIN Batch 148/200 loss 0.032936 acc 0.978664 lr 0.00013224 grad_norm 0.382369 rank 2
2025-01-11 04:01:42,008 DEBUG TRAIN Batch 148/200 loss 0.032824 acc 0.979945 lr 0.00013224 grad_norm 0.382369 rank 1
2025-01-11 04:01:42,008 DEBUG TRAIN Batch 148/200 loss 0.032082 acc 0.977778 lr 0.00013224 grad_norm 0.382369 rank 0
2025-01-11 04:02:06,242 DEBUG TRAIN Batch 148/300 loss 0.037637 acc 0.978261 lr 0.00013222 grad_norm 0.366698 rank 1
2025-01-11 04:02:06,243 DEBUG TRAIN Batch 148/300 loss 0.032809 acc 0.975948 lr 0.00013222 grad_norm 0.366698 rank 2
2025-01-11 04:02:06,244 DEBUG TRAIN Batch 148/300 loss 0.023951 acc 0.985232 lr 0.00013222 grad_norm 0.366698 rank 0
2025-01-11 04:02:31,405 DEBUG TRAIN Batch 148/400 loss 0.031024 acc 0.980498 lr 0.00013219 grad_norm 0.406125 rank 1
2025-01-11 04:02:31,406 DEBUG TRAIN Batch 148/400 loss 0.031764 acc 0.982199 lr 0.00013219 grad_norm 0.406125 rank 2
2025-01-11 04:02:31,406 DEBUG TRAIN Batch 148/400 loss 0.050761 acc 0.970350 lr 0.00013219 grad_norm 0.406125 rank 0
2025-01-11 04:02:55,238 DEBUG TRAIN Batch 148/500 loss 0.050549 acc 0.972355 lr 0.00013217 grad_norm 0.414836 rank 0
2025-01-11 04:02:55,238 DEBUG TRAIN Batch 148/500 loss 0.043136 acc 0.976285 lr 0.00013217 grad_norm 0.414836 rank 2
2025-01-11 04:02:55,239 DEBUG TRAIN Batch 148/500 loss 0.035626 acc 0.974874 lr 0.00013217 grad_norm 0.414836 rank 1
2025-01-11 04:03:19,736 DEBUG TRAIN Batch 148/600 loss 0.029607 acc 0.975410 lr 0.00013215 grad_norm 0.344696 rank 0
2025-01-11 04:03:19,736 DEBUG TRAIN Batch 148/600 loss 0.026261 acc 0.982391 lr 0.00013215 grad_norm 0.344696 rank 1
2025-01-11 04:03:19,736 DEBUG TRAIN Batch 148/600 loss 0.031131 acc 0.973118 lr 0.00013215 grad_norm 0.344696 rank 2
2025-01-11 04:03:44,530 DEBUG TRAIN Batch 148/700 loss 0.026713 acc 0.985148 lr 0.00013212 grad_norm 0.376481 rank 2
2025-01-11 04:03:44,530 DEBUG TRAIN Batch 148/700 loss 0.030016 acc 0.979873 lr 0.00013212 grad_norm 0.376481 rank 1
2025-01-11 04:03:44,530 DEBUG TRAIN Batch 148/700 loss 0.025794 acc 0.982440 lr 0.00013212 grad_norm 0.376481 rank 0
2025-01-11 04:04:08,940 DEBUG TRAIN Batch 148/800 loss 0.019723 acc 0.986974 lr 0.00013210 grad_norm 0.370548 rank 0
2025-01-11 04:04:08,940 DEBUG TRAIN Batch 148/800 loss 0.039197 acc 0.976256 lr 0.00013210 grad_norm 0.370548 rank 2
2025-01-11 04:04:08,941 DEBUG TRAIN Batch 148/800 loss 0.028581 acc 0.979753 lr 0.00013210 grad_norm 0.370548 rank 1
2025-01-11 04:04:33,027 DEBUG TRAIN Batch 148/900 loss 0.039329 acc 0.974000 lr 0.00013208 grad_norm 0.377890 rank 0
2025-01-11 04:04:33,027 DEBUG TRAIN Batch 148/900 loss 0.030997 acc 0.981185 lr 0.00013208 grad_norm 0.377890 rank 2
2025-01-11 04:04:33,027 DEBUG TRAIN Batch 148/900 loss 0.034783 acc 0.972275 lr 0.00013208 grad_norm 0.377890 rank 1
2025-01-11 04:04:57,734 DEBUG TRAIN Batch 148/1000 loss 0.024209 acc 0.982011 lr 0.00013205 grad_norm 0.365929 rank 0
2025-01-11 04:04:57,735 DEBUG TRAIN Batch 148/1000 loss 0.017528 acc 0.991870 lr 0.00013205 grad_norm 0.365929 rank 1
2025-01-11 04:04:57,735 DEBUG TRAIN Batch 148/1000 loss 0.042264 acc 0.974048 lr 0.00013205 grad_norm 0.365929 rank 2
2025-01-11 04:05:21,461 DEBUG TRAIN Batch 148/1100 loss 0.040503 acc 0.973460 lr 0.00013203 grad_norm 0.425613 rank 0
2025-01-11 04:05:21,462 DEBUG TRAIN Batch 148/1100 loss 0.032108 acc 0.976082 lr 0.00013203 grad_norm 0.425613 rank 2
2025-01-11 04:05:21,462 DEBUG TRAIN Batch 148/1100 loss 0.048431 acc 0.965217 lr 0.00013203 grad_norm 0.425613 rank 1
2025-01-11 04:05:45,887 DEBUG TRAIN Batch 148/1200 loss 0.052616 acc 0.966899 lr 0.00013201 grad_norm 0.428900 rank 0
2025-01-11 04:05:45,887 DEBUG TRAIN Batch 148/1200 loss 0.044256 acc 0.967213 lr 0.00013201 grad_norm 0.428900 rank 1
2025-01-11 04:05:45,888 DEBUG TRAIN Batch 148/1200 loss 0.035501 acc 0.974038 lr 0.00013201 grad_norm 0.428900 rank 2
2025-01-11 04:06:11,025 DEBUG TRAIN Batch 148/1300 loss 0.033698 acc 0.978474 lr 0.00013199 grad_norm 0.390472 rank 2
2025-01-11 04:06:11,026 DEBUG TRAIN Batch 148/1300 loss 0.026702 acc 0.979980 lr 0.00013199 grad_norm 0.390472 rank 1
2025-01-11 04:06:11,026 DEBUG TRAIN Batch 148/1300 loss 0.051242 acc 0.964991 lr 0.00013199 grad_norm 0.390472 rank 0
2025-01-11 04:06:34,779 DEBUG TRAIN Batch 148/1400 loss 0.034790 acc 0.974946 lr 0.00013196 grad_norm 0.391099 rank 2
2025-01-11 04:06:34,779 DEBUG TRAIN Batch 148/1400 loss 0.022844 acc 0.981308 lr 0.00013196 grad_norm 0.391099 rank 1
2025-01-11 04:06:34,779 DEBUG TRAIN Batch 148/1400 loss 0.033491 acc 0.977683 lr 0.00013196 grad_norm 0.391099 rank 0
2025-01-11 04:06:59,330 DEBUG TRAIN Batch 148/1500 loss 0.034701 acc 0.974217 lr 0.00013194 grad_norm 0.386712 rank 1
2025-01-11 04:06:59,330 DEBUG TRAIN Batch 148/1500 loss 0.034413 acc 0.977857 lr 0.00013194 grad_norm 0.386712 rank 2
2025-01-11 04:06:59,331 DEBUG TRAIN Batch 148/1500 loss 0.033900 acc 0.979927 lr 0.00013194 grad_norm 0.386712 rank 0
2025-01-11 04:07:24,063 DEBUG TRAIN Batch 148/1600 loss 0.032646 acc 0.976812 lr 0.00013192 grad_norm 0.397397 rank 0
2025-01-11 04:07:24,063 DEBUG TRAIN Batch 148/1600 loss 0.022729 acc 0.984177 lr 0.00013192 grad_norm 0.397397 rank 1
2025-01-11 04:07:24,063 DEBUG TRAIN Batch 148/1600 loss 0.045369 acc 0.966606 lr 0.00013192 grad_norm 0.397397 rank 2
2025-01-11 04:07:48,148 DEBUG TRAIN Batch 148/1700 loss 0.035570 acc 0.974510 lr 0.00013189 grad_norm 0.394487 rank 0
2025-01-11 04:07:48,149 DEBUG TRAIN Batch 148/1700 loss 0.018236 acc 0.983333 lr 0.00013189 grad_norm 0.394487 rank 1
2025-01-11 04:07:48,149 DEBUG TRAIN Batch 148/1700 loss 0.041792 acc 0.963588 lr 0.00013189 grad_norm 0.394487 rank 2
2025-01-11 04:08:13,282 DEBUG TRAIN Batch 148/1800 loss 0.038799 acc 0.967638 lr 0.00013187 grad_norm 0.385973 rank 1
2025-01-11 04:08:13,282 DEBUG TRAIN Batch 148/1800 loss 0.023454 acc 0.986842 lr 0.00013187 grad_norm 0.385973 rank 0
2025-01-11 04:08:13,283 DEBUG TRAIN Batch 148/1800 loss 0.038554 acc 0.974261 lr 0.00013187 grad_norm 0.385973 rank 2
2025-01-11 04:08:37,544 DEBUG TRAIN Batch 148/1900 loss 0.046378 acc 0.967573 lr 0.00013185 grad_norm 0.423340 rank 1
2025-01-11 04:08:37,544 DEBUG TRAIN Batch 148/1900 loss 0.044514 acc 0.968907 lr 0.00013185 grad_norm 0.423340 rank 2
2025-01-11 04:08:37,545 DEBUG TRAIN Batch 148/1900 loss 0.039013 acc 0.976852 lr 0.00013185 grad_norm 0.423340 rank 0
2025-01-11 04:09:01,305 DEBUG TRAIN Batch 148/2000 loss 0.041647 acc 0.973545 lr 0.00013183 grad_norm 0.391814 rank 2
2025-01-11 04:09:01,305 DEBUG TRAIN Batch 148/2000 loss 0.030529 acc 0.981939 lr 0.00013183 grad_norm 0.391814 rank 0
2025-01-11 04:09:01,305 DEBUG TRAIN Batch 148/2000 loss 0.033706 acc 0.976037 lr 0.00013183 grad_norm 0.391814 rank 1
2025-01-11 04:09:25,106 DEBUG TRAIN Batch 148/2100 loss 0.030809 acc 0.980630 lr 0.00013180 grad_norm 0.404140 rank 1
2025-01-11 04:09:25,107 DEBUG TRAIN Batch 148/2100 loss 0.029126 acc 0.982955 lr 0.00013180 grad_norm 0.404140 rank 0
2025-01-11 04:09:25,107 DEBUG TRAIN Batch 148/2100 loss 0.044900 acc 0.969112 lr 0.00013180 grad_norm 0.404140 rank 2
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 04:10:45,788 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 04:10:45,791 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 04:10:46,120 INFO Epoch 148 Step 143955 on_batch_end True CV rank 1
2025-01-11 04:10:46,120 INFO Epoch 148 Step 143955 on_batch_end True CV rank 0
2025-01-11 04:10:46,120 INFO Epoch 148 Step 143955 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 04:10:55,306 DEBUG CV Batch 148/100 loss 0.003339 acc 0.998885  rank 0
2025-01-11 04:10:55,359 DEBUG CV Batch 148/100 loss 0.003339 acc 0.998885  rank 2
2025-01-11 04:10:55,568 DEBUG CV Batch 148/100 loss 0.003339 acc 0.998885  rank 1
2025-01-11 04:10:55,796 INFO Epoch 148 Step 143955 CV info lr 0.00013178216174537555 0 rank loss_2.6148480067731406 acc_0.7801202535629272
2025-01-11 04:10:55,870 INFO Epoch 148 Step 143955 CV info lr 0.00013178216174537555 2 rank loss_2.6148480067731406 acc_0.7801202535629272
2025-01-11 04:10:56,103 INFO Epoch 148 Step 143955 CV info lr 0.00013178216174537555 1 rank loss_2.6148480067731406 acc_0.7801202535629272
2025-01-11 04:10:57,074 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_148_whole.pt
2025-01-11 04:10:57,096 INFO Added key: store_based_barrier_key:151 to store for rank: 0
2025-01-11 04:10:57,106 INFO Added key: store_based_barrier_key:151 to store for rank: 2
2025-01-11 04:10:57,107 INFO Added key: store_based_barrier_key:151 to store for rank: 1
2025-01-11 04:10:57,107 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:151 with 3 nodes.
2025-01-11 04:10:57,110 INFO Epoch 149 TRAIN info lr 0.00013178216174537555 rank 1
2025-01-11 04:10:57,110 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 04:10:57,116 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:151 with 3 nodes.
2025-01-11 04:10:57,117 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:151 with 3 nodes.
2025-01-11 04:10:57,126 INFO Epoch 149 TRAIN info lr 0.00013178216174537555 rank 2
2025-01-11 04:10:57,126 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 04:10:57,126 INFO Epoch 149 TRAIN info lr 0.00013178216174537555 rank 0
2025-01-11 04:10:57,126 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 04:11:30,620 DEBUG TRAIN Batch 149/100 loss 0.034490 acc 0.976723 lr 0.00013176 grad_norm 0.361500 rank 0
2025-01-11 04:11:30,620 DEBUG TRAIN Batch 149/100 loss 0.026884 acc 0.983556 lr 0.00013176 grad_norm 0.361500 rank 1
2025-01-11 04:11:30,620 DEBUG TRAIN Batch 149/100 loss 0.017334 acc 0.988730 lr 0.00013176 grad_norm 0.361500 rank 2
2025-01-11 04:11:54,402 DEBUG TRAIN Batch 149/200 loss 0.040262 acc 0.971307 lr 0.00013174 grad_norm 0.397456 rank 0
2025-01-11 04:11:54,403 DEBUG TRAIN Batch 149/200 loss 0.036167 acc 0.976303 lr 0.00013174 grad_norm 0.397456 rank 2
2025-01-11 04:11:54,402 DEBUG TRAIN Batch 149/200 loss 0.032892 acc 0.975936 lr 0.00013174 grad_norm 0.397456 rank 1
2025-01-11 04:12:18,853 DEBUG TRAIN Batch 149/300 loss 0.039265 acc 0.970782 lr 0.00013171 grad_norm 0.380780 rank 0
2025-01-11 04:12:18,853 DEBUG TRAIN Batch 149/300 loss 0.022260 acc 0.985158 lr 0.00013171 grad_norm 0.380780 rank 2
2025-01-11 04:12:18,854 DEBUG TRAIN Batch 149/300 loss 0.034961 acc 0.978011 lr 0.00013171 grad_norm 0.380780 rank 1
2025-01-11 04:12:42,754 DEBUG TRAIN Batch 149/400 loss 0.040147 acc 0.977871 lr 0.00013169 grad_norm 0.396190 rank 0
2025-01-11 04:12:42,754 DEBUG TRAIN Batch 149/400 loss 0.022696 acc 0.988439 lr 0.00013169 grad_norm 0.396190 rank 2
2025-01-11 04:12:42,754 DEBUG TRAIN Batch 149/400 loss 0.028217 acc 0.980371 lr 0.00013169 grad_norm 0.396190 rank 1
2025-01-11 04:13:06,859 DEBUG TRAIN Batch 149/500 loss 0.033707 acc 0.977231 lr 0.00013167 grad_norm 0.348154 rank 0
2025-01-11 04:13:06,859 DEBUG TRAIN Batch 149/500 loss 0.017721 acc 0.985310 lr 0.00013167 grad_norm 0.348154 rank 2
2025-01-11 04:13:06,860 DEBUG TRAIN Batch 149/500 loss 0.032224 acc 0.980870 lr 0.00013167 grad_norm 0.348154 rank 1
2025-01-11 04:13:31,444 DEBUG TRAIN Batch 149/600 loss 0.037977 acc 0.975191 lr 0.00013165 grad_norm 0.345839 rank 0
2025-01-11 04:13:31,445 DEBUG TRAIN Batch 149/600 loss 0.026275 acc 0.976773 lr 0.00013165 grad_norm 0.345839 rank 2
2025-01-11 04:13:31,446 DEBUG TRAIN Batch 149/600 loss 0.021266 acc 0.984552 lr 0.00013165 grad_norm 0.345839 rank 1
2025-01-11 04:13:55,063 DEBUG TRAIN Batch 149/700 loss 0.027384 acc 0.983838 lr 0.00013162 grad_norm 0.376048 rank 2
2025-01-11 04:13:55,063 DEBUG TRAIN Batch 149/700 loss 0.020307 acc 0.987261 lr 0.00013162 grad_norm 0.376048 rank 1
2025-01-11 04:13:55,063 DEBUG TRAIN Batch 149/700 loss 0.031226 acc 0.979068 lr 0.00013162 grad_norm 0.376048 rank 0
2025-01-11 04:14:19,447 DEBUG TRAIN Batch 149/800 loss 0.041457 acc 0.972272 lr 0.00013160 grad_norm 0.370681 rank 1
2025-01-11 04:14:19,447 DEBUG TRAIN Batch 149/800 loss 0.023037 acc 0.982488 lr 0.00013160 grad_norm 0.370681 rank 0
2025-01-11 04:14:19,447 DEBUG TRAIN Batch 149/800 loss 0.019513 acc 0.983582 lr 0.00013160 grad_norm 0.370681 rank 2
2025-01-11 04:14:43,071 DEBUG TRAIN Batch 149/900 loss 0.022186 acc 0.982888 lr 0.00013158 grad_norm 0.349551 rank 0
2025-01-11 04:14:43,071 DEBUG TRAIN Batch 149/900 loss 0.035140 acc 0.979226 lr 0.00013158 grad_norm 0.349551 rank 1
2025-01-11 04:14:43,072 DEBUG TRAIN Batch 149/900 loss 0.027547 acc 0.979508 lr 0.00013158 grad_norm 0.349551 rank 2
2025-01-11 04:15:07,578 DEBUG TRAIN Batch 149/1000 loss 0.035583 acc 0.977674 lr 0.00013155 grad_norm 0.365902 rank 2
2025-01-11 04:15:07,578 DEBUG TRAIN Batch 149/1000 loss 0.037189 acc 0.979186 lr 0.00013155 grad_norm 0.365902 rank 1
2025-01-11 04:15:07,579 DEBUG TRAIN Batch 149/1000 loss 0.034812 acc 0.977509 lr 0.00013155 grad_norm 0.365902 rank 0
2025-01-11 04:15:31,187 DEBUG TRAIN Batch 149/1100 loss 0.038344 acc 0.972196 lr 0.00013153 grad_norm 0.385076 rank 2
2025-01-11 04:15:31,187 DEBUG TRAIN Batch 149/1100 loss 0.025707 acc 0.978571 lr 0.00013153 grad_norm 0.385076 rank 0
2025-01-11 04:15:31,187 DEBUG TRAIN Batch 149/1100 loss 0.026032 acc 0.980270 lr 0.00013153 grad_norm 0.385076 rank 1
2025-01-11 04:15:55,076 DEBUG TRAIN Batch 149/1200 loss 0.048735 acc 0.967167 lr 0.00013151 grad_norm 0.444793 rank 2
2025-01-11 04:15:55,077 DEBUG TRAIN Batch 149/1200 loss 0.029546 acc 0.977085 lr 0.00013151 grad_norm 0.444793 rank 1
2025-01-11 04:15:55,076 DEBUG TRAIN Batch 149/1200 loss 0.032982 acc 0.977642 lr 0.00013151 grad_norm 0.444793 rank 0
2025-01-11 04:16:20,092 DEBUG TRAIN Batch 149/1300 loss 0.040063 acc 0.972945 lr 0.00013149 grad_norm 0.389373 rank 2
2025-01-11 04:16:20,092 DEBUG TRAIN Batch 149/1300 loss 0.044323 acc 0.969670 lr 0.00013149 grad_norm 0.389373 rank 0
2025-01-11 04:16:20,093 DEBUG TRAIN Batch 149/1300 loss 0.029437 acc 0.976806 lr 0.00013149 grad_norm 0.389373 rank 1
2025-01-11 04:16:44,433 DEBUG TRAIN Batch 149/1400 loss 0.029629 acc 0.978764 lr 0.00013146 grad_norm 0.365312 rank 2
2025-01-11 04:16:44,433 DEBUG TRAIN Batch 149/1400 loss 0.035460 acc 0.973517 lr 0.00013146 grad_norm 0.365312 rank 0
2025-01-11 04:16:44,434 DEBUG TRAIN Batch 149/1400 loss 0.035242 acc 0.978537 lr 0.00013146 grad_norm 0.365312 rank 1
2025-01-11 04:17:08,177 DEBUG TRAIN Batch 149/1500 loss 0.037148 acc 0.971429 lr 0.00013144 grad_norm 0.381583 rank 2
2025-01-11 04:17:08,177 DEBUG TRAIN Batch 149/1500 loss 0.030966 acc 0.978325 lr 0.00013144 grad_norm 0.381583 rank 0
2025-01-11 04:17:08,297 DEBUG TRAIN Batch 149/1500 loss 0.025332 acc 0.985386 lr 0.00013144 grad_norm 0.381583 rank 1
2025-01-11 04:17:33,252 DEBUG TRAIN Batch 149/1600 loss 0.041593 acc 0.974160 lr 0.00013142 grad_norm 0.428450 rank 1
2025-01-11 04:17:33,252 DEBUG TRAIN Batch 149/1600 loss 0.035705 acc 0.977452 lr 0.00013142 grad_norm 0.428450 rank 0
2025-01-11 04:17:33,252 DEBUG TRAIN Batch 149/1600 loss 0.039349 acc 0.969788 lr 0.00013142 grad_norm 0.428450 rank 2
2025-01-11 04:17:57,164 DEBUG TRAIN Batch 149/1700 loss 0.047050 acc 0.974757 lr 0.00013139 grad_norm 0.377644 rank 0
2025-01-11 04:17:57,164 DEBUG TRAIN Batch 149/1700 loss 0.037131 acc 0.971171 lr 0.00013139 grad_norm 0.377644 rank 2
2025-01-11 04:17:57,164 DEBUG TRAIN Batch 149/1700 loss 0.027454 acc 0.981043 lr 0.00013139 grad_norm 0.377644 rank 1
2025-01-11 04:18:21,537 DEBUG TRAIN Batch 149/1800 loss 0.032057 acc 0.975155 lr 0.00013137 grad_norm 0.413735 rank 1
2025-01-11 04:18:21,537 DEBUG TRAIN Batch 149/1800 loss 0.042658 acc 0.973713 lr 0.00013137 grad_norm 0.413735 rank 0
2025-01-11 04:18:21,537 DEBUG TRAIN Batch 149/1800 loss 0.038513 acc 0.973223 lr 0.00013137 grad_norm 0.413735 rank 2
2025-01-11 04:18:46,735 DEBUG TRAIN Batch 149/1900 loss 0.035410 acc 0.972833 lr 0.00013135 grad_norm 0.404312 rank 2
2025-01-11 04:18:46,735 DEBUG TRAIN Batch 149/1900 loss 0.029586 acc 0.978957 lr 0.00013135 grad_norm 0.404312 rank 0
2025-01-11 04:18:46,735 DEBUG TRAIN Batch 149/1900 loss 0.033861 acc 0.978032 lr 0.00013135 grad_norm 0.404312 rank 1
2025-01-11 04:19:09,999 DEBUG TRAIN Batch 149/2000 loss 0.026179 acc 0.982347 lr 0.00013133 grad_norm 0.405160 rank 2
2025-01-11 04:19:09,999 DEBUG TRAIN Batch 149/2000 loss 0.032378 acc 0.977933 lr 0.00013133 grad_norm 0.405160 rank 0
2025-01-11 04:19:09,999 DEBUG TRAIN Batch 149/2000 loss 0.028836 acc 0.979331 lr 0.00013133 grad_norm 0.405160 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 04:20:15,538 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59965ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 04:20:15,570 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 04:20:16,031 INFO Epoch 149 Step 144966 on_batch_end True CV rank 1
2025-01-11 04:20:16,031 INFO Epoch 149 Step 144966 on_batch_end True CV rank 0
2025-01-11 04:20:16,031 INFO Epoch 149 Step 144966 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 04:20:25,184 DEBUG CV Batch 149/100 loss 0.005566 acc 0.998885  rank 0
2025-01-11 04:20:25,421 DEBUG CV Batch 149/100 loss 0.005566 acc 0.998885  rank 2
2025-01-11 04:20:25,697 INFO Epoch 149 Step 144966 CV info lr 0.00013132183011486942 0 rank loss_2.621416788799443 acc_0.7797391917883304
2025-01-11 04:20:25,768 DEBUG CV Batch 149/100 loss 0.005566 acc 0.998885  rank 1
2025-01-11 04:20:25,973 INFO Epoch 149 Step 144966 CV info lr 0.00013132183011486942 2 rank loss_2.621416788799443 acc_0.7797391917883304
2025-01-11 04:20:26,311 INFO Epoch 149 Step 144966 CV info lr 0.00013132183011486942 1 rank loss_2.621416788799443 acc_0.7797391917883304
2025-01-11 04:20:26,980 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_149_whole.pt
2025-01-11 04:20:27,001 INFO Added key: store_based_barrier_key:152 to store for rank: 0
2025-01-11 04:20:27,002 INFO Added key: store_based_barrier_key:152 to store for rank: 2
2025-01-11 04:20:27,002 INFO Added key: store_based_barrier_key:152 to store for rank: 1
2025-01-11 04:20:27,002 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:152 with 3 nodes.
2025-01-11 04:20:27,002 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:152 with 3 nodes.
2025-01-11 04:20:27,004 INFO Epoch 150 TRAIN info lr 0.00013132183011486942 rank 1
2025-01-11 04:20:27,004 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 04:20:27,008 INFO Epoch 150 TRAIN info lr 0.00013132183011486942 rank 2
2025-01-11 04:20:27,008 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 04:20:27,012 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:152 with 3 nodes.
2025-01-11 04:20:27,021 INFO Epoch 150 TRAIN info lr 0.00013132183011486942 rank 0
2025-01-11 04:20:27,021 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 04:20:57,435 DEBUG TRAIN Batch 150/100 loss 0.037744 acc 0.975859 lr 0.00013130 grad_norm 0.367446 rank 1
2025-01-11 04:20:57,436 DEBUG TRAIN Batch 150/100 loss 0.032505 acc 0.974957 lr 0.00013130 grad_norm 0.367446 rank 2
2025-01-11 04:20:57,436 DEBUG TRAIN Batch 150/100 loss 0.038998 acc 0.973183 lr 0.00013130 grad_norm 0.367446 rank 0
2025-01-11 04:21:21,172 DEBUG TRAIN Batch 150/200 loss 0.038140 acc 0.978744 lr 0.00013128 grad_norm 0.372222 rank 1
2025-01-11 04:21:21,172 DEBUG TRAIN Batch 150/200 loss 0.028538 acc 0.977556 lr 0.00013128 grad_norm 0.372222 rank 2
2025-01-11 04:21:21,268 DEBUG TRAIN Batch 150/200 loss 0.021555 acc 0.982332 lr 0.00013128 grad_norm 0.372222 rank 0
2025-01-11 04:21:44,798 DEBUG TRAIN Batch 150/300 loss 0.033894 acc 0.980993 lr 0.00013125 grad_norm 0.367307 rank 1
2025-01-11 04:21:44,798 DEBUG TRAIN Batch 150/300 loss 0.033165 acc 0.975828 lr 0.00013125 grad_norm 0.367307 rank 0
2025-01-11 04:21:44,799 DEBUG TRAIN Batch 150/300 loss 0.027199 acc 0.982625 lr 0.00013125 grad_norm 0.367307 rank 2
2025-01-11 04:22:08,751 DEBUG TRAIN Batch 150/400 loss 0.026039 acc 0.977757 lr 0.00013123 grad_norm 0.392741 rank 1
2025-01-11 04:22:08,751 DEBUG TRAIN Batch 150/400 loss 0.041137 acc 0.978505 lr 0.00013123 grad_norm 0.392741 rank 0
2025-01-11 04:22:08,751 DEBUG TRAIN Batch 150/400 loss 0.044766 acc 0.967557 lr 0.00013123 grad_norm 0.392741 rank 2
2025-01-11 04:22:32,739 DEBUG TRAIN Batch 150/500 loss 0.029646 acc 0.977710 lr 0.00013121 grad_norm 0.367538 rank 2
2025-01-11 04:22:32,739 DEBUG TRAIN Batch 150/500 loss 0.033611 acc 0.980616 lr 0.00013121 grad_norm 0.367538 rank 1
2025-01-11 04:22:32,739 DEBUG TRAIN Batch 150/500 loss 0.030269 acc 0.980663 lr 0.00013121 grad_norm 0.367538 rank 0
2025-01-11 04:22:56,824 DEBUG TRAIN Batch 150/600 loss 0.026831 acc 0.981618 lr 0.00013119 grad_norm 0.356911 rank 1
2025-01-11 04:22:56,824 DEBUG TRAIN Batch 150/600 loss 0.024518 acc 0.981542 lr 0.00013119 grad_norm 0.356911 rank 2
2025-01-11 04:22:56,824 DEBUG TRAIN Batch 150/600 loss 0.027027 acc 0.985348 lr 0.00013119 grad_norm 0.356911 rank 0
2025-01-11 04:23:21,237 DEBUG TRAIN Batch 150/700 loss 0.034012 acc 0.981207 lr 0.00013116 grad_norm 0.385077 rank 1
2025-01-11 04:23:21,237 DEBUG TRAIN Batch 150/700 loss 0.046032 acc 0.968113 lr 0.00013116 grad_norm 0.385077 rank 2
2025-01-11 04:23:21,238 DEBUG TRAIN Batch 150/700 loss 0.033538 acc 0.978947 lr 0.00013116 grad_norm 0.385077 rank 0
2025-01-11 04:23:46,167 DEBUG TRAIN Batch 150/800 loss 0.042018 acc 0.970782 lr 0.00013114 grad_norm 0.383685 rank 2
2025-01-11 04:23:46,167 DEBUG TRAIN Batch 150/800 loss 0.038920 acc 0.972171 lr 0.00013114 grad_norm 0.383685 rank 0
2025-01-11 04:23:46,167 DEBUG TRAIN Batch 150/800 loss 0.019213 acc 0.986577 lr 0.00013114 grad_norm 0.383685 rank 1
2025-01-11 04:24:09,753 DEBUG TRAIN Batch 150/900 loss 0.036176 acc 0.970085 lr 0.00013112 grad_norm 0.378687 rank 0
2025-01-11 04:24:09,753 DEBUG TRAIN Batch 150/900 loss 0.033729 acc 0.975758 lr 0.00013112 grad_norm 0.378687 rank 1
2025-01-11 04:24:09,754 DEBUG TRAIN Batch 150/900 loss 0.034393 acc 0.973790 lr 0.00013112 grad_norm 0.378687 rank 2
2025-01-11 04:24:34,157 DEBUG TRAIN Batch 150/1000 loss 0.030541 acc 0.974954 lr 0.00013110 grad_norm 0.387656 rank 0
2025-01-11 04:24:34,157 DEBUG TRAIN Batch 150/1000 loss 0.034267 acc 0.976440 lr 0.00013110 grad_norm 0.387656 rank 2
2025-01-11 04:24:34,158 DEBUG TRAIN Batch 150/1000 loss 0.022499 acc 0.984283 lr 0.00013110 grad_norm 0.387656 rank 1
2025-01-11 04:24:59,980 DEBUG TRAIN Batch 150/1100 loss 0.022423 acc 0.981073 lr 0.00013107 grad_norm 0.363715 rank 1
2025-01-11 04:24:59,980 DEBUG TRAIN Batch 150/1100 loss 0.036076 acc 0.975610 lr 0.00013107 grad_norm 0.363715 rank 0
2025-01-11 04:24:59,981 DEBUG TRAIN Batch 150/1100 loss 0.023700 acc 0.980416 lr 0.00013107 grad_norm 0.363715 rank 2
2025-01-11 04:25:23,905 DEBUG TRAIN Batch 150/1200 loss 0.026003 acc 0.982968 lr 0.00013105 grad_norm 0.396263 rank 0
2025-01-11 04:25:23,905 DEBUG TRAIN Batch 150/1200 loss 0.044845 acc 0.973539 lr 0.00013105 grad_norm 0.396263 rank 1
2025-01-11 04:25:23,906 DEBUG TRAIN Batch 150/1200 loss 0.048159 acc 0.969578 lr 0.00013105 grad_norm 0.396263 rank 2
2025-01-11 04:25:47,824 DEBUG TRAIN Batch 150/1300 loss 0.047360 acc 0.968750 lr 0.00013103 grad_norm 0.377437 rank 2
2025-01-11 04:25:47,824 DEBUG TRAIN Batch 150/1300 loss 0.038585 acc 0.976043 lr 0.00013103 grad_norm 0.377437 rank 1
2025-01-11 04:25:47,824 DEBUG TRAIN Batch 150/1300 loss 0.030611 acc 0.979885 lr 0.00013103 grad_norm 0.377437 rank 0
2025-01-11 04:26:12,349 DEBUG TRAIN Batch 150/1400 loss 0.032176 acc 0.976998 lr 0.00013101 grad_norm 0.403819 rank 1
2025-01-11 04:26:12,349 DEBUG TRAIN Batch 150/1400 loss 0.030658 acc 0.979613 lr 0.00013101 grad_norm 0.403819 rank 2
2025-01-11 04:26:12,349 DEBUG TRAIN Batch 150/1400 loss 0.041124 acc 0.975385 lr 0.00013101 grad_norm 0.403819 rank 0
2025-01-11 04:26:36,249 DEBUG TRAIN Batch 150/1500 loss 0.032129 acc 0.980574 lr 0.00013098 grad_norm 0.381090 rank 1
2025-01-11 04:26:36,249 DEBUG TRAIN Batch 150/1500 loss 0.030641 acc 0.979710 lr 0.00013098 grad_norm 0.381090 rank 0
2025-01-11 04:26:36,250 DEBUG TRAIN Batch 150/1500 loss 0.035475 acc 0.975309 lr 0.00013098 grad_norm 0.381090 rank 2
2025-01-11 04:27:00,909 DEBUG TRAIN Batch 150/1600 loss 0.024636 acc 0.983377 lr 0.00013096 grad_norm 0.428475 rank 1
2025-01-11 04:27:00,910 DEBUG TRAIN Batch 150/1600 loss 0.042453 acc 0.969319 lr 0.00013096 grad_norm 0.428475 rank 0
2025-01-11 04:27:00,910 DEBUG TRAIN Batch 150/1600 loss 0.030511 acc 0.975610 lr 0.00013096 grad_norm 0.428475 rank 2
2025-01-11 04:27:25,938 DEBUG TRAIN Batch 150/1700 loss 0.032240 acc 0.978482 lr 0.00013094 grad_norm 0.392823 rank 0
2025-01-11 04:27:25,938 DEBUG TRAIN Batch 150/1700 loss 0.025158 acc 0.984227 lr 0.00013094 grad_norm 0.392823 rank 1
2025-01-11 04:27:25,938 DEBUG TRAIN Batch 150/1700 loss 0.050607 acc 0.965726 lr 0.00013094 grad_norm 0.392823 rank 2
2025-01-11 04:27:49,631 DEBUG TRAIN Batch 150/1800 loss 0.046693 acc 0.971014 lr 0.00013092 grad_norm 0.404916 rank 0
2025-01-11 04:27:49,631 DEBUG TRAIN Batch 150/1800 loss 0.031592 acc 0.977025 lr 0.00013092 grad_norm 0.404916 rank 1
2025-01-11 04:27:49,631 DEBUG TRAIN Batch 150/1800 loss 0.031798 acc 0.978281 lr 0.00013092 grad_norm 0.404916 rank 2
2025-01-11 04:28:13,942 DEBUG TRAIN Batch 150/1900 loss 0.052547 acc 0.963585 lr 0.00013089 grad_norm 0.387867 rank 0
2025-01-11 04:28:13,942 DEBUG TRAIN Batch 150/1900 loss 0.027329 acc 0.982726 lr 0.00013089 grad_norm 0.387867 rank 1
2025-01-11 04:28:13,942 DEBUG TRAIN Batch 150/1900 loss 0.022841 acc 0.987013 lr 0.00013089 grad_norm 0.387867 rank 2
2025-01-11 04:28:38,537 DEBUG TRAIN Batch 150/2000 loss 0.031188 acc 0.976815 lr 0.00013087 grad_norm 0.388708 rank 0
2025-01-11 04:28:38,537 DEBUG TRAIN Batch 150/2000 loss 0.034089 acc 0.973988 lr 0.00013087 grad_norm 0.388708 rank 1
2025-01-11 04:28:38,537 DEBUG TRAIN Batch 150/2000 loss 0.036261 acc 0.977451 lr 0.00013087 grad_norm 0.388708 rank 2
2025-01-11 04:29:02,780 DEBUG TRAIN Batch 150/2100 loss 0.028362 acc 0.978049 lr 0.00013085 grad_norm 0.371358 rank 0
2025-01-11 04:29:02,780 DEBUG TRAIN Batch 150/2100 loss 0.037833 acc 0.971767 lr 0.00013085 grad_norm 0.371358 rank 2
2025-01-11 04:29:02,780 DEBUG TRAIN Batch 150/2100 loss 0.012636 acc 0.994647 lr 0.00013085 grad_norm 0.371358 rank 1
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 04:30:04,234 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 04:30:04,239 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 04:30:04,643 INFO Epoch 150 Step 146019 on_batch_end True CV rank 2
2025-01-11 04:30:04,643 INFO Epoch 150 Step 146019 on_batch_end True CV rank 1
2025-01-11 04:30:04,643 INFO Epoch 150 Step 146019 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 04:30:13,756 DEBUG CV Batch 150/100 loss 0.000994 acc 1.000000  rank 0
2025-01-11 04:30:13,859 DEBUG CV Batch 150/100 loss 0.000994 acc 1.000000  rank 2
2025-01-11 04:30:14,147 DEBUG CV Batch 150/100 loss 0.000994 acc 1.000000  rank 1
2025-01-11 04:30:14,274 INFO Epoch 150 Step 146019 CV info lr 0.00013084746687703127 0 rank loss_2.637138771175319 acc_0.7813953635723967
2025-01-11 04:30:14,408 INFO Epoch 150 Step 146019 CV info lr 0.00013084746687703127 2 rank loss_2.637138771175319 acc_0.7813953635723967
2025-01-11 04:30:14,685 INFO Epoch 150 Step 146019 CV info lr 0.00013084746687703127 1 rank loss_2.637138771175319 acc_0.7813953635723967
2025-01-11 04:30:15,554 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_150_whole.pt
2025-01-11 04:30:15,575 INFO Added key: store_based_barrier_key:153 to store for rank: 0
2025-01-11 04:30:15,586 INFO Added key: store_based_barrier_key:153 to store for rank: 2
2025-01-11 04:30:15,586 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:153 with 3 nodes.
2025-01-11 04:30:15,586 INFO Added key: store_based_barrier_key:153 to store for rank: 1
2025-01-11 04:30:15,586 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:153 with 3 nodes.
2025-01-11 04:30:15,590 INFO Epoch 151 TRAIN info lr 0.00013084746687703127 rank 2
2025-01-11 04:30:15,590 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 04:30:15,594 INFO Epoch 151 TRAIN info lr 0.00013084746687703127 rank 1
2025-01-11 04:30:15,594 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 04:30:15,596 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:153 with 3 nodes.
2025-01-11 04:30:15,603 INFO Epoch 151 TRAIN info lr 0.00013084746687703127 rank 0
2025-01-11 04:30:15,603 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 04:30:47,221 DEBUG TRAIN Batch 151/100 loss 0.035465 acc 0.973044 lr 0.00013083 grad_norm 0.410975 rank 0
2025-01-11 04:30:47,222 DEBUG TRAIN Batch 151/100 loss 0.037281 acc 0.974630 lr 0.00013083 grad_norm 0.410975 rank 1
2025-01-11 04:30:47,222 DEBUG TRAIN Batch 151/100 loss 0.031081 acc 0.982238 lr 0.00013083 grad_norm 0.410975 rank 2
2025-01-11 04:31:11,239 DEBUG TRAIN Batch 151/200 loss 0.023670 acc 0.985037 lr 0.00013080 grad_norm 0.362097 rank 0
2025-01-11 04:31:11,239 DEBUG TRAIN Batch 151/200 loss 0.039900 acc 0.971715 lr 0.00013080 grad_norm 0.362097 rank 1
2025-01-11 04:31:11,239 DEBUG TRAIN Batch 151/200 loss 0.028429 acc 0.978410 lr 0.00013080 grad_norm 0.362097 rank 2
2025-01-11 04:31:35,595 DEBUG TRAIN Batch 151/300 loss 0.035176 acc 0.977583 lr 0.00013078 grad_norm 0.373013 rank 1
2025-01-11 04:31:35,595 DEBUG TRAIN Batch 151/300 loss 0.028907 acc 0.977670 lr 0.00013078 grad_norm 0.373013 rank 0
2025-01-11 04:31:35,596 DEBUG TRAIN Batch 151/300 loss 0.045796 acc 0.965096 lr 0.00013078 grad_norm 0.373013 rank 2
2025-01-11 04:31:59,274 DEBUG TRAIN Batch 151/400 loss 0.027222 acc 0.979920 lr 0.00013076 grad_norm 0.350980 rank 0
2025-01-11 04:31:59,274 DEBUG TRAIN Batch 151/400 loss 0.026912 acc 0.979846 lr 0.00013076 grad_norm 0.350980 rank 1
2025-01-11 04:31:59,274 DEBUG TRAIN Batch 151/400 loss 0.022786 acc 0.983854 lr 0.00013076 grad_norm 0.350980 rank 2
2025-01-11 04:32:23,450 DEBUG TRAIN Batch 151/500 loss 0.026797 acc 0.982709 lr 0.00013074 grad_norm 0.376927 rank 0
2025-01-11 04:32:23,450 DEBUG TRAIN Batch 151/500 loss 0.035250 acc 0.974113 lr 0.00013074 grad_norm 0.376927 rank 1
2025-01-11 04:32:23,451 DEBUG TRAIN Batch 151/500 loss 0.030914 acc 0.979633 lr 0.00013074 grad_norm 0.376927 rank 2
2025-01-11 04:32:47,704 DEBUG TRAIN Batch 151/600 loss 0.035644 acc 0.974414 lr 0.00013071 grad_norm 0.369854 rank 1
2025-01-11 04:32:47,704 DEBUG TRAIN Batch 151/600 loss 0.016697 acc 0.990333 lr 0.00013071 grad_norm 0.369854 rank 0
2025-01-11 04:32:47,704 DEBUG TRAIN Batch 151/600 loss 0.049508 acc 0.966964 lr 0.00013071 grad_norm 0.369854 rank 2
2025-01-11 04:33:11,204 DEBUG TRAIN Batch 151/700 loss 0.038887 acc 0.969379 lr 0.00013069 grad_norm 0.384782 rank 0
2025-01-11 04:33:11,204 DEBUG TRAIN Batch 151/700 loss 0.035984 acc 0.974684 lr 0.00013069 grad_norm 0.384782 rank 2
2025-01-11 04:33:11,205 DEBUG TRAIN Batch 151/700 loss 0.029986 acc 0.979424 lr 0.00013069 grad_norm 0.384782 rank 1
2025-01-11 04:33:34,498 DEBUG TRAIN Batch 151/800 loss 0.031788 acc 0.978745 lr 0.00013067 grad_norm 0.392639 rank 1
2025-01-11 04:33:34,499 DEBUG TRAIN Batch 151/800 loss 0.024741 acc 0.987406 lr 0.00013067 grad_norm 0.392639 rank 0
2025-01-11 04:33:34,499 DEBUG TRAIN Batch 151/800 loss 0.032982 acc 0.980392 lr 0.00013067 grad_norm 0.392639 rank 2
2025-01-11 04:33:58,373 DEBUG TRAIN Batch 151/900 loss 0.036913 acc 0.973776 lr 0.00013065 grad_norm 0.403012 rank 1
2025-01-11 04:33:58,373 DEBUG TRAIN Batch 151/900 loss 0.033371 acc 0.976521 lr 0.00013065 grad_norm 0.403012 rank 0
2025-01-11 04:33:58,373 DEBUG TRAIN Batch 151/900 loss 0.037472 acc 0.971302 lr 0.00013065 grad_norm 0.403012 rank 2
2025-01-11 04:34:22,398 DEBUG TRAIN Batch 151/1000 loss 0.041203 acc 0.968041 lr 0.00013062 grad_norm 0.436675 rank 1
2025-01-11 04:34:22,398 DEBUG TRAIN Batch 151/1000 loss 0.041213 acc 0.976804 lr 0.00013062 grad_norm 0.436675 rank 0
2025-01-11 04:34:22,398 DEBUG TRAIN Batch 151/1000 loss 0.024985 acc 0.979266 lr 0.00013062 grad_norm 0.436675 rank 2
2025-01-11 04:34:46,306 DEBUG TRAIN Batch 151/1100 loss 0.039147 acc 0.967520 lr 0.00013060 grad_norm 0.366670 rank 0
2025-01-11 04:34:46,306 DEBUG TRAIN Batch 151/1100 loss 0.022071 acc 0.985222 lr 0.00013060 grad_norm 0.366670 rank 1
2025-01-11 04:34:46,306 DEBUG TRAIN Batch 151/1100 loss 0.029891 acc 0.982915 lr 0.00013060 grad_norm 0.366670 rank 2
2025-01-11 04:35:09,949 DEBUG TRAIN Batch 151/1200 loss 0.032305 acc 0.987147 lr 0.00013058 grad_norm 0.401644 rank 2
2025-01-11 04:35:09,949 DEBUG TRAIN Batch 151/1200 loss 0.032156 acc 0.975824 lr 0.00013058 grad_norm 0.401644 rank 0
2025-01-11 04:35:09,949 DEBUG TRAIN Batch 151/1200 loss 0.032991 acc 0.972160 lr 0.00013058 grad_norm 0.401644 rank 1
2025-01-11 04:35:33,676 DEBUG TRAIN Batch 151/1300 loss 0.042373 acc 0.972872 lr 0.00013056 grad_norm 0.418668 rank 0
2025-01-11 04:35:33,676 DEBUG TRAIN Batch 151/1300 loss 0.032210 acc 0.981098 lr 0.00013056 grad_norm 0.418668 rank 2
2025-01-11 04:35:33,677 DEBUG TRAIN Batch 151/1300 loss 0.034317 acc 0.977340 lr 0.00013056 grad_norm 0.418668 rank 1
2025-01-11 04:35:57,520 DEBUG TRAIN Batch 151/1400 loss 0.035536 acc 0.970958 lr 0.00013053 grad_norm 0.395368 rank 1
2025-01-11 04:35:57,520 DEBUG TRAIN Batch 151/1400 loss 0.034136 acc 0.973451 lr 0.00013053 grad_norm 0.395368 rank 0
2025-01-11 04:35:57,520 DEBUG TRAIN Batch 151/1400 loss 0.023548 acc 0.981839 lr 0.00013053 grad_norm 0.395368 rank 2
2025-01-11 04:36:21,789 DEBUG TRAIN Batch 151/1500 loss 0.026877 acc 0.984962 lr 0.00013051 grad_norm 0.408136 rank 0
2025-01-11 04:36:21,789 DEBUG TRAIN Batch 151/1500 loss 0.037452 acc 0.968689 lr 0.00013051 grad_norm 0.408136 rank 2
2025-01-11 04:36:21,790 DEBUG TRAIN Batch 151/1500 loss 0.032536 acc 0.977340 lr 0.00013051 grad_norm 0.408136 rank 1
2025-01-11 04:36:46,162 DEBUG TRAIN Batch 151/1600 loss 0.018681 acc 0.987310 lr 0.00013049 grad_norm 0.416614 rank 1
2025-01-11 04:36:46,162 DEBUG TRAIN Batch 151/1600 loss 0.041458 acc 0.971061 lr 0.00013049 grad_norm 0.416614 rank 0
2025-01-11 04:36:46,163 DEBUG TRAIN Batch 151/1600 loss 0.026799 acc 0.985451 lr 0.00013049 grad_norm 0.416614 rank 2
2025-01-11 04:37:10,601 DEBUG TRAIN Batch 151/1700 loss 0.037590 acc 0.974624 lr 0.00013047 grad_norm 0.386481 rank 0
2025-01-11 04:37:10,601 DEBUG TRAIN Batch 151/1700 loss 0.030229 acc 0.975634 lr 0.00013047 grad_norm 0.386481 rank 1
2025-01-11 04:37:10,602 DEBUG TRAIN Batch 151/1700 loss 0.040035 acc 0.978300 lr 0.00013047 grad_norm 0.386481 rank 2
2025-01-11 04:37:35,190 DEBUG TRAIN Batch 151/1800 loss 0.034581 acc 0.977293 lr 0.00013045 grad_norm 0.391913 rank 0
2025-01-11 04:37:35,190 DEBUG TRAIN Batch 151/1800 loss 0.023317 acc 0.993464 lr 0.00013045 grad_norm 0.391913 rank 1
2025-01-11 04:37:35,191 DEBUG TRAIN Batch 151/1800 loss 0.045877 acc 0.967712 lr 0.00013045 grad_norm 0.391913 rank 2
2025-01-11 04:37:59,276 DEBUG TRAIN Batch 151/1900 loss 0.023431 acc 0.981767 lr 0.00013042 grad_norm 0.399226 rank 1
2025-01-11 04:37:59,276 DEBUG TRAIN Batch 151/1900 loss 0.033477 acc 0.973357 lr 0.00013042 grad_norm 0.399226 rank 2
2025-01-11 04:37:59,276 DEBUG TRAIN Batch 151/1900 loss 0.032415 acc 0.974003 lr 0.00013042 grad_norm 0.399226 rank 0
2025-01-11 04:38:24,394 DEBUG TRAIN Batch 151/2000 loss 0.022718 acc 0.987414 lr 0.00013040 grad_norm 0.380879 rank 1
2025-01-11 04:38:24,395 DEBUG TRAIN Batch 151/2000 loss 0.031361 acc 0.975108 lr 0.00013040 grad_norm 0.380879 rank 0
2025-01-11 04:38:24,395 DEBUG TRAIN Batch 151/2000 loss 0.036452 acc 0.975535 lr 0.00013040 grad_norm 0.380879 rank 2
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 04:39:29,019 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 04:39:29,020 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 04:39:29,454 INFO Epoch 151 Step 147028 on_batch_end True CV rank 1
2025-01-11 04:39:29,454 INFO Epoch 151 Step 147028 on_batch_end True CV rank 0
2025-01-11 04:39:29,454 INFO Epoch 151 Step 147028 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 04:39:38,401 DEBUG CV Batch 151/100 loss 0.003178 acc 0.998885  rank 0
2025-01-11 04:39:38,811 DEBUG CV Batch 151/100 loss 0.003178 acc 0.998885  rank 2
2025-01-11 04:39:38,885 INFO Epoch 151 Step 147028 CV info lr 0.00013039771450068936 0 rank loss_2.633414813354887 acc_0.7805592124922234
2025-01-11 04:39:38,981 DEBUG CV Batch 151/100 loss 0.003178 acc 0.998885  rank 1
2025-01-11 04:39:39,368 INFO Epoch 151 Step 147028 CV info lr 0.00013039771450068936 2 rank loss_2.633414813354887 acc_0.7805592124922234
2025-01-11 04:39:39,477 INFO Epoch 151 Step 147028 CV info lr 0.00013039771450068936 1 rank loss_2.633414813354887 acc_0.7805592124922234
2025-01-11 04:39:40,182 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_151_whole.pt
2025-01-11 04:39:40,203 INFO Added key: store_based_barrier_key:154 to store for rank: 0
2025-01-11 04:39:40,204 INFO Added key: store_based_barrier_key:154 to store for rank: 1
2025-01-11 04:39:40,204 INFO Added key: store_based_barrier_key:154 to store for rank: 2
2025-01-11 04:39:40,204 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:154 with 3 nodes.
2025-01-11 04:39:40,204 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:154 with 3 nodes.
2025-01-11 04:39:40,207 INFO Epoch 152 TRAIN info lr 0.00013039771450068936 rank 2
2025-01-11 04:39:40,207 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 04:39:40,208 INFO Epoch 152 TRAIN info lr 0.00013039771450068936 rank 1
2025-01-11 04:39:40,208 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 04:39:40,214 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:154 with 3 nodes.
2025-01-11 04:39:40,218 INFO Epoch 152 TRAIN info lr 0.00013039771450068936 rank 0
2025-01-11 04:39:40,218 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 04:40:13,579 DEBUG TRAIN Batch 152/100 loss 0.039683 acc 0.970398 lr 0.00013038 grad_norm 0.363747 rank 0
2025-01-11 04:40:13,579 DEBUG TRAIN Batch 152/100 loss 0.026865 acc 0.981215 lr 0.00013038 grad_norm 0.363747 rank 2
2025-01-11 04:40:13,579 DEBUG TRAIN Batch 152/100 loss 0.026657 acc 0.981868 lr 0.00013038 grad_norm 0.363747 rank 1
2025-01-11 04:40:37,687 DEBUG TRAIN Batch 152/200 loss 0.039246 acc 0.977337 lr 0.00013035 grad_norm 0.407256 rank 0
2025-01-11 04:40:37,687 DEBUG TRAIN Batch 152/200 loss 0.037122 acc 0.973502 lr 0.00013035 grad_norm 0.407256 rank 2
2025-01-11 04:40:37,687 DEBUG TRAIN Batch 152/200 loss 0.037704 acc 0.976116 lr 0.00013035 grad_norm 0.407256 rank 1
2025-01-11 04:41:02,636 DEBUG TRAIN Batch 152/300 loss 0.024917 acc 0.986538 lr 0.00013033 grad_norm 0.377977 rank 1
2025-01-11 04:41:02,637 DEBUG TRAIN Batch 152/300 loss 0.026818 acc 0.981211 lr 0.00013033 grad_norm 0.377977 rank 0
2025-01-11 04:41:02,637 DEBUG TRAIN Batch 152/300 loss 0.028826 acc 0.985646 lr 0.00013033 grad_norm 0.377977 rank 2
2025-01-11 04:41:26,741 DEBUG TRAIN Batch 152/400 loss 0.031387 acc 0.975930 lr 0.00013031 grad_norm 0.394503 rank 1
2025-01-11 04:41:26,741 DEBUG TRAIN Batch 152/400 loss 0.033317 acc 0.978339 lr 0.00013031 grad_norm 0.394503 rank 0
2025-01-11 04:41:26,741 DEBUG TRAIN Batch 152/400 loss 0.040728 acc 0.969753 lr 0.00013031 grad_norm 0.394503 rank 2
2025-01-11 04:41:51,131 DEBUG TRAIN Batch 152/500 loss 0.040352 acc 0.971396 lr 0.00013029 grad_norm 0.427566 rank 0
2025-01-11 04:41:51,131 DEBUG TRAIN Batch 152/500 loss 0.031992 acc 0.981113 lr 0.00013029 grad_norm 0.427566 rank 2
2025-01-11 04:41:51,132 DEBUG TRAIN Batch 152/500 loss 0.037905 acc 0.970326 lr 0.00013029 grad_norm 0.427566 rank 1
2025-01-11 04:42:15,726 DEBUG TRAIN Batch 152/600 loss 0.029487 acc 0.975915 lr 0.00013026 grad_norm 0.363728 rank 1
2025-01-11 04:42:15,726 DEBUG TRAIN Batch 152/600 loss 0.028159 acc 0.979646 lr 0.00013026 grad_norm 0.363728 rank 0
2025-01-11 04:42:15,726 DEBUG TRAIN Batch 152/600 loss 0.044898 acc 0.966986 lr 0.00013026 grad_norm 0.363728 rank 2
2025-01-11 04:42:40,322 DEBUG TRAIN Batch 152/700 loss 0.030647 acc 0.978193 lr 0.00013024 grad_norm 0.390509 rank 0
2025-01-11 04:42:40,322 DEBUG TRAIN Batch 152/700 loss 0.038631 acc 0.978042 lr 0.00013024 grad_norm 0.390509 rank 1
2025-01-11 04:42:40,322 DEBUG TRAIN Batch 152/700 loss 0.023276 acc 0.981320 lr 0.00013024 grad_norm 0.390509 rank 2
2025-01-11 04:43:04,328 DEBUG TRAIN Batch 152/800 loss 0.023170 acc 0.980961 lr 0.00013022 grad_norm 0.362965 rank 2
2025-01-11 04:43:04,328 DEBUG TRAIN Batch 152/800 loss 0.035138 acc 0.975936 lr 0.00013022 grad_norm 0.362965 rank 0
2025-01-11 04:43:04,328 DEBUG TRAIN Batch 152/800 loss 0.026750 acc 0.984293 lr 0.00013022 grad_norm 0.362965 rank 1
2025-01-11 04:43:29,439 DEBUG TRAIN Batch 152/900 loss 0.040996 acc 0.970339 lr 0.00013020 grad_norm 0.400529 rank 1
2025-01-11 04:43:29,439 DEBUG TRAIN Batch 152/900 loss 0.037364 acc 0.972727 lr 0.00013020 grad_norm 0.400529 rank 0
2025-01-11 04:43:29,440 DEBUG TRAIN Batch 152/900 loss 0.032001 acc 0.979808 lr 0.00013020 grad_norm 0.400529 rank 2
2025-01-11 04:43:53,522 DEBUG TRAIN Batch 152/1000 loss 0.034586 acc 0.974427 lr 0.00013018 grad_norm 0.378882 rank 1
2025-01-11 04:43:53,523 DEBUG TRAIN Batch 152/1000 loss 0.017143 acc 0.987212 lr 0.00013018 grad_norm 0.378882 rank 0
2025-01-11 04:43:53,523 DEBUG TRAIN Batch 152/1000 loss 0.031495 acc 0.972279 lr 0.00013018 grad_norm 0.378882 rank 2
2025-01-11 04:44:17,278 DEBUG TRAIN Batch 152/1100 loss 0.034278 acc 0.974972 lr 0.00013015 grad_norm 0.411801 rank 2
2025-01-11 04:44:17,279 DEBUG TRAIN Batch 152/1100 loss 0.030198 acc 0.977842 lr 0.00013015 grad_norm 0.411801 rank 0
2025-01-11 04:44:17,279 DEBUG TRAIN Batch 152/1100 loss 0.041870 acc 0.968497 lr 0.00013015 grad_norm 0.411801 rank 1
2025-01-11 04:44:41,057 DEBUG TRAIN Batch 152/1200 loss 0.025673 acc 0.984479 lr 0.00013013 grad_norm 0.362901 rank 1
2025-01-11 04:44:41,057 DEBUG TRAIN Batch 152/1200 loss 0.023134 acc 0.985413 lr 0.00013013 grad_norm 0.362901 rank 0
2025-01-11 04:44:41,058 DEBUG TRAIN Batch 152/1200 loss 0.032770 acc 0.979872 lr 0.00013013 grad_norm 0.362901 rank 2
2025-01-11 04:45:04,509 DEBUG TRAIN Batch 152/1300 loss 0.029998 acc 0.978198 lr 0.00013011 grad_norm 0.370459 rank 0
2025-01-11 04:45:04,509 DEBUG TRAIN Batch 152/1300 loss 0.033359 acc 0.975521 lr 0.00013011 grad_norm 0.370459 rank 1
2025-01-11 04:45:04,509 DEBUG TRAIN Batch 152/1300 loss 0.036836 acc 0.976371 lr 0.00013011 grad_norm 0.370459 rank 2
2025-01-11 04:45:28,490 DEBUG TRAIN Batch 152/1400 loss 0.030138 acc 0.977871 lr 0.00013009 grad_norm 0.399489 rank 1
2025-01-11 04:45:28,490 DEBUG TRAIN Batch 152/1400 loss 0.039021 acc 0.972569 lr 0.00013009 grad_norm 0.399489 rank 0
2025-01-11 04:45:28,490 DEBUG TRAIN Batch 152/1400 loss 0.024832 acc 0.983425 lr 0.00013009 grad_norm 0.399489 rank 2
2025-01-11 04:45:53,195 DEBUG TRAIN Batch 152/1500 loss 0.031514 acc 0.982714 lr 0.00013007 grad_norm 0.392561 rank 2
2025-01-11 04:45:53,195 DEBUG TRAIN Batch 152/1500 loss 0.054183 acc 0.969863 lr 0.00013007 grad_norm 0.392561 rank 0
2025-01-11 04:45:53,195 DEBUG TRAIN Batch 152/1500 loss 0.037259 acc 0.970537 lr 0.00013007 grad_norm 0.392561 rank 1
2025-01-11 04:46:17,261 DEBUG TRAIN Batch 152/1600 loss 0.026016 acc 0.980660 lr 0.00013004 grad_norm 0.414900 rank 1
2025-01-11 04:46:17,261 DEBUG TRAIN Batch 152/1600 loss 0.028756 acc 0.982633 lr 0.00013004 grad_norm 0.414900 rank 2
2025-01-11 04:46:17,261 DEBUG TRAIN Batch 152/1600 loss 0.027853 acc 0.981818 lr 0.00013004 grad_norm 0.414900 rank 0
2025-01-11 04:46:41,486 DEBUG TRAIN Batch 152/1700 loss 0.033560 acc 0.982759 lr 0.00013002 grad_norm 0.356285 rank 0
2025-01-11 04:46:41,486 DEBUG TRAIN Batch 152/1700 loss 0.022436 acc 0.985809 lr 0.00013002 grad_norm 0.356285 rank 1
2025-01-11 04:46:41,487 DEBUG TRAIN Batch 152/1700 loss 0.028879 acc 0.978495 lr 0.00013002 grad_norm 0.356285 rank 2
2025-01-11 04:47:05,205 DEBUG TRAIN Batch 152/1800 loss 0.030894 acc 0.976337 lr 0.00013000 grad_norm 0.404608 rank 0
2025-01-11 04:47:05,205 DEBUG TRAIN Batch 152/1800 loss 0.021342 acc 0.985309 lr 0.00013000 grad_norm 0.404608 rank 1
2025-01-11 04:47:05,205 DEBUG TRAIN Batch 152/1800 loss 0.049391 acc 0.969216 lr 0.00013000 grad_norm 0.404608 rank 2
2025-01-11 04:47:29,328 DEBUG TRAIN Batch 152/1900 loss 0.021590 acc 0.985112 lr 0.00012998 grad_norm 0.371026 rank 0
2025-01-11 04:47:29,329 DEBUG TRAIN Batch 152/1900 loss 0.033495 acc 0.976578 lr 0.00012998 grad_norm 0.371026 rank 2
2025-01-11 04:47:29,329 DEBUG TRAIN Batch 152/1900 loss 0.024555 acc 0.981025 lr 0.00012998 grad_norm 0.371026 rank 1
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 04:48:38,855 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 04:48:38,856 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 04:48:39,327 INFO Epoch 152 Step 147998 on_batch_end True CV rank 2
2025-01-11 04:48:39,327 INFO Epoch 152 Step 147998 on_batch_end True CV rank 0
2025-01-11 04:48:39,327 INFO Epoch 152 Step 147998 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 04:48:48,292 DEBUG CV Batch 152/100 loss 0.003347 acc 0.998885  rank 0
2025-01-11 04:48:48,814 INFO Epoch 152 Step 147998 CV info lr 0.00012996968940405298 0 rank loss_2.6514523885743344 acc_0.7811293634667731
2025-01-11 04:48:48,866 DEBUG CV Batch 152/100 loss 0.003347 acc 0.998885  rank 2
2025-01-11 04:48:49,109 DEBUG CV Batch 152/100 loss 0.003347 acc 0.998885  rank 1
2025-01-11 04:48:49,410 INFO Epoch 152 Step 147998 CV info lr 0.00012996968940405298 2 rank loss_2.6514523885743344 acc_0.7811293634667731
2025-01-11 04:48:49,651 INFO Epoch 152 Step 147998 CV info lr 0.00012996968940405298 1 rank loss_2.6514523885743344 acc_0.7811293634667731
2025-01-11 04:48:50,119 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_152_whole.pt
2025-01-11 04:48:50,131 INFO Added key: store_based_barrier_key:155 to store for rank: 0
2025-01-11 04:48:50,141 INFO Added key: store_based_barrier_key:155 to store for rank: 2
2025-01-11 04:48:50,141 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:155 with 3 nodes.
2025-01-11 04:48:50,141 INFO Added key: store_based_barrier_key:155 to store for rank: 1
2025-01-11 04:48:50,141 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:155 with 3 nodes.
2025-01-11 04:48:50,141 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:155 with 3 nodes.
2025-01-11 04:48:50,144 INFO Epoch 153 TRAIN info lr 0.00012996968940405298 rank 0
2025-01-11 04:48:50,144 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 04:48:50,145 INFO Epoch 153 TRAIN info lr 0.00012996968940405298 rank 2
2025-01-11 04:48:50,145 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 04:48:50,146 INFO Epoch 153 TRAIN info lr 0.00012996968940405298 rank 1
2025-01-11 04:48:50,146 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 04:49:26,722 DEBUG TRAIN Batch 153/100 loss 0.028567 acc 0.983316 lr 0.00012995 grad_norm 0.353416 rank 0
2025-01-11 04:49:26,722 DEBUG TRAIN Batch 153/100 loss 0.020239 acc 0.985203 lr 0.00012995 grad_norm 0.353416 rank 2
2025-01-11 04:49:26,723 DEBUG TRAIN Batch 153/100 loss 0.036715 acc 0.974739 lr 0.00012995 grad_norm 0.353416 rank 1
2025-01-11 04:49:50,983 DEBUG TRAIN Batch 153/200 loss 0.024341 acc 0.983083 lr 0.00012993 grad_norm 0.361819 rank 2
2025-01-11 04:49:50,983 DEBUG TRAIN Batch 153/200 loss 0.032772 acc 0.979263 lr 0.00012993 grad_norm 0.361819 rank 1
2025-01-11 04:49:50,983 DEBUG TRAIN Batch 153/200 loss 0.044737 acc 0.970669 lr 0.00012993 grad_norm 0.361819 rank 0
2025-01-11 04:50:15,592 DEBUG TRAIN Batch 153/300 loss 0.030254 acc 0.975883 lr 0.00012990 grad_norm 0.370544 rank 0
2025-01-11 04:50:15,593 DEBUG TRAIN Batch 153/300 loss 0.022208 acc 0.980583 lr 0.00012990 grad_norm 0.370544 rank 2
2025-01-11 04:50:15,594 DEBUG TRAIN Batch 153/300 loss 0.048201 acc 0.966546 lr 0.00012990 grad_norm 0.370544 rank 1
2025-01-11 04:50:39,416 DEBUG TRAIN Batch 153/400 loss 0.035667 acc 0.970996 lr 0.00012988 grad_norm 0.401953 rank 1
2025-01-11 04:50:39,416 DEBUG TRAIN Batch 153/400 loss 0.031016 acc 0.975419 lr 0.00012988 grad_norm 0.401953 rank 0
2025-01-11 04:50:39,417 DEBUG TRAIN Batch 153/400 loss 0.024645 acc 0.981241 lr 0.00012988 grad_norm 0.401953 rank 2
2025-01-11 04:51:04,499 DEBUG TRAIN Batch 153/500 loss 0.027941 acc 0.978545 lr 0.00012986 grad_norm 0.366642 rank 0
2025-01-11 04:51:04,499 DEBUG TRAIN Batch 153/500 loss 0.029587 acc 0.982609 lr 0.00012986 grad_norm 0.366642 rank 2
2025-01-11 04:51:04,500 DEBUG TRAIN Batch 153/500 loss 0.037958 acc 0.973048 lr 0.00012986 grad_norm 0.366642 rank 1
2025-01-11 04:51:29,570 DEBUG TRAIN Batch 153/600 loss 0.033236 acc 0.974671 lr 0.00012984 grad_norm 0.379799 rank 1
2025-01-11 04:51:29,570 DEBUG TRAIN Batch 153/600 loss 0.030681 acc 0.979068 lr 0.00012984 grad_norm 0.379799 rank 2
2025-01-11 04:51:29,571 DEBUG TRAIN Batch 153/600 loss 0.029541 acc 0.982938 lr 0.00012984 grad_norm 0.379799 rank 0
2025-01-11 04:51:54,001 DEBUG TRAIN Batch 153/700 loss 0.030898 acc 0.978824 lr 0.00012982 grad_norm 0.388368 rank 2
2025-01-11 04:51:54,002 DEBUG TRAIN Batch 153/700 loss 0.044689 acc 0.974432 lr 0.00012982 grad_norm 0.388368 rank 0
2025-01-11 04:51:54,003 DEBUG TRAIN Batch 153/700 loss 0.028827 acc 0.982238 lr 0.00012982 grad_norm 0.388368 rank 1
2025-01-11 04:52:19,464 DEBUG TRAIN Batch 153/800 loss 0.046202 acc 0.966667 lr 0.00012979 grad_norm 0.376684 rank 1
2025-01-11 04:52:19,464 DEBUG TRAIN Batch 153/800 loss 0.027050 acc 0.978995 lr 0.00012979 grad_norm 0.376684 rank 0
2025-01-11 04:52:19,464 DEBUG TRAIN Batch 153/800 loss 0.030050 acc 0.974312 lr 0.00012979 grad_norm 0.376684 rank 2
2025-01-11 04:52:44,446 DEBUG TRAIN Batch 153/900 loss 0.035013 acc 0.970297 lr 0.00012977 grad_norm 0.371392 rank 0
2025-01-11 04:52:44,446 DEBUG TRAIN Batch 153/900 loss 0.017262 acc 0.985827 lr 0.00012977 grad_norm 0.371392 rank 2
2025-01-11 04:52:44,446 DEBUG TRAIN Batch 153/900 loss 0.033106 acc 0.980734 lr 0.00012977 grad_norm 0.371392 rank 1
2025-01-11 04:53:08,524 DEBUG TRAIN Batch 153/1000 loss 0.040286 acc 0.981081 lr 0.00012975 grad_norm 0.407255 rank 1
2025-01-11 04:53:08,524 DEBUG TRAIN Batch 153/1000 loss 0.027898 acc 0.981944 lr 0.00012975 grad_norm 0.407255 rank 2
2025-01-11 04:53:08,525 DEBUG TRAIN Batch 153/1000 loss 0.045160 acc 0.973707 lr 0.00012975 grad_norm 0.407255 rank 0
2025-01-11 04:53:34,144 DEBUG TRAIN Batch 153/1100 loss 0.026512 acc 0.978703 lr 0.00012973 grad_norm 0.382404 rank 0
2025-01-11 04:53:34,144 DEBUG TRAIN Batch 153/1100 loss 0.021271 acc 0.979661 lr 0.00012973 grad_norm 0.382404 rank 1
2025-01-11 04:53:34,144 DEBUG TRAIN Batch 153/1100 loss 0.045111 acc 0.967677 lr 0.00012973 grad_norm 0.382404 rank 2
2025-01-11 04:53:58,960 DEBUG TRAIN Batch 153/1200 loss 0.029263 acc 0.976866 lr 0.00012971 grad_norm 0.396394 rank 1
2025-01-11 04:53:58,960 DEBUG TRAIN Batch 153/1200 loss 0.036963 acc 0.976603 lr 0.00012971 grad_norm 0.396394 rank 0
2025-01-11 04:53:58,960 DEBUG TRAIN Batch 153/1200 loss 0.033023 acc 0.978910 lr 0.00012971 grad_norm 0.396394 rank 2
2025-01-11 04:54:23,148 DEBUG TRAIN Batch 153/1300 loss 0.026323 acc 0.980053 lr 0.00012969 grad_norm 0.422803 rank 0
2025-01-11 04:54:23,148 DEBUG TRAIN Batch 153/1300 loss 0.038097 acc 0.972851 lr 0.00012969 grad_norm 0.422803 rank 1
2025-01-11 04:54:23,149 DEBUG TRAIN Batch 153/1300 loss 0.028720 acc 0.978287 lr 0.00012969 grad_norm 0.422803 rank 2
2025-01-11 04:54:46,705 DEBUG TRAIN Batch 153/1400 loss 0.025004 acc 0.984026 lr 0.00012966 grad_norm 0.377614 rank 0
2025-01-11 04:54:46,706 DEBUG TRAIN Batch 153/1400 loss 0.033905 acc 0.976145 lr 0.00012966 grad_norm 0.377614 rank 1
2025-01-11 04:54:46,706 DEBUG TRAIN Batch 153/1400 loss 0.042190 acc 0.969286 lr 0.00012966 grad_norm 0.377614 rank 2
2025-01-11 04:55:10,916 DEBUG TRAIN Batch 153/1500 loss 0.037501 acc 0.973044 lr 0.00012964 grad_norm 0.407206 rank 2
2025-01-11 04:55:10,916 DEBUG TRAIN Batch 153/1500 loss 0.027056 acc 0.984887 lr 0.00012964 grad_norm 0.407206 rank 0
2025-01-11 04:55:10,916 DEBUG TRAIN Batch 153/1500 loss 0.034277 acc 0.978328 lr 0.00012964 grad_norm 0.407206 rank 1
2025-01-11 04:55:35,144 DEBUG TRAIN Batch 153/1600 loss 0.035393 acc 0.977143 lr 0.00012962 grad_norm 0.381366 rank 0
2025-01-11 04:55:35,144 DEBUG TRAIN Batch 153/1600 loss 0.031751 acc 0.978766 lr 0.00012962 grad_norm 0.381366 rank 1
2025-01-11 04:55:35,145 DEBUG TRAIN Batch 153/1600 loss 0.031503 acc 0.975309 lr 0.00012962 grad_norm 0.381366 rank 2
2025-01-11 04:55:59,250 DEBUG TRAIN Batch 153/1700 loss 0.023067 acc 0.985491 lr 0.00012960 grad_norm 0.355092 rank 1
2025-01-11 04:55:59,251 DEBUG TRAIN Batch 153/1700 loss 0.028586 acc 0.980519 lr 0.00012960 grad_norm 0.355092 rank 0
2025-01-11 04:55:59,251 DEBUG TRAIN Batch 153/1700 loss 0.018467 acc 0.987406 lr 0.00012960 grad_norm 0.355092 rank 2
2025-01-11 04:56:23,033 DEBUG TRAIN Batch 153/1800 loss 0.030389 acc 0.980035 lr 0.00012958 grad_norm 0.380901 rank 1
2025-01-11 04:56:23,033 DEBUG TRAIN Batch 153/1800 loss 0.029497 acc 0.975610 lr 0.00012958 grad_norm 0.380901 rank 0
2025-01-11 04:56:23,034 DEBUG TRAIN Batch 153/1800 loss 0.048580 acc 0.964962 lr 0.00012958 grad_norm 0.380901 rank 2
2025-01-11 04:56:46,785 DEBUG TRAIN Batch 153/1900 loss 0.036197 acc 0.972469 lr 0.00012955 grad_norm 0.384108 rank 0
2025-01-11 04:56:46,786 DEBUG TRAIN Batch 153/1900 loss 0.035913 acc 0.969727 lr 0.00012955 grad_norm 0.384108 rank 1
2025-01-11 04:56:46,786 DEBUG TRAIN Batch 153/1900 loss 0.039182 acc 0.974843 lr 0.00012955 grad_norm 0.384108 rank 2
2025-01-11 04:57:10,850 DEBUG TRAIN Batch 153/2000 loss 0.032518 acc 0.974314 lr 0.00012953 grad_norm 0.397758 rank 0
2025-01-11 04:57:10,850 DEBUG TRAIN Batch 153/2000 loss 0.037331 acc 0.980704 lr 0.00012953 grad_norm 0.397758 rank 1
2025-01-11 04:57:10,851 DEBUG TRAIN Batch 153/2000 loss 0.038843 acc 0.971806 lr 0.00012953 grad_norm 0.397758 rank 2
2025-01-11 04:57:34,252 DEBUG TRAIN Batch 153/2100 loss 0.033754 acc 0.977549 lr 0.00012951 grad_norm 0.374493 rank 0
2025-01-11 04:57:34,252 DEBUG TRAIN Batch 153/2100 loss 0.028675 acc 0.984418 lr 0.00012951 grad_norm 0.374493 rank 1
2025-01-11 04:57:34,252 DEBUG TRAIN Batch 153/2100 loss 0.035007 acc 0.973148 lr 0.00012951 grad_norm 0.374493 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 04:58:45,719 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 04:58:45,720 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 04:58:46,143 INFO Epoch 153 Step 149072 on_batch_end True CV rank 0
2025-01-11 04:58:46,143 INFO Epoch 153 Step 149072 on_batch_end True CV rank 1
2025-01-11 04:58:46,143 INFO Epoch 153 Step 149072 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 04:58:55,196 DEBUG CV Batch 153/100 loss 0.004948 acc 0.997770  rank 0
2025-01-11 04:58:55,379 DEBUG CV Batch 153/100 loss 0.004948 acc 0.997770  rank 2
2025-01-11 04:58:55,677 INFO Epoch 153 Step 149072 CV info lr 0.0001295006550677704 0 rank loss_2.642301827064601 acc_0.7805970538603632
2025-01-11 04:58:55,873 INFO Epoch 153 Step 149072 CV info lr 0.0001295006550677704 2 rank loss_2.642301827064601 acc_0.7805970538603632
2025-01-11 04:58:56,062 DEBUG CV Batch 153/100 loss 0.004948 acc 0.997770  rank 1
2025-01-11 04:58:56,623 INFO Epoch 153 Step 149072 CV info lr 0.0001295006550677704 1 rank loss_2.642301827064601 acc_0.7805970538603632
2025-01-11 04:58:56,961 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_153_whole.pt
2025-01-11 04:58:56,973 INFO Added key: store_based_barrier_key:156 to store for rank: 0
2025-01-11 04:58:56,983 INFO Added key: store_based_barrier_key:156 to store for rank: 2
2025-01-11 04:58:56,983 INFO Added key: store_based_barrier_key:156 to store for rank: 1
2025-01-11 04:58:56,983 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:156 with 3 nodes.
2025-01-11 04:58:56,983 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:156 with 3 nodes.
2025-01-11 04:58:56,988 INFO Epoch 154 TRAIN info lr 0.0001295006550677704 rank 2
2025-01-11 04:58:56,988 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 04:58:56,990 INFO Epoch 154 TRAIN info lr 0.0001295006550677704 rank 1
2025-01-11 04:58:56,990 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 04:58:56,993 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:156 with 3 nodes.
2025-01-11 04:58:56,998 INFO Epoch 154 TRAIN info lr 0.0001295006550677704 rank 0
2025-01-11 04:58:56,998 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 04:59:28,128 DEBUG TRAIN Batch 154/100 loss 0.026596 acc 0.980493 lr 0.00012948 grad_norm 0.365070 rank 2
2025-01-11 04:59:28,128 DEBUG TRAIN Batch 154/100 loss 0.023972 acc 0.982420 lr 0.00012948 grad_norm 0.365070 rank 0
2025-01-11 04:59:28,128 DEBUG TRAIN Batch 154/100 loss 0.026642 acc 0.978791 lr 0.00012948 grad_norm 0.365070 rank 1
2025-01-11 04:59:52,035 DEBUG TRAIN Batch 154/200 loss 0.022658 acc 0.988117 lr 0.00012946 grad_norm 0.350113 rank 1
2025-01-11 04:59:52,035 DEBUG TRAIN Batch 154/200 loss 0.039145 acc 0.972603 lr 0.00012946 grad_norm 0.350113 rank 0
2025-01-11 04:59:52,035 DEBUG TRAIN Batch 154/200 loss 0.041096 acc 0.970044 lr 0.00012946 grad_norm 0.350113 rank 2
2025-01-11 05:00:15,523 DEBUG TRAIN Batch 154/300 loss 0.034996 acc 0.975214 lr 0.00012944 grad_norm 0.378190 rank 2
2025-01-11 05:00:15,524 DEBUG TRAIN Batch 154/300 loss 0.031872 acc 0.975543 lr 0.00012944 grad_norm 0.378190 rank 1
2025-01-11 05:00:15,524 DEBUG TRAIN Batch 154/300 loss 0.025610 acc 0.981660 lr 0.00012944 grad_norm 0.378190 rank 0
2025-01-11 05:00:39,210 DEBUG TRAIN Batch 154/400 loss 0.025676 acc 0.981481 lr 0.00012941 grad_norm 0.378138 rank 0
2025-01-11 05:00:39,211 DEBUG TRAIN Batch 154/400 loss 0.021627 acc 0.982310 lr 0.00012941 grad_norm 0.378138 rank 1
2025-01-11 05:00:39,211 DEBUG TRAIN Batch 154/400 loss 0.028420 acc 0.982163 lr 0.00012941 grad_norm 0.378138 rank 2
2025-01-11 05:01:03,400 DEBUG TRAIN Batch 154/500 loss 0.033897 acc 0.980820 lr 0.00012939 grad_norm 0.388091 rank 0
2025-01-11 05:01:03,400 DEBUG TRAIN Batch 154/500 loss 0.043666 acc 0.972272 lr 0.00012939 grad_norm 0.388091 rank 2
2025-01-11 05:01:03,401 DEBUG TRAIN Batch 154/500 loss 0.024497 acc 0.979960 lr 0.00012939 grad_norm 0.388091 rank 1
2025-01-11 05:01:26,812 DEBUG TRAIN Batch 154/600 loss 0.047227 acc 0.968153 lr 0.00012937 grad_norm 0.408154 rank 2
2025-01-11 05:01:26,812 DEBUG TRAIN Batch 154/600 loss 0.028083 acc 0.983539 lr 0.00012937 grad_norm 0.408154 rank 1
2025-01-11 05:01:26,812 DEBUG TRAIN Batch 154/600 loss 0.027462 acc 0.984756 lr 0.00012937 grad_norm 0.408154 rank 0
2025-01-11 05:01:50,823 DEBUG TRAIN Batch 154/700 loss 0.029595 acc 0.981517 lr 0.00012935 grad_norm 0.415330 rank 0
2025-01-11 05:01:50,824 DEBUG TRAIN Batch 154/700 loss 0.035652 acc 0.976787 lr 0.00012935 grad_norm 0.415330 rank 1
2025-01-11 05:01:50,824 DEBUG TRAIN Batch 154/700 loss 0.042649 acc 0.977173 lr 0.00012935 grad_norm 0.415330 rank 2
2025-01-11 05:02:14,051 DEBUG TRAIN Batch 154/800 loss 0.028678 acc 0.981361 lr 0.00012933 grad_norm 0.362071 rank 2
2025-01-11 05:02:14,051 DEBUG TRAIN Batch 154/800 loss 0.037459 acc 0.975472 lr 0.00012933 grad_norm 0.362071 rank 1
2025-01-11 05:02:14,051 DEBUG TRAIN Batch 154/800 loss 0.032383 acc 0.978507 lr 0.00012933 grad_norm 0.362071 rank 0
2025-01-11 05:02:37,939 DEBUG TRAIN Batch 154/900 loss 0.041238 acc 0.971154 lr 0.00012931 grad_norm 0.390680 rank 2
2025-01-11 05:02:37,939 DEBUG TRAIN Batch 154/900 loss 0.035694 acc 0.976258 lr 0.00012931 grad_norm 0.390680 rank 0
2025-01-11 05:02:37,940 DEBUG TRAIN Batch 154/900 loss 0.034905 acc 0.976037 lr 0.00012931 grad_norm 0.390680 rank 1
2025-01-11 05:03:01,573 DEBUG TRAIN Batch 154/1000 loss 0.022350 acc 0.982609 lr 0.00012928 grad_norm 0.388431 rank 0
2025-01-11 05:03:01,573 DEBUG TRAIN Batch 154/1000 loss 0.021565 acc 0.987879 lr 0.00012928 grad_norm 0.388431 rank 1
2025-01-11 05:03:01,574 DEBUG TRAIN Batch 154/1000 loss 0.043746 acc 0.974130 lr 0.00012928 grad_norm 0.388431 rank 2
2025-01-11 05:03:25,801 DEBUG TRAIN Batch 154/1100 loss 0.026609 acc 0.980188 lr 0.00012926 grad_norm 0.364251 rank 0
2025-01-11 05:03:25,801 DEBUG TRAIN Batch 154/1100 loss 0.035080 acc 0.971507 lr 0.00012926 grad_norm 0.364251 rank 1
2025-01-11 05:03:25,802 DEBUG TRAIN Batch 154/1100 loss 0.027373 acc 0.975952 lr 0.00012926 grad_norm 0.364251 rank 2
2025-01-11 05:03:50,527 DEBUG TRAIN Batch 154/1200 loss 0.033604 acc 0.976679 lr 0.00012924 grad_norm 0.377362 rank 0
2025-01-11 05:03:50,527 DEBUG TRAIN Batch 154/1200 loss 0.031662 acc 0.982365 lr 0.00012924 grad_norm 0.377362 rank 1
2025-01-11 05:03:50,528 DEBUG TRAIN Batch 154/1200 loss 0.027845 acc 0.980328 lr 0.00012924 grad_norm 0.377362 rank 2
2025-01-11 05:04:14,954 DEBUG TRAIN Batch 154/1300 loss 0.026948 acc 0.982438 lr 0.00012922 grad_norm 0.360373 rank 0
2025-01-11 05:04:14,955 DEBUG TRAIN Batch 154/1300 loss 0.015956 acc 0.991556 lr 0.00012922 grad_norm 0.360373 rank 1
2025-01-11 05:04:14,955 DEBUG TRAIN Batch 154/1300 loss 0.030641 acc 0.979710 lr 0.00012922 grad_norm 0.360373 rank 2
2025-01-11 05:04:38,861 DEBUG TRAIN Batch 154/1400 loss 0.025362 acc 0.982517 lr 0.00012920 grad_norm 0.381340 rank 0
2025-01-11 05:04:38,862 DEBUG TRAIN Batch 154/1400 loss 0.029398 acc 0.979339 lr 0.00012920 grad_norm 0.381340 rank 1
2025-01-11 05:04:38,862 DEBUG TRAIN Batch 154/1400 loss 0.023999 acc 0.977987 lr 0.00012920 grad_norm 0.381340 rank 2
2025-01-11 05:05:03,235 DEBUG TRAIN Batch 154/1500 loss 0.037497 acc 0.976119 lr 0.00012918 grad_norm 0.376518 rank 0
2025-01-11 05:05:03,235 DEBUG TRAIN Batch 154/1500 loss 0.031845 acc 0.973173 lr 0.00012918 grad_norm 0.376518 rank 2
2025-01-11 05:05:03,235 DEBUG TRAIN Batch 154/1500 loss 0.031719 acc 0.974940 lr 0.00012918 grad_norm 0.376518 rank 1
2025-01-11 05:05:28,070 DEBUG TRAIN Batch 154/1600 loss 0.037190 acc 0.969957 lr 0.00012915 grad_norm 0.391041 rank 0
2025-01-11 05:05:28,070 DEBUG TRAIN Batch 154/1600 loss 0.027679 acc 0.981287 lr 0.00012915 grad_norm 0.391041 rank 1
2025-01-11 05:05:28,071 DEBUG TRAIN Batch 154/1600 loss 0.050805 acc 0.962825 lr 0.00012915 grad_norm 0.391041 rank 2
2025-01-11 05:05:53,084 DEBUG TRAIN Batch 154/1700 loss 0.032685 acc 0.975587 lr 0.00012913 grad_norm 0.370126 rank 0
2025-01-11 05:05:53,085 DEBUG TRAIN Batch 154/1700 loss 0.031696 acc 0.974737 lr 0.00012913 grad_norm 0.370126 rank 2
2025-01-11 05:05:53,085 DEBUG TRAIN Batch 154/1700 loss 0.037802 acc 0.976916 lr 0.00012913 grad_norm 0.370126 rank 1
2025-01-11 05:06:17,471 DEBUG TRAIN Batch 154/1800 loss 0.029394 acc 0.978795 lr 0.00012911 grad_norm 0.399237 rank 0
2025-01-11 05:06:17,471 DEBUG TRAIN Batch 154/1800 loss 0.027829 acc 0.979310 lr 0.00012911 grad_norm 0.399237 rank 1
2025-01-11 05:06:17,472 DEBUG TRAIN Batch 154/1800 loss 0.047507 acc 0.966956 lr 0.00012911 grad_norm 0.399237 rank 2
2025-01-11 05:06:42,657 DEBUG TRAIN Batch 154/1900 loss 0.029520 acc 0.980431 lr 0.00012909 grad_norm 0.382113 rank 1
2025-01-11 05:06:42,657 DEBUG TRAIN Batch 154/1900 loss 0.033612 acc 0.980847 lr 0.00012909 grad_norm 0.382113 rank 0
2025-01-11 05:06:42,658 DEBUG TRAIN Batch 154/1900 loss 0.022510 acc 0.986395 lr 0.00012909 grad_norm 0.382113 rank 2
2025-01-11 05:07:08,380 DEBUG TRAIN Batch 154/2000 loss 0.023139 acc 0.978213 lr 0.00012907 grad_norm 0.379762 rank 0
2025-01-11 05:07:08,380 DEBUG TRAIN Batch 154/2000 loss 0.021971 acc 0.986804 lr 0.00012907 grad_norm 0.379762 rank 1
2025-01-11 05:07:08,381 DEBUG TRAIN Batch 154/2000 loss 0.030795 acc 0.976676 lr 0.00012907 grad_norm 0.379762 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 05:08:15,735 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 05:08:15,741 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 05:08:16,218 INFO Epoch 154 Step 150087 on_batch_end True CV rank 2
2025-01-11 05:08:16,218 INFO Epoch 154 Step 150087 on_batch_end True CV rank 1
2025-01-11 05:08:16,218 INFO Epoch 154 Step 150087 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 05:08:25,331 DEBUG CV Batch 154/100 loss 0.002256 acc 1.000000  rank 0
2025-01-11 05:08:25,663 DEBUG CV Batch 154/100 loss 0.002256 acc 1.000000  rank 2
2025-01-11 05:08:25,825 INFO Epoch 154 Step 150087 CV info lr 0.00012906202231259466 0 rank loss_2.6493791704862115 acc_0.7797526437462422
2025-01-11 05:08:26,074 DEBUG CV Batch 154/100 loss 0.002256 acc 1.000000  rank 1
2025-01-11 05:08:26,203 INFO Epoch 154 Step 150087 CV info lr 0.00012906202231259466 2 rank loss_2.6493791704862115 acc_0.7797526437462422
2025-01-11 05:08:26,621 INFO Epoch 154 Step 150087 CV info lr 0.00012906202231259466 1 rank loss_2.6493791704862115 acc_0.7797526437462422
2025-01-11 05:08:27,089 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_154_whole.pt
2025-01-11 05:08:27,111 INFO Added key: store_based_barrier_key:157 to store for rank: 0
2025-01-11 05:08:27,111 INFO Added key: store_based_barrier_key:157 to store for rank: 1
2025-01-11 05:08:27,112 INFO Added key: store_based_barrier_key:157 to store for rank: 2
2025-01-11 05:08:27,112 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:157 with 3 nodes.
2025-01-11 05:08:27,113 INFO Epoch 155 TRAIN info lr 0.00012906202231259466 rank 2
2025-01-11 05:08:27,113 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 05:08:27,122 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:157 with 3 nodes.
2025-01-11 05:08:27,122 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:157 with 3 nodes.
2025-01-11 05:08:27,130 INFO Epoch 155 TRAIN info lr 0.00012906202231259466 rank 0
2025-01-11 05:08:27,130 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 05:08:27,132 INFO Epoch 155 TRAIN info lr 0.00012906202231259466 rank 1
2025-01-11 05:08:27,132 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 05:09:03,271 DEBUG TRAIN Batch 155/100 loss 0.032250 acc 0.976697 lr 0.00012904 grad_norm 0.377435 rank 2
2025-01-11 05:09:03,271 DEBUG TRAIN Batch 155/100 loss 0.031856 acc 0.978022 lr 0.00012904 grad_norm 0.377435 rank 0
2025-01-11 05:09:03,271 DEBUG TRAIN Batch 155/100 loss 0.022859 acc 0.981132 lr 0.00012904 grad_norm 0.377435 rank 1
2025-01-11 05:09:27,425 DEBUG TRAIN Batch 155/200 loss 0.041865 acc 0.969786 lr 0.00012902 grad_norm 0.387522 rank 1
2025-01-11 05:09:27,426 DEBUG TRAIN Batch 155/200 loss 0.027242 acc 0.980304 lr 0.00012902 grad_norm 0.387522 rank 2
2025-01-11 05:09:27,426 DEBUG TRAIN Batch 155/200 loss 0.025194 acc 0.981503 lr 0.00012902 grad_norm 0.387522 rank 0
2025-01-11 05:09:51,958 DEBUG TRAIN Batch 155/300 loss 0.023379 acc 0.986708 lr 0.00012900 grad_norm 0.360092 rank 2
2025-01-11 05:09:51,958 DEBUG TRAIN Batch 155/300 loss 0.020250 acc 0.985871 lr 0.00012900 grad_norm 0.360092 rank 0
2025-01-11 05:09:51,959 DEBUG TRAIN Batch 155/300 loss 0.019394 acc 0.988543 lr 0.00012900 grad_norm 0.360092 rank 1
2025-01-11 05:10:16,190 DEBUG TRAIN Batch 155/400 loss 0.040405 acc 0.968623 lr 0.00012898 grad_norm 0.377360 rank 0
2025-01-11 05:10:16,190 DEBUG TRAIN Batch 155/400 loss 0.029471 acc 0.983578 lr 0.00012898 grad_norm 0.377360 rank 2
2025-01-11 05:10:16,190 DEBUG TRAIN Batch 155/400 loss 0.023584 acc 0.986919 lr 0.00012898 grad_norm 0.377360 rank 1
2025-01-11 05:10:40,990 DEBUG TRAIN Batch 155/500 loss 0.028117 acc 0.985119 lr 0.00012895 grad_norm 0.381165 rank 0
2025-01-11 05:10:40,990 DEBUG TRAIN Batch 155/500 loss 0.028203 acc 0.973877 lr 0.00012895 grad_norm 0.381165 rank 2
2025-01-11 05:10:40,990 DEBUG TRAIN Batch 155/500 loss 0.038508 acc 0.973485 lr 0.00012895 grad_norm 0.381165 rank 1
2025-01-11 05:11:05,757 DEBUG TRAIN Batch 155/600 loss 0.030114 acc 0.979526 lr 0.00012893 grad_norm 0.377734 rank 0
2025-01-11 05:11:05,757 DEBUG TRAIN Batch 155/600 loss 0.030210 acc 0.982014 lr 0.00012893 grad_norm 0.377734 rank 2
2025-01-11 05:11:05,758 DEBUG TRAIN Batch 155/600 loss 0.035821 acc 0.969783 lr 0.00012893 grad_norm 0.377734 rank 1
2025-01-11 05:11:30,141 DEBUG TRAIN Batch 155/700 loss 0.027432 acc 0.978684 lr 0.00012891 grad_norm 0.369538 rank 2
2025-01-11 05:11:30,141 DEBUG TRAIN Batch 155/700 loss 0.020299 acc 0.983607 lr 0.00012891 grad_norm 0.369538 rank 0
2025-01-11 05:11:30,142 DEBUG TRAIN Batch 155/700 loss 0.020199 acc 0.985277 lr 0.00012891 grad_norm 0.369538 rank 1
2025-01-11 05:11:55,166 DEBUG TRAIN Batch 155/800 loss 0.034770 acc 0.978053 lr 0.00012889 grad_norm 0.368603 rank 0
2025-01-11 05:11:55,167 DEBUG TRAIN Batch 155/800 loss 0.039352 acc 0.976274 lr 0.00012889 grad_norm 0.368603 rank 1
2025-01-11 05:11:55,167 DEBUG TRAIN Batch 155/800 loss 0.027781 acc 0.978903 lr 0.00012889 grad_norm 0.368603 rank 2
2025-01-11 05:12:19,172 DEBUG TRAIN Batch 155/900 loss 0.034371 acc 0.976971 lr 0.00012887 grad_norm 0.371124 rank 2
2025-01-11 05:12:19,172 DEBUG TRAIN Batch 155/900 loss 0.025084 acc 0.981501 lr 0.00012887 grad_norm 0.371124 rank 0
2025-01-11 05:12:19,175 DEBUG TRAIN Batch 155/900 loss 0.021858 acc 0.984894 lr 0.00012887 grad_norm 0.371124 rank 1
2025-01-11 05:12:43,359 DEBUG TRAIN Batch 155/1000 loss 0.038715 acc 0.973310 lr 0.00012885 grad_norm 0.372227 rank 2
2025-01-11 05:12:43,360 DEBUG TRAIN Batch 155/1000 loss 0.032604 acc 0.977273 lr 0.00012885 grad_norm 0.372227 rank 0
2025-01-11 05:12:43,360 DEBUG TRAIN Batch 155/1000 loss 0.025425 acc 0.984127 lr 0.00012885 grad_norm 0.372227 rank 1
2025-01-11 05:13:09,342 DEBUG TRAIN Batch 155/1100 loss 0.037158 acc 0.971845 lr 0.00012883 grad_norm 0.390638 rank 1
2025-01-11 05:13:09,343 DEBUG TRAIN Batch 155/1100 loss 0.043860 acc 0.969644 lr 0.00012883 grad_norm 0.390638 rank 0
2025-01-11 05:13:09,343 DEBUG TRAIN Batch 155/1100 loss 0.029076 acc 0.977574 lr 0.00012883 grad_norm 0.390638 rank 2
2025-01-11 05:13:33,081 DEBUG TRAIN Batch 155/1200 loss 0.044211 acc 0.972973 lr 0.00012880 grad_norm 0.376473 rank 0
2025-01-11 05:13:33,081 DEBUG TRAIN Batch 155/1200 loss 0.027064 acc 0.979661 lr 0.00012880 grad_norm 0.376473 rank 2
2025-01-11 05:13:33,082 DEBUG TRAIN Batch 155/1200 loss 0.041006 acc 0.976264 lr 0.00012880 grad_norm 0.376473 rank 1
2025-01-11 05:13:57,021 DEBUG TRAIN Batch 155/1300 loss 0.040926 acc 0.972277 lr 0.00012878 grad_norm 0.382619 rank 0
2025-01-11 05:13:57,021 DEBUG TRAIN Batch 155/1300 loss 0.025961 acc 0.983932 lr 0.00012878 grad_norm 0.382619 rank 2
2025-01-11 05:13:57,022 DEBUG TRAIN Batch 155/1300 loss 0.037852 acc 0.972656 lr 0.00012878 grad_norm 0.382619 rank 1
2025-01-11 05:14:20,737 DEBUG TRAIN Batch 155/1400 loss 0.025662 acc 0.982628 lr 0.00012876 grad_norm 0.333784 rank 0
2025-01-11 05:14:20,738 DEBUG TRAIN Batch 155/1400 loss 0.018435 acc 0.985481 lr 0.00012876 grad_norm 0.333784 rank 2
2025-01-11 05:14:20,738 DEBUG TRAIN Batch 155/1400 loss 0.031189 acc 0.977737 lr 0.00012876 grad_norm 0.333784 rank 1
2025-01-11 05:14:45,334 DEBUG TRAIN Batch 155/1500 loss 0.012224 acc 0.989744 lr 0.00012874 grad_norm 0.341491 rank 2
2025-01-11 05:14:45,334 DEBUG TRAIN Batch 155/1500 loss 0.033634 acc 0.980903 lr 0.00012874 grad_norm 0.341491 rank 0
2025-01-11 05:14:45,335 DEBUG TRAIN Batch 155/1500 loss 0.031985 acc 0.975775 lr 0.00012874 grad_norm 0.341491 rank 1
2025-01-11 05:15:09,232 DEBUG TRAIN Batch 155/1600 loss 0.034061 acc 0.980189 lr 0.00012872 grad_norm 0.366994 rank 0
2025-01-11 05:15:09,233 DEBUG TRAIN Batch 155/1600 loss 0.026299 acc 0.977798 lr 0.00012872 grad_norm 0.366994 rank 2
2025-01-11 05:15:09,233 DEBUG TRAIN Batch 155/1600 loss 0.040884 acc 0.974650 lr 0.00012872 grad_norm 0.366994 rank 1
2025-01-11 05:15:34,081 DEBUG TRAIN Batch 155/1700 loss 0.026770 acc 0.981354 lr 0.00012870 grad_norm 0.348592 rank 0
2025-01-11 05:15:34,082 DEBUG TRAIN Batch 155/1700 loss 0.027108 acc 0.982935 lr 0.00012870 grad_norm 0.348592 rank 2
2025-01-11 05:15:34,082 DEBUG TRAIN Batch 155/1700 loss 0.026675 acc 0.978842 lr 0.00012870 grad_norm 0.348592 rank 1
2025-01-11 05:15:57,843 DEBUG TRAIN Batch 155/1800 loss 0.037041 acc 0.969613 lr 0.00012868 grad_norm 0.382566 rank 1
2025-01-11 05:15:57,843 DEBUG TRAIN Batch 155/1800 loss 0.033274 acc 0.973286 lr 0.00012868 grad_norm 0.382566 rank 0
2025-01-11 05:15:57,843 DEBUG TRAIN Batch 155/1800 loss 0.039658 acc 0.972561 lr 0.00012868 grad_norm 0.382566 rank 2
2025-01-11 05:16:21,663 DEBUG TRAIN Batch 155/1900 loss 0.019261 acc 0.989781 lr 0.00012866 grad_norm 0.382907 rank 0
2025-01-11 05:16:21,663 DEBUG TRAIN Batch 155/1900 loss 0.035543 acc 0.981149 lr 0.00012866 grad_norm 0.382907 rank 2
2025-01-11 05:16:21,663 DEBUG TRAIN Batch 155/1900 loss 0.036229 acc 0.977064 lr 0.00012866 grad_norm 0.382907 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 05:17:26,017 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 05:17:26,018 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 05:17:26,499 INFO Epoch 155 Step 151046 on_batch_end True CV rank 0
2025-01-11 05:17:26,499 INFO Epoch 155 Step 151046 on_batch_end True CV rank 1
2025-01-11 05:17:26,499 INFO Epoch 155 Step 151046 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 05:17:35,637 DEBUG CV Batch 155/100 loss 0.001216 acc 1.000000  rank 0
2025-01-11 05:17:35,774 DEBUG CV Batch 155/100 loss 0.001216 acc 1.000000  rank 2
2025-01-11 05:17:36,143 INFO Epoch 155 Step 151046 CV info lr 0.00012865165870790894 0 rank loss_2.6609704019628175 acc_0.780393458772124
2025-01-11 05:17:36,155 DEBUG CV Batch 155/100 loss 0.001216 acc 1.000000  rank 1
2025-01-11 05:17:36,280 INFO Epoch 155 Step 151046 CV info lr 0.00012865165870790894 2 rank loss_2.6609704019628175 acc_0.780393458772124
2025-01-11 05:17:36,715 INFO Epoch 155 Step 151046 CV info lr 0.00012865165870790894 1 rank loss_2.6609704019628175 acc_0.780393458772124
2025-01-11 05:17:37,661 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_155_whole.pt
2025-01-11 05:17:37,683 INFO Added key: store_based_barrier_key:158 to store for rank: 0
2025-01-11 05:17:37,683 INFO Added key: store_based_barrier_key:158 to store for rank: 1
2025-01-11 05:17:37,683 INFO Added key: store_based_barrier_key:158 to store for rank: 2
2025-01-11 05:17:37,684 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:158 with 3 nodes.
2025-01-11 05:17:37,687 INFO Epoch 156 TRAIN info lr 0.00012865165870790894 rank 2
2025-01-11 05:17:37,687 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 05:17:37,693 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:158 with 3 nodes.
2025-01-11 05:17:37,693 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:158 with 3 nodes.
2025-01-11 05:17:37,696 INFO Epoch 156 TRAIN info lr 0.00012865165870790894 rank 0
2025-01-11 05:17:37,696 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 05:17:37,699 INFO Epoch 156 TRAIN info lr 0.00012865165870790894 rank 1
2025-01-11 05:17:37,699 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 05:18:07,989 DEBUG TRAIN Batch 156/100 loss 0.026905 acc 0.988566 lr 0.00012863 grad_norm 0.368871 rank 0
2025-01-11 05:18:07,989 DEBUG TRAIN Batch 156/100 loss 0.028311 acc 0.979232 lr 0.00012863 grad_norm 0.368871 rank 1
2025-01-11 05:18:07,990 DEBUG TRAIN Batch 156/100 loss 0.037513 acc 0.975385 lr 0.00012863 grad_norm 0.368871 rank 2
2025-01-11 05:18:31,930 DEBUG TRAIN Batch 156/200 loss 0.036846 acc 0.973897 lr 0.00012861 grad_norm 0.369575 rank 2
2025-01-11 05:18:31,930 DEBUG TRAIN Batch 156/200 loss 0.032542 acc 0.975799 lr 0.00012861 grad_norm 0.369575 rank 1
2025-01-11 05:18:31,930 DEBUG TRAIN Batch 156/200 loss 0.030394 acc 0.981481 lr 0.00012861 grad_norm 0.369575 rank 0
2025-01-11 05:18:55,325 DEBUG TRAIN Batch 156/300 loss 0.037244 acc 0.974480 lr 0.00012859 grad_norm 0.374726 rank 0
2025-01-11 05:18:55,326 DEBUG TRAIN Batch 156/300 loss 0.032246 acc 0.971352 lr 0.00012859 grad_norm 0.374726 rank 1
2025-01-11 05:18:55,327 DEBUG TRAIN Batch 156/300 loss 0.028484 acc 0.982659 lr 0.00012859 grad_norm 0.374726 rank 2
2025-01-11 05:19:19,194 DEBUG TRAIN Batch 156/400 loss 0.028707 acc 0.977318 lr 0.00012857 grad_norm 0.374006 rank 0
2025-01-11 05:19:19,194 DEBUG TRAIN Batch 156/400 loss 0.025039 acc 0.980827 lr 0.00012857 grad_norm 0.374006 rank 1
2025-01-11 05:19:19,194 DEBUG TRAIN Batch 156/400 loss 0.031105 acc 0.979937 lr 0.00012857 grad_norm 0.374006 rank 2
2025-01-11 05:19:43,377 DEBUG TRAIN Batch 156/500 loss 0.043602 acc 0.970019 lr 0.00012855 grad_norm 0.361142 rank 0
2025-01-11 05:19:43,377 DEBUG TRAIN Batch 156/500 loss 0.037880 acc 0.971762 lr 0.00012855 grad_norm 0.361142 rank 1
2025-01-11 05:19:43,377 DEBUG TRAIN Batch 156/500 loss 0.029840 acc 0.978860 lr 0.00012855 grad_norm 0.361142 rank 2
2025-01-11 05:20:07,332 DEBUG TRAIN Batch 156/600 loss 0.040558 acc 0.970027 lr 0.00012852 grad_norm 0.394233 rank 0
2025-01-11 05:20:07,332 DEBUG TRAIN Batch 156/600 loss 0.036646 acc 0.973807 lr 0.00012852 grad_norm 0.394233 rank 2
2025-01-11 05:20:07,333 DEBUG TRAIN Batch 156/600 loss 0.034347 acc 0.974837 lr 0.00012852 grad_norm 0.394233 rank 1
2025-01-11 05:20:31,666 DEBUG TRAIN Batch 156/700 loss 0.021013 acc 0.987377 lr 0.00012850 grad_norm 0.366879 rank 0
2025-01-11 05:20:31,666 DEBUG TRAIN Batch 156/700 loss 0.030717 acc 0.975687 lr 0.00012850 grad_norm 0.366879 rank 1
2025-01-11 05:20:31,667 DEBUG TRAIN Batch 156/700 loss 0.027105 acc 0.983096 lr 0.00012850 grad_norm 0.366879 rank 2
2025-01-11 05:20:55,713 DEBUG TRAIN Batch 156/800 loss 0.023470 acc 0.986287 lr 0.00012848 grad_norm 0.363915 rank 2
2025-01-11 05:20:55,713 DEBUG TRAIN Batch 156/800 loss 0.029536 acc 0.980549 lr 0.00012848 grad_norm 0.363915 rank 1
2025-01-11 05:20:55,713 DEBUG TRAIN Batch 156/800 loss 0.030016 acc 0.980750 lr 0.00012848 grad_norm 0.363915 rank 0
2025-01-11 05:21:20,034 DEBUG TRAIN Batch 156/900 loss 0.027782 acc 0.982014 lr 0.00012846 grad_norm 0.365278 rank 0
2025-01-11 05:21:20,034 DEBUG TRAIN Batch 156/900 loss 0.021191 acc 0.983073 lr 0.00012846 grad_norm 0.365278 rank 2
2025-01-11 05:21:20,034 DEBUG TRAIN Batch 156/900 loss 0.020076 acc 0.985782 lr 0.00012846 grad_norm 0.365278 rank 1
2025-01-11 05:21:44,520 DEBUG TRAIN Batch 156/1000 loss 0.026162 acc 0.981100 lr 0.00012844 grad_norm 0.367826 rank 2
2025-01-11 05:21:44,521 DEBUG TRAIN Batch 156/1000 loss 0.027997 acc 0.980027 lr 0.00012844 grad_norm 0.367826 rank 0
2025-01-11 05:21:44,521 DEBUG TRAIN Batch 156/1000 loss 0.023443 acc 0.982428 lr 0.00012844 grad_norm 0.367826 rank 1
2025-01-11 05:22:09,324 DEBUG TRAIN Batch 156/1100 loss 0.022321 acc 0.986096 lr 0.00012842 grad_norm 0.360764 rank 2
2025-01-11 05:22:09,325 DEBUG TRAIN Batch 156/1100 loss 0.031412 acc 0.980719 lr 0.00012842 grad_norm 0.360764 rank 0
2025-01-11 05:22:09,325 DEBUG TRAIN Batch 156/1100 loss 0.030338 acc 0.980496 lr 0.00012842 grad_norm 0.360764 rank 1
2025-01-11 05:22:33,190 DEBUG TRAIN Batch 156/1200 loss 0.031377 acc 0.978032 lr 0.00012840 grad_norm 0.378451 rank 0
2025-01-11 05:22:33,190 DEBUG TRAIN Batch 156/1200 loss 0.034230 acc 0.969286 lr 0.00012840 grad_norm 0.378451 rank 1
2025-01-11 05:22:33,191 DEBUG TRAIN Batch 156/1200 loss 0.037695 acc 0.974335 lr 0.00012840 grad_norm 0.378451 rank 2
2025-01-11 05:22:57,743 DEBUG TRAIN Batch 156/1300 loss 0.028545 acc 0.981283 lr 0.00012838 grad_norm 0.376834 rank 2
2025-01-11 05:22:57,743 DEBUG TRAIN Batch 156/1300 loss 0.027498 acc 0.979775 lr 0.00012838 grad_norm 0.376834 rank 0
2025-01-11 05:22:57,743 DEBUG TRAIN Batch 156/1300 loss 0.036538 acc 0.975439 lr 0.00012838 grad_norm 0.376834 rank 1
2025-01-11 05:23:22,626 DEBUG TRAIN Batch 156/1400 loss 0.030446 acc 0.972249 lr 0.00012835 grad_norm 0.384687 rank 2
2025-01-11 05:23:22,626 DEBUG TRAIN Batch 156/1400 loss 0.026807 acc 0.983463 lr 0.00012835 grad_norm 0.384687 rank 0
2025-01-11 05:23:22,627 DEBUG TRAIN Batch 156/1400 loss 0.030785 acc 0.979757 lr 0.00012835 grad_norm 0.384687 rank 1
2025-01-11 05:23:46,917 DEBUG TRAIN Batch 156/1500 loss 0.038913 acc 0.978175 lr 0.00012833 grad_norm 0.366427 rank 0
2025-01-11 05:23:46,917 DEBUG TRAIN Batch 156/1500 loss 0.029343 acc 0.979432 lr 0.00012833 grad_norm 0.366427 rank 2
2025-01-11 05:23:46,917 DEBUG TRAIN Batch 156/1500 loss 0.025005 acc 0.982163 lr 0.00012833 grad_norm 0.366427 rank 1
2025-01-11 05:24:11,146 DEBUG TRAIN Batch 156/1600 loss 0.026468 acc 0.981061 lr 0.00012831 grad_norm 0.400547 rank 1
2025-01-11 05:24:11,147 DEBUG TRAIN Batch 156/1600 loss 0.049128 acc 0.966197 lr 0.00012831 grad_norm 0.400547 rank 2
2025-01-11 05:24:11,147 DEBUG TRAIN Batch 156/1600 loss 0.034292 acc 0.980658 lr 0.00012831 grad_norm 0.400547 rank 0
2025-01-11 05:24:35,902 DEBUG TRAIN Batch 156/1700 loss 0.023402 acc 0.983193 lr 0.00012829 grad_norm 0.388256 rank 1
2025-01-11 05:24:35,902 DEBUG TRAIN Batch 156/1700 loss 0.040999 acc 0.970617 lr 0.00012829 grad_norm 0.388256 rank 2
2025-01-11 05:24:35,902 DEBUG TRAIN Batch 156/1700 loss 0.045263 acc 0.969507 lr 0.00012829 grad_norm 0.388256 rank 0
2025-01-11 05:25:00,452 DEBUG TRAIN Batch 156/1800 loss 0.028578 acc 0.981195 lr 0.00012827 grad_norm 0.367941 rank 0
2025-01-11 05:25:00,453 DEBUG TRAIN Batch 156/1800 loss 0.031161 acc 0.977798 lr 0.00012827 grad_norm 0.367941 rank 2
2025-01-11 05:25:00,453 DEBUG TRAIN Batch 156/1800 loss 0.022757 acc 0.984906 lr 0.00012827 grad_norm 0.367941 rank 1
2025-01-11 05:25:24,614 DEBUG TRAIN Batch 156/1900 loss 0.031545 acc 0.972803 lr 0.00012825 grad_norm 0.384694 rank 2
2025-01-11 05:25:24,614 DEBUG TRAIN Batch 156/1900 loss 0.038718 acc 0.978385 lr 0.00012825 grad_norm 0.384694 rank 1
2025-01-11 05:25:24,615 DEBUG TRAIN Batch 156/1900 loss 0.034966 acc 0.984848 lr 0.00012825 grad_norm 0.384694 rank 0
2025-01-11 05:25:49,237 DEBUG TRAIN Batch 156/2000 loss 0.031288 acc 0.980159 lr 0.00012823 grad_norm 0.378914 rank 2
2025-01-11 05:25:49,238 DEBUG TRAIN Batch 156/2000 loss 0.025917 acc 0.980501 lr 0.00012823 grad_norm 0.378914 rank 1
2025-01-11 05:25:49,238 DEBUG TRAIN Batch 156/2000 loss 0.024187 acc 0.984916 lr 0.00012823 grad_norm 0.378914 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 05:26:53,295 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 05:26:53,304 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 05:26:53,739 INFO Epoch 156 Step 152054 on_batch_end True CV rank 2
2025-01-11 05:26:53,739 INFO Epoch 156 Step 152054 on_batch_end True CV rank 0
2025-01-11 05:26:53,740 INFO Epoch 156 Step 152054 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 05:27:02,741 DEBUG CV Batch 156/100 loss 0.001432 acc 1.000000  rank 0
2025-01-11 05:27:03,025 DEBUG CV Batch 156/100 loss 0.001432 acc 1.000000  rank 2
2025-01-11 05:27:03,269 INFO Epoch 156 Step 152054 CV info lr 0.000128224519309393 0 rank loss_2.6692191101249416 acc_0.7794394700935012
2025-01-11 05:27:03,419 DEBUG CV Batch 156/100 loss 0.001432 acc 1.000000  rank 1
2025-01-11 05:27:03,575 INFO Epoch 156 Step 152054 CV info lr 0.000128224519309393 2 rank loss_2.6692191101249416 acc_0.7794394700935012
2025-01-11 05:27:03,965 INFO Epoch 156 Step 152054 CV info lr 0.000128224519309393 1 rank loss_2.6692191101249416 acc_0.7794394700935012
2025-01-11 05:27:04,545 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_156_whole.pt
2025-01-11 05:27:04,557 INFO Added key: store_based_barrier_key:159 to store for rank: 0
2025-01-11 05:27:04,567 INFO Added key: store_based_barrier_key:159 to store for rank: 1
2025-01-11 05:27:04,567 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:159 with 3 nodes.
2025-01-11 05:27:04,567 INFO Added key: store_based_barrier_key:159 to store for rank: 2
2025-01-11 05:27:04,567 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:159 with 3 nodes.
2025-01-11 05:27:04,573 INFO Epoch 157 TRAIN info lr 0.000128224519309393 rank 2
2025-01-11 05:27:04,573 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 05:27:04,576 INFO Epoch 157 TRAIN info lr 0.000128224519309393 rank 1
2025-01-11 05:27:04,576 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 05:27:04,577 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:159 with 3 nodes.
2025-01-11 05:27:04,578 INFO Epoch 157 TRAIN info lr 0.000128224519309393 rank 0
2025-01-11 05:27:04,578 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 05:27:35,207 DEBUG TRAIN Batch 157/100 loss 0.036484 acc 0.977422 lr 0.00012820 grad_norm 0.359588 rank 1
2025-01-11 05:27:35,208 DEBUG TRAIN Batch 157/100 loss 0.050741 acc 0.968784 lr 0.00012820 grad_norm 0.359588 rank 0
2025-01-11 05:27:35,208 DEBUG TRAIN Batch 157/100 loss 0.026624 acc 0.979487 lr 0.00012820 grad_norm 0.359588 rank 2
2025-01-11 05:27:59,159 DEBUG TRAIN Batch 157/200 loss 0.038315 acc 0.975631 lr 0.00012818 grad_norm 0.361281 rank 2
2025-01-11 05:27:59,159 DEBUG TRAIN Batch 157/200 loss 0.029343 acc 0.981308 lr 0.00012818 grad_norm 0.361281 rank 1
2025-01-11 05:27:59,159 DEBUG TRAIN Batch 157/200 loss 0.024682 acc 0.984579 lr 0.00012818 grad_norm 0.361281 rank 0
2025-01-11 05:28:22,728 DEBUG TRAIN Batch 157/300 loss 0.037284 acc 0.976190 lr 0.00012816 grad_norm 0.368328 rank 1
2025-01-11 05:28:22,728 DEBUG TRAIN Batch 157/300 loss 0.041827 acc 0.965284 lr 0.00012816 grad_norm 0.368328 rank 0
2025-01-11 05:28:22,729 DEBUG TRAIN Batch 157/300 loss 0.022021 acc 0.984940 lr 0.00012816 grad_norm 0.368328 rank 2
2025-01-11 05:28:46,337 DEBUG TRAIN Batch 157/400 loss 0.029979 acc 0.981347 lr 0.00012814 grad_norm 0.365560 rank 1
2025-01-11 05:28:46,337 DEBUG TRAIN Batch 157/400 loss 0.026236 acc 0.978065 lr 0.00012814 grad_norm 0.365560 rank 0
2025-01-11 05:28:46,337 DEBUG TRAIN Batch 157/400 loss 0.020734 acc 0.985619 lr 0.00012814 grad_norm 0.365560 rank 2
2025-01-11 05:29:10,366 DEBUG TRAIN Batch 157/500 loss 0.039931 acc 0.972247 lr 0.00012812 grad_norm 0.362951 rank 0
2025-01-11 05:29:10,366 DEBUG TRAIN Batch 157/500 loss 0.021235 acc 0.984238 lr 0.00012812 grad_norm 0.362951 rank 2
2025-01-11 05:29:10,366 DEBUG TRAIN Batch 157/500 loss 0.028772 acc 0.977117 lr 0.00012812 grad_norm 0.362951 rank 1
2025-01-11 05:29:33,816 DEBUG TRAIN Batch 157/600 loss 0.032723 acc 0.980198 lr 0.00012810 grad_norm 0.340366 rank 0
2025-01-11 05:29:33,816 DEBUG TRAIN Batch 157/600 loss 0.036846 acc 0.974888 lr 0.00012810 grad_norm 0.340366 rank 1
2025-01-11 05:29:33,816 DEBUG TRAIN Batch 157/600 loss 0.028206 acc 0.984630 lr 0.00012810 grad_norm 0.340366 rank 2
2025-01-11 05:29:57,759 DEBUG TRAIN Batch 157/700 loss 0.031772 acc 0.979393 lr 0.00012808 grad_norm 0.397883 rank 2
2025-01-11 05:29:57,759 DEBUG TRAIN Batch 157/700 loss 0.035221 acc 0.974138 lr 0.00012808 grad_norm 0.397883 rank 0
2025-01-11 05:29:57,759 DEBUG TRAIN Batch 157/700 loss 0.039541 acc 0.973958 lr 0.00012808 grad_norm 0.397883 rank 1
2025-01-11 05:30:21,502 DEBUG TRAIN Batch 157/800 loss 0.045163 acc 0.968664 lr 0.00012806 grad_norm 0.367542 rank 0
2025-01-11 05:30:21,502 DEBUG TRAIN Batch 157/800 loss 0.025976 acc 0.981912 lr 0.00012806 grad_norm 0.367542 rank 2
2025-01-11 05:30:21,502 DEBUG TRAIN Batch 157/800 loss 0.030114 acc 0.976482 lr 0.00012806 grad_norm 0.367542 rank 1
2025-01-11 05:30:45,378 DEBUG TRAIN Batch 157/900 loss 0.036725 acc 0.974913 lr 0.00012804 grad_norm 0.377588 rank 2
2025-01-11 05:30:45,378 DEBUG TRAIN Batch 157/900 loss 0.029708 acc 0.976119 lr 0.00012804 grad_norm 0.377588 rank 0
2025-01-11 05:30:45,379 DEBUG TRAIN Batch 157/900 loss 0.025774 acc 0.979129 lr 0.00012804 grad_norm 0.377588 rank 1
2025-01-11 05:31:09,382 DEBUG TRAIN Batch 157/1000 loss 0.031252 acc 0.979909 lr 0.00012801 grad_norm 0.386039 rank 0
2025-01-11 05:31:09,382 DEBUG TRAIN Batch 157/1000 loss 0.035989 acc 0.978193 lr 0.00012801 grad_norm 0.386039 rank 2
2025-01-11 05:31:09,383 DEBUG TRAIN Batch 157/1000 loss 0.033305 acc 0.974634 lr 0.00012801 grad_norm 0.386039 rank 1
2025-01-11 05:31:32,659 DEBUG TRAIN Batch 157/1100 loss 0.027316 acc 0.981640 lr 0.00012799 grad_norm 0.427973 rank 0
2025-01-11 05:31:32,659 DEBUG TRAIN Batch 157/1100 loss 0.045039 acc 0.971963 lr 0.00012799 grad_norm 0.427973 rank 2
2025-01-11 05:31:32,659 DEBUG TRAIN Batch 157/1100 loss 0.041780 acc 0.966595 lr 0.00012799 grad_norm 0.427973 rank 1
2025-01-11 05:31:56,589 DEBUG TRAIN Batch 157/1200 loss 0.039781 acc 0.970280 lr 0.00012797 grad_norm 0.420458 rank 2
2025-01-11 05:31:56,590 DEBUG TRAIN Batch 157/1200 loss 0.032218 acc 0.980796 lr 0.00012797 grad_norm 0.420458 rank 0
2025-01-11 05:31:56,590 DEBUG TRAIN Batch 157/1200 loss 0.025847 acc 0.981007 lr 0.00012797 grad_norm 0.420458 rank 1
2025-01-11 05:32:20,718 DEBUG TRAIN Batch 157/1300 loss 0.042217 acc 0.966350 lr 0.00012795 grad_norm 0.365823 rank 0
2025-01-11 05:32:20,718 DEBUG TRAIN Batch 157/1300 loss 0.031376 acc 0.976682 lr 0.00012795 grad_norm 0.365823 rank 1
2025-01-11 05:32:20,718 DEBUG TRAIN Batch 157/1300 loss 0.030061 acc 0.981043 lr 0.00012795 grad_norm 0.365823 rank 2
2025-01-11 05:32:45,692 DEBUG TRAIN Batch 157/1400 loss 0.034993 acc 0.971926 lr 0.00012793 grad_norm 0.395251 rank 2
2025-01-11 05:32:45,693 DEBUG TRAIN Batch 157/1400 loss 0.026593 acc 0.978700 lr 0.00012793 grad_norm 0.395251 rank 1
2025-01-11 05:32:45,693 DEBUG TRAIN Batch 157/1400 loss 0.034935 acc 0.976507 lr 0.00012793 grad_norm 0.395251 rank 0
2025-01-11 05:33:10,587 DEBUG TRAIN Batch 157/1500 loss 0.021374 acc 0.986441 lr 0.00012791 grad_norm 0.385266 rank 1
2025-01-11 05:33:10,588 DEBUG TRAIN Batch 157/1500 loss 0.048640 acc 0.962963 lr 0.00012791 grad_norm 0.385266 rank 2
2025-01-11 05:33:10,588 DEBUG TRAIN Batch 157/1500 loss 0.038104 acc 0.976449 lr 0.00012791 grad_norm 0.385266 rank 0
2025-01-11 05:33:34,753 DEBUG TRAIN Batch 157/1600 loss 0.032730 acc 0.977335 lr 0.00012789 grad_norm 0.394916 rank 0
2025-01-11 05:33:34,753 DEBUG TRAIN Batch 157/1600 loss 0.030408 acc 0.974975 lr 0.00012789 grad_norm 0.394916 rank 2
2025-01-11 05:33:34,754 DEBUG TRAIN Batch 157/1600 loss 0.023253 acc 0.986046 lr 0.00012789 grad_norm 0.394916 rank 1
2025-01-11 05:33:59,946 DEBUG TRAIN Batch 157/1700 loss 0.028701 acc 0.982068 lr 0.00012787 grad_norm 0.387421 rank 0
2025-01-11 05:33:59,946 DEBUG TRAIN Batch 157/1700 loss 0.038755 acc 0.974215 lr 0.00012787 grad_norm 0.387421 rank 2
2025-01-11 05:33:59,946 DEBUG TRAIN Batch 157/1700 loss 0.025227 acc 0.982938 lr 0.00012787 grad_norm 0.387421 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 05:35:00,734 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 05:35:00,736 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 05:35:01,217 INFO Epoch 157 Step 152905 on_batch_end True CV rank 1
2025-01-11 05:35:01,217 INFO Epoch 157 Step 152905 on_batch_end True CV rank 0
2025-01-11 05:35:01,217 INFO Epoch 157 Step 152905 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 05:35:10,450 DEBUG CV Batch 157/100 loss 0.001052 acc 1.000000  rank 0
2025-01-11 05:35:10,798 DEBUG CV Batch 157/100 loss 0.001052 acc 1.000000  rank 2
2025-01-11 05:35:10,963 DEBUG CV Batch 157/100 loss 0.001052 acc 1.000000  rank 1
2025-01-11 05:35:10,967 INFO Epoch 157 Step 152905 CV info lr 0.0001278672016391523 0 rank loss_2.6753808939119743 acc_0.780502804407948
2025-01-11 05:35:11,365 INFO Epoch 157 Step 152905 CV info lr 0.0001278672016391523 2 rank loss_2.6753808939119743 acc_0.780502804407948
2025-01-11 05:35:11,526 INFO Epoch 157 Step 152905 CV info lr 0.0001278672016391523 1 rank loss_2.6753808939119743 acc_0.780502804407948
2025-01-11 05:35:12,269 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_157_whole.pt
2025-01-11 05:35:12,291 INFO Added key: store_based_barrier_key:160 to store for rank: 0
2025-01-11 05:35:12,301 INFO Added key: store_based_barrier_key:160 to store for rank: 1
2025-01-11 05:35:12,301 INFO Added key: store_based_barrier_key:160 to store for rank: 2
2025-01-11 05:35:12,301 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:160 with 3 nodes.
2025-01-11 05:35:12,301 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:160 with 3 nodes.
2025-01-11 05:35:12,303 INFO Epoch 158 TRAIN info lr 0.0001278672016391523 rank 1
2025-01-11 05:35:12,303 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 05:35:12,310 INFO Epoch 158 TRAIN info lr 0.0001278672016391523 rank 2
2025-01-11 05:35:12,310 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 05:35:12,311 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:160 with 3 nodes.
2025-01-11 05:35:12,321 INFO Epoch 158 TRAIN info lr 0.0001278672016391523 rank 0
2025-01-11 05:35:12,321 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 05:35:42,970 DEBUG TRAIN Batch 158/100 loss 0.025524 acc 0.984023 lr 0.00012785 grad_norm 0.350364 rank 0
2025-01-11 05:35:42,970 DEBUG TRAIN Batch 158/100 loss 0.029406 acc 0.980207 lr 0.00012785 grad_norm 0.350364 rank 1
2025-01-11 05:35:42,971 DEBUG TRAIN Batch 158/100 loss 0.024919 acc 0.981576 lr 0.00012785 grad_norm 0.350364 rank 2
2025-01-11 05:36:06,780 DEBUG TRAIN Batch 158/200 loss 0.019721 acc 0.982639 lr 0.00012783 grad_norm 0.373984 rank 1
2025-01-11 05:36:06,780 DEBUG TRAIN Batch 158/200 loss 0.023832 acc 0.982971 lr 0.00012783 grad_norm 0.373984 rank 0
2025-01-11 05:36:06,780 DEBUG TRAIN Batch 158/200 loss 0.025134 acc 0.983709 lr 0.00012783 grad_norm 0.373984 rank 2
2025-01-11 05:36:30,331 DEBUG TRAIN Batch 158/300 loss 0.029450 acc 0.980839 lr 0.00012780 grad_norm 0.362737 rank 0
2025-01-11 05:36:30,331 DEBUG TRAIN Batch 158/300 loss 0.034135 acc 0.973610 lr 0.00012780 grad_norm 0.362737 rank 1
2025-01-11 05:36:30,333 DEBUG TRAIN Batch 158/300 loss 0.027014 acc 0.978537 lr 0.00012780 grad_norm 0.362737 rank 2
2025-01-11 05:36:54,041 DEBUG TRAIN Batch 158/400 loss 0.030044 acc 0.977974 lr 0.00012778 grad_norm 0.397914 rank 1
2025-01-11 05:36:54,042 DEBUG TRAIN Batch 158/400 loss 0.028615 acc 0.981211 lr 0.00012778 grad_norm 0.397914 rank 0
2025-01-11 05:36:54,042 DEBUG TRAIN Batch 158/400 loss 0.033643 acc 0.974576 lr 0.00012778 grad_norm 0.397914 rank 2
2025-01-11 05:37:18,123 DEBUG TRAIN Batch 158/500 loss 0.033603 acc 0.979631 lr 0.00012776 grad_norm 0.360073 rank 2
2025-01-11 05:37:18,123 DEBUG TRAIN Batch 158/500 loss 0.022760 acc 0.984962 lr 0.00012776 grad_norm 0.360073 rank 1
2025-01-11 05:37:18,124 DEBUG TRAIN Batch 158/500 loss 0.031685 acc 0.980047 lr 0.00012776 grad_norm 0.360073 rank 0
2025-01-11 05:37:41,687 DEBUG TRAIN Batch 158/600 loss 0.043084 acc 0.967681 lr 0.00012774 grad_norm 0.393562 rank 0
2025-01-11 05:37:41,687 DEBUG TRAIN Batch 158/600 loss 0.045972 acc 0.966736 lr 0.00012774 grad_norm 0.393562 rank 2
2025-01-11 05:37:41,687 DEBUG TRAIN Batch 158/600 loss 0.030631 acc 0.978620 lr 0.00012774 grad_norm 0.393562 rank 1
2025-01-11 05:38:05,952 DEBUG TRAIN Batch 158/700 loss 0.031911 acc 0.976277 lr 0.00012772 grad_norm 0.362862 rank 0
2025-01-11 05:38:05,952 DEBUG TRAIN Batch 158/700 loss 0.025066 acc 0.979612 lr 0.00012772 grad_norm 0.362862 rank 1
2025-01-11 05:38:05,953 DEBUG TRAIN Batch 158/700 loss 0.037425 acc 0.973025 lr 0.00012772 grad_norm 0.362862 rank 2
2025-01-11 05:38:30,162 DEBUG TRAIN Batch 158/800 loss 0.035739 acc 0.975659 lr 0.00012770 grad_norm 0.402560 rank 2
2025-01-11 05:38:30,162 DEBUG TRAIN Batch 158/800 loss 0.041323 acc 0.968421 lr 0.00012770 grad_norm 0.402560 rank 0
2025-01-11 05:38:30,162 DEBUG TRAIN Batch 158/800 loss 0.031729 acc 0.980681 lr 0.00012770 grad_norm 0.402560 rank 1
2025-01-11 05:38:54,175 DEBUG TRAIN Batch 158/900 loss 0.022539 acc 0.985279 lr 0.00012768 grad_norm 0.361192 rank 0
2025-01-11 05:38:54,175 DEBUG TRAIN Batch 158/900 loss 0.023286 acc 0.980019 lr 0.00012768 grad_norm 0.361192 rank 2
2025-01-11 05:38:54,175 DEBUG TRAIN Batch 158/900 loss 0.027950 acc 0.976037 lr 0.00012768 grad_norm 0.361192 rank 1
2025-01-11 05:39:18,290 DEBUG TRAIN Batch 158/1000 loss 0.028615 acc 0.983017 lr 0.00012766 grad_norm 0.361641 rank 1
2025-01-11 05:39:18,290 DEBUG TRAIN Batch 158/1000 loss 0.026126 acc 0.982353 lr 0.00012766 grad_norm 0.361641 rank 0
2025-01-11 05:39:18,292 DEBUG TRAIN Batch 158/1000 loss 0.030714 acc 0.974106 lr 0.00012766 grad_norm 0.361641 rank 2
2025-01-11 05:39:42,901 DEBUG TRAIN Batch 158/1100 loss 0.040178 acc 0.971136 lr 0.00012764 grad_norm 0.373135 rank 2
2025-01-11 05:39:42,901 DEBUG TRAIN Batch 158/1100 loss 0.023923 acc 0.986386 lr 0.00012764 grad_norm 0.373135 rank 1
2025-01-11 05:39:42,901 DEBUG TRAIN Batch 158/1100 loss 0.041629 acc 0.975161 lr 0.00012764 grad_norm 0.373135 rank 0
2025-01-11 05:40:07,331 DEBUG TRAIN Batch 158/1200 loss 0.017227 acc 0.984000 lr 0.00012762 grad_norm 0.352613 rank 2
2025-01-11 05:40:07,331 DEBUG TRAIN Batch 158/1200 loss 0.028014 acc 0.979424 lr 0.00012762 grad_norm 0.352613 rank 1
2025-01-11 05:40:07,331 DEBUG TRAIN Batch 158/1200 loss 0.020992 acc 0.984456 lr 0.00012762 grad_norm 0.352613 rank 0
2025-01-11 05:40:31,374 DEBUG TRAIN Batch 158/1300 loss 0.041058 acc 0.976445 lr 0.00012760 grad_norm 0.394205 rank 0
2025-01-11 05:40:31,374 DEBUG TRAIN Batch 158/1300 loss 0.033482 acc 0.984463 lr 0.00012760 grad_norm 0.394205 rank 2
2025-01-11 05:40:31,374 DEBUG TRAIN Batch 158/1300 loss 0.034252 acc 0.978664 lr 0.00012760 grad_norm 0.394205 rank 1
2025-01-11 05:40:56,477 DEBUG TRAIN Batch 158/1400 loss 0.021222 acc 0.987028 lr 0.00012758 grad_norm 0.371472 rank 2
2025-01-11 05:40:56,477 DEBUG TRAIN Batch 158/1400 loss 0.029172 acc 0.979148 lr 0.00012758 grad_norm 0.371472 rank 0
2025-01-11 05:40:56,477 DEBUG TRAIN Batch 158/1400 loss 0.021650 acc 0.987828 lr 0.00012758 grad_norm 0.371472 rank 1
2025-01-11 05:41:21,086 DEBUG TRAIN Batch 158/1500 loss 0.032407 acc 0.979003 lr 0.00012755 grad_norm 0.393316 rank 1
2025-01-11 05:41:21,086 DEBUG TRAIN Batch 158/1500 loss 0.034161 acc 0.971259 lr 0.00012755 grad_norm 0.393316 rank 0
2025-01-11 05:41:21,086 DEBUG TRAIN Batch 158/1500 loss 0.031948 acc 0.978788 lr 0.00012755 grad_norm 0.393316 rank 2
2025-01-11 05:41:45,142 DEBUG TRAIN Batch 158/1600 loss 0.032691 acc 0.973740 lr 0.00012753 grad_norm 0.382485 rank 2
2025-01-11 05:41:45,143 DEBUG TRAIN Batch 158/1600 loss 0.035381 acc 0.971996 lr 0.00012753 grad_norm 0.382485 rank 1
2025-01-11 05:41:45,143 DEBUG TRAIN Batch 158/1600 loss 0.031494 acc 0.982143 lr 0.00012753 grad_norm 0.382485 rank 0
2025-01-11 05:42:10,100 DEBUG TRAIN Batch 158/1700 loss 0.026129 acc 0.980952 lr 0.00012751 grad_norm 0.405786 rank 2
2025-01-11 05:42:10,100 DEBUG TRAIN Batch 158/1700 loss 0.038467 acc 0.975752 lr 0.00012751 grad_norm 0.405786 rank 1
2025-01-11 05:42:10,101 DEBUG TRAIN Batch 158/1700 loss 0.032558 acc 0.977012 lr 0.00012751 grad_norm 0.405786 rank 0
2025-01-11 05:42:35,964 DEBUG TRAIN Batch 158/1800 loss 0.030351 acc 0.981818 lr 0.00012749 grad_norm 0.394429 rank 2
2025-01-11 05:42:35,965 DEBUG TRAIN Batch 158/1800 loss 0.041384 acc 0.972807 lr 0.00012749 grad_norm 0.394429 rank 0
2025-01-11 05:42:35,965 DEBUG TRAIN Batch 158/1800 loss 0.017807 acc 0.991848 lr 0.00012749 grad_norm 0.394429 rank 1
2025-01-11 05:43:00,428 DEBUG TRAIN Batch 158/1900 loss 0.032479 acc 0.977064 lr 0.00012747 grad_norm 0.371963 rank 0
2025-01-11 05:43:00,428 DEBUG TRAIN Batch 158/1900 loss 0.022436 acc 0.984359 lr 0.00012747 grad_norm 0.371963 rank 2
2025-01-11 05:43:00,428 DEBUG TRAIN Batch 158/1900 loss 0.042336 acc 0.971618 lr 0.00012747 grad_norm 0.371963 rank 1
2025-01-11 05:43:24,478 DEBUG TRAIN Batch 158/2000 loss 0.043262 acc 0.970165 lr 0.00012745 grad_norm 0.387015 rank 0
2025-01-11 05:43:24,478 DEBUG TRAIN Batch 158/2000 loss 0.033907 acc 0.981713 lr 0.00012745 grad_norm 0.387015 rank 2
2025-01-11 05:43:24,478 DEBUG TRAIN Batch 158/2000 loss 0.026563 acc 0.986094 lr 0.00012745 grad_norm 0.387015 rank 1
2025-01-11 05:43:48,296 DEBUG TRAIN Batch 158/2100 loss 0.037242 acc 0.973577 lr 0.00012743 grad_norm 0.371609 rank 0
2025-01-11 05:43:48,296 DEBUG TRAIN Batch 158/2100 loss 0.032585 acc 0.980880 lr 0.00012743 grad_norm 0.371609 rank 2
2025-01-11 05:43:48,296 DEBUG TRAIN Batch 158/2100 loss 0.019133 acc 0.985148 lr 0.00012743 grad_norm 0.371609 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 05:45:10,641 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 05:45:10,641 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 05:45:10,980 INFO Epoch 158 Step 154001 on_batch_end True CV rank 2
2025-01-11 05:45:10,980 INFO Epoch 158 Step 154001 on_batch_end True CV rank 0
2025-01-11 05:45:10,981 INFO Epoch 158 Step 154001 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 05:45:20,151 DEBUG CV Batch 158/100 loss 0.001047 acc 1.000000  rank 2
2025-01-11 05:45:20,308 DEBUG CV Batch 158/100 loss 0.001047 acc 1.000000  rank 0
2025-01-11 05:45:20,631 DEBUG CV Batch 158/100 loss 0.001047 acc 1.000000  rank 1
2025-01-11 05:45:20,679 INFO Epoch 158 Step 154001 CV info lr 0.00012741138418675266 2 rank loss_2.6451684399804085 acc_0.7798645483297214
2025-01-11 05:45:20,820 INFO Epoch 158 Step 154001 CV info lr 0.00012741138418675266 0 rank loss_2.6451684399804085 acc_0.7798645483297214
2025-01-11 05:45:21,167 INFO Epoch 158 Step 154001 CV info lr 0.00012741138418675266 1 rank loss_2.6451684399804085 acc_0.7798645483297214
2025-01-11 05:45:22,097 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_158_whole.pt
2025-01-11 05:45:22,119 INFO Added key: store_based_barrier_key:161 to store for rank: 0
2025-01-11 05:45:22,130 INFO Added key: store_based_barrier_key:161 to store for rank: 1
2025-01-11 05:45:22,130 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:161 with 3 nodes.
2025-01-11 05:45:22,130 INFO Added key: store_based_barrier_key:161 to store for rank: 2
2025-01-11 05:45:22,131 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:161 with 3 nodes.
2025-01-11 05:45:22,132 INFO Epoch 159 TRAIN info lr 0.00012741138418675266 rank 1
2025-01-11 05:45:22,132 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 05:45:22,133 INFO Epoch 159 TRAIN info lr 0.00012741138418675266 rank 2
2025-01-11 05:45:22,133 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 05:45:22,140 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:161 with 3 nodes.
2025-01-11 05:45:22,144 INFO Epoch 159 TRAIN info lr 0.00012741138418675266 rank 0
2025-01-11 05:45:22,144 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 05:45:57,532 DEBUG TRAIN Batch 159/100 loss 0.038475 acc 0.974790 lr 0.00012739 grad_norm 0.380085 rank 2
2025-01-11 05:45:57,533 DEBUG TRAIN Batch 159/100 loss 0.029570 acc 0.980553 lr 0.00012739 grad_norm 0.380085 rank 1
2025-01-11 05:45:57,533 DEBUG TRAIN Batch 159/100 loss 0.025768 acc 0.980769 lr 0.00012739 grad_norm 0.380085 rank 0
2025-01-11 05:46:21,579 DEBUG TRAIN Batch 159/200 loss 0.035846 acc 0.978320 lr 0.00012737 grad_norm 0.388974 rank 2
2025-01-11 05:46:21,580 DEBUG TRAIN Batch 159/200 loss 0.030347 acc 0.983126 lr 0.00012737 grad_norm 0.388974 rank 1
2025-01-11 05:46:21,580 DEBUG TRAIN Batch 159/200 loss 0.027399 acc 0.979716 lr 0.00012737 grad_norm 0.388974 rank 0
2025-01-11 05:46:46,086 DEBUG TRAIN Batch 159/300 loss 0.034014 acc 0.976640 lr 0.00012735 grad_norm 0.381806 rank 2
2025-01-11 05:46:46,086 DEBUG TRAIN Batch 159/300 loss 0.023898 acc 0.985394 lr 0.00012735 grad_norm 0.381806 rank 1
2025-01-11 05:46:46,086 DEBUG TRAIN Batch 159/300 loss 0.031511 acc 0.977848 lr 0.00012735 grad_norm 0.381806 rank 0
2025-01-11 05:47:09,705 DEBUG TRAIN Batch 159/400 loss 0.024891 acc 0.982796 lr 0.00012733 grad_norm 0.405597 rank 1
2025-01-11 05:47:09,705 DEBUG TRAIN Batch 159/400 loss 0.039063 acc 0.975948 lr 0.00012733 grad_norm 0.405597 rank 0
2025-01-11 05:47:09,706 DEBUG TRAIN Batch 159/400 loss 0.048125 acc 0.967257 lr 0.00012733 grad_norm 0.405597 rank 2
2025-01-11 05:47:34,464 DEBUG TRAIN Batch 159/500 loss 0.032063 acc 0.979091 lr 0.00012731 grad_norm 0.368021 rank 2
2025-01-11 05:47:34,465 DEBUG TRAIN Batch 159/500 loss 0.032116 acc 0.974359 lr 0.00012731 grad_norm 0.368021 rank 1
2025-01-11 05:47:34,465 DEBUG TRAIN Batch 159/500 loss 0.032159 acc 0.971014 lr 0.00012731 grad_norm 0.368021 rank 0
2025-01-11 05:47:59,146 DEBUG TRAIN Batch 159/600 loss 0.042461 acc 0.973776 lr 0.00012729 grad_norm 0.380225 rank 2
2025-01-11 05:47:59,146 DEBUG TRAIN Batch 159/600 loss 0.037530 acc 0.970075 lr 0.00012729 grad_norm 0.380225 rank 0
2025-01-11 05:47:59,146 DEBUG TRAIN Batch 159/600 loss 0.025328 acc 0.978095 lr 0.00012729 grad_norm 0.380225 rank 1
2025-01-11 05:48:24,004 DEBUG TRAIN Batch 159/700 loss 0.030001 acc 0.977674 lr 0.00012727 grad_norm 0.381113 rank 1
2025-01-11 05:48:24,004 DEBUG TRAIN Batch 159/700 loss 0.035900 acc 0.976701 lr 0.00012727 grad_norm 0.381113 rank 0
2025-01-11 05:48:24,004 DEBUG TRAIN Batch 159/700 loss 0.019059 acc 0.984652 lr 0.00012727 grad_norm 0.381113 rank 2
2025-01-11 05:48:48,279 DEBUG TRAIN Batch 159/800 loss 0.024855 acc 0.984956 lr 0.00012725 grad_norm 0.358809 rank 2
2025-01-11 05:48:48,279 DEBUG TRAIN Batch 159/800 loss 0.042195 acc 0.969512 lr 0.00012725 grad_norm 0.358809 rank 1
2025-01-11 05:48:48,280 DEBUG TRAIN Batch 159/800 loss 0.026230 acc 0.980533 lr 0.00012725 grad_norm 0.358809 rank 0
2025-01-11 05:49:12,290 DEBUG TRAIN Batch 159/900 loss 0.021993 acc 0.985933 lr 0.00012723 grad_norm 0.373741 rank 2
2025-01-11 05:49:12,291 DEBUG TRAIN Batch 159/900 loss 0.032696 acc 0.979428 lr 0.00012723 grad_norm 0.373741 rank 0
2025-01-11 05:49:12,291 DEBUG TRAIN Batch 159/900 loss 0.029682 acc 0.979798 lr 0.00012723 grad_norm 0.373741 rank 1
2025-01-11 05:49:36,367 DEBUG TRAIN Batch 159/1000 loss 0.021368 acc 0.982310 lr 0.00012721 grad_norm 0.340522 rank 1
2025-01-11 05:49:36,368 DEBUG TRAIN Batch 159/1000 loss 0.033211 acc 0.974456 lr 0.00012721 grad_norm 0.340522 rank 2
2025-01-11 05:49:36,368 DEBUG TRAIN Batch 159/1000 loss 0.039007 acc 0.976809 lr 0.00012721 grad_norm 0.340522 rank 0
2025-01-11 05:50:01,582 DEBUG TRAIN Batch 159/1100 loss 0.040408 acc 0.974003 lr 0.00012718 grad_norm 0.389947 rank 1
2025-01-11 05:50:01,583 DEBUG TRAIN Batch 159/1100 loss 0.027360 acc 0.984053 lr 0.00012718 grad_norm 0.389947 rank 2
2025-01-11 05:50:01,584 DEBUG TRAIN Batch 159/1100 loss 0.034721 acc 0.975892 lr 0.00012718 grad_norm 0.389947 rank 0
2025-01-11 05:50:25,529 DEBUG TRAIN Batch 159/1200 loss 0.038506 acc 0.963706 lr 0.00012716 grad_norm 0.389973 rank 1
2025-01-11 05:50:25,529 DEBUG TRAIN Batch 159/1200 loss 0.028914 acc 0.983010 lr 0.00012716 grad_norm 0.389973 rank 0
2025-01-11 05:50:25,529 DEBUG TRAIN Batch 159/1200 loss 0.032785 acc 0.974783 lr 0.00012716 grad_norm 0.389973 rank 2
2025-01-11 05:50:49,170 DEBUG TRAIN Batch 159/1300 loss 0.030840 acc 0.978485 lr 0.00012714 grad_norm 0.389298 rank 1
2025-01-11 05:50:49,170 DEBUG TRAIN Batch 159/1300 loss 0.037154 acc 0.974739 lr 0.00012714 grad_norm 0.389298 rank 0
2025-01-11 05:50:49,170 DEBUG TRAIN Batch 159/1300 loss 0.025312 acc 0.979098 lr 0.00012714 grad_norm 0.389298 rank 2
2025-01-11 05:51:13,570 DEBUG TRAIN Batch 159/1400 loss 0.039042 acc 0.973827 lr 0.00012712 grad_norm 0.404308 rank 1
2025-01-11 05:51:13,570 DEBUG TRAIN Batch 159/1400 loss 0.033349 acc 0.972323 lr 0.00012712 grad_norm 0.404308 rank 0
2025-01-11 05:51:13,571 DEBUG TRAIN Batch 159/1400 loss 0.036873 acc 0.973659 lr 0.00012712 grad_norm 0.404308 rank 2
2025-01-11 05:51:37,415 DEBUG TRAIN Batch 159/1500 loss 0.033557 acc 0.977143 lr 0.00012710 grad_norm 0.362857 rank 1
2025-01-11 05:51:37,415 DEBUG TRAIN Batch 159/1500 loss 0.023241 acc 0.978286 lr 0.00012710 grad_norm 0.362857 rank 2
2025-01-11 05:51:37,415 DEBUG TRAIN Batch 159/1500 loss 0.014009 acc 0.992013 lr 0.00012710 grad_norm 0.362857 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 05:52:42,194 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 05:52:42,212 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 05:52:42,620 INFO Epoch 159 Step 154761 on_batch_end True CV rank 0
2025-01-11 05:52:42,620 INFO Epoch 159 Step 154761 on_batch_end True CV rank 2
2025-01-11 05:52:42,620 INFO Epoch 159 Step 154761 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 05:52:51,612 DEBUG CV Batch 159/100 loss 0.001777 acc 0.998885  rank 0
2025-01-11 05:52:51,927 DEBUG CV Batch 159/100 loss 0.001777 acc 0.998885  rank 2
2025-01-11 05:52:52,138 INFO Epoch 159 Step 154761 CV info lr 0.0001270981533786706 0 rank loss_2.6881039147497576 acc_0.7795421722949597
2025-01-11 05:52:52,465 INFO Epoch 159 Step 154761 CV info lr 0.0001270981533786706 2 rank loss_2.6881039147497576 acc_0.7795421722949597
2025-01-11 05:52:52,529 DEBUG CV Batch 159/100 loss 0.001777 acc 0.998885  rank 1
2025-01-11 05:52:53,101 INFO Epoch 159 Step 154761 CV info lr 0.0001270981533786706 1 rank loss_2.6881039147497576 acc_0.7795421722949597
2025-01-11 05:52:53,442 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_159_whole.pt
2025-01-11 05:52:53,463 INFO Added key: store_based_barrier_key:162 to store for rank: 0
2025-01-11 05:52:53,474 INFO Added key: store_based_barrier_key:162 to store for rank: 1
2025-01-11 05:52:53,474 INFO Added key: store_based_barrier_key:162 to store for rank: 2
2025-01-11 05:52:53,474 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:162 with 3 nodes.
2025-01-11 05:52:53,474 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:162 with 3 nodes.
2025-01-11 05:52:53,482 INFO Epoch 160 TRAIN info lr 0.0001270981533786706 rank 1
2025-01-11 05:52:53,482 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 05:52:53,482 INFO Epoch 160 TRAIN info lr 0.0001270981533786706 rank 2
2025-01-11 05:52:53,483 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 05:52:53,484 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:162 with 3 nodes.
2025-01-11 05:52:53,488 INFO Epoch 160 TRAIN info lr 0.0001270981533786706 rank 0
2025-01-11 05:52:53,488 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 05:53:29,155 DEBUG TRAIN Batch 160/100 loss 0.020565 acc 0.985340 lr 0.00012708 grad_norm 0.351330 rank 2
2025-01-11 05:53:29,156 DEBUG TRAIN Batch 160/100 loss 0.024024 acc 0.982737 lr 0.00012708 grad_norm 0.351330 rank 0
2025-01-11 05:53:29,156 DEBUG TRAIN Batch 160/100 loss 0.020026 acc 0.983623 lr 0.00012708 grad_norm 0.351330 rank 1
2025-01-11 05:53:53,439 DEBUG TRAIN Batch 160/200 loss 0.017986 acc 0.986842 lr 0.00012706 grad_norm 0.354545 rank 1
2025-01-11 05:53:53,439 DEBUG TRAIN Batch 160/200 loss 0.026376 acc 0.985116 lr 0.00012706 grad_norm 0.354545 rank 0
2025-01-11 05:53:53,439 DEBUG TRAIN Batch 160/200 loss 0.019985 acc 0.985395 lr 0.00012706 grad_norm 0.354545 rank 2
2025-01-11 05:54:18,052 DEBUG TRAIN Batch 160/300 loss 0.026859 acc 0.982456 lr 0.00012704 grad_norm 0.356619 rank 1
2025-01-11 05:54:18,052 DEBUG TRAIN Batch 160/300 loss 0.009314 acc 0.993569 lr 0.00012704 grad_norm 0.356619 rank 0
2025-01-11 05:54:18,053 DEBUG TRAIN Batch 160/300 loss 0.026641 acc 0.987770 lr 0.00012704 grad_norm 0.356619 rank 2
2025-01-11 05:54:42,037 DEBUG TRAIN Batch 160/400 loss 0.026614 acc 0.981800 lr 0.00012702 grad_norm 0.375375 rank 1
2025-01-11 05:54:42,038 DEBUG TRAIN Batch 160/400 loss 0.033767 acc 0.973224 lr 0.00012702 grad_norm 0.375375 rank 2
2025-01-11 05:54:42,038 DEBUG TRAIN Batch 160/400 loss 0.021717 acc 0.981508 lr 0.00012702 grad_norm 0.375375 rank 0
2025-01-11 05:55:06,834 DEBUG TRAIN Batch 160/500 loss 0.020338 acc 0.983284 lr 0.00012700 grad_norm 0.352113 rank 1
2025-01-11 05:55:06,835 DEBUG TRAIN Batch 160/500 loss 0.028588 acc 0.980050 lr 0.00012700 grad_norm 0.352113 rank 0
2025-01-11 05:55:06,849 DEBUG TRAIN Batch 160/500 loss 0.031221 acc 0.977659 lr 0.00012700 grad_norm 0.352113 rank 2
2025-01-11 05:55:31,836 DEBUG TRAIN Batch 160/600 loss 0.024819 acc 0.985205 lr 0.00012698 grad_norm 0.376300 rank 0
2025-01-11 05:55:31,837 DEBUG TRAIN Batch 160/600 loss 0.044755 acc 0.969641 lr 0.00012698 grad_norm 0.376300 rank 2
2025-01-11 05:55:31,837 DEBUG TRAIN Batch 160/600 loss 0.025735 acc 0.983721 lr 0.00012698 grad_norm 0.376300 rank 1
2025-01-11 05:55:56,674 DEBUG TRAIN Batch 160/700 loss 0.028418 acc 0.979415 lr 0.00012695 grad_norm 0.382212 rank 2
2025-01-11 05:55:56,674 DEBUG TRAIN Batch 160/700 loss 0.027728 acc 0.980000 lr 0.00012695 grad_norm 0.382212 rank 0
2025-01-11 05:55:56,674 DEBUG TRAIN Batch 160/700 loss 0.031017 acc 0.980961 lr 0.00012695 grad_norm 0.382212 rank 1
2025-01-11 05:56:21,032 DEBUG TRAIN Batch 160/800 loss 0.032158 acc 0.978444 lr 0.00012693 grad_norm 0.386137 rank 0
2025-01-11 05:56:21,032 DEBUG TRAIN Batch 160/800 loss 0.031424 acc 0.976521 lr 0.00012693 grad_norm 0.386137 rank 2
2025-01-11 05:56:21,032 DEBUG TRAIN Batch 160/800 loss 0.016111 acc 0.990437 lr 0.00012693 grad_norm 0.386137 rank 1
2025-01-11 05:56:45,212 DEBUG TRAIN Batch 160/900 loss 0.022542 acc 0.988854 lr 0.00012691 grad_norm 0.356602 rank 0
2025-01-11 05:56:45,212 DEBUG TRAIN Batch 160/900 loss 0.034647 acc 0.973118 lr 0.00012691 grad_norm 0.356602 rank 1
2025-01-11 05:56:45,212 DEBUG TRAIN Batch 160/900 loss 0.033359 acc 0.983019 lr 0.00012691 grad_norm 0.356602 rank 2
2025-01-11 05:57:08,929 DEBUG TRAIN Batch 160/1000 loss 0.014756 acc 0.991632 lr 0.00012689 grad_norm 0.367548 rank 0
2025-01-11 05:57:08,929 DEBUG TRAIN Batch 160/1000 loss 0.027392 acc 0.981256 lr 0.00012689 grad_norm 0.367548 rank 1
2025-01-11 05:57:08,929 DEBUG TRAIN Batch 160/1000 loss 0.027367 acc 0.980444 lr 0.00012689 grad_norm 0.367548 rank 2
2025-01-11 05:57:34,240 DEBUG TRAIN Batch 160/1100 loss 0.029644 acc 0.980583 lr 0.00012687 grad_norm 0.401771 rank 0
2025-01-11 05:57:34,240 DEBUG TRAIN Batch 160/1100 loss 0.031150 acc 0.980924 lr 0.00012687 grad_norm 0.401771 rank 1
2025-01-11 05:57:34,240 DEBUG TRAIN Batch 160/1100 loss 0.040645 acc 0.971093 lr 0.00012687 grad_norm 0.401771 rank 2
2025-01-11 05:57:58,559 DEBUG TRAIN Batch 160/1200 loss 0.028834 acc 0.977498 lr 0.00012685 grad_norm 0.367938 rank 0
2025-01-11 05:57:58,559 DEBUG TRAIN Batch 160/1200 loss 0.034013 acc 0.975345 lr 0.00012685 grad_norm 0.367938 rank 2
2025-01-11 05:57:58,559 DEBUG TRAIN Batch 160/1200 loss 0.033627 acc 0.976987 lr 0.00012685 grad_norm 0.367938 rank 1
2025-01-11 05:58:23,257 DEBUG TRAIN Batch 160/1300 loss 0.030196 acc 0.976526 lr 0.00012683 grad_norm 0.368488 rank 0
2025-01-11 05:58:23,257 DEBUG TRAIN Batch 160/1300 loss 0.028843 acc 0.982103 lr 0.00012683 grad_norm 0.368488 rank 2
2025-01-11 05:58:23,258 DEBUG TRAIN Batch 160/1300 loss 0.034153 acc 0.980825 lr 0.00012683 grad_norm 0.368488 rank 1
2025-01-11 05:58:46,934 DEBUG TRAIN Batch 160/1400 loss 0.021955 acc 0.987928 lr 0.00012681 grad_norm 0.372295 rank 0
2025-01-11 05:58:46,934 DEBUG TRAIN Batch 160/1400 loss 0.024300 acc 0.982528 lr 0.00012681 grad_norm 0.372295 rank 2
2025-01-11 05:58:46,934 DEBUG TRAIN Batch 160/1400 loss 0.044796 acc 0.973188 lr 0.00012681 grad_norm 0.372295 rank 1
2025-01-11 05:59:11,658 DEBUG TRAIN Batch 160/1500 loss 0.033805 acc 0.978771 lr 0.00012679 grad_norm 0.398213 rank 0
2025-01-11 05:59:11,658 DEBUG TRAIN Batch 160/1500 loss 0.025739 acc 0.980054 lr 0.00012679 grad_norm 0.398213 rank 2
2025-01-11 05:59:11,658 DEBUG TRAIN Batch 160/1500 loss 0.029694 acc 0.976787 lr 0.00012679 grad_norm 0.398213 rank 1
2025-01-11 05:59:35,724 DEBUG TRAIN Batch 160/1600 loss 0.023978 acc 0.982851 lr 0.00012677 grad_norm 0.378226 rank 0
2025-01-11 05:59:35,724 DEBUG TRAIN Batch 160/1600 loss 0.035796 acc 0.973238 lr 0.00012677 grad_norm 0.378226 rank 2
2025-01-11 05:59:35,724 DEBUG TRAIN Batch 160/1600 loss 0.032151 acc 0.978637 lr 0.00012677 grad_norm 0.378226 rank 1
2025-01-11 05:59:59,690 DEBUG TRAIN Batch 160/1700 loss 0.029985 acc 0.975309 lr 0.00012675 grad_norm 0.379959 rank 1
2025-01-11 05:59:59,690 DEBUG TRAIN Batch 160/1700 loss 0.037304 acc 0.971215 lr 0.00012675 grad_norm 0.379959 rank 2
2025-01-11 05:59:59,690 DEBUG TRAIN Batch 160/1700 loss 0.027239 acc 0.981413 lr 0.00012675 grad_norm 0.379959 rank 0
2025-01-11 06:00:23,316 DEBUG TRAIN Batch 160/1800 loss 0.024350 acc 0.983085 lr 0.00012673 grad_norm 0.371822 rank 0
2025-01-11 06:00:23,316 DEBUG TRAIN Batch 160/1800 loss 0.026037 acc 0.982125 lr 0.00012673 grad_norm 0.371822 rank 2
2025-01-11 06:00:23,316 DEBUG TRAIN Batch 160/1800 loss 0.033728 acc 0.974280 lr 0.00012673 grad_norm 0.371822 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 06:01:45,084 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59977ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 06:01:45,104 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 06:01:45,520 INFO Epoch 160 Step 155707 on_batch_end True CV rank 0
2025-01-11 06:01:45,520 INFO Epoch 160 Step 155707 on_batch_end True CV rank 1
2025-01-11 06:01:45,520 INFO Epoch 160 Step 155707 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 06:01:54,509 DEBUG CV Batch 160/100 loss 0.002290 acc 0.998885  rank 0
2025-01-11 06:01:54,776 DEBUG CV Batch 160/100 loss 0.002290 acc 0.998885  rank 2
2025-01-11 06:01:55,019 INFO Epoch 160 Step 155707 CV info lr 0.00012671147188042262 0 rank loss_2.67949644360628 acc_0.7788809482988558
2025-01-11 06:01:55,283 INFO Epoch 160 Step 155707 CV info lr 0.00012671147188042262 2 rank loss_2.67949644360628 acc_0.7788809482988558
2025-01-11 06:01:55,590 DEBUG CV Batch 160/100 loss 0.002290 acc 0.998885  rank 1
2025-01-11 06:01:56,158 INFO Epoch 160 Step 155707 CV info lr 0.00012671147188042262 1 rank loss_2.67949644360628 acc_0.7788809482988558
2025-01-11 06:01:56,307 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_160_whole.pt
2025-01-11 06:01:56,318 INFO Added key: store_based_barrier_key:163 to store for rank: 0
2025-01-11 06:01:56,329 INFO Added key: store_based_barrier_key:163 to store for rank: 1
2025-01-11 06:01:56,329 INFO Added key: store_based_barrier_key:163 to store for rank: 2
2025-01-11 06:01:56,329 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:163 with 3 nodes.
2025-01-11 06:01:56,329 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:163 with 3 nodes.
2025-01-11 06:01:56,335 INFO Epoch 161 TRAIN info lr 0.00012671147188042262 rank 2
2025-01-11 06:01:56,335 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 06:01:56,338 INFO Epoch 161 TRAIN info lr 0.00012671147188042262 rank 1
2025-01-11 06:01:56,338 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 06:01:56,339 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:163 with 3 nodes.
2025-01-11 06:01:56,344 INFO Epoch 161 TRAIN info lr 0.00012671147188042262 rank 0
2025-01-11 06:01:56,344 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 06:02:32,023 DEBUG TRAIN Batch 161/100 loss 0.029084 acc 0.980732 lr 0.00012669 grad_norm 0.345351 rank 0
2025-01-11 06:02:32,023 DEBUG TRAIN Batch 161/100 loss 0.028344 acc 0.980786 lr 0.00012669 grad_norm 0.345351 rank 2
2025-01-11 06:02:32,023 DEBUG TRAIN Batch 161/100 loss 0.027647 acc 0.982218 lr 0.00012669 grad_norm 0.345351 rank 1
2025-01-11 06:02:56,147 DEBUG TRAIN Batch 161/200 loss 0.027584 acc 0.981361 lr 0.00012667 grad_norm 0.314224 rank 0
2025-01-11 06:02:56,147 DEBUG TRAIN Batch 161/200 loss 0.018506 acc 0.988693 lr 0.00012667 grad_norm 0.314224 rank 1
2025-01-11 06:02:56,147 DEBUG TRAIN Batch 161/200 loss 0.015290 acc 0.989078 lr 0.00012667 grad_norm 0.314224 rank 2
2025-01-11 06:03:20,972 DEBUG TRAIN Batch 161/300 loss 0.031284 acc 0.977251 lr 0.00012665 grad_norm 0.384439 rank 1
2025-01-11 06:03:20,973 DEBUG TRAIN Batch 161/300 loss 0.039481 acc 0.969565 lr 0.00012665 grad_norm 0.384439 rank 0
2025-01-11 06:03:20,973 DEBUG TRAIN Batch 161/300 loss 0.027385 acc 0.981516 lr 0.00012665 grad_norm 0.384439 rank 2
2025-01-11 06:03:45,365 DEBUG TRAIN Batch 161/400 loss 0.019187 acc 0.981132 lr 0.00012663 grad_norm 0.392593 rank 2
2025-01-11 06:03:45,365 DEBUG TRAIN Batch 161/400 loss 0.027628 acc 0.979125 lr 0.00012663 grad_norm 0.392593 rank 1
2025-01-11 06:03:45,365 DEBUG TRAIN Batch 161/400 loss 0.042538 acc 0.967626 lr 0.00012663 grad_norm 0.392593 rank 0
2025-01-11 06:04:09,947 DEBUG TRAIN Batch 161/500 loss 0.033351 acc 0.978095 lr 0.00012661 grad_norm 0.362623 rank 2
2025-01-11 06:04:09,948 DEBUG TRAIN Batch 161/500 loss 0.038707 acc 0.973921 lr 0.00012661 grad_norm 0.362623 rank 1
2025-01-11 06:04:09,948 DEBUG TRAIN Batch 161/500 loss 0.028588 acc 0.980769 lr 0.00012661 grad_norm 0.362623 rank 0
2025-01-11 06:04:34,702 DEBUG TRAIN Batch 161/600 loss 0.022906 acc 0.982163 lr 0.00012659 grad_norm 0.361012 rank 1
2025-01-11 06:04:34,703 DEBUG TRAIN Batch 161/600 loss 0.036723 acc 0.974729 lr 0.00012659 grad_norm 0.361012 rank 0
2025-01-11 06:04:34,703 DEBUG TRAIN Batch 161/600 loss 0.033910 acc 0.973837 lr 0.00012659 grad_norm 0.361012 rank 2
2025-01-11 06:04:59,084 DEBUG TRAIN Batch 161/700 loss 0.036680 acc 0.976103 lr 0.00012657 grad_norm 0.392445 rank 1
2025-01-11 06:04:59,084 DEBUG TRAIN Batch 161/700 loss 0.021448 acc 0.984747 lr 0.00012657 grad_norm 0.392445 rank 0
2025-01-11 06:04:59,084 DEBUG TRAIN Batch 161/700 loss 0.038834 acc 0.974014 lr 0.00012657 grad_norm 0.392445 rank 2
2025-01-11 06:05:24,046 DEBUG TRAIN Batch 161/800 loss 0.023498 acc 0.981672 lr 0.00012655 grad_norm 0.403382 rank 2
2025-01-11 06:05:24,047 DEBUG TRAIN Batch 161/800 loss 0.037348 acc 0.974638 lr 0.00012655 grad_norm 0.403382 rank 0
2025-01-11 06:05:24,047 DEBUG TRAIN Batch 161/800 loss 0.041381 acc 0.973921 lr 0.00012655 grad_norm 0.403382 rank 1
2025-01-11 06:05:48,116 DEBUG TRAIN Batch 161/900 loss 0.024425 acc 0.984389 lr 0.00012653 grad_norm 0.386690 rank 2
2025-01-11 06:05:48,116 DEBUG TRAIN Batch 161/900 loss 0.051725 acc 0.969432 lr 0.00012653 grad_norm 0.386690 rank 0
2025-01-11 06:05:48,116 DEBUG TRAIN Batch 161/900 loss 0.031475 acc 0.979879 lr 0.00012653 grad_norm 0.386690 rank 1
2025-01-11 06:06:12,202 DEBUG TRAIN Batch 161/1000 loss 0.030153 acc 0.981973 lr 0.00012651 grad_norm 0.414212 rank 0
2025-01-11 06:06:12,202 DEBUG TRAIN Batch 161/1000 loss 0.027418 acc 0.981837 lr 0.00012651 grad_norm 0.414212 rank 2
2025-01-11 06:06:12,203 DEBUG TRAIN Batch 161/1000 loss 0.042918 acc 0.973000 lr 0.00012651 grad_norm 0.414212 rank 1
2025-01-11 06:06:37,796 DEBUG TRAIN Batch 161/1100 loss 0.023519 acc 0.982164 lr 0.00012649 grad_norm 0.376981 rank 2
2025-01-11 06:06:37,796 DEBUG TRAIN Batch 161/1100 loss 0.014998 acc 0.991639 lr 0.00012649 grad_norm 0.376981 rank 1
2025-01-11 06:06:37,797 DEBUG TRAIN Batch 161/1100 loss 0.037667 acc 0.977249 lr 0.00012649 grad_norm 0.376981 rank 0
2025-01-11 06:07:02,395 DEBUG TRAIN Batch 161/1200 loss 0.032598 acc 0.975694 lr 0.00012647 grad_norm 0.383849 rank 0
2025-01-11 06:07:02,395 DEBUG TRAIN Batch 161/1200 loss 0.026134 acc 0.983122 lr 0.00012647 grad_norm 0.383849 rank 2
2025-01-11 06:07:02,395 DEBUG TRAIN Batch 161/1200 loss 0.022853 acc 0.986111 lr 0.00012647 grad_norm 0.383849 rank 1
2025-01-11 06:07:27,171 DEBUG TRAIN Batch 161/1300 loss 0.031363 acc 0.979354 lr 0.00012645 grad_norm 0.397473 rank 0
2025-01-11 06:07:27,171 DEBUG TRAIN Batch 161/1300 loss 0.046787 acc 0.970448 lr 0.00012645 grad_norm 0.397473 rank 2
2025-01-11 06:07:27,171 DEBUG TRAIN Batch 161/1300 loss 0.036469 acc 0.976371 lr 0.00012645 grad_norm 0.397473 rank 1
2025-01-11 06:07:52,362 DEBUG TRAIN Batch 161/1400 loss 0.029496 acc 0.981043 lr 0.00012643 grad_norm 0.359372 rank 0
2025-01-11 06:07:52,362 DEBUG TRAIN Batch 161/1400 loss 0.038578 acc 0.971403 lr 0.00012643 grad_norm 0.359372 rank 2
2025-01-11 06:07:52,362 DEBUG TRAIN Batch 161/1400 loss 0.017775 acc 0.987654 lr 0.00012643 grad_norm 0.359372 rank 1
2025-01-11 06:08:16,538 DEBUG TRAIN Batch 161/1500 loss 0.034777 acc 0.975472 lr 0.00012641 grad_norm 0.423683 rank 0
2025-01-11 06:08:16,538 DEBUG TRAIN Batch 161/1500 loss 0.050504 acc 0.960501 lr 0.00012641 grad_norm 0.423683 rank 2
2025-01-11 06:08:16,538 DEBUG TRAIN Batch 161/1500 loss 0.031481 acc 0.976143 lr 0.00012641 grad_norm 0.423683 rank 1
2025-01-11 06:08:40,895 DEBUG TRAIN Batch 161/1600 loss 0.038120 acc 0.974182 lr 0.00012639 grad_norm 0.393343 rank 0
2025-01-11 06:08:40,895 DEBUG TRAIN Batch 161/1600 loss 0.037617 acc 0.975820 lr 0.00012639 grad_norm 0.393343 rank 2
2025-01-11 06:08:40,895 DEBUG TRAIN Batch 161/1600 loss 0.030347 acc 0.983957 lr 0.00012639 grad_norm 0.393343 rank 1
2025-01-11 06:09:05,198 DEBUG TRAIN Batch 161/1700 loss 0.025283 acc 0.981174 lr 0.00012637 grad_norm 0.409879 rank 2
2025-01-11 06:09:05,198 DEBUG TRAIN Batch 161/1700 loss 0.037256 acc 0.975221 lr 0.00012637 grad_norm 0.409879 rank 1
2025-01-11 06:09:05,198 DEBUG TRAIN Batch 161/1700 loss 0.041994 acc 0.971609 lr 0.00012637 grad_norm 0.409879 rank 0
2025-01-11 06:09:29,245 DEBUG TRAIN Batch 161/1800 loss 0.027122 acc 0.983105 lr 0.00012635 grad_norm 0.359945 rank 0
2025-01-11 06:09:29,246 DEBUG TRAIN Batch 161/1800 loss 0.030044 acc 0.980207 lr 0.00012635 grad_norm 0.359945 rank 2
2025-01-11 06:09:29,246 DEBUG TRAIN Batch 161/1800 loss 0.035314 acc 0.980151 lr 0.00012635 grad_norm 0.359945 rank 1
2025-01-11 06:09:52,840 DEBUG TRAIN Batch 161/1900 loss 0.042547 acc 0.966146 lr 0.00012633 grad_norm 0.392496 rank 0
2025-01-11 06:09:52,840 DEBUG TRAIN Batch 161/1900 loss 0.023670 acc 0.985344 lr 0.00012633 grad_norm 0.392496 rank 2
2025-01-11 06:09:52,840 DEBUG TRAIN Batch 161/1900 loss 0.034709 acc 0.972136 lr 0.00012633 grad_norm 0.392496 rank 1
2025-01-11 06:10:16,537 DEBUG TRAIN Batch 161/2000 loss 0.011868 acc 0.993620 lr 0.00012631 grad_norm 0.345807 rank 0
2025-01-11 06:10:16,537 DEBUG TRAIN Batch 161/2000 loss 0.027139 acc 0.982609 lr 0.00012631 grad_norm 0.345807 rank 1
2025-01-11 06:10:16,537 DEBUG TRAIN Batch 161/2000 loss 0.026436 acc 0.983437 lr 0.00012631 grad_norm 0.345807 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 06:11:28,850 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59984ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 06:11:28,856 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 06:11:29,242 INFO Epoch 161 Step 156733 on_batch_end True CV rank 1
2025-01-11 06:11:29,242 INFO Epoch 161 Step 156733 on_batch_end True CV rank 0
2025-01-11 06:11:29,242 INFO Epoch 161 Step 156733 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 06:11:38,477 DEBUG CV Batch 161/100 loss 0.001705 acc 1.000000  rank 2
2025-01-11 06:11:38,516 DEBUG CV Batch 161/100 loss 0.001705 acc 1.000000  rank 0
2025-01-11 06:11:38,986 INFO Epoch 161 Step 156733 CV info lr 0.00012629605384621966 0 rank loss_2.6845409648744143 acc_0.7798201688810399
2025-01-11 06:11:38,995 INFO Epoch 161 Step 156733 CV info lr 0.00012629605384621966 2 rank loss_2.6845409648744143 acc_0.7798201688810399
2025-01-11 06:11:39,230 DEBUG CV Batch 161/100 loss 0.001705 acc 1.000000  rank 1
2025-01-11 06:11:39,790 INFO Epoch 161 Step 156733 CV info lr 0.00012629605384621966 1 rank loss_2.6845409648744143 acc_0.7798201688810399
2025-01-11 06:11:40,287 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_161_whole.pt
2025-01-11 06:11:40,309 INFO Added key: store_based_barrier_key:164 to store for rank: 0
2025-01-11 06:11:40,320 INFO Added key: store_based_barrier_key:164 to store for rank: 1
2025-01-11 06:11:40,320 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:164 with 3 nodes.
2025-01-11 06:11:40,320 INFO Added key: store_based_barrier_key:164 to store for rank: 2
2025-01-11 06:11:40,320 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:164 with 3 nodes.
2025-01-11 06:11:40,322 INFO Epoch 162 TRAIN info lr 0.00012629605384621966 rank 2
2025-01-11 06:11:40,322 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 06:11:40,326 INFO Epoch 162 TRAIN info lr 0.00012629605384621966 rank 1
2025-01-11 06:11:40,327 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 06:11:40,330 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:164 with 3 nodes.
2025-01-11 06:11:40,338 INFO Epoch 162 TRAIN info lr 0.00012629605384621966 rank 0
2025-01-11 06:11:40,338 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 06:12:16,412 DEBUG TRAIN Batch 162/100 loss 0.020783 acc 0.982522 lr 0.00012628 grad_norm 0.380244 rank 0
2025-01-11 06:12:16,412 DEBUG TRAIN Batch 162/100 loss 0.027473 acc 0.980932 lr 0.00012628 grad_norm 0.380244 rank 2
2025-01-11 06:12:16,412 DEBUG TRAIN Batch 162/100 loss 0.030669 acc 0.978925 lr 0.00012628 grad_norm 0.380244 rank 1
2025-01-11 06:12:40,561 DEBUG TRAIN Batch 162/200 loss 0.026987 acc 0.982387 lr 0.00012626 grad_norm 0.375293 rank 0
2025-01-11 06:12:40,562 DEBUG TRAIN Batch 162/200 loss 0.035911 acc 0.975737 lr 0.00012626 grad_norm 0.375293 rank 1
2025-01-11 06:12:40,562 DEBUG TRAIN Batch 162/200 loss 0.019191 acc 0.984655 lr 0.00012626 grad_norm 0.375293 rank 2
2025-01-11 06:13:04,918 DEBUG TRAIN Batch 162/300 loss 0.008412 acc 0.991830 lr 0.00012624 grad_norm 0.333098 rank 0
2025-01-11 06:13:04,918 DEBUG TRAIN Batch 162/300 loss 0.023757 acc 0.988235 lr 0.00012624 grad_norm 0.333098 rank 2
2025-01-11 06:13:04,918 DEBUG TRAIN Batch 162/300 loss 0.037165 acc 0.974335 lr 0.00012624 grad_norm 0.333098 rank 1
2025-01-11 06:13:28,733 DEBUG TRAIN Batch 162/400 loss 0.025115 acc 0.982684 lr 0.00012622 grad_norm 0.380293 rank 0
2025-01-11 06:13:28,733 DEBUG TRAIN Batch 162/400 loss 0.028751 acc 0.978970 lr 0.00012622 grad_norm 0.380293 rank 1
2025-01-11 06:13:28,733 DEBUG TRAIN Batch 162/400 loss 0.029726 acc 0.981818 lr 0.00012622 grad_norm 0.380293 rank 2
2025-01-11 06:13:52,847 DEBUG TRAIN Batch 162/500 loss 0.027728 acc 0.983769 lr 0.00012620 grad_norm 0.370946 rank 2
2025-01-11 06:13:52,847 DEBUG TRAIN Batch 162/500 loss 0.028778 acc 0.983511 lr 0.00012620 grad_norm 0.370946 rank 1
2025-01-11 06:13:52,847 DEBUG TRAIN Batch 162/500 loss 0.023592 acc 0.986420 lr 0.00012620 grad_norm 0.370946 rank 0
2025-01-11 06:14:16,827 DEBUG TRAIN Batch 162/600 loss 0.029643 acc 0.973868 lr 0.00012618 grad_norm 0.348768 rank 1
2025-01-11 06:14:16,827 DEBUG TRAIN Batch 162/600 loss 0.031606 acc 0.980018 lr 0.00012618 grad_norm 0.348768 rank 2
2025-01-11 06:14:16,828 DEBUG TRAIN Batch 162/600 loss 0.024661 acc 0.984547 lr 0.00012618 grad_norm 0.348768 rank 0
2025-01-11 06:14:40,416 DEBUG TRAIN Batch 162/700 loss 0.031605 acc 0.979962 lr 0.00012616 grad_norm 0.356192 rank 1
2025-01-11 06:14:40,416 DEBUG TRAIN Batch 162/700 loss 0.025720 acc 0.983713 lr 0.00012616 grad_norm 0.356192 rank 0
2025-01-11 06:14:40,417 DEBUG TRAIN Batch 162/700 loss 0.030701 acc 0.976496 lr 0.00012616 grad_norm 0.356192 rank 2
2025-01-11 06:15:04,835 DEBUG TRAIN Batch 162/800 loss 0.025123 acc 0.981207 lr 0.00012614 grad_norm 0.365886 rank 1
2025-01-11 06:15:04,835 DEBUG TRAIN Batch 162/800 loss 0.016518 acc 0.989796 lr 0.00012614 grad_norm 0.365886 rank 0
2025-01-11 06:15:04,835 DEBUG TRAIN Batch 162/800 loss 0.031793 acc 0.982310 lr 0.00012614 grad_norm 0.365886 rank 2
2025-01-11 06:15:28,989 DEBUG TRAIN Batch 162/900 loss 0.016330 acc 0.986405 lr 0.00012612 grad_norm 0.401502 rank 0
2025-01-11 06:15:28,989 DEBUG TRAIN Batch 162/900 loss 0.025993 acc 0.977823 lr 0.00012612 grad_norm 0.401502 rank 1
2025-01-11 06:15:28,990 DEBUG TRAIN Batch 162/900 loss 0.023159 acc 0.983810 lr 0.00012612 grad_norm 0.401502 rank 2
2025-01-11 06:15:53,134 DEBUG TRAIN Batch 162/1000 loss 0.022645 acc 0.984064 lr 0.00012610 grad_norm 0.353421 rank 0
2025-01-11 06:15:53,134 DEBUG TRAIN Batch 162/1000 loss 0.037323 acc 0.976337 lr 0.00012610 grad_norm 0.353421 rank 2
2025-01-11 06:15:53,134 DEBUG TRAIN Batch 162/1000 loss 0.026106 acc 0.980372 lr 0.00012610 grad_norm 0.353421 rank 1
2025-01-11 06:16:18,740 DEBUG TRAIN Batch 162/1100 loss 0.027893 acc 0.985825 lr 0.00012608 grad_norm 0.387729 rank 1
2025-01-11 06:16:18,740 DEBUG TRAIN Batch 162/1100 loss 0.030106 acc 0.981634 lr 0.00012608 grad_norm 0.387729 rank 0
2025-01-11 06:16:18,741 DEBUG TRAIN Batch 162/1100 loss 0.022472 acc 0.985075 lr 0.00012608 grad_norm 0.387729 rank 2
2025-01-11 06:16:42,841 DEBUG TRAIN Batch 162/1200 loss 0.028266 acc 0.978430 lr 0.00012606 grad_norm 0.386280 rank 0
2025-01-11 06:16:42,841 DEBUG TRAIN Batch 162/1200 loss 0.028625 acc 0.979063 lr 0.00012606 grad_norm 0.386280 rank 1
2025-01-11 06:16:42,842 DEBUG TRAIN Batch 162/1200 loss 0.036852 acc 0.979816 lr 0.00012606 grad_norm 0.386280 rank 2
2025-01-11 06:17:07,356 DEBUG TRAIN Batch 162/1300 loss 0.028257 acc 0.987941 lr 0.00012603 grad_norm 0.369455 rank 2
2025-01-11 06:17:07,357 DEBUG TRAIN Batch 162/1300 loss 0.025214 acc 0.978986 lr 0.00012603 grad_norm 0.369455 rank 0
2025-01-11 06:17:07,357 DEBUG TRAIN Batch 162/1300 loss 0.029580 acc 0.973573 lr 0.00012603 grad_norm 0.369455 rank 1
2025-01-11 06:17:31,655 DEBUG TRAIN Batch 162/1400 loss 0.024900 acc 0.980315 lr 0.00012601 grad_norm 0.339296 rank 0
2025-01-11 06:17:31,655 DEBUG TRAIN Batch 162/1400 loss 0.036470 acc 0.975321 lr 0.00012601 grad_norm 0.339296 rank 1
2025-01-11 06:17:31,655 DEBUG TRAIN Batch 162/1400 loss 0.021018 acc 0.985475 lr 0.00012601 grad_norm 0.339296 rank 2
2025-01-11 06:17:55,083 DEBUG TRAIN Batch 162/1500 loss 0.034809 acc 0.973057 lr 0.00012599 grad_norm 0.405608 rank 1
2025-01-11 06:17:55,083 DEBUG TRAIN Batch 162/1500 loss 0.025837 acc 0.976507 lr 0.00012599 grad_norm 0.405608 rank 2
2025-01-11 06:17:55,084 DEBUG TRAIN Batch 162/1500 loss 0.034371 acc 0.978239 lr 0.00012599 grad_norm 0.405608 rank 0
2025-01-11 06:18:19,266 DEBUG TRAIN Batch 162/1600 loss 0.030100 acc 0.979651 lr 0.00012597 grad_norm 0.375768 rank 1
2025-01-11 06:18:19,266 DEBUG TRAIN Batch 162/1600 loss 0.030286 acc 0.978680 lr 0.00012597 grad_norm 0.375768 rank 0
2025-01-11 06:18:19,266 DEBUG TRAIN Batch 162/1600 loss 0.030594 acc 0.979516 lr 0.00012597 grad_norm 0.375768 rank 2
2025-01-11 06:18:43,124 DEBUG TRAIN Batch 162/1700 loss 0.039834 acc 0.974948 lr 0.00012595 grad_norm 0.404519 rank 0
2025-01-11 06:18:43,124 DEBUG TRAIN Batch 162/1700 loss 0.028561 acc 0.977516 lr 0.00012595 grad_norm 0.404519 rank 1
2025-01-11 06:18:43,124 DEBUG TRAIN Batch 162/1700 loss 0.033029 acc 0.979648 lr 0.00012595 grad_norm 0.404519 rank 2
2025-01-11 06:19:07,361 DEBUG TRAIN Batch 162/1800 loss 0.021785 acc 0.984436 lr 0.00012593 grad_norm 0.369324 rank 1
2025-01-11 06:19:07,361 DEBUG TRAIN Batch 162/1800 loss 0.027136 acc 0.980170 lr 0.00012593 grad_norm 0.369324 rank 2
2025-01-11 06:19:07,361 DEBUG TRAIN Batch 162/1800 loss 0.032744 acc 0.972299 lr 0.00012593 grad_norm 0.369324 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 06:20:30,749 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 06:20:30,751 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 06:20:31,235 INFO Epoch 162 Step 157682 on_batch_end True CV rank 0
2025-01-11 06:20:31,235 INFO Epoch 162 Step 157682 on_batch_end True CV rank 1
2025-01-11 06:20:31,235 INFO Epoch 162 Step 157682 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 06:20:40,560 DEBUG CV Batch 162/100 loss 0.000853 acc 1.000000  rank 0
2025-01-11 06:20:40,697 DEBUG CV Batch 162/100 loss 0.000853 acc 1.000000  rank 2
2025-01-11 06:20:40,916 DEBUG CV Batch 162/100 loss 0.000853 acc 1.000000  rank 1
2025-01-11 06:20:41,077 INFO Epoch 162 Step 157682 CV info lr 0.0001259154275386916 0 rank loss_2.6879539504246948 acc_0.7801185650260825
2025-01-11 06:20:41,245 INFO Epoch 162 Step 157682 CV info lr 0.0001259154275386916 2 rank loss_2.6879539504246948 acc_0.7801185650260825
2025-01-11 06:20:41,468 INFO Epoch 162 Step 157682 CV info lr 0.0001259154275386916 1 rank loss_2.6879539504246948 acc_0.7801185650260825
2025-01-11 06:20:42,459 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_162_whole.pt
2025-01-11 06:20:42,481 INFO Added key: store_based_barrier_key:165 to store for rank: 0
2025-01-11 06:20:42,491 INFO Added key: store_based_barrier_key:165 to store for rank: 2
2025-01-11 06:20:42,491 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:165 with 3 nodes.
2025-01-11 06:20:42,491 INFO Added key: store_based_barrier_key:165 to store for rank: 1
2025-01-11 06:20:42,491 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:165 with 3 nodes.
2025-01-11 06:20:42,494 INFO Epoch 163 TRAIN info lr 0.0001259154275386916 rank 1
2025-01-11 06:20:42,494 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 06:20:42,497 INFO Epoch 163 TRAIN info lr 0.0001259154275386916 rank 2
2025-01-11 06:20:42,497 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 06:20:42,501 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:165 with 3 nodes.
2025-01-11 06:20:42,511 INFO Epoch 163 TRAIN info lr 0.0001259154275386916 rank 0
2025-01-11 06:20:42,511 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 06:21:16,771 DEBUG TRAIN Batch 163/100 loss 0.029160 acc 0.982218 lr 0.00012590 grad_norm 0.360753 rank 2
2025-01-11 06:21:16,771 DEBUG TRAIN Batch 163/100 loss 0.031634 acc 0.974163 lr 0.00012590 grad_norm 0.360753 rank 1
2025-01-11 06:21:16,772 DEBUG TRAIN Batch 163/100 loss 0.019830 acc 0.987421 lr 0.00012590 grad_norm 0.360753 rank 0
2025-01-11 06:21:40,790 DEBUG TRAIN Batch 163/200 loss 0.039683 acc 0.969981 lr 0.00012588 grad_norm 0.373775 rank 1
2025-01-11 06:21:40,790 DEBUG TRAIN Batch 163/200 loss 0.017397 acc 0.987437 lr 0.00012588 grad_norm 0.373775 rank 0
2025-01-11 06:21:40,791 DEBUG TRAIN Batch 163/200 loss 0.038388 acc 0.975541 lr 0.00012588 grad_norm 0.373775 rank 2
2025-01-11 06:22:05,234 DEBUG TRAIN Batch 163/300 loss 0.028582 acc 0.980843 lr 0.00012586 grad_norm 0.358785 rank 0
2025-01-11 06:22:05,235 DEBUG TRAIN Batch 163/300 loss 0.031777 acc 0.981771 lr 0.00012586 grad_norm 0.358785 rank 1
2025-01-11 06:22:05,235 DEBUG TRAIN Batch 163/300 loss 0.029112 acc 0.978995 lr 0.00012586 grad_norm 0.358785 rank 2
2025-01-11 06:22:29,897 DEBUG TRAIN Batch 163/400 loss 0.030262 acc 0.979879 lr 0.00012584 grad_norm 0.373326 rank 1
2025-01-11 06:22:29,897 DEBUG TRAIN Batch 163/400 loss 0.034252 acc 0.978805 lr 0.00012584 grad_norm 0.373326 rank 0
2025-01-11 06:22:29,898 DEBUG TRAIN Batch 163/400 loss 0.041053 acc 0.968504 lr 0.00012584 grad_norm 0.373326 rank 2
2025-01-11 06:22:53,570 DEBUG TRAIN Batch 163/500 loss 0.026748 acc 0.984142 lr 0.00012582 grad_norm 0.382705 rank 0
2025-01-11 06:22:53,570 DEBUG TRAIN Batch 163/500 loss 0.035890 acc 0.975691 lr 0.00012582 grad_norm 0.382705 rank 1
2025-01-11 06:22:53,572 DEBUG TRAIN Batch 163/500 loss 0.029074 acc 0.978571 lr 0.00012582 grad_norm 0.382705 rank 2
2025-01-11 06:23:17,373 DEBUG TRAIN Batch 163/600 loss 0.034911 acc 0.974729 lr 0.00012580 grad_norm 0.363929 rank 0
2025-01-11 06:23:17,373 DEBUG TRAIN Batch 163/600 loss 0.030255 acc 0.979058 lr 0.00012580 grad_norm 0.363929 rank 1
2025-01-11 06:23:17,374 DEBUG TRAIN Batch 163/600 loss 0.025228 acc 0.983623 lr 0.00012580 grad_norm 0.363929 rank 2
2025-01-11 06:23:42,018 DEBUG TRAIN Batch 163/700 loss 0.024543 acc 0.978805 lr 0.00012578 grad_norm 0.375790 rank 1
2025-01-11 06:23:42,018 DEBUG TRAIN Batch 163/700 loss 0.030796 acc 0.979508 lr 0.00012578 grad_norm 0.375790 rank 0
2025-01-11 06:23:42,019 DEBUG TRAIN Batch 163/700 loss 0.021222 acc 0.987310 lr 0.00012578 grad_norm 0.375790 rank 2
2025-01-11 06:24:06,958 DEBUG TRAIN Batch 163/800 loss 0.036259 acc 0.976602 lr 0.00012576 grad_norm 0.357476 rank 0
2025-01-11 06:24:06,959 DEBUG TRAIN Batch 163/800 loss 0.026971 acc 0.983216 lr 0.00012576 grad_norm 0.357476 rank 2
2025-01-11 06:24:06,959 DEBUG TRAIN Batch 163/800 loss 0.041216 acc 0.975862 lr 0.00012576 grad_norm 0.357476 rank 1
2025-01-11 06:24:31,471 DEBUG TRAIN Batch 163/900 loss 0.039263 acc 0.971307 lr 0.00012574 grad_norm 0.384806 rank 0
2025-01-11 06:24:31,471 DEBUG TRAIN Batch 163/900 loss 0.042528 acc 0.970000 lr 0.00012574 grad_norm 0.384806 rank 1
2025-01-11 06:24:31,471 DEBUG TRAIN Batch 163/900 loss 0.025046 acc 0.982409 lr 0.00012574 grad_norm 0.384806 rank 2
2025-01-11 06:24:56,459 DEBUG TRAIN Batch 163/1000 loss 0.028176 acc 0.982692 lr 0.00012572 grad_norm 0.376036 rank 2
2025-01-11 06:24:56,462 DEBUG TRAIN Batch 163/1000 loss 0.026584 acc 0.984446 lr 0.00012572 grad_norm 0.376036 rank 0
2025-01-11 06:24:56,463 DEBUG TRAIN Batch 163/1000 loss 0.032074 acc 0.979208 lr 0.00012572 grad_norm 0.376036 rank 1
2025-01-11 06:25:21,506 DEBUG TRAIN Batch 163/1100 loss 0.032664 acc 0.973874 lr 0.00012570 grad_norm 0.386525 rank 0
2025-01-11 06:25:21,507 DEBUG TRAIN Batch 163/1100 loss 0.034612 acc 0.975043 lr 0.00012570 grad_norm 0.386525 rank 2
2025-01-11 06:25:21,507 DEBUG TRAIN Batch 163/1100 loss 0.030086 acc 0.981779 lr 0.00012570 grad_norm 0.386525 rank 1
2025-01-11 06:25:46,276 DEBUG TRAIN Batch 163/1200 loss 0.025006 acc 0.981697 lr 0.00012568 grad_norm 0.361564 rank 0
2025-01-11 06:25:46,276 DEBUG TRAIN Batch 163/1200 loss 0.015166 acc 0.989950 lr 0.00012568 grad_norm 0.361564 rank 2
2025-01-11 06:25:46,276 DEBUG TRAIN Batch 163/1200 loss 0.036279 acc 0.972401 lr 0.00012568 grad_norm 0.361564 rank 1
2025-01-11 06:26:11,559 DEBUG TRAIN Batch 163/1300 loss 0.023845 acc 0.983906 lr 0.00012566 grad_norm 0.373970 rank 0
2025-01-11 06:26:11,559 DEBUG TRAIN Batch 163/1300 loss 0.020968 acc 0.981188 lr 0.00012566 grad_norm 0.373970 rank 2
2025-01-11 06:26:11,559 DEBUG TRAIN Batch 163/1300 loss 0.037596 acc 0.979592 lr 0.00012566 grad_norm 0.373970 rank 1
2025-01-11 06:26:36,525 DEBUG TRAIN Batch 163/1400 loss 0.030442 acc 0.982792 lr 0.00012564 grad_norm 0.374789 rank 2
2025-01-11 06:26:36,525 DEBUG TRAIN Batch 163/1400 loss 0.036091 acc 0.974743 lr 0.00012564 grad_norm 0.374789 rank 0
2025-01-11 06:26:36,525 DEBUG TRAIN Batch 163/1400 loss 0.030499 acc 0.981798 lr 0.00012564 grad_norm 0.374789 rank 1
2025-01-11 06:27:00,604 DEBUG TRAIN Batch 163/1500 loss 0.026848 acc 0.982456 lr 0.00012562 grad_norm 0.369836 rank 2
2025-01-11 06:27:00,604 DEBUG TRAIN Batch 163/1500 loss 0.024650 acc 0.987085 lr 0.00012562 grad_norm 0.369836 rank 0
2025-01-11 06:27:00,604 DEBUG TRAIN Batch 163/1500 loss 0.034709 acc 0.974061 lr 0.00012562 grad_norm 0.369836 rank 1
2025-01-11 06:27:25,140 DEBUG TRAIN Batch 163/1600 loss 0.032650 acc 0.980533 lr 0.00012560 grad_norm 0.370267 rank 0
2025-01-11 06:27:25,141 DEBUG TRAIN Batch 163/1600 loss 0.034398 acc 0.976967 lr 0.00012560 grad_norm 0.370267 rank 2
2025-01-11 06:27:25,141 DEBUG TRAIN Batch 163/1600 loss 0.027395 acc 0.980392 lr 0.00012560 grad_norm 0.370267 rank 1
2025-01-11 06:27:49,166 DEBUG TRAIN Batch 163/1700 loss 0.029836 acc 0.978958 lr 0.00012558 grad_norm 0.386192 rank 0
2025-01-11 06:27:49,167 DEBUG TRAIN Batch 163/1700 loss 0.043017 acc 0.971457 lr 0.00012558 grad_norm 0.386192 rank 2
2025-01-11 06:27:49,167 DEBUG TRAIN Batch 163/1700 loss 0.031534 acc 0.978625 lr 0.00012558 grad_norm 0.386192 rank 1
2025-01-11 06:28:12,984 DEBUG TRAIN Batch 163/1800 loss 0.017160 acc 0.987603 lr 0.00012556 grad_norm 0.382709 rank 0
2025-01-11 06:28:12,984 DEBUG TRAIN Batch 163/1800 loss 0.037504 acc 0.975045 lr 0.00012556 grad_norm 0.382709 rank 2
2025-01-11 06:28:12,984 DEBUG TRAIN Batch 163/1800 loss 0.035840 acc 0.973904 lr 0.00012556 grad_norm 0.382709 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 06:29:29,614 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 06:29:29,620 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 06:29:30,034 INFO Epoch 163 Step 158614 on_batch_end True CV rank 1
2025-01-11 06:29:30,034 INFO Epoch 163 Step 158614 on_batch_end True CV rank 0
2025-01-11 06:29:30,034 INFO Epoch 163 Step 158614 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 06:29:39,048 DEBUG CV Batch 163/100 loss 0.000992 acc 1.000000  rank 0
2025-01-11 06:29:39,492 DEBUG CV Batch 163/100 loss 0.000992 acc 1.000000  rank 2
2025-01-11 06:29:39,580 INFO Epoch 163 Step 158614 CV info lr 0.00012554494928428624 0 rank loss_2.684050998224465 acc_0.7805825960740709
2025-01-11 06:29:39,656 DEBUG CV Batch 163/100 loss 0.000992 acc 1.000000  rank 1
2025-01-11 06:29:40,037 INFO Epoch 163 Step 158614 CV info lr 0.00012554494928428624 2 rank loss_2.684050998224465 acc_0.7805825960740709
2025-01-11 06:29:40,212 INFO Epoch 163 Step 158614 CV info lr 0.00012554494928428624 1 rank loss_2.684050998224465 acc_0.7805825960740709
2025-01-11 06:29:40,864 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_163_whole.pt
2025-01-11 06:29:40,886 INFO Added key: store_based_barrier_key:166 to store for rank: 0
2025-01-11 06:29:40,886 INFO Added key: store_based_barrier_key:166 to store for rank: 1
2025-01-11 06:29:40,887 INFO Added key: store_based_barrier_key:166 to store for rank: 2
2025-01-11 06:29:40,887 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:166 with 3 nodes.
2025-01-11 06:29:40,893 INFO Epoch 164 TRAIN info lr 0.00012554494928428624 rank 2
2025-01-11 06:29:40,893 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 06:29:40,897 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:166 with 3 nodes.
2025-01-11 06:29:40,897 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:166 with 3 nodes.
2025-01-11 06:29:40,898 INFO Epoch 164 TRAIN info lr 0.00012554494928428624 rank 0
2025-01-11 06:29:40,898 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 06:29:40,905 INFO Epoch 164 TRAIN info lr 0.00012554494928428624 rank 1
2025-01-11 06:29:40,905 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 06:30:11,579 DEBUG TRAIN Batch 164/100 loss 0.027523 acc 0.977083 lr 0.00012553 grad_norm 0.335410 rank 2
2025-01-11 06:30:11,580 DEBUG TRAIN Batch 164/100 loss 0.029722 acc 0.973849 lr 0.00012553 grad_norm 0.335410 rank 1
2025-01-11 06:30:11,581 DEBUG TRAIN Batch 164/100 loss 0.028100 acc 0.980926 lr 0.00012553 grad_norm 0.335410 rank 0
2025-01-11 06:30:35,143 DEBUG TRAIN Batch 164/200 loss 0.039652 acc 0.975948 lr 0.00012551 grad_norm 0.399798 rank 1
2025-01-11 06:30:35,144 DEBUG TRAIN Batch 164/200 loss 0.033747 acc 0.980357 lr 0.00012551 grad_norm 0.399798 rank 0
2025-01-11 06:30:35,144 DEBUG TRAIN Batch 164/200 loss 0.025688 acc 0.984127 lr 0.00012551 grad_norm 0.399798 rank 2
2025-01-11 06:30:58,568 DEBUG TRAIN Batch 164/300 loss 0.030715 acc 0.979753 lr 0.00012549 grad_norm 0.353545 rank 0
2025-01-11 06:30:58,568 DEBUG TRAIN Batch 164/300 loss 0.021480 acc 0.984293 lr 0.00012549 grad_norm 0.353545 rank 1
2025-01-11 06:30:58,568 DEBUG TRAIN Batch 164/300 loss 0.025647 acc 0.980810 lr 0.00012549 grad_norm 0.353545 rank 2
2025-01-11 06:31:22,564 DEBUG TRAIN Batch 164/400 loss 0.025069 acc 0.982521 lr 0.00012547 grad_norm 0.372427 rank 0
2025-01-11 06:31:22,565 DEBUG TRAIN Batch 164/400 loss 0.038195 acc 0.974729 lr 0.00012547 grad_norm 0.372427 rank 2
2025-01-11 06:31:22,565 DEBUG TRAIN Batch 164/400 loss 0.035035 acc 0.978102 lr 0.00012547 grad_norm 0.372427 rank 1
2025-01-11 06:31:47,228 DEBUG TRAIN Batch 164/500 loss 0.025071 acc 0.980944 lr 0.00012545 grad_norm 0.390641 rank 0
2025-01-11 06:31:47,229 DEBUG TRAIN Batch 164/500 loss 0.043751 acc 0.970378 lr 0.00012545 grad_norm 0.390641 rank 2
2025-01-11 06:31:47,232 DEBUG TRAIN Batch 164/500 loss 0.040033 acc 0.973893 lr 0.00012545 grad_norm 0.390641 rank 1
2025-01-11 06:32:11,434 DEBUG TRAIN Batch 164/600 loss 0.036931 acc 0.971731 lr 0.00012543 grad_norm 0.380478 rank 1
2025-01-11 06:32:11,435 DEBUG TRAIN Batch 164/600 loss 0.036634 acc 0.978927 lr 0.00012543 grad_norm 0.380478 rank 0
2025-01-11 06:32:11,435 DEBUG TRAIN Batch 164/600 loss 0.029149 acc 0.980054 lr 0.00012543 grad_norm 0.380478 rank 2
2025-01-11 06:32:36,808 DEBUG TRAIN Batch 164/700 loss 0.039502 acc 0.970000 lr 0.00012541 grad_norm 0.387591 rank 0
2025-01-11 06:32:36,808 DEBUG TRAIN Batch 164/700 loss 0.031262 acc 0.977233 lr 0.00012541 grad_norm 0.387591 rank 2
2025-01-11 06:32:36,808 DEBUG TRAIN Batch 164/700 loss 0.022622 acc 0.983203 lr 0.00012541 grad_norm 0.387591 rank 1
2025-01-11 06:33:02,629 DEBUG TRAIN Batch 164/800 loss 0.031745 acc 0.979705 lr 0.00012539 grad_norm 0.380989 rank 1
2025-01-11 06:33:02,629 DEBUG TRAIN Batch 164/800 loss 0.024225 acc 0.981744 lr 0.00012539 grad_norm 0.380989 rank 2
2025-01-11 06:33:02,629 DEBUG TRAIN Batch 164/800 loss 0.027054 acc 0.984563 lr 0.00012539 grad_norm 0.380989 rank 0
2025-01-11 06:33:26,618 DEBUG TRAIN Batch 164/900 loss 0.013450 acc 0.992395 lr 0.00012537 grad_norm 0.333013 rank 2
2025-01-11 06:33:26,618 DEBUG TRAIN Batch 164/900 loss 0.021422 acc 0.987013 lr 0.00012537 grad_norm 0.333013 rank 0
2025-01-11 06:33:26,618 DEBUG TRAIN Batch 164/900 loss 0.032156 acc 0.977876 lr 0.00012537 grad_norm 0.333013 rank 1
2025-01-11 06:33:51,808 DEBUG TRAIN Batch 164/1000 loss 0.016754 acc 0.988426 lr 0.00012535 grad_norm 0.369667 rank 1
2025-01-11 06:33:51,809 DEBUG TRAIN Batch 164/1000 loss 0.027175 acc 0.979909 lr 0.00012535 grad_norm 0.369667 rank 2
2025-01-11 06:33:51,809 DEBUG TRAIN Batch 164/1000 loss 0.047997 acc 0.965827 lr 0.00012535 grad_norm 0.369667 rank 0
2025-01-11 06:34:16,618 DEBUG TRAIN Batch 164/1100 loss 0.022631 acc 0.986288 lr 0.00012533 grad_norm 0.350150 rank 2
2025-01-11 06:34:16,619 DEBUG TRAIN Batch 164/1100 loss 0.025595 acc 0.985244 lr 0.00012533 grad_norm 0.350150 rank 0
2025-01-11 06:34:16,619 DEBUG TRAIN Batch 164/1100 loss 0.025857 acc 0.986486 lr 0.00012533 grad_norm 0.350150 rank 1
2025-01-11 06:34:41,140 DEBUG TRAIN Batch 164/1200 loss 0.028999 acc 0.979953 lr 0.00012531 grad_norm 0.409232 rank 1
2025-01-11 06:34:41,141 DEBUG TRAIN Batch 164/1200 loss 0.039956 acc 0.969849 lr 0.00012531 grad_norm 0.409232 rank 2
2025-01-11 06:34:41,141 DEBUG TRAIN Batch 164/1200 loss 0.038138 acc 0.976930 lr 0.00012531 grad_norm 0.409232 rank 0
2025-01-11 06:35:05,822 DEBUG TRAIN Batch 164/1300 loss 0.036645 acc 0.976166 lr 0.00012529 grad_norm 0.403923 rank 1
2025-01-11 06:35:05,822 DEBUG TRAIN Batch 164/1300 loss 0.043120 acc 0.974241 lr 0.00012529 grad_norm 0.403923 rank 0
2025-01-11 06:35:05,823 DEBUG TRAIN Batch 164/1300 loss 0.027052 acc 0.981557 lr 0.00012529 grad_norm 0.403923 rank 2
2025-01-11 06:35:29,878 DEBUG TRAIN Batch 164/1400 loss 0.027118 acc 0.984902 lr 0.00012527 grad_norm 0.378478 rank 1
2025-01-11 06:35:29,878 DEBUG TRAIN Batch 164/1400 loss 0.023095 acc 0.984741 lr 0.00012527 grad_norm 0.378478 rank 0
2025-01-11 06:35:29,879 DEBUG TRAIN Batch 164/1400 loss 0.037402 acc 0.977213 lr 0.00012527 grad_norm 0.378478 rank 2
2025-01-11 06:35:54,398 DEBUG TRAIN Batch 164/1500 loss 0.038195 acc 0.969866 lr 0.00012525 grad_norm 0.377892 rank 2
2025-01-11 06:35:54,398 DEBUG TRAIN Batch 164/1500 loss 0.018777 acc 0.990220 lr 0.00012525 grad_norm 0.377892 rank 0
2025-01-11 06:35:54,398 DEBUG TRAIN Batch 164/1500 loss 0.031944 acc 0.986097 lr 0.00012525 grad_norm 0.377892 rank 1
2025-01-11 06:36:19,319 DEBUG TRAIN Batch 164/1600 loss 0.034766 acc 0.977124 lr 0.00012523 grad_norm 0.377713 rank 1
2025-01-11 06:36:19,319 DEBUG TRAIN Batch 164/1600 loss 0.039709 acc 0.971664 lr 0.00012523 grad_norm 0.377713 rank 2
2025-01-11 06:36:19,320 DEBUG TRAIN Batch 164/1600 loss 0.035369 acc 0.976147 lr 0.00012523 grad_norm 0.377713 rank 0
2025-01-11 06:36:42,983 DEBUG TRAIN Batch 164/1700 loss 0.037517 acc 0.976901 lr 0.00012521 grad_norm 0.360619 rank 1
2025-01-11 06:36:42,983 DEBUG TRAIN Batch 164/1700 loss 0.027020 acc 0.981731 lr 0.00012521 grad_norm 0.360619 rank 0
2025-01-11 06:36:42,983 DEBUG TRAIN Batch 164/1700 loss 0.025735 acc 0.981787 lr 0.00012521 grad_norm 0.360619 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 06:38:01,558 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 06:38:01,558 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 06:38:01,979 INFO Epoch 164 Step 159503 on_batch_end True CV rank 0
2025-01-11 06:38:01,979 INFO Epoch 164 Step 159503 on_batch_end True CV rank 2
2025-01-11 06:38:01,979 INFO Epoch 164 Step 159503 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 06:38:10,814 DEBUG CV Batch 164/100 loss 0.001714 acc 1.000000  rank 0
2025-01-11 06:38:11,323 INFO Epoch 164 Step 159503 CV info lr 0.00012519459408594203 0 rank loss_2.6947833321250902 acc_0.7806112103556332
2025-01-11 06:38:11,343 DEBUG CV Batch 164/100 loss 0.001714 acc 1.000000  rank 2
2025-01-11 06:38:11,800 DEBUG CV Batch 164/100 loss 0.001714 acc 1.000000  rank 1
2025-01-11 06:38:11,841 INFO Epoch 164 Step 159503 CV info lr 0.00012519459408594203 2 rank loss_2.6947833321250902 acc_0.7806112103556332
2025-01-11 06:38:12,339 INFO Epoch 164 Step 159503 CV info lr 0.00012519459408594203 1 rank loss_2.6947833321250902 acc_0.7806112103556332
2025-01-11 06:38:12,606 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_164_whole.pt
2025-01-11 06:38:12,618 INFO Added key: store_based_barrier_key:167 to store for rank: 0
2025-01-11 06:38:12,628 INFO Added key: store_based_barrier_key:167 to store for rank: 1
2025-01-11 06:38:12,628 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:167 with 3 nodes.
2025-01-11 06:38:12,628 INFO Added key: store_based_barrier_key:167 to store for rank: 2
2025-01-11 06:38:12,628 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:167 with 3 nodes.
2025-01-11 06:38:12,629 INFO Epoch 165 TRAIN info lr 0.00012519459408594203 rank 1
2025-01-11 06:38:12,629 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 06:38:12,631 INFO Epoch 165 TRAIN info lr 0.00012519459408594203 rank 2
2025-01-11 06:38:12,632 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 06:38:12,638 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:167 with 3 nodes.
2025-01-11 06:38:12,641 INFO Epoch 165 TRAIN info lr 0.00012519459408594203 rank 0
2025-01-11 06:38:12,641 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 06:38:43,001 DEBUG TRAIN Batch 165/100 loss 0.036019 acc 0.976370 lr 0.00012517 grad_norm 0.384402 rank 2
2025-01-11 06:38:43,001 DEBUG TRAIN Batch 165/100 loss 0.028702 acc 0.981897 lr 0.00012517 grad_norm 0.384402 rank 0
2025-01-11 06:38:43,001 DEBUG TRAIN Batch 165/100 loss 0.036972 acc 0.973803 lr 0.00012517 grad_norm 0.384402 rank 1
2025-01-11 06:39:06,584 DEBUG TRAIN Batch 165/200 loss 0.019940 acc 0.988708 lr 0.00012516 grad_norm 0.356414 rank 0
2025-01-11 06:39:06,584 DEBUG TRAIN Batch 165/200 loss 0.028838 acc 0.980247 lr 0.00012516 grad_norm 0.356414 rank 2
2025-01-11 06:39:06,584 DEBUG TRAIN Batch 165/200 loss 0.025621 acc 0.983471 lr 0.00012516 grad_norm 0.356414 rank 1
2025-01-11 06:39:30,024 DEBUG TRAIN Batch 165/300 loss 0.028356 acc 0.978841 lr 0.00012514 grad_norm 0.365805 rank 1
2025-01-11 06:39:30,025 DEBUG TRAIN Batch 165/300 loss 0.022566 acc 0.986654 lr 0.00012514 grad_norm 0.365805 rank 0
2025-01-11 06:39:30,025 DEBUG TRAIN Batch 165/300 loss 0.028786 acc 0.973247 lr 0.00012514 grad_norm 0.365805 rank 2
2025-01-11 06:39:53,446 DEBUG TRAIN Batch 165/400 loss 0.023949 acc 0.982962 lr 0.00012512 grad_norm 0.357520 rank 1
2025-01-11 06:39:53,447 DEBUG TRAIN Batch 165/400 loss 0.030575 acc 0.979980 lr 0.00012512 grad_norm 0.357520 rank 2
2025-01-11 06:39:53,447 DEBUG TRAIN Batch 165/400 loss 0.025358 acc 0.982353 lr 0.00012512 grad_norm 0.357520 rank 0
2025-01-11 06:40:16,845 DEBUG TRAIN Batch 165/500 loss 0.030019 acc 0.977362 lr 0.00012510 grad_norm 0.393144 rank 0
2025-01-11 06:40:16,845 DEBUG TRAIN Batch 165/500 loss 0.032817 acc 0.977927 lr 0.00012510 grad_norm 0.393144 rank 2
2025-01-11 06:40:16,845 DEBUG TRAIN Batch 165/500 loss 0.043263 acc 0.968525 lr 0.00012510 grad_norm 0.393144 rank 1
2025-01-11 06:40:40,386 DEBUG TRAIN Batch 165/600 loss 0.034795 acc 0.976035 lr 0.00012508 grad_norm 0.358268 rank 0
2025-01-11 06:40:40,386 DEBUG TRAIN Batch 165/600 loss 0.021966 acc 0.983389 lr 0.00012508 grad_norm 0.358268 rank 2
2025-01-11 06:40:40,386 DEBUG TRAIN Batch 165/600 loss 0.039151 acc 0.973905 lr 0.00012508 grad_norm 0.358268 rank 1
2025-01-11 06:41:04,348 DEBUG TRAIN Batch 165/700 loss 0.029491 acc 0.982883 lr 0.00012506 grad_norm 0.342811 rank 0
2025-01-11 06:41:04,349 DEBUG TRAIN Batch 165/700 loss 0.038819 acc 0.974806 lr 0.00012506 grad_norm 0.342811 rank 2
2025-01-11 06:41:04,349 DEBUG TRAIN Batch 165/700 loss 0.024321 acc 0.981150 lr 0.00012506 grad_norm 0.342811 rank 1
2025-01-11 06:41:29,012 DEBUG TRAIN Batch 165/800 loss 0.026152 acc 0.982792 lr 0.00012504 grad_norm 0.352142 rank 0
2025-01-11 06:41:29,013 DEBUG TRAIN Batch 165/800 loss 0.043770 acc 0.969072 lr 0.00012504 grad_norm 0.352142 rank 2
2025-01-11 06:41:29,013 DEBUG TRAIN Batch 165/800 loss 0.020956 acc 0.985552 lr 0.00012504 grad_norm 0.352142 rank 1
2025-01-11 06:41:52,763 DEBUG TRAIN Batch 165/900 loss 0.022302 acc 0.977578 lr 0.00012502 grad_norm 0.375981 rank 0
2025-01-11 06:41:52,763 DEBUG TRAIN Batch 165/900 loss 0.024167 acc 0.981013 lr 0.00012502 grad_norm 0.375981 rank 1
2025-01-11 06:41:52,763 DEBUG TRAIN Batch 165/900 loss 0.041707 acc 0.970443 lr 0.00012502 grad_norm 0.375981 rank 2
2025-01-11 06:42:16,832 DEBUG TRAIN Batch 165/1000 loss 0.047088 acc 0.971481 lr 0.00012500 grad_norm 0.379665 rank 1
2025-01-11 06:42:16,833 DEBUG TRAIN Batch 165/1000 loss 0.029624 acc 0.979816 lr 0.00012500 grad_norm 0.379665 rank 2
2025-01-11 06:42:16,833 DEBUG TRAIN Batch 165/1000 loss 0.034348 acc 0.972350 lr 0.00012500 grad_norm 0.379665 rank 0
2025-01-11 06:42:40,583 DEBUG TRAIN Batch 165/1100 loss 0.021090 acc 0.985240 lr 0.00012498 grad_norm 0.358893 rank 0
2025-01-11 06:42:40,584 DEBUG TRAIN Batch 165/1100 loss 0.025114 acc 0.984799 lr 0.00012498 grad_norm 0.358893 rank 2
2025-01-11 06:42:40,587 DEBUG TRAIN Batch 165/1100 loss 0.037887 acc 0.975330 lr 0.00012498 grad_norm 0.358893 rank 1
2025-01-11 06:43:05,930 DEBUG TRAIN Batch 165/1200 loss 0.012163 acc 0.991883 lr 0.00012496 grad_norm 0.340693 rank 0
2025-01-11 06:43:05,930 DEBUG TRAIN Batch 165/1200 loss 0.027480 acc 0.979866 lr 0.00012496 grad_norm 0.340693 rank 2
2025-01-11 06:43:05,930 DEBUG TRAIN Batch 165/1200 loss 0.029233 acc 0.975892 lr 0.00012496 grad_norm 0.340693 rank 1
2025-01-11 06:43:31,103 DEBUG TRAIN Batch 165/1300 loss 0.034255 acc 0.974695 lr 0.00012494 grad_norm 0.403509 rank 0
2025-01-11 06:43:31,103 DEBUG TRAIN Batch 165/1300 loss 0.031003 acc 0.975057 lr 0.00012494 grad_norm 0.403509 rank 2
2025-01-11 06:43:31,103 DEBUG TRAIN Batch 165/1300 loss 0.028025 acc 0.985163 lr 0.00012494 grad_norm 0.403509 rank 1
2025-01-11 06:43:55,147 DEBUG TRAIN Batch 165/1400 loss 0.028450 acc 0.980176 lr 0.00012492 grad_norm 0.401538 rank 1
2025-01-11 06:43:55,147 DEBUG TRAIN Batch 165/1400 loss 0.039366 acc 0.978516 lr 0.00012492 grad_norm 0.401538 rank 0
2025-01-11 06:43:55,147 DEBUG TRAIN Batch 165/1400 loss 0.042127 acc 0.971204 lr 0.00012492 grad_norm 0.401538 rank 2
2025-01-11 06:44:20,368 DEBUG TRAIN Batch 165/1500 loss 0.021490 acc 0.985043 lr 0.00012490 grad_norm 0.379497 rank 0
2025-01-11 06:44:20,368 DEBUG TRAIN Batch 165/1500 loss 0.042331 acc 0.973921 lr 0.00012490 grad_norm 0.379497 rank 2
2025-01-11 06:44:20,368 DEBUG TRAIN Batch 165/1500 loss 0.024090 acc 0.984825 lr 0.00012490 grad_norm 0.379497 rank 1
2025-01-11 06:44:46,482 DEBUG TRAIN Batch 165/1600 loss 0.028604 acc 0.977629 lr 0.00012488 grad_norm 0.367765 rank 1
2025-01-11 06:44:46,483 DEBUG TRAIN Batch 165/1600 loss 0.020532 acc 0.986647 lr 0.00012488 grad_norm 0.367765 rank 0
2025-01-11 06:44:46,483 DEBUG TRAIN Batch 165/1600 loss 0.027062 acc 0.980871 lr 0.00012488 grad_norm 0.367765 rank 2
2025-01-11 06:45:11,015 DEBUG TRAIN Batch 165/1700 loss 0.028153 acc 0.980583 lr 0.00012486 grad_norm 0.361332 rank 0
2025-01-11 06:45:11,015 DEBUG TRAIN Batch 165/1700 loss 0.028364 acc 0.980372 lr 0.00012486 grad_norm 0.361332 rank 2
2025-01-11 06:45:11,016 DEBUG TRAIN Batch 165/1700 loss 0.028079 acc 0.984678 lr 0.00012486 grad_norm 0.361332 rank 1
2025-01-11 06:45:35,545 DEBUG TRAIN Batch 165/1800 loss 0.043376 acc 0.972125 lr 0.00012484 grad_norm 0.370634 rank 0
2025-01-11 06:45:35,546 DEBUG TRAIN Batch 165/1800 loss 0.034705 acc 0.974014 lr 0.00012484 grad_norm 0.370634 rank 2
2025-01-11 06:45:35,546 DEBUG TRAIN Batch 165/1800 loss 0.022488 acc 0.985401 lr 0.00012484 grad_norm 0.370634 rank 1
2025-01-11 06:46:01,430 DEBUG TRAIN Batch 165/1900 loss 0.047640 acc 0.971606 lr 0.00012482 grad_norm 0.399706 rank 1
2025-01-11 06:46:01,430 DEBUG TRAIN Batch 165/1900 loss 0.042395 acc 0.972101 lr 0.00012482 grad_norm 0.399706 rank 0
2025-01-11 06:46:01,431 DEBUG TRAIN Batch 165/1900 loss 0.030995 acc 0.979466 lr 0.00012482 grad_norm 0.399706 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 06:47:21,824 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 06:47:21,829 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 06:47:22,253 INFO Epoch 165 Step 160497 on_batch_end True CV rank 2
2025-01-11 06:47:22,253 INFO Epoch 165 Step 160497 on_batch_end True CV rank 0
2025-01-11 06:47:22,253 INFO Epoch 165 Step 160497 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 06:47:31,291 DEBUG CV Batch 165/100 loss 0.008933 acc 0.997770  rank 0
2025-01-11 06:47:31,422 DEBUG CV Batch 165/100 loss 0.008933 acc 0.997770  rank 2
2025-01-11 06:47:31,757 INFO Epoch 165 Step 160497 CV info lr 0.00012480631049439683 0 rank loss_2.686683638041646 acc_0.7794347877303759
2025-01-11 06:47:31,943 INFO Epoch 165 Step 160497 CV info lr 0.00012480631049439683 2 rank loss_2.686683638041646 acc_0.7794347877303759
2025-01-11 06:47:32,219 DEBUG CV Batch 165/100 loss 0.008933 acc 0.997770  rank 1
2025-01-11 06:47:32,788 INFO Epoch 165 Step 160497 CV info lr 0.00012480631049439683 1 rank loss_2.686683638041646 acc_0.7794347877303759
2025-01-11 06:47:33,081 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_165_whole.pt
2025-01-11 06:47:33,103 INFO Added key: store_based_barrier_key:168 to store for rank: 0
2025-01-11 06:47:33,103 INFO Added key: store_based_barrier_key:168 to store for rank: 1
2025-01-11 06:47:33,103 INFO Added key: store_based_barrier_key:168 to store for rank: 2
2025-01-11 06:47:33,104 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:168 with 3 nodes.
2025-01-11 06:47:33,106 INFO Epoch 166 TRAIN info lr 0.00012480631049439683 rank 2
2025-01-11 06:47:33,106 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 06:47:33,113 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:168 with 3 nodes.
2025-01-11 06:47:33,113 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:168 with 3 nodes.
2025-01-11 06:47:33,117 INFO Epoch 166 TRAIN info lr 0.00012480631049439683 rank 0
2025-01-11 06:47:33,117 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 06:47:33,121 INFO Epoch 166 TRAIN info lr 0.00012480631049439683 rank 1
2025-01-11 06:47:33,121 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 06:48:07,237 DEBUG TRAIN Batch 166/100 loss 0.020302 acc 0.984016 lr 0.00012479 grad_norm 0.340707 rank 1
2025-01-11 06:48:07,238 DEBUG TRAIN Batch 166/100 loss 0.032895 acc 0.977106 lr 0.00012479 grad_norm 0.340707 rank 2
2025-01-11 06:48:07,238 DEBUG TRAIN Batch 166/100 loss 0.021729 acc 0.988911 lr 0.00012479 grad_norm 0.340707 rank 0
2025-01-11 06:48:31,201 DEBUG TRAIN Batch 166/200 loss 0.026984 acc 0.983683 lr 0.00012477 grad_norm 0.369049 rank 1
2025-01-11 06:48:31,201 DEBUG TRAIN Batch 166/200 loss 0.028333 acc 0.983397 lr 0.00012477 grad_norm 0.369049 rank 0
2025-01-11 06:48:31,202 DEBUG TRAIN Batch 166/200 loss 0.019803 acc 0.984223 lr 0.00012477 grad_norm 0.369049 rank 2
2025-01-11 06:48:55,385 DEBUG TRAIN Batch 166/300 loss 0.029873 acc 0.980880 lr 0.00012475 grad_norm 0.339341 rank 1
2025-01-11 06:48:55,385 DEBUG TRAIN Batch 166/300 loss 0.026725 acc 0.982370 lr 0.00012475 grad_norm 0.339341 rank 0
2025-01-11 06:48:55,386 DEBUG TRAIN Batch 166/300 loss 0.023705 acc 0.982867 lr 0.00012475 grad_norm 0.339341 rank 2
2025-01-11 06:49:19,524 DEBUG TRAIN Batch 166/400 loss 0.022772 acc 0.985112 lr 0.00012473 grad_norm 0.357565 rank 2
2025-01-11 06:49:19,524 DEBUG TRAIN Batch 166/400 loss 0.014908 acc 0.992690 lr 0.00012473 grad_norm 0.357565 rank 1
2025-01-11 06:49:19,525 DEBUG TRAIN Batch 166/400 loss 0.033247 acc 0.982877 lr 0.00012473 grad_norm 0.357565 rank 0
2025-01-11 06:49:43,013 DEBUG TRAIN Batch 166/500 loss 0.027895 acc 0.978541 lr 0.00012471 grad_norm 0.374304 rank 1
2025-01-11 06:49:43,013 DEBUG TRAIN Batch 166/500 loss 0.029169 acc 0.976657 lr 0.00012471 grad_norm 0.374304 rank 0
2025-01-11 06:49:43,014 DEBUG TRAIN Batch 166/500 loss 0.046775 acc 0.968313 lr 0.00012471 grad_norm 0.374304 rank 2
2025-01-11 06:50:06,720 DEBUG TRAIN Batch 166/600 loss 0.018685 acc 0.987624 lr 0.00012469 grad_norm 0.346990 rank 1
2025-01-11 06:50:06,721 DEBUG TRAIN Batch 166/600 loss 0.028607 acc 0.986667 lr 0.00012469 grad_norm 0.346990 rank 0
2025-01-11 06:50:06,721 DEBUG TRAIN Batch 166/600 loss 0.029695 acc 0.977954 lr 0.00012469 grad_norm 0.346990 rank 2
2025-01-11 06:50:30,857 DEBUG TRAIN Batch 166/700 loss 0.016877 acc 0.990521 lr 0.00012467 grad_norm 0.335882 rank 0
2025-01-11 06:50:30,857 DEBUG TRAIN Batch 166/700 loss 0.033309 acc 0.981262 lr 0.00012467 grad_norm 0.335882 rank 2
2025-01-11 06:50:30,857 DEBUG TRAIN Batch 166/700 loss 0.019196 acc 0.987217 lr 0.00012467 grad_norm 0.335882 rank 1
2025-01-11 06:50:55,659 DEBUG TRAIN Batch 166/800 loss 0.038574 acc 0.972662 lr 0.00012465 grad_norm 0.421835 rank 1
2025-01-11 06:50:55,660 DEBUG TRAIN Batch 166/800 loss 0.039772 acc 0.975174 lr 0.00012465 grad_norm 0.421835 rank 2
2025-01-11 06:50:55,660 DEBUG TRAIN Batch 166/800 loss 0.026531 acc 0.981510 lr 0.00012465 grad_norm 0.421835 rank 0
2025-01-11 06:51:19,958 DEBUG TRAIN Batch 166/900 loss 0.025699 acc 0.982507 lr 0.00012463 grad_norm 0.370940 rank 1
2025-01-11 06:51:19,958 DEBUG TRAIN Batch 166/900 loss 0.035566 acc 0.974954 lr 0.00012463 grad_norm 0.370940 rank 0
2025-01-11 06:51:19,959 DEBUG TRAIN Batch 166/900 loss 0.031361 acc 0.977800 lr 0.00012463 grad_norm 0.370940 rank 2
2025-01-11 06:51:43,540 DEBUG TRAIN Batch 166/1000 loss 0.030233 acc 0.978927 lr 0.00012461 grad_norm 0.375186 rank 1
2025-01-11 06:51:43,540 DEBUG TRAIN Batch 166/1000 loss 0.028796 acc 0.982553 lr 0.00012461 grad_norm 0.375186 rank 0
2025-01-11 06:51:43,540 DEBUG TRAIN Batch 166/1000 loss 0.028362 acc 0.982684 lr 0.00012461 grad_norm 0.375186 rank 2
2025-01-11 06:52:07,316 DEBUG TRAIN Batch 166/1100 loss 0.036187 acc 0.968902 lr 0.00012459 grad_norm 0.374420 rank 2
2025-01-11 06:52:07,316 DEBUG TRAIN Batch 166/1100 loss 0.025995 acc 0.979279 lr 0.00012459 grad_norm 0.374420 rank 1
2025-01-11 06:52:07,317 DEBUG TRAIN Batch 166/1100 loss 0.033714 acc 0.977885 lr 0.00012459 grad_norm 0.374420 rank 0
2025-01-11 06:52:31,458 DEBUG TRAIN Batch 166/1200 loss 0.027915 acc 0.980620 lr 0.00012457 grad_norm 0.397921 rank 1
2025-01-11 06:52:31,458 DEBUG TRAIN Batch 166/1200 loss 0.021636 acc 0.987705 lr 0.00012457 grad_norm 0.397921 rank 0
2025-01-11 06:52:31,459 DEBUG TRAIN Batch 166/1200 loss 0.033765 acc 0.975455 lr 0.00012457 grad_norm 0.397921 rank 2
2025-01-11 06:52:56,005 DEBUG TRAIN Batch 166/1300 loss 0.031779 acc 0.978516 lr 0.00012455 grad_norm 0.366104 rank 2
2025-01-11 06:52:56,005 DEBUG TRAIN Batch 166/1300 loss 0.012733 acc 0.991342 lr 0.00012455 grad_norm 0.366104 rank 1
2025-01-11 06:52:56,005 DEBUG TRAIN Batch 166/1300 loss 0.030596 acc 0.977273 lr 0.00012455 grad_norm 0.366104 rank 0
2025-01-11 06:53:20,379 DEBUG TRAIN Batch 166/1400 loss 0.022854 acc 0.981744 lr 0.00012454 grad_norm 0.372295 rank 2
2025-01-11 06:53:20,379 DEBUG TRAIN Batch 166/1400 loss 0.045581 acc 0.970848 lr 0.00012454 grad_norm 0.372295 rank 1
2025-01-11 06:53:20,380 DEBUG TRAIN Batch 166/1400 loss 0.031219 acc 0.980000 lr 0.00012454 grad_norm 0.372295 rank 0
2025-01-11 06:53:44,345 DEBUG TRAIN Batch 166/1500 loss 0.038525 acc 0.970536 lr 0.00012452 grad_norm 0.353379 rank 2
2025-01-11 06:53:44,345 DEBUG TRAIN Batch 166/1500 loss 0.026539 acc 0.984821 lr 0.00012452 grad_norm 0.353379 rank 0
2025-01-11 06:53:44,345 DEBUG TRAIN Batch 166/1500 loss 0.029741 acc 0.976456 lr 0.00012452 grad_norm 0.353379 rank 1
2025-01-11 06:54:08,512 DEBUG TRAIN Batch 166/1600 loss 0.032476 acc 0.979849 lr 0.00012450 grad_norm 0.385220 rank 1
2025-01-11 06:54:08,512 DEBUG TRAIN Batch 166/1600 loss 0.033789 acc 0.975108 lr 0.00012450 grad_norm 0.385220 rank 2
2025-01-11 06:54:08,512 DEBUG TRAIN Batch 166/1600 loss 0.021679 acc 0.985106 lr 0.00012450 grad_norm 0.385220 rank 0
2025-01-11 06:54:33,450 DEBUG TRAIN Batch 166/1700 loss 0.030808 acc 0.979705 lr 0.00012448 grad_norm 0.369017 rank 0
2025-01-11 06:54:33,450 DEBUG TRAIN Batch 166/1700 loss 0.018310 acc 0.984615 lr 0.00012448 grad_norm 0.369017 rank 2
2025-01-11 06:54:33,451 DEBUG TRAIN Batch 166/1700 loss 0.026008 acc 0.980300 lr 0.00012448 grad_norm 0.369017 rank 1
2025-01-11 06:54:58,726 DEBUG TRAIN Batch 166/1800 loss 0.031406 acc 0.980270 lr 0.00012446 grad_norm 0.382860 rank 2
2025-01-11 06:54:58,726 DEBUG TRAIN Batch 166/1800 loss 0.020455 acc 0.981876 lr 0.00012446 grad_norm 0.382860 rank 0
2025-01-11 06:54:58,727 DEBUG TRAIN Batch 166/1800 loss 0.026508 acc 0.983304 lr 0.00012446 grad_norm 0.382860 rank 1
2025-01-11 06:55:22,778 DEBUG TRAIN Batch 166/1900 loss 0.032297 acc 0.970588 lr 0.00012444 grad_norm 0.368862 rank 2
2025-01-11 06:55:22,778 DEBUG TRAIN Batch 166/1900 loss 0.028673 acc 0.984630 lr 0.00012444 grad_norm 0.368862 rank 1
2025-01-11 06:55:22,779 DEBUG TRAIN Batch 166/1900 loss 0.034191 acc 0.977495 lr 0.00012444 grad_norm 0.368862 rank 0
2025-01-11 06:55:47,400 DEBUG TRAIN Batch 166/2000 loss 0.034212 acc 0.979914 lr 0.00012442 grad_norm 0.398162 rank 2
2025-01-11 06:55:47,400 DEBUG TRAIN Batch 166/2000 loss 0.030101 acc 0.981966 lr 0.00012442 grad_norm 0.398162 rank 1
2025-01-11 06:55:47,400 DEBUG TRAIN Batch 166/2000 loss 0.040309 acc 0.972892 lr 0.00012442 grad_norm 0.398162 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 06:57:08,259 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59992ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 06:57:08,260 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 06:57:08,666 INFO Epoch 166 Step 161537 on_batch_end True CV rank 1
2025-01-11 06:57:08,666 INFO Epoch 166 Step 161537 on_batch_end True CV rank 0
2025-01-11 06:57:08,666 INFO Epoch 166 Step 161537 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 06:57:17,757 DEBUG CV Batch 166/100 loss 0.001206 acc 1.000000  rank 0
2025-01-11 06:57:18,204 DEBUG CV Batch 166/100 loss 0.001206 acc 1.000000  rank 2
2025-01-11 06:57:18,246 INFO Epoch 166 Step 161537 CV info lr 0.00012440390066285342 0 rank loss_2.7016493072539256 acc_0.7810959776765422
2025-01-11 06:57:18,378 DEBUG CV Batch 166/100 loss 0.001206 acc 1.000000  rank 1
2025-01-11 06:57:18,752 INFO Epoch 166 Step 161537 CV info lr 0.00012440390066285342 2 rank loss_2.7016493072539256 acc_0.7810959776765422
2025-01-11 06:57:18,936 INFO Epoch 166 Step 161537 CV info lr 0.00012440390066285342 1 rank loss_2.7016493072539256 acc_0.7810959776765422
2025-01-11 06:57:19,669 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_166_whole.pt
2025-01-11 06:57:19,681 INFO Added key: store_based_barrier_key:169 to store for rank: 0
2025-01-11 06:57:19,691 INFO Added key: store_based_barrier_key:169 to store for rank: 1
2025-01-11 06:57:19,691 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:169 with 3 nodes.
2025-01-11 06:57:19,691 INFO Added key: store_based_barrier_key:169 to store for rank: 2
2025-01-11 06:57:19,691 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:169 with 3 nodes.
2025-01-11 06:57:19,699 INFO Epoch 167 TRAIN info lr 0.00012440390066285342 rank 1
2025-01-11 06:57:19,699 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 06:57:19,701 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:169 with 3 nodes.
2025-01-11 06:57:19,701 INFO Epoch 167 TRAIN info lr 0.00012440390066285342 rank 2
2025-01-11 06:57:19,701 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 06:57:19,709 INFO Epoch 167 TRAIN info lr 0.00012440390066285342 rank 0
2025-01-11 06:57:19,709 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 06:57:50,709 DEBUG TRAIN Batch 167/100 loss 0.032327 acc 0.978702 lr 0.00012438 grad_norm 0.360176 rank 1
2025-01-11 06:57:50,709 DEBUG TRAIN Batch 167/100 loss 0.025061 acc 0.981112 lr 0.00012438 grad_norm 0.360176 rank 2
2025-01-11 06:57:50,709 DEBUG TRAIN Batch 167/100 loss 0.034179 acc 0.976866 lr 0.00012438 grad_norm 0.360176 rank 0
2025-01-11 06:58:14,691 DEBUG TRAIN Batch 167/200 loss 0.034686 acc 0.971429 lr 0.00012437 grad_norm 0.418426 rank 2
2025-01-11 06:58:14,690 DEBUG TRAIN Batch 167/200 loss 0.023951 acc 0.983668 lr 0.00012437 grad_norm 0.418426 rank 1
2025-01-11 06:58:14,690 DEBUG TRAIN Batch 167/200 loss 0.041202 acc 0.974472 lr 0.00012437 grad_norm 0.418426 rank 0
2025-01-11 06:58:38,443 DEBUG TRAIN Batch 167/300 loss 0.038298 acc 0.973373 lr 0.00012435 grad_norm 0.371888 rank 1
2025-01-11 06:58:38,443 DEBUG TRAIN Batch 167/300 loss 0.033329 acc 0.978178 lr 0.00012435 grad_norm 0.371888 rank 2
2025-01-11 06:58:38,445 DEBUG TRAIN Batch 167/300 loss 0.028748 acc 0.978918 lr 0.00012435 grad_norm 0.371888 rank 0
2025-01-11 06:59:01,896 DEBUG TRAIN Batch 167/400 loss 0.030952 acc 0.981462 lr 0.00012433 grad_norm 0.350029 rank 0
2025-01-11 06:59:01,896 DEBUG TRAIN Batch 167/400 loss 0.032724 acc 0.984725 lr 0.00012433 grad_norm 0.350029 rank 2
2025-01-11 06:59:01,897 DEBUG TRAIN Batch 167/400 loss 0.024092 acc 0.985122 lr 0.00012433 grad_norm 0.350029 rank 1
2025-01-11 06:59:25,955 DEBUG TRAIN Batch 167/500 loss 0.030159 acc 0.981413 lr 0.00012431 grad_norm 0.354438 rank 0
2025-01-11 06:59:25,955 DEBUG TRAIN Batch 167/500 loss 0.032912 acc 0.981098 lr 0.00012431 grad_norm 0.354438 rank 2
2025-01-11 06:59:25,956 DEBUG TRAIN Batch 167/500 loss 0.029373 acc 0.976378 lr 0.00012431 grad_norm 0.354438 rank 1
2025-01-11 06:59:49,744 DEBUG TRAIN Batch 167/600 loss 0.032987 acc 0.977860 lr 0.00012429 grad_norm 0.388043 rank 2
2025-01-11 06:59:49,744 DEBUG TRAIN Batch 167/600 loss 0.030138 acc 0.976122 lr 0.00012429 grad_norm 0.388043 rank 0
2025-01-11 06:59:49,747 DEBUG TRAIN Batch 167/600 loss 0.041358 acc 0.968930 lr 0.00012429 grad_norm 0.388043 rank 1
2025-01-11 07:00:14,764 DEBUG TRAIN Batch 167/700 loss 0.021216 acc 0.986780 lr 0.00012427 grad_norm 0.363040 rank 1
2025-01-11 07:00:14,765 DEBUG TRAIN Batch 167/700 loss 0.022174 acc 0.982075 lr 0.00012427 grad_norm 0.363040 rank 2
2025-01-11 07:00:14,765 DEBUG TRAIN Batch 167/700 loss 0.031705 acc 0.976895 lr 0.00012427 grad_norm 0.363040 rank 0
2025-01-11 07:00:38,457 DEBUG TRAIN Batch 167/800 loss 0.028144 acc 0.978723 lr 0.00012425 grad_norm 0.358467 rank 2
2025-01-11 07:00:38,457 DEBUG TRAIN Batch 167/800 loss 0.024104 acc 0.981799 lr 0.00012425 grad_norm 0.358467 rank 0
2025-01-11 07:00:38,457 DEBUG TRAIN Batch 167/800 loss 0.030232 acc 0.976796 lr 0.00012425 grad_norm 0.358467 rank 1
2025-01-11 07:01:02,533 DEBUG TRAIN Batch 167/900 loss 0.024677 acc 0.982927 lr 0.00012423 grad_norm 0.400156 rank 2
2025-01-11 07:01:02,533 DEBUG TRAIN Batch 167/900 loss 0.036890 acc 0.968335 lr 0.00012423 grad_norm 0.400156 rank 1
2025-01-11 07:01:02,533 DEBUG TRAIN Batch 167/900 loss 0.025688 acc 0.981366 lr 0.00012423 grad_norm 0.400156 rank 0
2025-01-11 07:01:27,120 DEBUG TRAIN Batch 167/1000 loss 0.025819 acc 0.982063 lr 0.00012421 grad_norm 0.370309 rank 2
2025-01-11 07:01:27,120 DEBUG TRAIN Batch 167/1000 loss 0.016048 acc 0.991139 lr 0.00012421 grad_norm 0.370309 rank 1
2025-01-11 07:01:27,120 DEBUG TRAIN Batch 167/1000 loss 0.039486 acc 0.969863 lr 0.00012421 grad_norm 0.370309 rank 0
2025-01-11 07:01:50,372 DEBUG TRAIN Batch 167/1100 loss 0.040990 acc 0.973709 lr 0.00012419 grad_norm 0.378187 rank 0
2025-01-11 07:01:50,372 DEBUG TRAIN Batch 167/1100 loss 0.036701 acc 0.977230 lr 0.00012419 grad_norm 0.378187 rank 1
2025-01-11 07:01:50,373 DEBUG TRAIN Batch 167/1100 loss 0.023454 acc 0.984762 lr 0.00012419 grad_norm 0.378187 rank 2
2025-01-11 07:02:14,021 DEBUG TRAIN Batch 167/1200 loss 0.036673 acc 0.971631 lr 0.00012417 grad_norm 0.395704 rank 1
2025-01-11 07:02:14,022 DEBUG TRAIN Batch 167/1200 loss 0.039144 acc 0.974592 lr 0.00012417 grad_norm 0.395704 rank 2
2025-01-11 07:02:14,022 DEBUG TRAIN Batch 167/1200 loss 0.035994 acc 0.971179 lr 0.00012417 grad_norm 0.395704 rank 0
2025-01-11 07:02:37,611 DEBUG TRAIN Batch 167/1300 loss 0.028358 acc 0.978947 lr 0.00012415 grad_norm 0.346981 rank 0
2025-01-11 07:02:37,611 DEBUG TRAIN Batch 167/1300 loss 0.034224 acc 0.975610 lr 0.00012415 grad_norm 0.346981 rank 2
2025-01-11 07:02:37,611 DEBUG TRAIN Batch 167/1300 loss 0.021618 acc 0.984174 lr 0.00012415 grad_norm 0.346981 rank 1
2025-01-11 07:03:02,251 DEBUG TRAIN Batch 167/1400 loss 0.029999 acc 0.977716 lr 0.00012414 grad_norm 0.359750 rank 1
2025-01-11 07:03:02,251 DEBUG TRAIN Batch 167/1400 loss 0.027409 acc 0.981499 lr 0.00012414 grad_norm 0.359750 rank 0
2025-01-11 07:03:02,252 DEBUG TRAIN Batch 167/1400 loss 0.016610 acc 0.989691 lr 0.00012414 grad_norm 0.359750 rank 2
2025-01-11 07:03:26,384 DEBUG TRAIN Batch 167/1500 loss 0.027018 acc 0.980447 lr 0.00012412 grad_norm 0.367422 rank 0
2025-01-11 07:03:26,384 DEBUG TRAIN Batch 167/1500 loss 0.033854 acc 0.977000 lr 0.00012412 grad_norm 0.367422 rank 2
2025-01-11 07:03:26,385 DEBUG TRAIN Batch 167/1500 loss 0.025105 acc 0.986425 lr 0.00012412 grad_norm 0.367422 rank 1
2025-01-11 07:03:51,383 DEBUG TRAIN Batch 167/1600 loss 0.027452 acc 0.974672 lr 0.00012410 grad_norm 0.367340 rank 1
2025-01-11 07:03:51,383 DEBUG TRAIN Batch 167/1600 loss 0.028714 acc 0.979290 lr 0.00012410 grad_norm 0.367340 rank 0
2025-01-11 07:03:51,384 DEBUG TRAIN Batch 167/1600 loss 0.035820 acc 0.976898 lr 0.00012410 grad_norm 0.367340 rank 2
2025-01-11 07:04:14,998 DEBUG TRAIN Batch 167/1700 loss 0.032483 acc 0.979143 lr 0.00012408 grad_norm 0.386560 rank 2
2025-01-11 07:04:14,999 DEBUG TRAIN Batch 167/1700 loss 0.027602 acc 0.982949 lr 0.00012408 grad_norm 0.386560 rank 1
2025-01-11 07:04:14,999 DEBUG TRAIN Batch 167/1700 loss 0.023087 acc 0.985604 lr 0.00012408 grad_norm 0.386560 rank 0
2025-01-11 07:04:40,008 DEBUG TRAIN Batch 167/1800 loss 0.029637 acc 0.984995 lr 0.00012406 grad_norm 0.374811 rank 0
2025-01-11 07:04:40,008 DEBUG TRAIN Batch 167/1800 loss 0.033005 acc 0.975093 lr 0.00012406 grad_norm 0.374811 rank 2
2025-01-11 07:04:40,008 DEBUG TRAIN Batch 167/1800 loss 0.026957 acc 0.981481 lr 0.00012406 grad_norm 0.374811 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 07:05:44,205 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 07:05:44,206 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 07:05:44,678 INFO Epoch 167 Step 162445 on_batch_end True CV rank 1
2025-01-11 07:05:44,678 INFO Epoch 167 Step 162445 on_batch_end True CV rank 0
2025-01-11 07:05:44,679 INFO Epoch 167 Step 162445 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 07:05:53,806 DEBUG CV Batch 167/100 loss 0.005561 acc 0.997770  rank 0
2025-01-11 07:05:54,334 INFO Epoch 167 Step 162445 CV info lr 0.0001240557304126137 0 rank loss_2.7094761062909494 acc_0.7801678086581983
2025-01-11 07:05:54,425 DEBUG CV Batch 167/100 loss 0.005561 acc 0.997770  rank 2
2025-01-11 07:05:54,601 DEBUG CV Batch 167/100 loss 0.005561 acc 0.997770  rank 1
2025-01-11 07:05:54,971 INFO Epoch 167 Step 162445 CV info lr 0.0001240557304126137 2 rank loss_2.7094761062909494 acc_0.7801678086581983
2025-01-11 07:05:55,163 INFO Epoch 167 Step 162445 CV info lr 0.0001240557304126137 1 rank loss_2.7094761062909494 acc_0.7801678086581983
2025-01-11 07:05:55,628 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_167_whole.pt
2025-01-11 07:05:55,640 INFO Added key: store_based_barrier_key:170 to store for rank: 0
2025-01-11 07:05:55,650 INFO Added key: store_based_barrier_key:170 to store for rank: 1
2025-01-11 07:05:55,650 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:170 with 3 nodes.
2025-01-11 07:05:55,650 INFO Added key: store_based_barrier_key:170 to store for rank: 2
2025-01-11 07:05:55,650 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:170 with 3 nodes.
2025-01-11 07:05:55,655 INFO Epoch 168 TRAIN info lr 0.0001240557304126137 rank 1
2025-01-11 07:05:55,655 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 07:05:55,659 INFO Epoch 168 TRAIN info lr 0.0001240557304126137 rank 2
2025-01-11 07:05:55,659 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 07:05:55,660 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:170 with 3 nodes.
2025-01-11 07:05:55,662 INFO Epoch 168 TRAIN info lr 0.0001240557304126137 rank 0
2025-01-11 07:05:55,662 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 07:06:33,649 DEBUG TRAIN Batch 168/100 loss 0.026422 acc 0.984293 lr 0.00012404 grad_norm 0.379214 rank 0
2025-01-11 07:06:33,650 DEBUG TRAIN Batch 168/100 loss 0.029665 acc 0.975521 lr 0.00012404 grad_norm 0.379214 rank 2
2025-01-11 07:06:33,651 DEBUG TRAIN Batch 168/100 loss 0.032524 acc 0.974050 lr 0.00012404 grad_norm 0.379214 rank 1
2025-01-11 07:06:57,872 DEBUG TRAIN Batch 168/200 loss 0.037841 acc 0.975432 lr 0.00012402 grad_norm 0.359787 rank 0
2025-01-11 07:06:57,872 DEBUG TRAIN Batch 168/200 loss 0.028272 acc 0.980535 lr 0.00012402 grad_norm 0.359787 rank 2
2025-01-11 07:06:57,872 DEBUG TRAIN Batch 168/200 loss 0.029485 acc 0.983130 lr 0.00012402 grad_norm 0.359787 rank 1
2025-01-11 07:07:22,531 DEBUG TRAIN Batch 168/300 loss 0.031116 acc 0.975238 lr 0.00012400 grad_norm 0.376654 rank 0
2025-01-11 07:07:22,531 DEBUG TRAIN Batch 168/300 loss 0.028872 acc 0.980681 lr 0.00012400 grad_norm 0.376654 rank 2
2025-01-11 07:07:22,532 DEBUG TRAIN Batch 168/300 loss 0.032775 acc 0.979679 lr 0.00012400 grad_norm 0.376654 rank 1
2025-01-11 07:07:46,493 DEBUG TRAIN Batch 168/400 loss 0.026159 acc 0.981713 lr 0.00012398 grad_norm 0.357941 rank 1
2025-01-11 07:07:46,493 DEBUG TRAIN Batch 168/400 loss 0.031219 acc 0.975976 lr 0.00012398 grad_norm 0.357941 rank 0
2025-01-11 07:07:46,493 DEBUG TRAIN Batch 168/400 loss 0.016495 acc 0.988722 lr 0.00012398 grad_norm 0.357941 rank 2
2025-01-11 07:08:11,649 DEBUG TRAIN Batch 168/500 loss 0.026954 acc 0.978218 lr 0.00012396 grad_norm 0.372999 rank 0
2025-01-11 07:08:11,650 DEBUG TRAIN Batch 168/500 loss 0.031464 acc 0.980108 lr 0.00012396 grad_norm 0.372999 rank 2
2025-01-11 07:08:11,650 DEBUG TRAIN Batch 168/500 loss 0.026592 acc 0.982072 lr 0.00012396 grad_norm 0.372999 rank 1
2025-01-11 07:08:36,587 DEBUG TRAIN Batch 168/600 loss 0.034815 acc 0.978700 lr 0.00012394 grad_norm 0.362335 rank 0
2025-01-11 07:08:36,587 DEBUG TRAIN Batch 168/600 loss 0.027140 acc 0.983319 lr 0.00012394 grad_norm 0.362335 rank 2
2025-01-11 07:08:36,588 DEBUG TRAIN Batch 168/600 loss 0.024644 acc 0.985605 lr 0.00012394 grad_norm 0.362335 rank 1
2025-01-11 07:09:01,106 DEBUG TRAIN Batch 168/700 loss 0.024208 acc 0.986948 lr 0.00012392 grad_norm 0.357604 rank 2
2025-01-11 07:09:01,107 DEBUG TRAIN Batch 168/700 loss 0.025111 acc 0.982484 lr 0.00012392 grad_norm 0.357604 rank 1
2025-01-11 07:09:01,107 DEBUG TRAIN Batch 168/700 loss 0.021616 acc 0.984361 lr 0.00012392 grad_norm 0.357604 rank 0
2025-01-11 07:09:26,401 DEBUG TRAIN Batch 168/800 loss 0.035457 acc 0.981660 lr 0.00012390 grad_norm 0.343672 rank 0
2025-01-11 07:09:26,401 DEBUG TRAIN Batch 168/800 loss 0.026781 acc 0.981651 lr 0.00012390 grad_norm 0.343672 rank 1
2025-01-11 07:09:26,402 DEBUG TRAIN Batch 168/800 loss 0.017788 acc 0.987421 lr 0.00012390 grad_norm 0.343672 rank 2
2025-01-11 07:09:50,397 DEBUG TRAIN Batch 168/900 loss 0.025806 acc 0.983763 lr 0.00012388 grad_norm 0.387030 rank 2
2025-01-11 07:09:50,397 DEBUG TRAIN Batch 168/900 loss 0.025548 acc 0.982906 lr 0.00012388 grad_norm 0.387030 rank 1
2025-01-11 07:09:50,397 DEBUG TRAIN Batch 168/900 loss 0.040375 acc 0.978454 lr 0.00012388 grad_norm 0.387030 rank 0
2025-01-11 07:10:15,051 DEBUG TRAIN Batch 168/1000 loss 0.029161 acc 0.980820 lr 0.00012387 grad_norm 0.361403 rank 0
2025-01-11 07:10:15,051 DEBUG TRAIN Batch 168/1000 loss 0.038337 acc 0.968668 lr 0.00012387 grad_norm 0.361403 rank 2
2025-01-11 07:10:15,051 DEBUG TRAIN Batch 168/1000 loss 0.031310 acc 0.981966 lr 0.00012387 grad_norm 0.361403 rank 1
2025-01-11 07:10:41,096 DEBUG TRAIN Batch 168/1100 loss 0.027438 acc 0.981763 lr 0.00012385 grad_norm 0.378650 rank 0
2025-01-11 07:10:41,096 DEBUG TRAIN Batch 168/1100 loss 0.033202 acc 0.977798 lr 0.00012385 grad_norm 0.378650 rank 2
2025-01-11 07:10:41,097 DEBUG TRAIN Batch 168/1100 loss 0.030797 acc 0.977330 lr 0.00012385 grad_norm 0.378650 rank 1
2025-01-11 07:11:05,006 DEBUG TRAIN Batch 168/1200 loss 0.033658 acc 0.978938 lr 0.00012383 grad_norm 0.372683 rank 0
2025-01-11 07:11:05,006 DEBUG TRAIN Batch 168/1200 loss 0.023218 acc 0.983871 lr 0.00012383 grad_norm 0.372683 rank 2
2025-01-11 07:11:05,006 DEBUG TRAIN Batch 168/1200 loss 0.040800 acc 0.973207 lr 0.00012383 grad_norm 0.372683 rank 1
2025-01-11 07:11:29,057 DEBUG TRAIN Batch 168/1300 loss 0.037948 acc 0.972052 lr 0.00012381 grad_norm 0.357443 rank 2
2025-01-11 07:11:29,057 DEBUG TRAIN Batch 168/1300 loss 0.031666 acc 0.979933 lr 0.00012381 grad_norm 0.357443 rank 0
2025-01-11 07:11:29,057 DEBUG TRAIN Batch 168/1300 loss 0.021120 acc 0.983010 lr 0.00012381 grad_norm 0.357443 rank 1
2025-01-11 07:11:53,400 DEBUG TRAIN Batch 168/1400 loss 0.031888 acc 0.980038 lr 0.00012379 grad_norm 0.398355 rank 0
2025-01-11 07:11:53,401 DEBUG TRAIN Batch 168/1400 loss 0.029606 acc 0.978836 lr 0.00012379 grad_norm 0.398355 rank 2
2025-01-11 07:11:53,401 DEBUG TRAIN Batch 168/1400 loss 0.026672 acc 0.978297 lr 0.00012379 grad_norm 0.398355 rank 1
2025-01-11 07:12:17,808 DEBUG TRAIN Batch 168/1500 loss 0.031907 acc 0.978185 lr 0.00012377 grad_norm 0.347199 rank 0
2025-01-11 07:12:17,808 DEBUG TRAIN Batch 168/1500 loss 0.033313 acc 0.975161 lr 0.00012377 grad_norm 0.347199 rank 2
2025-01-11 07:12:17,808 DEBUG TRAIN Batch 168/1500 loss 0.016514 acc 0.986891 lr 0.00012377 grad_norm 0.347199 rank 1
2025-01-11 07:12:41,650 DEBUG TRAIN Batch 168/1600 loss 0.033765 acc 0.977941 lr 0.00012375 grad_norm 0.389463 rank 0
2025-01-11 07:12:41,651 DEBUG TRAIN Batch 168/1600 loss 0.032125 acc 0.981151 lr 0.00012375 grad_norm 0.389463 rank 2
2025-01-11 07:12:41,651 DEBUG TRAIN Batch 168/1600 loss 0.024903 acc 0.979633 lr 0.00012375 grad_norm 0.389463 rank 1
2025-01-11 07:13:05,368 DEBUG TRAIN Batch 168/1700 loss 0.030930 acc 0.978022 lr 0.00012373 grad_norm 0.370452 rank 0
2025-01-11 07:13:05,368 DEBUG TRAIN Batch 168/1700 loss 0.030756 acc 0.976908 lr 0.00012373 grad_norm 0.370452 rank 2
2025-01-11 07:13:05,368 DEBUG TRAIN Batch 168/1700 loss 0.026660 acc 0.978546 lr 0.00012373 grad_norm 0.370452 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 07:14:20,899 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59994ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 07:14:20,904 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 07:14:21,402 INFO Epoch 168 Step 163327 on_batch_end True CV rank 0
2025-01-11 07:14:21,402 INFO Epoch 168 Step 163327 on_batch_end True CV rank 1
2025-01-11 07:14:21,402 INFO Epoch 168 Step 163327 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 07:14:30,655 DEBUG CV Batch 168/100 loss 0.002648 acc 1.000000  rank 0
2025-01-11 07:14:30,833 DEBUG CV Batch 168/100 loss 0.002648 acc 1.000000  rank 2
2025-01-11 07:14:31,105 DEBUG CV Batch 168/100 loss 0.002648 acc 1.000000  rank 1
2025-01-11 07:14:31,188 INFO Epoch 168 Step 163327 CV info lr 0.0001237203135087406 0 rank loss_2.6864601105004557 acc_0.7801618064966118
2025-01-11 07:14:31,369 INFO Epoch 168 Step 163327 CV info lr 0.0001237203135087406 2 rank loss_2.6864601105004557 acc_0.7801618064966118
2025-01-11 07:14:31,665 INFO Epoch 168 Step 163327 CV info lr 0.0001237203135087406 1 rank loss_2.6864601105004557 acc_0.7801618064966118
2025-01-11 07:14:32,496 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_168_whole.pt
2025-01-11 07:14:32,508 INFO Added key: store_based_barrier_key:171 to store for rank: 0
2025-01-11 07:14:32,518 INFO Added key: store_based_barrier_key:171 to store for rank: 1
2025-01-11 07:14:32,518 INFO Added key: store_based_barrier_key:171 to store for rank: 2
2025-01-11 07:14:32,518 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:171 with 3 nodes.
2025-01-11 07:14:32,518 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:171 with 3 nodes.
2025-01-11 07:14:32,521 INFO Epoch 169 TRAIN info lr 0.0001237203135087406 rank 2
2025-01-11 07:14:32,521 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 07:14:32,527 INFO Epoch 169 TRAIN info lr 0.0001237203135087406 rank 1
2025-01-11 07:14:32,527 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 07:14:32,528 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:171 with 3 nodes.
2025-01-11 07:14:32,536 INFO Epoch 169 TRAIN info lr 0.0001237203135087406 rank 0
2025-01-11 07:14:32,536 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 07:15:08,966 DEBUG TRAIN Batch 169/100 loss 0.022753 acc 0.984787 lr 0.00012370 grad_norm 0.351583 rank 0
2025-01-11 07:15:08,966 DEBUG TRAIN Batch 169/100 loss 0.036894 acc 0.976513 lr 0.00012370 grad_norm 0.351583 rank 2
2025-01-11 07:15:08,967 DEBUG TRAIN Batch 169/100 loss 0.032564 acc 0.972393 lr 0.00012370 grad_norm 0.351583 rank 1
2025-01-11 07:15:33,176 DEBUG TRAIN Batch 169/200 loss 0.022281 acc 0.983911 lr 0.00012368 grad_norm 0.361327 rank 2
2025-01-11 07:15:33,176 DEBUG TRAIN Batch 169/200 loss 0.017937 acc 0.989899 lr 0.00012368 grad_norm 0.361327 rank 1
2025-01-11 07:15:33,176 DEBUG TRAIN Batch 169/200 loss 0.033256 acc 0.972495 lr 0.00012368 grad_norm 0.361327 rank 0
2025-01-11 07:15:57,639 DEBUG TRAIN Batch 169/300 loss 0.033271 acc 0.974265 lr 0.00012366 grad_norm 0.399199 rank 2
2025-01-11 07:15:57,639 DEBUG TRAIN Batch 169/300 loss 0.021988 acc 0.981113 lr 0.00012366 grad_norm 0.399199 rank 1
2025-01-11 07:15:57,639 DEBUG TRAIN Batch 169/300 loss 0.031741 acc 0.980526 lr 0.00012366 grad_norm 0.399199 rank 0
2025-01-11 07:16:21,293 DEBUG TRAIN Batch 169/400 loss 0.025997 acc 0.980144 lr 0.00012364 grad_norm 0.378950 rank 0
2025-01-11 07:16:21,293 DEBUG TRAIN Batch 169/400 loss 0.022002 acc 0.984887 lr 0.00012364 grad_norm 0.378950 rank 2
2025-01-11 07:16:21,293 DEBUG TRAIN Batch 169/400 loss 0.035031 acc 0.973002 lr 0.00012364 grad_norm 0.378950 rank 1
2025-01-11 07:16:46,227 DEBUG TRAIN Batch 169/500 loss 0.022458 acc 0.983264 lr 0.00012363 grad_norm 0.361184 rank 2
2025-01-11 07:16:46,227 DEBUG TRAIN Batch 169/500 loss 0.037905 acc 0.976950 lr 0.00012363 grad_norm 0.361184 rank 1
2025-01-11 07:16:46,228 DEBUG TRAIN Batch 169/500 loss 0.030744 acc 0.975893 lr 0.00012363 grad_norm 0.361184 rank 0
2025-01-11 07:17:10,798 DEBUG TRAIN Batch 169/600 loss 0.024950 acc 0.981663 lr 0.00012361 grad_norm 0.339583 rank 2
2025-01-11 07:17:10,798 DEBUG TRAIN Batch 169/600 loss 0.028735 acc 0.981018 lr 0.00012361 grad_norm 0.339583 rank 1
2025-01-11 07:17:10,799 DEBUG TRAIN Batch 169/600 loss 0.043281 acc 0.969130 lr 0.00012361 grad_norm 0.339583 rank 0
2025-01-11 07:17:34,986 DEBUG TRAIN Batch 169/700 loss 0.036399 acc 0.972789 lr 0.00012359 grad_norm 0.379004 rank 0
2025-01-11 07:17:34,986 DEBUG TRAIN Batch 169/700 loss 0.034472 acc 0.971645 lr 0.00012359 grad_norm 0.379004 rank 2
2025-01-11 07:17:34,987 DEBUG TRAIN Batch 169/700 loss 0.039221 acc 0.970149 lr 0.00012359 grad_norm 0.379004 rank 1
2025-01-11 07:18:00,141 DEBUG TRAIN Batch 169/800 loss 0.028815 acc 0.982375 lr 0.00012357 grad_norm 0.331243 rank 0
2025-01-11 07:18:00,142 DEBUG TRAIN Batch 169/800 loss 0.015576 acc 0.989736 lr 0.00012357 grad_norm 0.331243 rank 2
2025-01-11 07:18:00,142 DEBUG TRAIN Batch 169/800 loss 0.031008 acc 0.976985 lr 0.00012357 grad_norm 0.331243 rank 1
2025-01-11 07:18:24,204 DEBUG TRAIN Batch 169/900 loss 0.028230 acc 0.977492 lr 0.00012355 grad_norm 0.369554 rank 2
2025-01-11 07:18:24,205 DEBUG TRAIN Batch 169/900 loss 0.035392 acc 0.978199 lr 0.00012355 grad_norm 0.369554 rank 0
2025-01-11 07:18:24,205 DEBUG TRAIN Batch 169/900 loss 0.031444 acc 0.978591 lr 0.00012355 grad_norm 0.369554 rank 1
2025-01-11 07:18:48,353 DEBUG TRAIN Batch 169/1000 loss 0.031159 acc 0.974900 lr 0.00012353 grad_norm 0.339771 rank 0
2025-01-11 07:18:48,354 DEBUG TRAIN Batch 169/1000 loss 0.016018 acc 0.992718 lr 0.00012353 grad_norm 0.339771 rank 2
2025-01-11 07:18:48,354 DEBUG TRAIN Batch 169/1000 loss 0.028464 acc 0.984095 lr 0.00012353 grad_norm 0.339771 rank 1
2025-01-11 07:19:14,224 DEBUG TRAIN Batch 169/1100 loss 0.028162 acc 0.983740 lr 0.00012351 grad_norm 0.377595 rank 2
2025-01-11 07:19:14,224 DEBUG TRAIN Batch 169/1100 loss 0.033254 acc 0.975057 lr 0.00012351 grad_norm 0.377595 rank 1
2025-01-11 07:19:14,225 DEBUG TRAIN Batch 169/1100 loss 0.025266 acc 0.980700 lr 0.00012351 grad_norm 0.377595 rank 0
2025-01-11 07:19:38,236 DEBUG TRAIN Batch 169/1200 loss 0.010933 acc 0.990812 lr 0.00012349 grad_norm 0.340023 rank 2
2025-01-11 07:19:38,236 DEBUG TRAIN Batch 169/1200 loss 0.027593 acc 0.981939 lr 0.00012349 grad_norm 0.340023 rank 0
2025-01-11 07:19:38,236 DEBUG TRAIN Batch 169/1200 loss 0.022862 acc 0.986643 lr 0.00012349 grad_norm 0.340023 rank 1
2025-01-11 07:20:02,123 DEBUG TRAIN Batch 169/1300 loss 0.027982 acc 0.980300 lr 0.00012347 grad_norm 0.365728 rank 2
2025-01-11 07:20:02,123 DEBUG TRAIN Batch 169/1300 loss 0.017730 acc 0.986163 lr 0.00012347 grad_norm 0.365728 rank 0
2025-01-11 07:20:02,124 DEBUG TRAIN Batch 169/1300 loss 0.030267 acc 0.976923 lr 0.00012347 grad_norm 0.365728 rank 1
2025-01-11 07:20:26,548 DEBUG TRAIN Batch 169/1400 loss 0.021401 acc 0.984342 lr 0.00012346 grad_norm 0.396216 rank 2
2025-01-11 07:20:26,549 DEBUG TRAIN Batch 169/1400 loss 0.035191 acc 0.973469 lr 0.00012346 grad_norm 0.396216 rank 1
2025-01-11 07:20:26,548 DEBUG TRAIN Batch 169/1400 loss 0.024228 acc 0.983137 lr 0.00012346 grad_norm 0.396216 rank 0
2025-01-11 07:20:50,720 DEBUG TRAIN Batch 169/1500 loss 0.039614 acc 0.971404 lr 0.00012344 grad_norm 0.345318 rank 1
2025-01-11 07:20:50,721 DEBUG TRAIN Batch 169/1500 loss 0.019025 acc 0.985522 lr 0.00012344 grad_norm 0.345318 rank 0
2025-01-11 07:20:50,722 DEBUG TRAIN Batch 169/1500 loss 0.027752 acc 0.976619 lr 0.00012344 grad_norm 0.345318 rank 2
2025-01-11 07:21:14,889 DEBUG TRAIN Batch 169/1600 loss 0.030856 acc 0.979167 lr 0.00012342 grad_norm 0.394132 rank 0
2025-01-11 07:21:14,889 DEBUG TRAIN Batch 169/1600 loss 0.039641 acc 0.973708 lr 0.00012342 grad_norm 0.394132 rank 1
2025-01-11 07:21:14,890 DEBUG TRAIN Batch 169/1600 loss 0.030433 acc 0.978051 lr 0.00012342 grad_norm 0.394132 rank 2
2025-01-11 07:21:38,521 DEBUG TRAIN Batch 169/1700 loss 0.024443 acc 0.981150 lr 0.00012340 grad_norm 0.363176 rank 1
2025-01-11 07:21:38,522 DEBUG TRAIN Batch 169/1700 loss 0.021060 acc 0.989311 lr 0.00012340 grad_norm 0.363176 rank 0
2025-01-11 07:21:38,522 DEBUG TRAIN Batch 169/1700 loss 0.028258 acc 0.978299 lr 0.00012340 grad_norm 0.363176 rank 2
2025-01-11 07:22:02,955 DEBUG TRAIN Batch 169/1800 loss 0.024064 acc 0.984909 lr 0.00012338 grad_norm 0.365919 rank 1
2025-01-11 07:22:02,956 DEBUG TRAIN Batch 169/1800 loss 0.015724 acc 0.990461 lr 0.00012338 grad_norm 0.365919 rank 0
2025-01-11 07:22:02,956 DEBUG TRAIN Batch 169/1800 loss 0.034777 acc 0.975708 lr 0.00012338 grad_norm 0.365919 rank 2
2025-01-11 07:22:27,369 DEBUG TRAIN Batch 169/1900 loss 0.022506 acc 0.984375 lr 0.00012336 grad_norm 0.349298 rank 1
2025-01-11 07:22:27,370 DEBUG TRAIN Batch 169/1900 loss 0.048690 acc 0.965673 lr 0.00012336 grad_norm 0.349298 rank 0
2025-01-11 07:22:27,370 DEBUG TRAIN Batch 169/1900 loss 0.012954 acc 0.994915 lr 0.00012336 grad_norm 0.349298 rank 2
2025-01-11 07:22:51,460 DEBUG TRAIN Batch 169/2000 loss 0.020107 acc 0.986317 lr 0.00012334 grad_norm 0.370777 rank 0
2025-01-11 07:22:51,460 DEBUG TRAIN Batch 169/2000 loss 0.032309 acc 0.973409 lr 0.00012334 grad_norm 0.370777 rank 2
2025-01-11 07:22:51,460 DEBUG TRAIN Batch 169/2000 loss 0.027493 acc 0.979644 lr 0.00012334 grad_norm 0.370777 rank 1
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 07:23:57,279 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 07:23:57,281 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 07:23:57,659 INFO Epoch 169 Step 164339 on_batch_end True CV rank 2
2025-01-11 07:23:57,659 INFO Epoch 169 Step 164339 on_batch_end True CV rank 1
2025-01-11 07:23:57,659 INFO Epoch 169 Step 164339 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 07:24:06,871 DEBUG CV Batch 169/100 loss 0.000967 acc 1.000000  rank 0
2025-01-11 07:24:06,887 DEBUG CV Batch 169/100 loss 0.000967 acc 1.000000  rank 2
2025-01-11 07:24:07,347 DEBUG CV Batch 169/100 loss 0.000967 acc 1.000000  rank 1
2025-01-11 07:24:07,398 INFO Epoch 169 Step 164339 CV info lr 0.00012333879023621502 0 rank loss_2.7067761863030397 acc_0.7801202726468706
2025-01-11 07:24:07,428 INFO Epoch 169 Step 164339 CV info lr 0.00012333879023621502 2 rank loss_2.7067761863030397 acc_0.7801202726468706
2025-01-11 07:24:07,913 INFO Epoch 169 Step 164339 CV info lr 0.00012333879023621502 1 rank loss_2.7067761863030397 acc_0.7801202726468706
2025-01-11 07:24:08,675 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_169_whole.pt
2025-01-11 07:24:08,686 INFO Added key: store_based_barrier_key:172 to store for rank: 0
2025-01-11 07:24:08,697 INFO Added key: store_based_barrier_key:172 to store for rank: 2
2025-01-11 07:24:08,697 INFO Added key: store_based_barrier_key:172 to store for rank: 1
2025-01-11 07:24:08,697 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:172 with 3 nodes.
2025-01-11 07:24:08,697 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:172 with 3 nodes.
2025-01-11 07:24:08,702 INFO Epoch 170 TRAIN info lr 0.00012333879023621502 rank 2
2025-01-11 07:24:08,703 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 07:24:08,704 INFO Epoch 170 TRAIN info lr 0.00012333879023621502 rank 1
2025-01-11 07:24:08,704 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 07:24:08,707 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:172 with 3 nodes.
2025-01-11 07:24:08,715 INFO Epoch 170 TRAIN info lr 0.00012333879023621502 rank 0
2025-01-11 07:24:08,716 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 07:24:38,879 DEBUG TRAIN Batch 170/100 loss 0.041971 acc 0.969432 lr 0.00012332 grad_norm 0.371681 rank 2
2025-01-11 07:24:38,879 DEBUG TRAIN Batch 170/100 loss 0.026916 acc 0.974568 lr 0.00012332 grad_norm 0.371681 rank 0
2025-01-11 07:24:38,879 DEBUG TRAIN Batch 170/100 loss 0.024917 acc 0.981651 lr 0.00012332 grad_norm 0.371681 rank 1
2025-01-11 07:25:02,580 DEBUG TRAIN Batch 170/200 loss 0.034539 acc 0.979372 lr 0.00012330 grad_norm 0.369960 rank 0
2025-01-11 07:25:02,580 DEBUG TRAIN Batch 170/200 loss 0.029027 acc 0.981174 lr 0.00012330 grad_norm 0.369960 rank 2
2025-01-11 07:25:02,580 DEBUG TRAIN Batch 170/200 loss 0.037848 acc 0.972468 lr 0.00012330 grad_norm 0.369960 rank 1
2025-01-11 07:25:25,709 DEBUG TRAIN Batch 170/300 loss 0.018177 acc 0.984571 lr 0.00012328 grad_norm 0.341859 rank 0
2025-01-11 07:25:25,709 DEBUG TRAIN Batch 170/300 loss 0.036240 acc 0.974359 lr 0.00012328 grad_norm 0.341859 rank 1
2025-01-11 07:25:25,709 DEBUG TRAIN Batch 170/300 loss 0.029361 acc 0.980392 lr 0.00012328 grad_norm 0.341859 rank 2
2025-01-11 07:25:49,590 DEBUG TRAIN Batch 170/400 loss 0.030963 acc 0.979149 lr 0.00012326 grad_norm 0.350557 rank 0
2025-01-11 07:25:49,591 DEBUG TRAIN Batch 170/400 loss 0.033056 acc 0.979592 lr 0.00012326 grad_norm 0.350557 rank 2
2025-01-11 07:25:49,591 DEBUG TRAIN Batch 170/400 loss 0.034277 acc 0.981818 lr 0.00012326 grad_norm 0.350557 rank 1
2025-01-11 07:26:13,503 DEBUG TRAIN Batch 170/500 loss 0.022262 acc 0.981517 lr 0.00012325 grad_norm 0.349247 rank 0
2025-01-11 07:26:13,504 DEBUG TRAIN Batch 170/500 loss 0.030705 acc 0.980978 lr 0.00012325 grad_norm 0.349247 rank 1
2025-01-11 07:26:13,504 DEBUG TRAIN Batch 170/500 loss 0.033402 acc 0.976407 lr 0.00012325 grad_norm 0.349247 rank 2
2025-01-11 07:26:37,289 DEBUG TRAIN Batch 170/600 loss 0.036411 acc 0.976285 lr 0.00012323 grad_norm 0.356655 rank 2
2025-01-11 07:26:37,289 DEBUG TRAIN Batch 170/600 loss 0.034312 acc 0.978866 lr 0.00012323 grad_norm 0.356655 rank 1
2025-01-11 07:26:37,289 DEBUG TRAIN Batch 170/600 loss 0.029240 acc 0.975752 lr 0.00012323 grad_norm 0.356655 rank 0
2025-01-11 07:27:00,998 DEBUG TRAIN Batch 170/700 loss 0.027587 acc 0.980627 lr 0.00012321 grad_norm 0.348739 rank 0
2025-01-11 07:27:00,999 DEBUG TRAIN Batch 170/700 loss 0.027624 acc 0.980431 lr 0.00012321 grad_norm 0.348739 rank 1
2025-01-11 07:27:00,999 DEBUG TRAIN Batch 170/700 loss 0.026745 acc 0.983590 lr 0.00012321 grad_norm 0.348739 rank 2
2025-01-11 07:27:24,452 DEBUG TRAIN Batch 170/800 loss 0.020764 acc 0.988453 lr 0.00012319 grad_norm 0.354068 rank 0
2025-01-11 07:27:24,452 DEBUG TRAIN Batch 170/800 loss 0.035949 acc 0.977901 lr 0.00012319 grad_norm 0.354068 rank 2
2025-01-11 07:27:24,452 DEBUG TRAIN Batch 170/800 loss 0.035185 acc 0.978339 lr 0.00012319 grad_norm 0.354068 rank 1
2025-01-11 07:27:48,601 DEBUG TRAIN Batch 170/900 loss 0.033358 acc 0.976321 lr 0.00012317 grad_norm 0.364720 rank 2
2025-01-11 07:27:48,601 DEBUG TRAIN Batch 170/900 loss 0.028133 acc 0.977228 lr 0.00012317 grad_norm 0.364720 rank 1
2025-01-11 07:27:48,601 DEBUG TRAIN Batch 170/900 loss 0.025947 acc 0.981098 lr 0.00012317 grad_norm 0.364720 rank 0
2025-01-11 07:28:12,390 DEBUG TRAIN Batch 170/1000 loss 0.024176 acc 0.983573 lr 0.00012315 grad_norm 0.362594 rank 0
2025-01-11 07:28:12,390 DEBUG TRAIN Batch 170/1000 loss 0.027221 acc 0.978763 lr 0.00012315 grad_norm 0.362594 rank 2
2025-01-11 07:28:12,391 DEBUG TRAIN Batch 170/1000 loss 0.023933 acc 0.984689 lr 0.00012315 grad_norm 0.362594 rank 1
2025-01-11 07:28:36,888 DEBUG TRAIN Batch 170/1100 loss 0.031830 acc 0.978196 lr 0.00012313 grad_norm 0.391210 rank 1
2025-01-11 07:28:36,888 DEBUG TRAIN Batch 170/1100 loss 0.040879 acc 0.968547 lr 0.00012313 grad_norm 0.391210 rank 2
2025-01-11 07:28:36,888 DEBUG TRAIN Batch 170/1100 loss 0.026082 acc 0.982883 lr 0.00012313 grad_norm 0.391210 rank 0
2025-01-11 07:29:00,904 DEBUG TRAIN Batch 170/1200 loss 0.042758 acc 0.973148 lr 0.00012311 grad_norm 0.383713 rank 2
2025-01-11 07:29:00,905 DEBUG TRAIN Batch 170/1200 loss 0.033123 acc 0.975232 lr 0.00012311 grad_norm 0.383713 rank 1
2025-01-11 07:29:00,905 DEBUG TRAIN Batch 170/1200 loss 0.034834 acc 0.977293 lr 0.00012311 grad_norm 0.383713 rank 0
2025-01-11 07:29:26,068 DEBUG TRAIN Batch 170/1300 loss 0.033221 acc 0.980488 lr 0.00012310 grad_norm 0.359452 rank 2
2025-01-11 07:29:26,068 DEBUG TRAIN Batch 170/1300 loss 0.026187 acc 0.983902 lr 0.00012310 grad_norm 0.359452 rank 0
2025-01-11 07:29:26,069 DEBUG TRAIN Batch 170/1300 loss 0.028830 acc 0.975162 lr 0.00012310 grad_norm 0.359452 rank 1
2025-01-11 07:29:50,588 DEBUG TRAIN Batch 170/1400 loss 0.028102 acc 0.981083 lr 0.00012308 grad_norm 0.367035 rank 0
2025-01-11 07:29:50,588 DEBUG TRAIN Batch 170/1400 loss 0.023990 acc 0.985089 lr 0.00012308 grad_norm 0.367035 rank 2
2025-01-11 07:29:50,589 DEBUG TRAIN Batch 170/1400 loss 0.020549 acc 0.985549 lr 0.00012308 grad_norm 0.367035 rank 1
2025-01-11 07:30:15,521 DEBUG TRAIN Batch 170/1500 loss 0.040453 acc 0.977253 lr 0.00012306 grad_norm 0.341540 rank 2
2025-01-11 07:30:15,521 DEBUG TRAIN Batch 170/1500 loss 0.025194 acc 0.986087 lr 0.00012306 grad_norm 0.341540 rank 1
2025-01-11 07:30:15,521 DEBUG TRAIN Batch 170/1500 loss 0.028563 acc 0.983871 lr 0.00012306 grad_norm 0.341540 rank 0
2025-01-11 07:30:40,704 DEBUG TRAIN Batch 170/1600 loss 0.043196 acc 0.974268 lr 0.00012304 grad_norm 0.374388 rank 2
2025-01-11 07:30:40,704 DEBUG TRAIN Batch 170/1600 loss 0.029650 acc 0.977457 lr 0.00012304 grad_norm 0.374388 rank 1
2025-01-11 07:30:40,704 DEBUG TRAIN Batch 170/1600 loss 0.032905 acc 0.978142 lr 0.00012304 grad_norm 0.374388 rank 0
2025-01-11 07:31:06,329 DEBUG TRAIN Batch 170/1700 loss 0.024740 acc 0.986755 lr 0.00012302 grad_norm 0.362741 rank 2
2025-01-11 07:31:06,329 DEBUG TRAIN Batch 170/1700 loss 0.034121 acc 0.981047 lr 0.00012302 grad_norm 0.362741 rank 1
2025-01-11 07:31:06,329 DEBUG TRAIN Batch 170/1700 loss 0.031614 acc 0.977654 lr 0.00012302 grad_norm 0.362741 rank 0
2025-01-11 07:31:30,681 DEBUG TRAIN Batch 170/1800 loss 0.029681 acc 0.974645 lr 0.00012300 grad_norm 0.362991 rank 2
2025-01-11 07:31:30,682 DEBUG TRAIN Batch 170/1800 loss 0.024350 acc 0.980548 lr 0.00012300 grad_norm 0.362991 rank 0
2025-01-11 07:31:30,682 DEBUG TRAIN Batch 170/1800 loss 0.035175 acc 0.974816 lr 0.00012300 grad_norm 0.362991 rank 1
2025-01-11 07:31:55,766 DEBUG TRAIN Batch 170/1900 loss 0.025058 acc 0.983385 lr 0.00012298 grad_norm 0.325836 rank 0
2025-01-11 07:31:55,766 DEBUG TRAIN Batch 170/1900 loss 0.017756 acc 0.991896 lr 0.00012298 grad_norm 0.325836 rank 2
2025-01-11 07:31:55,767 DEBUG TRAIN Batch 170/1900 loss 0.016735 acc 0.989023 lr 0.00012298 grad_norm 0.325836 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 07:33:16,477 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 07:33:16,505 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 07:33:16,931 INFO Epoch 170 Step 165330 on_batch_end True CV rank 2
2025-01-11 07:33:16,931 INFO Epoch 170 Step 165330 on_batch_end True CV rank 0
2025-01-11 07:33:16,931 INFO Epoch 170 Step 165330 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 07:33:26,087 DEBUG CV Batch 170/100 loss 0.001695 acc 1.000000  rank 0
2025-01-11 07:33:26,216 DEBUG CV Batch 170/100 loss 0.001695 acc 1.000000  rank 2
2025-01-11 07:33:26,489 DEBUG CV Batch 170/100 loss 0.001695 acc 1.000000  rank 1
2025-01-11 07:33:26,598 INFO Epoch 170 Step 165330 CV info lr 0.0001229685838183987 0 rank loss_2.7140950779623316 acc_0.7807225604590616
2025-01-11 07:33:26,712 INFO Epoch 170 Step 165330 CV info lr 0.0001229685838183987 2 rank loss_2.7140950779623316 acc_0.7807225604590616
2025-01-11 07:33:27,025 INFO Epoch 170 Step 165330 CV info lr 0.0001229685838183987 1 rank loss_2.7140950779623316 acc_0.7807225604590616
2025-01-11 07:33:27,890 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_170_whole.pt
2025-01-11 07:33:27,911 INFO Added key: store_based_barrier_key:173 to store for rank: 0
2025-01-11 07:33:27,912 INFO Added key: store_based_barrier_key:173 to store for rank: 1
2025-01-11 07:33:27,912 INFO Added key: store_based_barrier_key:173 to store for rank: 2
2025-01-11 07:33:27,912 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:173 with 3 nodes.
2025-01-11 07:33:27,912 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:173 with 3 nodes.
2025-01-11 07:33:27,918 INFO Epoch 171 TRAIN info lr 0.0001229685838183987 rank 2
2025-01-11 07:33:27,918 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 07:33:27,919 INFO Epoch 171 TRAIN info lr 0.0001229685838183987 rank 1
2025-01-11 07:33:27,919 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 07:33:27,922 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:173 with 3 nodes.
2025-01-11 07:33:27,928 INFO Epoch 171 TRAIN info lr 0.0001229685838183987 rank 0
2025-01-11 07:33:27,928 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 07:33:58,578 DEBUG TRAIN Batch 171/100 loss 0.021004 acc 0.984009 lr 0.00012295 grad_norm 0.352049 rank 2
2025-01-11 07:33:58,579 DEBUG TRAIN Batch 171/100 loss 0.023932 acc 0.985310 lr 0.00012295 grad_norm 0.352049 rank 1
2025-01-11 07:33:58,579 DEBUG TRAIN Batch 171/100 loss 0.037176 acc 0.979446 lr 0.00012295 grad_norm 0.352049 rank 0
2025-01-11 07:34:22,430 DEBUG TRAIN Batch 171/200 loss 0.019464 acc 0.985697 lr 0.00012293 grad_norm 0.323759 rank 0
2025-01-11 07:34:22,431 DEBUG TRAIN Batch 171/200 loss 0.013261 acc 0.991515 lr 0.00012293 grad_norm 0.323759 rank 2
2025-01-11 07:34:22,431 DEBUG TRAIN Batch 171/200 loss 0.018413 acc 0.986058 lr 0.00012293 grad_norm 0.323759 rank 1
2025-01-11 07:34:46,269 DEBUG TRAIN Batch 171/300 loss 0.022064 acc 0.983871 lr 0.00012291 grad_norm 0.359469 rank 0
2025-01-11 07:34:46,269 DEBUG TRAIN Batch 171/300 loss 0.031793 acc 0.973051 lr 0.00012291 grad_norm 0.359469 rank 1
2025-01-11 07:34:46,270 DEBUG TRAIN Batch 171/300 loss 0.036041 acc 0.974472 lr 0.00012291 grad_norm 0.359469 rank 2
2025-01-11 07:35:09,873 DEBUG TRAIN Batch 171/400 loss 0.041700 acc 0.970874 lr 0.00012289 grad_norm 0.403574 rank 0
2025-01-11 07:35:09,873 DEBUG TRAIN Batch 171/400 loss 0.032784 acc 0.977895 lr 0.00012289 grad_norm 0.403574 rank 1
2025-01-11 07:35:09,875 DEBUG TRAIN Batch 171/400 loss 0.044502 acc 0.969874 lr 0.00012289 grad_norm 0.403574 rank 2
2025-01-11 07:35:34,015 DEBUG TRAIN Batch 171/500 loss 0.031898 acc 0.980087 lr 0.00012288 grad_norm 0.347544 rank 0
2025-01-11 07:35:34,015 DEBUG TRAIN Batch 171/500 loss 0.028153 acc 0.985101 lr 0.00012288 grad_norm 0.347544 rank 2
2025-01-11 07:35:34,015 DEBUG TRAIN Batch 171/500 loss 0.027885 acc 0.978514 lr 0.00012288 grad_norm 0.347544 rank 1
2025-01-11 07:35:57,289 DEBUG TRAIN Batch 171/600 loss 0.031389 acc 0.974528 lr 0.00012286 grad_norm 0.363016 rank 0
2025-01-11 07:35:57,289 DEBUG TRAIN Batch 171/600 loss 0.033599 acc 0.980668 lr 0.00012286 grad_norm 0.363016 rank 2
2025-01-11 07:35:57,289 DEBUG TRAIN Batch 171/600 loss 0.029690 acc 0.981256 lr 0.00012286 grad_norm 0.363016 rank 1
2025-01-11 07:36:21,408 DEBUG TRAIN Batch 171/700 loss 0.032182 acc 0.982759 lr 0.00012284 grad_norm 0.355531 rank 0
2025-01-11 07:36:21,409 DEBUG TRAIN Batch 171/700 loss 0.034943 acc 0.977528 lr 0.00012284 grad_norm 0.355531 rank 2
2025-01-11 07:36:21,409 DEBUG TRAIN Batch 171/700 loss 0.031302 acc 0.978411 lr 0.00012284 grad_norm 0.355531 rank 1
2025-01-11 07:36:45,629 DEBUG TRAIN Batch 171/800 loss 0.021971 acc 0.981614 lr 0.00012282 grad_norm 0.347671 rank 0
2025-01-11 07:36:45,629 DEBUG TRAIN Batch 171/800 loss 0.030320 acc 0.982092 lr 0.00012282 grad_norm 0.347671 rank 2
2025-01-11 07:36:45,629 DEBUG TRAIN Batch 171/800 loss 0.035060 acc 0.977178 lr 0.00012282 grad_norm 0.347671 rank 1
2025-01-11 07:37:09,504 DEBUG TRAIN Batch 171/900 loss 0.020330 acc 0.987167 lr 0.00012280 grad_norm 0.362371 rank 2
2025-01-11 07:37:09,504 DEBUG TRAIN Batch 171/900 loss 0.027738 acc 0.984287 lr 0.00012280 grad_norm 0.362371 rank 1
2025-01-11 07:37:09,504 DEBUG TRAIN Batch 171/900 loss 0.024698 acc 0.981225 lr 0.00012280 grad_norm 0.362371 rank 0
2025-01-11 07:37:33,339 DEBUG TRAIN Batch 171/1000 loss 0.028224 acc 0.980973 lr 0.00012278 grad_norm 0.360022 rank 1
2025-01-11 07:37:33,339 DEBUG TRAIN Batch 171/1000 loss 0.032173 acc 0.975521 lr 0.00012278 grad_norm 0.360022 rank 2
2025-01-11 07:37:33,339 DEBUG TRAIN Batch 171/1000 loss 0.046089 acc 0.966192 lr 0.00012278 grad_norm 0.360022 rank 0
2025-01-11 07:37:57,833 DEBUG TRAIN Batch 171/1100 loss 0.041337 acc 0.967276 lr 0.00012276 grad_norm 0.376973 rank 0
2025-01-11 07:37:57,834 DEBUG TRAIN Batch 171/1100 loss 0.026525 acc 0.978283 lr 0.00012276 grad_norm 0.376973 rank 2
2025-01-11 07:37:57,834 DEBUG TRAIN Batch 171/1100 loss 0.013079 acc 0.992754 lr 0.00012276 grad_norm 0.376973 rank 1
2025-01-11 07:38:22,912 DEBUG TRAIN Batch 171/1200 loss 0.021216 acc 0.980218 lr 0.00012275 grad_norm 0.391589 rank 0
2025-01-11 07:38:22,913 DEBUG TRAIN Batch 171/1200 loss 0.047710 acc 0.970392 lr 0.00012275 grad_norm 0.391589 rank 2
2025-01-11 07:38:22,913 DEBUG TRAIN Batch 171/1200 loss 0.028654 acc 0.979769 lr 0.00012275 grad_norm 0.391589 rank 1
2025-01-11 07:38:46,759 DEBUG TRAIN Batch 171/1300 loss 0.024161 acc 0.981838 lr 0.00012273 grad_norm 0.368011 rank 0
2025-01-11 07:38:46,759 DEBUG TRAIN Batch 171/1300 loss 0.026029 acc 0.984615 lr 0.00012273 grad_norm 0.368011 rank 2
2025-01-11 07:38:46,759 DEBUG TRAIN Batch 171/1300 loss 0.024542 acc 0.982090 lr 0.00012273 grad_norm 0.368011 rank 1
2025-01-11 07:39:11,167 DEBUG TRAIN Batch 171/1400 loss 0.028361 acc 0.981524 lr 0.00012271 grad_norm 0.387501 rank 2
2025-01-11 07:39:11,168 DEBUG TRAIN Batch 171/1400 loss 0.055013 acc 0.963822 lr 0.00012271 grad_norm 0.387501 rank 0
2025-01-11 07:39:11,168 DEBUG TRAIN Batch 171/1400 loss 0.018905 acc 0.987124 lr 0.00012271 grad_norm 0.387501 rank 1
2025-01-11 07:39:35,125 DEBUG TRAIN Batch 171/1500 loss 0.034674 acc 0.972272 lr 0.00012269 grad_norm 0.378029 rank 2
2025-01-11 07:39:35,125 DEBUG TRAIN Batch 171/1500 loss 0.022999 acc 0.985148 lr 0.00012269 grad_norm 0.378029 rank 1
2025-01-11 07:39:35,125 DEBUG TRAIN Batch 171/1500 loss 0.041788 acc 0.972807 lr 0.00012269 grad_norm 0.378029 rank 0
2025-01-11 07:39:59,429 DEBUG TRAIN Batch 171/1600 loss 0.026954 acc 0.979775 lr 0.00012267 grad_norm 0.402413 rank 0
2025-01-11 07:39:59,430 DEBUG TRAIN Batch 171/1600 loss 0.016422 acc 0.985148 lr 0.00012267 grad_norm 0.402413 rank 2
2025-01-11 07:39:59,430 DEBUG TRAIN Batch 171/1600 loss 0.039450 acc 0.967579 lr 0.00012267 grad_norm 0.402413 rank 1
2025-01-11 07:40:24,750 DEBUG TRAIN Batch 171/1700 loss 0.036441 acc 0.976950 lr 0.00012265 grad_norm 0.360675 rank 0
2025-01-11 07:40:24,751 DEBUG TRAIN Batch 171/1700 loss 0.026636 acc 0.982085 lr 0.00012265 grad_norm 0.360675 rank 2
2025-01-11 07:40:24,751 DEBUG TRAIN Batch 171/1700 loss 0.007972 acc 0.995406 lr 0.00012265 grad_norm 0.360675 rank 1
2025-01-11 07:40:49,599 DEBUG TRAIN Batch 171/1800 loss 0.029319 acc 0.976510 lr 0.00012264 grad_norm 0.365035 rank 2
2025-01-11 07:40:49,600 DEBUG TRAIN Batch 171/1800 loss 0.026856 acc 0.982255 lr 0.00012264 grad_norm 0.365035 rank 0
2025-01-11 07:40:49,600 DEBUG TRAIN Batch 171/1800 loss 0.031099 acc 0.977293 lr 0.00012264 grad_norm 0.365035 rank 1
2025-01-11 07:41:14,132 DEBUG TRAIN Batch 171/1900 loss 0.033140 acc 0.978242 lr 0.00012262 grad_norm 0.344994 rank 0
2025-01-11 07:41:14,132 DEBUG TRAIN Batch 171/1900 loss 0.023717 acc 0.981873 lr 0.00012262 grad_norm 0.344994 rank 2
2025-01-11 07:41:14,132 DEBUG TRAIN Batch 171/1900 loss 0.032601 acc 0.974552 lr 0.00012262 grad_norm 0.344994 rank 1
2025-01-11 07:41:38,692 DEBUG TRAIN Batch 171/2000 loss 0.016544 acc 0.991018 lr 0.00012260 grad_norm 0.373749 rank 2
2025-01-11 07:41:38,692 DEBUG TRAIN Batch 171/2000 loss 0.034331 acc 0.975518 lr 0.00012260 grad_norm 0.373749 rank 1
2025-01-11 07:41:38,692 DEBUG TRAIN Batch 171/2000 loss 0.031669 acc 0.979079 lr 0.00012260 grad_norm 0.373749 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 07:42:48,004 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 07:42:48,008 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 07:42:48,426 INFO Epoch 171 Step 166349 on_batch_end True CV rank 2
2025-01-11 07:42:48,426 INFO Epoch 171 Step 166349 on_batch_end True CV rank 0
2025-01-11 07:42:48,426 INFO Epoch 171 Step 166349 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 07:42:57,441 DEBUG CV Batch 171/100 loss 0.000945 acc 1.000000  rank 0
2025-01-11 07:42:57,881 DEBUG CV Batch 171/100 loss 0.000945 acc 1.000000  rank 2
2025-01-11 07:42:57,969 INFO Epoch 171 Step 166349 CV info lr 0.00012259137243950376 0 rank loss_2.697021520008811 acc_0.7805305620034536
2025-01-11 07:42:58,095 DEBUG CV Batch 171/100 loss 0.000945 acc 1.000000  rank 1
2025-01-11 07:42:58,418 INFO Epoch 171 Step 166349 CV info lr 0.00012259137243950376 2 rank loss_2.697021520008811 acc_0.7805305620034536
2025-01-11 07:42:58,651 INFO Epoch 171 Step 166349 CV info lr 0.00012259137243950376 1 rank loss_2.697021520008811 acc_0.7805305620034536
2025-01-11 07:42:59,261 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_171_whole.pt
2025-01-11 07:42:59,283 INFO Added key: store_based_barrier_key:174 to store for rank: 0
2025-01-11 07:42:59,293 INFO Added key: store_based_barrier_key:174 to store for rank: 1
2025-01-11 07:42:59,293 INFO Added key: store_based_barrier_key:174 to store for rank: 2
2025-01-11 07:42:59,293 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:174 with 3 nodes.
2025-01-11 07:42:59,293 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:174 with 3 nodes.
2025-01-11 07:42:59,300 INFO Epoch 172 TRAIN info lr 0.00012259137243950376 rank 2
2025-01-11 07:42:59,300 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 07:42:59,300 INFO Epoch 172 TRAIN info lr 0.00012259137243950376 rank 1
2025-01-11 07:42:59,300 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 07:42:59,303 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:174 with 3 nodes.
2025-01-11 07:42:59,305 INFO Epoch 172 TRAIN info lr 0.00012259137243950376 rank 0
2025-01-11 07:42:59,305 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 07:43:31,900 DEBUG TRAIN Batch 172/100 loss 0.020678 acc 0.981982 lr 0.00012257 grad_norm 0.378607 rank 0
2025-01-11 07:43:31,900 DEBUG TRAIN Batch 172/100 loss 0.035166 acc 0.973684 lr 0.00012257 grad_norm 0.378607 rank 2
2025-01-11 07:43:31,900 DEBUG TRAIN Batch 172/100 loss 0.032254 acc 0.981250 lr 0.00012257 grad_norm 0.378607 rank 1
2025-01-11 07:43:56,014 DEBUG TRAIN Batch 172/200 loss 0.019132 acc 0.985981 lr 0.00012255 grad_norm 0.390620 rank 0
2025-01-11 07:43:56,015 DEBUG TRAIN Batch 172/200 loss 0.038591 acc 0.973176 lr 0.00012255 grad_norm 0.390620 rank 2
2025-01-11 07:43:56,015 DEBUG TRAIN Batch 172/200 loss 0.029767 acc 0.979012 lr 0.00012255 grad_norm 0.390620 rank 1
2025-01-11 07:44:20,909 DEBUG TRAIN Batch 172/300 loss 0.017047 acc 0.990755 lr 0.00012254 grad_norm 0.363355 rank 0
2025-01-11 07:44:20,909 DEBUG TRAIN Batch 172/300 loss 0.027162 acc 0.977915 lr 0.00012254 grad_norm 0.363355 rank 2
2025-01-11 07:44:20,909 DEBUG TRAIN Batch 172/300 loss 0.033761 acc 0.976701 lr 0.00012254 grad_norm 0.363355 rank 1
2025-01-11 07:44:45,326 DEBUG TRAIN Batch 172/400 loss 0.020016 acc 0.986643 lr 0.00012252 grad_norm 0.375366 rank 0
2025-01-11 07:44:45,326 DEBUG TRAIN Batch 172/400 loss 0.020737 acc 0.986942 lr 0.00012252 grad_norm 0.375366 rank 2
2025-01-11 07:44:45,326 DEBUG TRAIN Batch 172/400 loss 0.038454 acc 0.971014 lr 0.00012252 grad_norm 0.375366 rank 1
2025-01-11 07:45:09,775 DEBUG TRAIN Batch 172/500 loss 0.035917 acc 0.981651 lr 0.00012250 grad_norm 0.348495 rank 2
2025-01-11 07:45:09,776 DEBUG TRAIN Batch 172/500 loss 0.026786 acc 0.980072 lr 0.00012250 grad_norm 0.348495 rank 0
2025-01-11 07:45:09,776 DEBUG TRAIN Batch 172/500 loss 0.022041 acc 0.982358 lr 0.00012250 grad_norm 0.348495 rank 1
2025-01-11 07:45:33,861 DEBUG TRAIN Batch 172/600 loss 0.030382 acc 0.978282 lr 0.00012248 grad_norm 0.370765 rank 1
2025-01-11 07:45:33,861 DEBUG TRAIN Batch 172/600 loss 0.024854 acc 0.974684 lr 0.00012248 grad_norm 0.370765 rank 0
2025-01-11 07:45:33,861 DEBUG TRAIN Batch 172/600 loss 0.028114 acc 0.980600 lr 0.00012248 grad_norm 0.370765 rank 2
2025-01-11 07:45:57,933 DEBUG TRAIN Batch 172/700 loss 0.049128 acc 0.971300 lr 0.00012246 grad_norm 0.387440 rank 2
2025-01-11 07:45:57,934 DEBUG TRAIN Batch 172/700 loss 0.021576 acc 0.987688 lr 0.00012246 grad_norm 0.387440 rank 0
2025-01-11 07:45:57,934 DEBUG TRAIN Batch 172/700 loss 0.026510 acc 0.980658 lr 0.00012246 grad_norm 0.387440 rank 1
2025-01-11 07:46:21,987 DEBUG TRAIN Batch 172/800 loss 0.026268 acc 0.983035 lr 0.00012244 grad_norm 0.346293 rank 0
2025-01-11 07:46:21,987 DEBUG TRAIN Batch 172/800 loss 0.023512 acc 0.983871 lr 0.00012244 grad_norm 0.346293 rank 2
2025-01-11 07:46:21,987 DEBUG TRAIN Batch 172/800 loss 0.024719 acc 0.980249 lr 0.00012244 grad_norm 0.346293 rank 1
2025-01-11 07:46:45,378 DEBUG TRAIN Batch 172/900 loss 0.032049 acc 0.979130 lr 0.00012243 grad_norm 0.365867 rank 2
2025-01-11 07:46:45,379 DEBUG TRAIN Batch 172/900 loss 0.029539 acc 0.979014 lr 0.00012243 grad_norm 0.365867 rank 0
2025-01-11 07:46:45,379 DEBUG TRAIN Batch 172/900 loss 0.024524 acc 0.982838 lr 0.00012243 grad_norm 0.365867 rank 1
2025-01-11 07:47:09,538 DEBUG TRAIN Batch 172/1000 loss 0.035760 acc 0.978836 lr 0.00012241 grad_norm 0.353816 rank 2
2025-01-11 07:47:09,539 DEBUG TRAIN Batch 172/1000 loss 0.024929 acc 0.981584 lr 0.00012241 grad_norm 0.353816 rank 1
2025-01-11 07:47:09,539 DEBUG TRAIN Batch 172/1000 loss 0.035118 acc 0.979859 lr 0.00012241 grad_norm 0.353816 rank 0
2025-01-11 07:47:33,539 DEBUG TRAIN Batch 172/1100 loss 0.030958 acc 0.981256 lr 0.00012239 grad_norm 0.344074 rank 0
2025-01-11 07:47:33,540 DEBUG TRAIN Batch 172/1100 loss 0.022659 acc 0.981905 lr 0.00012239 grad_norm 0.344074 rank 2
2025-01-11 07:47:33,540 DEBUG TRAIN Batch 172/1100 loss 0.036076 acc 0.980319 lr 0.00012239 grad_norm 0.344074 rank 1
2025-01-11 07:47:58,697 DEBUG TRAIN Batch 172/1200 loss 0.017486 acc 0.987488 lr 0.00012237 grad_norm 0.341596 rank 0
2025-01-11 07:47:58,697 DEBUG TRAIN Batch 172/1200 loss 0.021981 acc 0.983763 lr 0.00012237 grad_norm 0.341596 rank 2
2025-01-11 07:47:58,698 DEBUG TRAIN Batch 172/1200 loss 0.032024 acc 0.980870 lr 0.00012237 grad_norm 0.341596 rank 1
2025-01-11 07:48:22,493 DEBUG TRAIN Batch 172/1300 loss 0.017317 acc 0.985348 lr 0.00012235 grad_norm 0.339185 rank 0
2025-01-11 07:48:22,493 DEBUG TRAIN Batch 172/1300 loss 0.025698 acc 0.978240 lr 0.00012235 grad_norm 0.339185 rank 2
2025-01-11 07:48:22,494 DEBUG TRAIN Batch 172/1300 loss 0.022190 acc 0.982375 lr 0.00012235 grad_norm 0.339185 rank 1
2025-01-11 07:48:46,860 DEBUG TRAIN Batch 172/1400 loss 0.035842 acc 0.982193 lr 0.00012233 grad_norm 0.348627 rank 0
2025-01-11 07:48:46,861 DEBUG TRAIN Batch 172/1400 loss 0.034904 acc 0.976744 lr 0.00012233 grad_norm 0.348627 rank 2
2025-01-11 07:48:46,861 DEBUG TRAIN Batch 172/1400 loss 0.019992 acc 0.986258 lr 0.00012233 grad_norm 0.348627 rank 1
2025-01-11 07:49:11,536 DEBUG TRAIN Batch 172/1500 loss 0.011641 acc 0.995290 lr 0.00012232 grad_norm 0.364420 rank 0
2025-01-11 07:49:11,536 DEBUG TRAIN Batch 172/1500 loss 0.031724 acc 0.976789 lr 0.00012232 grad_norm 0.364420 rank 2
2025-01-11 07:49:11,536 DEBUG TRAIN Batch 172/1500 loss 0.030978 acc 0.982126 lr 0.00012232 grad_norm 0.364420 rank 1
2025-01-11 07:49:36,103 DEBUG TRAIN Batch 172/1600 loss 0.020727 acc 0.984572 lr 0.00012230 grad_norm 0.380639 rank 0
2025-01-11 07:49:36,103 DEBUG TRAIN Batch 172/1600 loss 0.027810 acc 0.980488 lr 0.00012230 grad_norm 0.380639 rank 2
2025-01-11 07:49:36,103 DEBUG TRAIN Batch 172/1600 loss 0.037757 acc 0.976145 lr 0.00012230 grad_norm 0.380639 rank 1
2025-01-11 07:50:00,377 DEBUG TRAIN Batch 172/1700 loss 0.025040 acc 0.985799 lr 0.00012228 grad_norm 0.389017 rank 0
2025-01-11 07:50:00,377 DEBUG TRAIN Batch 172/1700 loss 0.025416 acc 0.980838 lr 0.00012228 grad_norm 0.389017 rank 1
2025-01-11 07:50:00,378 DEBUG TRAIN Batch 172/1700 loss 0.032803 acc 0.975733 lr 0.00012228 grad_norm 0.389017 rank 2
2025-01-11 07:50:25,038 DEBUG TRAIN Batch 172/1800 loss 0.029319 acc 0.977993 lr 0.00012226 grad_norm 0.362274 rank 1
2025-01-11 07:50:25,038 DEBUG TRAIN Batch 172/1800 loss 0.020207 acc 0.988636 lr 0.00012226 grad_norm 0.362274 rank 0
2025-01-11 07:50:25,039 DEBUG TRAIN Batch 172/1800 loss 0.030872 acc 0.980392 lr 0.00012226 grad_norm 0.362274 rank 2
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 07:51:31,871 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 07:51:31,875 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 07:51:32,326 INFO Epoch 172 Step 167263 on_batch_end True CV rank 1
2025-01-11 07:51:32,327 INFO Epoch 172 Step 167263 on_batch_end True CV rank 0
2025-01-11 07:51:32,327 INFO Epoch 172 Step 167263 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 07:51:41,216 DEBUG CV Batch 172/100 loss 0.001585 acc 1.000000  rank 0
2025-01-11 07:51:41,707 INFO Epoch 172 Step 167263 CV info lr 0.00012225596650724982 0 rank loss_2.7163088866247818 acc_0.7806425872340537
2025-01-11 07:51:41,829 DEBUG CV Batch 172/100 loss 0.001585 acc 1.000000  rank 2
2025-01-11 07:51:41,950 DEBUG CV Batch 172/100 loss 0.001585 acc 1.000000  rank 1
2025-01-11 07:51:42,377 INFO Epoch 172 Step 167263 CV info lr 0.00012225596650724982 2 rank loss_2.7163088866247818 acc_0.7806425872340537
2025-01-11 07:51:42,486 INFO Epoch 172 Step 167263 CV info lr 0.00012225596650724982 1 rank loss_2.7163088866247818 acc_0.7806425872340537
2025-01-11 07:51:42,990 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_172_whole.pt
2025-01-11 07:51:43,002 INFO Added key: store_based_barrier_key:175 to store for rank: 0
2025-01-11 07:51:43,012 INFO Added key: store_based_barrier_key:175 to store for rank: 2
2025-01-11 07:51:43,012 INFO Added key: store_based_barrier_key:175 to store for rank: 1
2025-01-11 07:51:43,012 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:175 with 3 nodes.
2025-01-11 07:51:43,012 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:175 with 3 nodes.
2025-01-11 07:51:43,015 INFO Epoch 173 TRAIN info lr 0.00012225596650724982 rank 1
2025-01-11 07:51:43,015 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 07:51:43,015 INFO Epoch 173 TRAIN info lr 0.00012225596650724982 rank 2
2025-01-11 07:51:43,015 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 07:51:43,022 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:175 with 3 nodes.
2025-01-11 07:51:43,024 INFO Epoch 173 TRAIN info lr 0.00012225596650724982 rank 0
2025-01-11 07:51:43,024 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 07:52:19,400 DEBUG TRAIN Batch 173/100 loss 0.022516 acc 0.984043 lr 0.00012224 grad_norm 0.337874 rank 0
2025-01-11 07:52:19,401 DEBUG TRAIN Batch 173/100 loss 0.019799 acc 0.987342 lr 0.00012224 grad_norm 0.337874 rank 1
2025-01-11 07:52:19,401 DEBUG TRAIN Batch 173/100 loss 0.027890 acc 0.982997 lr 0.00012224 grad_norm 0.337874 rank 2
2025-01-11 07:52:43,566 DEBUG TRAIN Batch 173/200 loss 0.022810 acc 0.989091 lr 0.00012222 grad_norm 0.350601 rank 0
2025-01-11 07:52:43,567 DEBUG TRAIN Batch 173/200 loss 0.019316 acc 0.985632 lr 0.00012222 grad_norm 0.350601 rank 1
2025-01-11 07:52:43,567 DEBUG TRAIN Batch 173/200 loss 0.029890 acc 0.982440 lr 0.00012222 grad_norm 0.350601 rank 2
2025-01-11 07:53:08,209 DEBUG TRAIN Batch 173/300 loss 0.025468 acc 0.979483 lr 0.00012220 grad_norm 0.352277 rank 0
2025-01-11 07:53:08,209 DEBUG TRAIN Batch 173/300 loss 0.022608 acc 0.984481 lr 0.00012220 grad_norm 0.352277 rank 2
2025-01-11 07:53:08,209 DEBUG TRAIN Batch 173/300 loss 0.020780 acc 0.990276 lr 0.00012220 grad_norm 0.352277 rank 1
2025-01-11 07:53:31,891 DEBUG TRAIN Batch 173/400 loss 0.025503 acc 0.982906 lr 0.00012218 grad_norm 0.361477 rank 2
2025-01-11 07:53:31,891 DEBUG TRAIN Batch 173/400 loss 0.016095 acc 0.986919 lr 0.00012218 grad_norm 0.361477 rank 1
2025-01-11 07:53:31,895 DEBUG TRAIN Batch 173/400 loss 0.028471 acc 0.980304 lr 0.00012218 grad_norm 0.361477 rank 0
2025-01-11 07:53:57,217 DEBUG TRAIN Batch 173/500 loss 0.025480 acc 0.984863 lr 0.00012216 grad_norm 0.345010 rank 2
2025-01-11 07:53:57,217 DEBUG TRAIN Batch 173/500 loss 0.037919 acc 0.973262 lr 0.00012216 grad_norm 0.345010 rank 0
2025-01-11 07:53:57,217 DEBUG TRAIN Batch 173/500 loss 0.029241 acc 0.975155 lr 0.00012216 grad_norm 0.345010 rank 1
2025-01-11 07:54:21,589 DEBUG TRAIN Batch 173/600 loss 0.025872 acc 0.984549 lr 0.00012215 grad_norm 0.369410 rank 2
2025-01-11 07:54:21,590 DEBUG TRAIN Batch 173/600 loss 0.014787 acc 0.991071 lr 0.00012215 grad_norm 0.369410 rank 1
2025-01-11 07:54:21,590 DEBUG TRAIN Batch 173/600 loss 0.024647 acc 0.979679 lr 0.00012215 grad_norm 0.369410 rank 0
2025-01-11 07:54:45,822 DEBUG TRAIN Batch 173/700 loss 0.044159 acc 0.972538 lr 0.00012213 grad_norm 0.365807 rank 0
2025-01-11 07:54:45,822 DEBUG TRAIN Batch 173/700 loss 0.020950 acc 0.983101 lr 0.00012213 grad_norm 0.365807 rank 2
2025-01-11 07:54:45,823 DEBUG TRAIN Batch 173/700 loss 0.020536 acc 0.981360 lr 0.00012213 grad_norm 0.365807 rank 1
2025-01-11 07:55:10,709 DEBUG TRAIN Batch 173/800 loss 0.036051 acc 0.975820 lr 0.00012211 grad_norm 0.397406 rank 1
2025-01-11 07:55:10,709 DEBUG TRAIN Batch 173/800 loss 0.042204 acc 0.972973 lr 0.00012211 grad_norm 0.397406 rank 0
2025-01-11 07:55:10,709 DEBUG TRAIN Batch 173/800 loss 0.038534 acc 0.971741 lr 0.00012211 grad_norm 0.397406 rank 2
2025-01-11 07:55:34,498 DEBUG TRAIN Batch 173/900 loss 0.018790 acc 0.987879 lr 0.00012209 grad_norm 0.394462 rank 1
2025-01-11 07:55:34,498 DEBUG TRAIN Batch 173/900 loss 0.041919 acc 0.979006 lr 0.00012209 grad_norm 0.394462 rank 2
2025-01-11 07:55:34,498 DEBUG TRAIN Batch 173/900 loss 0.030658 acc 0.981366 lr 0.00012209 grad_norm 0.394462 rank 0
2025-01-11 07:55:59,205 DEBUG TRAIN Batch 173/1000 loss 0.020670 acc 0.982736 lr 0.00012207 grad_norm 0.370164 rank 1
2025-01-11 07:55:59,205 DEBUG TRAIN Batch 173/1000 loss 0.026956 acc 0.980035 lr 0.00012207 grad_norm 0.370164 rank 0
2025-01-11 07:55:59,206 DEBUG TRAIN Batch 173/1000 loss 0.024351 acc 0.985000 lr 0.00012207 grad_norm 0.370164 rank 2
2025-01-11 07:56:24,754 DEBUG TRAIN Batch 173/1100 loss 0.013426 acc 0.992188 lr 0.00012206 grad_norm 0.346280 rank 1
2025-01-11 07:56:24,754 DEBUG TRAIN Batch 173/1100 loss 0.031282 acc 0.980263 lr 0.00012206 grad_norm 0.346280 rank 0
2025-01-11 07:56:24,754 DEBUG TRAIN Batch 173/1100 loss 0.026029 acc 0.982236 lr 0.00012206 grad_norm 0.346280 rank 2
2025-01-11 07:56:48,015 DEBUG TRAIN Batch 173/1200 loss 0.025362 acc 0.983349 lr 0.00012204 grad_norm 0.396654 rank 2
2025-01-11 07:56:48,015 DEBUG TRAIN Batch 173/1200 loss 0.035933 acc 0.974672 lr 0.00012204 grad_norm 0.396654 rank 0
2025-01-11 07:56:48,015 DEBUG TRAIN Batch 173/1200 loss 0.043813 acc 0.972603 lr 0.00012204 grad_norm 0.396654 rank 1
2025-01-11 07:57:12,098 DEBUG TRAIN Batch 173/1300 loss 0.028581 acc 0.980117 lr 0.00012202 grad_norm 0.364398 rank 0
2025-01-11 07:57:12,099 DEBUG TRAIN Batch 173/1300 loss 0.031733 acc 0.978011 lr 0.00012202 grad_norm 0.364398 rank 1
2025-01-11 07:57:12,099 DEBUG TRAIN Batch 173/1300 loss 0.015085 acc 0.992117 lr 0.00012202 grad_norm 0.364398 rank 2
2025-01-11 07:57:36,337 DEBUG TRAIN Batch 173/1400 loss 0.020380 acc 0.985891 lr 0.00012200 grad_norm 0.356798 rank 2
2025-01-11 07:57:36,337 DEBUG TRAIN Batch 173/1400 loss 0.039193 acc 0.975800 lr 0.00012200 grad_norm 0.356798 rank 0
2025-01-11 07:57:36,337 DEBUG TRAIN Batch 173/1400 loss 0.029565 acc 0.977226 lr 0.00012200 grad_norm 0.356798 rank 1
2025-01-11 07:58:00,236 DEBUG TRAIN Batch 173/1500 loss 0.033153 acc 0.977750 lr 0.00012198 grad_norm 0.364747 rank 0
2025-01-11 07:58:00,236 DEBUG TRAIN Batch 173/1500 loss 0.030837 acc 0.974312 lr 0.00012198 grad_norm 0.364747 rank 1
2025-01-11 07:58:00,236 DEBUG TRAIN Batch 173/1500 loss 0.030737 acc 0.978070 lr 0.00012198 grad_norm 0.364747 rank 2
2025-01-11 07:58:23,578 DEBUG TRAIN Batch 173/1600 loss 0.041171 acc 0.979798 lr 0.00012196 grad_norm 0.386657 rank 1
2025-01-11 07:58:23,578 DEBUG TRAIN Batch 173/1600 loss 0.023923 acc 0.985116 lr 0.00012196 grad_norm 0.386657 rank 0
2025-01-11 07:58:23,579 DEBUG TRAIN Batch 173/1600 loss 0.020259 acc 0.985279 lr 0.00012196 grad_norm 0.386657 rank 2
2025-01-11 07:58:47,154 DEBUG TRAIN Batch 173/1700 loss 0.025003 acc 0.983668 lr 0.00012195 grad_norm 0.353372 rank 1
2025-01-11 07:58:47,155 DEBUG TRAIN Batch 173/1700 loss 0.027342 acc 0.982846 lr 0.00012195 grad_norm 0.353372 rank 0
2025-01-11 07:58:47,155 DEBUG TRAIN Batch 173/1700 loss 0.022958 acc 0.983810 lr 0.00012195 grad_norm 0.353372 rank 2
2025-01-11 07:59:11,134 DEBUG TRAIN Batch 173/1800 loss 0.026439 acc 0.979592 lr 0.00012193 grad_norm 0.362311 rank 0
2025-01-11 07:59:11,134 DEBUG TRAIN Batch 173/1800 loss 0.031001 acc 0.981169 lr 0.00012193 grad_norm 0.362311 rank 2
2025-01-11 07:59:11,135 DEBUG TRAIN Batch 173/1800 loss 0.031922 acc 0.979428 lr 0.00012193 grad_norm 0.362311 rank 1
2025-01-11 07:59:35,512 DEBUG TRAIN Batch 173/1900 loss 0.034313 acc 0.975904 lr 0.00012191 grad_norm 0.380159 rank 0
2025-01-11 07:59:35,513 DEBUG TRAIN Batch 173/1900 loss 0.028555 acc 0.979825 lr 0.00012191 grad_norm 0.380159 rank 2
2025-01-11 07:59:35,513 DEBUG TRAIN Batch 173/1900 loss 0.033371 acc 0.979710 lr 0.00012191 grad_norm 0.380159 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 08:00:55,743 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 08:00:55,745 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 08:00:56,243 INFO Epoch 173 Step 168255 on_batch_end True CV rank 1
2025-01-11 08:00:56,243 INFO Epoch 173 Step 168255 on_batch_end True CV rank 0
2025-01-11 08:00:56,243 INFO Epoch 173 Step 168255 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 08:01:05,285 DEBUG CV Batch 173/100 loss 0.002417 acc 0.998885  rank 0
2025-01-11 08:01:05,642 DEBUG CV Batch 173/100 loss 0.002417 acc 0.998885  rank 2
2025-01-11 08:01:05,804 INFO Epoch 173 Step 168255 CV info lr 0.00012189503457159729 0 rank loss_2.7135900897794687 acc_0.7800126700547704
2025-01-11 08:01:05,819 DEBUG CV Batch 173/100 loss 0.002417 acc 0.998885  rank 1
2025-01-11 08:01:06,178 INFO Epoch 173 Step 168255 CV info lr 0.00012189503457159729 2 rank loss_2.7135900897794687 acc_0.7800126700547704
2025-01-11 08:01:06,319 INFO Epoch 173 Step 168255 CV info lr 0.00012189503457159729 1 rank loss_2.7135900897794687 acc_0.7800126700547704
2025-01-11 08:01:07,077 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_173_whole.pt
2025-01-11 08:01:07,089 INFO Added key: store_based_barrier_key:176 to store for rank: 0
2025-01-11 08:01:07,099 INFO Added key: store_based_barrier_key:176 to store for rank: 2
2025-01-11 08:01:07,099 INFO Added key: store_based_barrier_key:176 to store for rank: 1
2025-01-11 08:01:07,099 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:176 with 3 nodes.
2025-01-11 08:01:07,099 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:176 with 3 nodes.
2025-01-11 08:01:07,103 INFO Epoch 174 TRAIN info lr 0.00012189503457159729 rank 2
2025-01-11 08:01:07,103 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 08:01:07,109 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:176 with 3 nodes.
2025-01-11 08:01:07,109 INFO Epoch 174 TRAIN info lr 0.00012189503457159729 rank 1
2025-01-11 08:01:07,109 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 08:01:07,119 INFO Epoch 174 TRAIN info lr 0.00012189503457159729 rank 0
2025-01-11 08:01:07,119 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 08:01:39,873 DEBUG TRAIN Batch 174/100 loss 0.034075 acc 0.971725 lr 0.00012188 grad_norm 0.360442 rank 0
2025-01-11 08:01:39,874 DEBUG TRAIN Batch 174/100 loss 0.025636 acc 0.984657 lr 0.00012188 grad_norm 0.360442 rank 2
2025-01-11 08:01:39,874 DEBUG TRAIN Batch 174/100 loss 0.035860 acc 0.973160 lr 0.00012188 grad_norm 0.360442 rank 1
2025-01-11 08:02:03,676 DEBUG TRAIN Batch 174/200 loss 0.011127 acc 0.995043 lr 0.00012186 grad_norm 0.305833 rank 1
2025-01-11 08:02:03,676 DEBUG TRAIN Batch 174/200 loss 0.030672 acc 0.982676 lr 0.00012186 grad_norm 0.305833 rank 0
2025-01-11 08:02:03,677 DEBUG TRAIN Batch 174/200 loss 0.018988 acc 0.989975 lr 0.00012186 grad_norm 0.305833 rank 2
2025-01-11 08:02:27,683 DEBUG TRAIN Batch 174/300 loss 0.026111 acc 0.980806 lr 0.00012184 grad_norm 0.362403 rank 1
2025-01-11 08:02:27,684 DEBUG TRAIN Batch 174/300 loss 0.022733 acc 0.983099 lr 0.00012184 grad_norm 0.362403 rank 2
2025-01-11 08:02:27,684 DEBUG TRAIN Batch 174/300 loss 0.029402 acc 0.981216 lr 0.00012184 grad_norm 0.362403 rank 0
2025-01-11 08:02:52,102 DEBUG TRAIN Batch 174/400 loss 0.031120 acc 0.978799 lr 0.00012182 grad_norm 0.339126 rank 2
2025-01-11 08:02:52,102 DEBUG TRAIN Batch 174/400 loss 0.028048 acc 0.979839 lr 0.00012182 grad_norm 0.339126 rank 1
2025-01-11 08:02:52,102 DEBUG TRAIN Batch 174/400 loss 0.030196 acc 0.983666 lr 0.00012182 grad_norm 0.339126 rank 0
2025-01-11 08:03:15,880 DEBUG TRAIN Batch 174/500 loss 0.037135 acc 0.972949 lr 0.00012180 grad_norm 0.357698 rank 0
2025-01-11 08:03:15,880 DEBUG TRAIN Batch 174/500 loss 0.033905 acc 0.975866 lr 0.00012180 grad_norm 0.357698 rank 1
2025-01-11 08:03:15,881 DEBUG TRAIN Batch 174/500 loss 0.024389 acc 0.983635 lr 0.00012180 grad_norm 0.357698 rank 2
2025-01-11 08:03:39,888 DEBUG TRAIN Batch 174/600 loss 0.022926 acc 0.986084 lr 0.00012179 grad_norm 0.350513 rank 0
2025-01-11 08:03:39,888 DEBUG TRAIN Batch 174/600 loss 0.033114 acc 0.978012 lr 0.00012179 grad_norm 0.350513 rank 2
2025-01-11 08:03:39,888 DEBUG TRAIN Batch 174/600 loss 0.031671 acc 0.976909 lr 0.00012179 grad_norm 0.350513 rank 1
2025-01-11 08:04:04,668 DEBUG TRAIN Batch 174/700 loss 0.026059 acc 0.981064 lr 0.00012177 grad_norm 0.361189 rank 1
2025-01-11 08:04:04,669 DEBUG TRAIN Batch 174/700 loss 0.027982 acc 0.979927 lr 0.00012177 grad_norm 0.361189 rank 0
2025-01-11 08:04:04,670 DEBUG TRAIN Batch 174/700 loss 0.036703 acc 0.975072 lr 0.00012177 grad_norm 0.361189 rank 2
2025-01-11 08:04:29,414 DEBUG TRAIN Batch 174/800 loss 0.028528 acc 0.983435 lr 0.00012175 grad_norm 0.344382 rank 0
2025-01-11 08:04:29,414 DEBUG TRAIN Batch 174/800 loss 0.022942 acc 0.983957 lr 0.00012175 grad_norm 0.344382 rank 2
2025-01-11 08:04:29,414 DEBUG TRAIN Batch 174/800 loss 0.028088 acc 0.980218 lr 0.00012175 grad_norm 0.344382 rank 1
2025-01-11 08:04:53,437 DEBUG TRAIN Batch 174/900 loss 0.017257 acc 0.989201 lr 0.00012173 grad_norm 0.341438 rank 1
2025-01-11 08:04:53,438 DEBUG TRAIN Batch 174/900 loss 0.050708 acc 0.965950 lr 0.00012173 grad_norm 0.341438 rank 2
2025-01-11 08:04:53,438 DEBUG TRAIN Batch 174/900 loss 0.024773 acc 0.980269 lr 0.00012173 grad_norm 0.341438 rank 0
2025-01-11 08:05:17,481 DEBUG TRAIN Batch 174/1000 loss 0.022322 acc 0.983732 lr 0.00012171 grad_norm 0.345871 rank 0
2025-01-11 08:05:17,481 DEBUG TRAIN Batch 174/1000 loss 0.027207 acc 0.983221 lr 0.00012171 grad_norm 0.345871 rank 1
2025-01-11 08:05:17,481 DEBUG TRAIN Batch 174/1000 loss 0.028003 acc 0.980874 lr 0.00012171 grad_norm 0.345871 rank 2
2025-01-11 08:05:42,749 DEBUG TRAIN Batch 174/1100 loss 0.029025 acc 0.983051 lr 0.00012170 grad_norm 0.400994 rank 2
2025-01-11 08:05:42,749 DEBUG TRAIN Batch 174/1100 loss 0.027416 acc 0.977671 lr 0.00012170 grad_norm 0.400994 rank 1
2025-01-11 08:05:42,749 DEBUG TRAIN Batch 174/1100 loss 0.034151 acc 0.974672 lr 0.00012170 grad_norm 0.400994 rank 0
2025-01-11 08:06:06,868 DEBUG TRAIN Batch 174/1200 loss 0.022458 acc 0.983871 lr 0.00012168 grad_norm 0.363356 rank 2
2025-01-11 08:06:06,868 DEBUG TRAIN Batch 174/1200 loss 0.026986 acc 0.984725 lr 0.00012168 grad_norm 0.363356 rank 0
2025-01-11 08:06:06,868 DEBUG TRAIN Batch 174/1200 loss 0.035492 acc 0.980892 lr 0.00012168 grad_norm 0.363356 rank 1
2025-01-11 08:06:30,956 DEBUG TRAIN Batch 174/1300 loss 0.014473 acc 0.995080 lr 0.00012166 grad_norm 0.391685 rank 0
2025-01-11 08:06:30,956 DEBUG TRAIN Batch 174/1300 loss 0.039204 acc 0.972744 lr 0.00012166 grad_norm 0.391685 rank 2
2025-01-11 08:06:30,957 DEBUG TRAIN Batch 174/1300 loss 0.029376 acc 0.983854 lr 0.00012166 grad_norm 0.391685 rank 1
2025-01-11 08:06:56,193 DEBUG TRAIN Batch 174/1400 loss 0.025442 acc 0.986780 lr 0.00012164 grad_norm 0.342732 rank 2
2025-01-11 08:06:56,194 DEBUG TRAIN Batch 174/1400 loss 0.028951 acc 0.980132 lr 0.00012164 grad_norm 0.342732 rank 0
2025-01-11 08:06:56,194 DEBUG TRAIN Batch 174/1400 loss 0.026464 acc 0.987292 lr 0.00012164 grad_norm 0.342732 rank 1
2025-01-11 08:07:20,258 DEBUG TRAIN Batch 174/1500 loss 0.039209 acc 0.975610 lr 0.00012162 grad_norm 0.383496 rank 2
2025-01-11 08:07:20,259 DEBUG TRAIN Batch 174/1500 loss 0.032387 acc 0.977355 lr 0.00012162 grad_norm 0.383496 rank 0
2025-01-11 08:07:20,259 DEBUG TRAIN Batch 174/1500 loss 0.033594 acc 0.978089 lr 0.00012162 grad_norm 0.383496 rank 1
2025-01-11 08:07:44,703 DEBUG TRAIN Batch 174/1600 loss 0.031645 acc 0.977551 lr 0.00012161 grad_norm 0.399367 rank 0
2025-01-11 08:07:44,703 DEBUG TRAIN Batch 174/1600 loss 0.035388 acc 0.976526 lr 0.00012161 grad_norm 0.399367 rank 2
2025-01-11 08:07:44,705 DEBUG TRAIN Batch 174/1600 loss 0.018901 acc 0.988166 lr 0.00012161 grad_norm 0.399367 rank 1
2025-01-11 08:08:09,426 DEBUG TRAIN Batch 174/1700 loss 0.038997 acc 0.979529 lr 0.00012159 grad_norm 0.398717 rank 0
2025-01-11 08:08:09,427 DEBUG TRAIN Batch 174/1700 loss 0.030082 acc 0.978346 lr 0.00012159 grad_norm 0.398717 rank 2
2025-01-11 08:08:09,427 DEBUG TRAIN Batch 174/1700 loss 0.034849 acc 0.973737 lr 0.00012159 grad_norm 0.398717 rank 1
2025-01-11 08:08:33,327 DEBUG TRAIN Batch 174/1800 loss 0.028087 acc 0.975189 lr 0.00012157 grad_norm 0.349119 rank 0
2025-01-11 08:08:33,327 DEBUG TRAIN Batch 174/1800 loss 0.022937 acc 0.986967 lr 0.00012157 grad_norm 0.349119 rank 2
2025-01-11 08:08:33,328 DEBUG TRAIN Batch 174/1800 loss 0.028286 acc 0.979535 lr 0.00012157 grad_norm 0.349119 rank 1
2025-01-11 08:08:58,846 DEBUG TRAIN Batch 174/1900 loss 0.025878 acc 0.982841 lr 0.00012155 grad_norm 0.378900 rank 0
2025-01-11 08:08:58,846 DEBUG TRAIN Batch 174/1900 loss 0.031147 acc 0.976767 lr 0.00012155 grad_norm 0.378900 rank 2
2025-01-11 08:08:58,847 DEBUG TRAIN Batch 174/1900 loss 0.023357 acc 0.981838 lr 0.00012155 grad_norm 0.378900 rank 1
2025-01-11 08:09:23,023 DEBUG TRAIN Batch 174/2000 loss 0.029876 acc 0.975000 lr 0.00012153 grad_norm 0.383568 rank 2
2025-01-11 08:09:23,023 DEBUG TRAIN Batch 174/2000 loss 0.018757 acc 0.983582 lr 0.00012153 grad_norm 0.383568 rank 0
2025-01-11 08:09:23,024 DEBUG TRAIN Batch 174/2000 loss 0.028883 acc 0.975705 lr 0.00012153 grad_norm 0.383568 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 08:10:31,349 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 08:10:31,363 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 08:10:31,797 INFO Epoch 174 Step 169271 on_batch_end True CV rank 1
2025-01-11 08:10:31,797 INFO Epoch 174 Step 169271 on_batch_end True CV rank 2
2025-01-11 08:10:31,797 INFO Epoch 174 Step 169271 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 08:10:40,963 DEBUG CV Batch 174/100 loss 0.003231 acc 0.998885  rank 0
2025-01-11 08:10:41,127 DEBUG CV Batch 174/100 loss 0.003231 acc 0.998885  rank 2
2025-01-11 08:10:41,394 DEBUG CV Batch 174/100 loss 0.003231 acc 0.998885  rank 1
2025-01-11 08:10:41,479 INFO Epoch 174 Step 169271 CV info lr 0.00012152866422055848 0 rank loss_2.719854708536188 acc_0.7804700555770021
2025-01-11 08:10:41,654 INFO Epoch 174 Step 169271 CV info lr 0.00012152866422055848 2 rank loss_2.719854708536188 acc_0.7804700555770021
2025-01-11 08:10:41,930 INFO Epoch 174 Step 169271 CV info lr 0.00012152866422055848 1 rank loss_2.719854708536188 acc_0.7804700555770021
2025-01-11 08:10:42,788 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_174_whole.pt
2025-01-11 08:10:42,800 INFO Added key: store_based_barrier_key:177 to store for rank: 0
2025-01-11 08:10:42,810 INFO Added key: store_based_barrier_key:177 to store for rank: 2
2025-01-11 08:10:42,811 INFO Added key: store_based_barrier_key:177 to store for rank: 1
2025-01-11 08:10:42,811 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:177 with 3 nodes.
2025-01-11 08:10:42,811 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:177 with 3 nodes.
2025-01-11 08:10:42,817 INFO Epoch 175 TRAIN info lr 0.00012152866422055848 rank 1
2025-01-11 08:10:42,817 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 08:10:42,819 INFO Epoch 175 TRAIN info lr 0.00012152866422055848 rank 2
2025-01-11 08:10:42,819 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 08:10:42,821 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:177 with 3 nodes.
2025-01-11 08:10:42,821 INFO Epoch 175 TRAIN info lr 0.00012152866422055848 rank 0
2025-01-11 08:10:42,821 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 08:11:13,265 DEBUG TRAIN Batch 175/100 loss 0.018068 acc 0.988934 lr 0.00012151 grad_norm 0.370602 rank 0
2025-01-11 08:11:13,266 DEBUG TRAIN Batch 175/100 loss 0.027896 acc 0.984099 lr 0.00012151 grad_norm 0.370602 rank 1
2025-01-11 08:11:13,266 DEBUG TRAIN Batch 175/100 loss 0.037030 acc 0.973205 lr 0.00012151 grad_norm 0.370602 rank 2
2025-01-11 08:11:36,967 DEBUG TRAIN Batch 175/200 loss 0.024859 acc 0.978628 lr 0.00012149 grad_norm 0.371303 rank 1
2025-01-11 08:11:36,967 DEBUG TRAIN Batch 175/200 loss 0.021443 acc 0.983871 lr 0.00012149 grad_norm 0.371303 rank 0
2025-01-11 08:11:36,967 DEBUG TRAIN Batch 175/200 loss 0.021641 acc 0.983523 lr 0.00012149 grad_norm 0.371303 rank 2
2025-01-11 08:12:00,419 DEBUG TRAIN Batch 175/300 loss 0.030216 acc 0.979960 lr 0.00012147 grad_norm 0.374326 rank 0
2025-01-11 08:12:00,420 DEBUG TRAIN Batch 175/300 loss 0.034533 acc 0.981651 lr 0.00012147 grad_norm 0.374326 rank 1
2025-01-11 08:12:00,420 DEBUG TRAIN Batch 175/300 loss 0.024788 acc 0.982326 lr 0.00012147 grad_norm 0.374326 rank 2
2025-01-11 08:12:23,901 DEBUG TRAIN Batch 175/400 loss 0.042126 acc 0.969828 lr 0.00012146 grad_norm 0.380896 rank 0
2025-01-11 08:12:23,901 DEBUG TRAIN Batch 175/400 loss 0.029362 acc 0.978761 lr 0.00012146 grad_norm 0.380896 rank 1
2025-01-11 08:12:23,901 DEBUG TRAIN Batch 175/400 loss 0.029995 acc 0.981939 lr 0.00012146 grad_norm 0.380896 rank 2
2025-01-11 08:12:48,028 DEBUG TRAIN Batch 175/500 loss 0.024367 acc 0.984503 lr 0.00012144 grad_norm 0.338150 rank 0
2025-01-11 08:12:48,029 DEBUG TRAIN Batch 175/500 loss 0.030192 acc 0.981447 lr 0.00012144 grad_norm 0.338150 rank 1
2025-01-11 08:12:48,029 DEBUG TRAIN Batch 175/500 loss 0.032931 acc 0.981881 lr 0.00012144 grad_norm 0.338150 rank 2
2025-01-11 08:13:11,963 DEBUG TRAIN Batch 175/600 loss 0.046179 acc 0.972449 lr 0.00012142 grad_norm 0.352673 rank 1
2025-01-11 08:13:11,963 DEBUG TRAIN Batch 175/600 loss 0.015498 acc 0.990960 lr 0.00012142 grad_norm 0.352673 rank 2
2025-01-11 08:13:11,963 DEBUG TRAIN Batch 175/600 loss 0.020968 acc 0.980370 lr 0.00012142 grad_norm 0.352673 rank 0
2025-01-11 08:13:36,893 DEBUG TRAIN Batch 175/700 loss 0.028599 acc 0.978464 lr 0.00012140 grad_norm 0.374567 rank 0
2025-01-11 08:13:36,893 DEBUG TRAIN Batch 175/700 loss 0.029482 acc 0.978629 lr 0.00012140 grad_norm 0.374567 rank 1
2025-01-11 08:13:36,893 DEBUG TRAIN Batch 175/700 loss 0.023540 acc 0.984048 lr 0.00012140 grad_norm 0.374567 rank 2
2025-01-11 08:14:00,697 DEBUG TRAIN Batch 175/800 loss 0.007503 acc 0.997942 lr 0.00012139 grad_norm 0.344491 rank 0
2025-01-11 08:14:00,698 DEBUG TRAIN Batch 175/800 loss 0.025093 acc 0.985075 lr 0.00012139 grad_norm 0.344491 rank 1
2025-01-11 08:14:00,698 DEBUG TRAIN Batch 175/800 loss 0.032700 acc 0.974757 lr 0.00012139 grad_norm 0.344491 rank 2
2025-01-11 08:14:24,690 DEBUG TRAIN Batch 175/900 loss 0.030692 acc 0.976399 lr 0.00012137 grad_norm 0.372035 rank 0
2025-01-11 08:14:24,690 DEBUG TRAIN Batch 175/900 loss 0.022701 acc 0.983582 lr 0.00012137 grad_norm 0.372035 rank 1
2025-01-11 08:14:24,690 DEBUG TRAIN Batch 175/900 loss 0.034197 acc 0.974925 lr 0.00012137 grad_norm 0.372035 rank 2
2025-01-11 08:14:48,765 DEBUG TRAIN Batch 175/1000 loss 0.033346 acc 0.983425 lr 0.00012135 grad_norm 0.343990 rank 1
2025-01-11 08:14:48,765 DEBUG TRAIN Batch 175/1000 loss 0.019965 acc 0.986335 lr 0.00012135 grad_norm 0.343990 rank 0
2025-01-11 08:14:48,766 DEBUG TRAIN Batch 175/1000 loss 0.012626 acc 0.992318 lr 0.00012135 grad_norm 0.343990 rank 2
2025-01-11 08:15:13,908 DEBUG TRAIN Batch 175/1100 loss 0.035968 acc 0.976348 lr 0.00012133 grad_norm 0.376639 rank 0
2025-01-11 08:15:13,908 DEBUG TRAIN Batch 175/1100 loss 0.023299 acc 0.983626 lr 0.00012133 grad_norm 0.376639 rank 1
2025-01-11 08:15:13,909 DEBUG TRAIN Batch 175/1100 loss 0.017809 acc 0.985222 lr 0.00012133 grad_norm 0.376639 rank 2
2025-01-11 08:15:38,684 DEBUG TRAIN Batch 175/1200 loss 0.023081 acc 0.983240 lr 0.00012131 grad_norm 0.341849 rank 0
2025-01-11 08:15:38,684 DEBUG TRAIN Batch 175/1200 loss 0.015170 acc 0.990415 lr 0.00012131 grad_norm 0.341849 rank 1
2025-01-11 08:15:38,685 DEBUG TRAIN Batch 175/1200 loss 0.016341 acc 0.986667 lr 0.00012131 grad_norm 0.341849 rank 2
2025-01-11 08:16:02,932 DEBUG TRAIN Batch 175/1300 loss 0.029583 acc 0.981149 lr 0.00012130 grad_norm 0.373079 rank 0
2025-01-11 08:16:02,932 DEBUG TRAIN Batch 175/1300 loss 0.030039 acc 0.976331 lr 0.00012130 grad_norm 0.373079 rank 1
2025-01-11 08:16:02,933 DEBUG TRAIN Batch 175/1300 loss 0.027568 acc 0.980655 lr 0.00012130 grad_norm 0.373079 rank 2
2025-01-11 08:16:27,018 DEBUG TRAIN Batch 175/1400 loss 0.036540 acc 0.975262 lr 0.00012128 grad_norm 0.364835 rank 0
2025-01-11 08:16:27,018 DEBUG TRAIN Batch 175/1400 loss 0.035820 acc 0.982051 lr 0.00012128 grad_norm 0.364835 rank 2
2025-01-11 08:16:27,019 DEBUG TRAIN Batch 175/1400 loss 0.024309 acc 0.986193 lr 0.00012128 grad_norm 0.364835 rank 1
2025-01-11 08:16:51,963 DEBUG TRAIN Batch 175/1500 loss 0.030738 acc 0.976695 lr 0.00012126 grad_norm 0.386807 rank 1
2025-01-11 08:16:51,963 DEBUG TRAIN Batch 175/1500 loss 0.038289 acc 0.973294 lr 0.00012126 grad_norm 0.386807 rank 0
2025-01-11 08:16:51,963 DEBUG TRAIN Batch 175/1500 loss 0.032110 acc 0.979167 lr 0.00012126 grad_norm 0.386807 rank 2
2025-01-11 08:17:16,088 DEBUG TRAIN Batch 175/1600 loss 0.030909 acc 0.977384 lr 0.00012124 grad_norm 0.366032 rank 0
2025-01-11 08:17:16,089 DEBUG TRAIN Batch 175/1600 loss 0.024163 acc 0.979757 lr 0.00012124 grad_norm 0.366032 rank 1
2025-01-11 08:17:16,089 DEBUG TRAIN Batch 175/1600 loss 0.020163 acc 0.984632 lr 0.00012124 grad_norm 0.366032 rank 2
2025-01-11 08:17:41,336 DEBUG TRAIN Batch 175/1700 loss 0.015004 acc 0.988581 lr 0.00012122 grad_norm 0.360992 rank 2
2025-01-11 08:17:41,336 DEBUG TRAIN Batch 175/1700 loss 0.029550 acc 0.979296 lr 0.00012122 grad_norm 0.360992 rank 0
2025-01-11 08:17:41,337 DEBUG TRAIN Batch 175/1700 loss 0.027536 acc 0.981973 lr 0.00012122 grad_norm 0.360992 rank 1
2025-01-11 08:18:06,006 DEBUG TRAIN Batch 175/1800 loss 0.019120 acc 0.987261 lr 0.00012121 grad_norm 0.369192 rank 1
2025-01-11 08:18:06,006 DEBUG TRAIN Batch 175/1800 loss 0.026870 acc 0.980146 lr 0.00012121 grad_norm 0.369192 rank 0
2025-01-11 08:18:06,007 DEBUG TRAIN Batch 175/1800 loss 0.021726 acc 0.981663 lr 0.00012121 grad_norm 0.369192 rank 2
2025-01-11 08:18:31,413 DEBUG TRAIN Batch 175/1900 loss 0.031039 acc 0.979146 lr 0.00012119 grad_norm 0.352602 rank 0
2025-01-11 08:18:31,413 DEBUG TRAIN Batch 175/1900 loss 0.033464 acc 0.977876 lr 0.00012119 grad_norm 0.352602 rank 1
2025-01-11 08:18:31,413 DEBUG TRAIN Batch 175/1900 loss 0.024016 acc 0.983463 lr 0.00012119 grad_norm 0.352602 rank 2
2025-01-11 08:18:55,336 DEBUG TRAIN Batch 175/2000 loss 0.020174 acc 0.983949 lr 0.00012117 grad_norm 0.410274 rank 0
2025-01-11 08:18:55,337 DEBUG TRAIN Batch 175/2000 loss 0.033871 acc 0.974708 lr 0.00012117 grad_norm 0.410274 rank 1
2025-01-11 08:18:55,337 DEBUG TRAIN Batch 175/2000 loss 0.028674 acc 0.981838 lr 0.00012117 grad_norm 0.410274 rank 2
2025-01-11 08:19:19,465 DEBUG TRAIN Batch 175/2100 loss 0.040244 acc 0.970175 lr 0.00012115 grad_norm 0.401416 rank 1
2025-01-11 08:19:19,465 DEBUG TRAIN Batch 175/2100 loss 0.030116 acc 0.978652 lr 0.00012115 grad_norm 0.401416 rank 0
2025-01-11 08:19:19,466 DEBUG TRAIN Batch 175/2100 loss 0.033350 acc 0.973822 lr 0.00012115 grad_norm 0.401416 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 08:20:33,351 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59988ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 08:20:33,365 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 08:20:33,701 INFO Epoch 175 Step 170350 on_batch_end True CV rank 1
2025-01-11 08:20:33,701 INFO Epoch 175 Step 170350 on_batch_end True CV rank 0
2025-01-11 08:20:33,701 INFO Epoch 175 Step 170350 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 08:20:42,754 DEBUG CV Batch 175/100 loss 0.001758 acc 1.000000  rank 0
2025-01-11 08:20:43,061 DEBUG CV Batch 175/100 loss 0.001758 acc 1.000000  rank 2
2025-01-11 08:20:43,222 DEBUG CV Batch 175/100 loss 0.001758 acc 1.000000  rank 1
2025-01-11 08:20:43,270 INFO Epoch 175 Step 170350 CV info lr 0.00012114317043433485 0 rank loss_2.723073647888349 acc_0.7807008170506411
2025-01-11 08:20:43,590 INFO Epoch 175 Step 170350 CV info lr 0.00012114317043433485 2 rank loss_2.723073647888349 acc_0.7807008170506411
2025-01-11 08:20:43,758 INFO Epoch 175 Step 170350 CV info lr 0.00012114317043433485 1 rank loss_2.723073647888349 acc_0.7807008170506411
2025-01-11 08:20:44,573 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_175_whole.pt
2025-01-11 08:20:44,595 INFO Added key: store_based_barrier_key:178 to store for rank: 0
2025-01-11 08:20:44,605 INFO Added key: store_based_barrier_key:178 to store for rank: 2
2025-01-11 08:20:44,605 INFO Added key: store_based_barrier_key:178 to store for rank: 1
2025-01-11 08:20:44,606 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:178 with 3 nodes.
2025-01-11 08:20:44,606 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:178 with 3 nodes.
2025-01-11 08:20:44,609 INFO Epoch 176 TRAIN info lr 0.00012114317043433485 rank 1
2025-01-11 08:20:44,609 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 08:20:44,615 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:178 with 3 nodes.
2025-01-11 08:20:44,616 INFO Epoch 176 TRAIN info lr 0.00012114317043433485 rank 2
2025-01-11 08:20:44,616 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 08:20:44,622 INFO Epoch 176 TRAIN info lr 0.00012114317043433485 rank 0
2025-01-11 08:20:44,622 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 08:21:15,324 DEBUG TRAIN Batch 176/100 loss 0.022644 acc 0.982961 lr 0.00012113 grad_norm 0.346305 rank 0
2025-01-11 08:21:15,325 DEBUG TRAIN Batch 176/100 loss 0.019947 acc 0.989177 lr 0.00012113 grad_norm 0.346305 rank 2
2025-01-11 08:21:15,325 DEBUG TRAIN Batch 176/100 loss 0.023144 acc 0.982075 lr 0.00012113 grad_norm 0.346305 rank 1
2025-01-11 08:21:39,140 DEBUG TRAIN Batch 176/200 loss 0.028345 acc 0.978320 lr 0.00012111 grad_norm 0.370829 rank 2
2025-01-11 08:21:39,141 DEBUG TRAIN Batch 176/200 loss 0.023292 acc 0.985022 lr 0.00012111 grad_norm 0.370829 rank 0
2025-01-11 08:21:39,141 DEBUG TRAIN Batch 176/200 loss 0.030225 acc 0.976592 lr 0.00012111 grad_norm 0.370829 rank 1
2025-01-11 08:22:02,748 DEBUG TRAIN Batch 176/300 loss 0.032734 acc 0.975297 lr 0.00012109 grad_norm 0.343061 rank 2
2025-01-11 08:22:02,748 DEBUG TRAIN Batch 176/300 loss 0.020441 acc 0.985915 lr 0.00012109 grad_norm 0.343061 rank 0
2025-01-11 08:22:02,749 DEBUG TRAIN Batch 176/300 loss 0.026617 acc 0.982260 lr 0.00012109 grad_norm 0.343061 rank 1
2025-01-11 08:22:26,628 DEBUG TRAIN Batch 176/400 loss 0.024218 acc 0.984060 lr 0.00012107 grad_norm 0.367389 rank 0
2025-01-11 08:22:26,628 DEBUG TRAIN Batch 176/400 loss 0.019450 acc 0.985112 lr 0.00012107 grad_norm 0.367389 rank 1
2025-01-11 08:22:26,629 DEBUG TRAIN Batch 176/400 loss 0.025320 acc 0.986250 lr 0.00012107 grad_norm 0.367389 rank 2
2025-01-11 08:22:51,294 DEBUG TRAIN Batch 176/500 loss 0.025494 acc 0.980971 lr 0.00012105 grad_norm 0.341628 rank 0
2025-01-11 08:22:51,294 DEBUG TRAIN Batch 176/500 loss 0.030515 acc 0.981870 lr 0.00012105 grad_norm 0.341628 rank 1
2025-01-11 08:22:51,295 DEBUG TRAIN Batch 176/500 loss 0.011855 acc 0.993355 lr 0.00012105 grad_norm 0.341628 rank 2
2025-01-11 08:23:16,409 DEBUG TRAIN Batch 176/600 loss 0.030439 acc 0.980603 lr 0.00012104 grad_norm 0.370070 rank 0
2025-01-11 08:23:16,409 DEBUG TRAIN Batch 176/600 loss 0.018089 acc 0.987055 lr 0.00012104 grad_norm 0.370070 rank 1
2025-01-11 08:23:16,409 DEBUG TRAIN Batch 176/600 loss 0.023532 acc 0.982601 lr 0.00012104 grad_norm 0.370070 rank 2
2025-01-11 08:23:40,600 DEBUG TRAIN Batch 176/700 loss 0.019783 acc 0.985653 lr 0.00012102 grad_norm 0.346042 rank 1
2025-01-11 08:23:40,600 DEBUG TRAIN Batch 176/700 loss 0.029638 acc 0.975851 lr 0.00012102 grad_norm 0.346042 rank 2
2025-01-11 08:23:40,601 DEBUG TRAIN Batch 176/700 loss 0.017996 acc 0.987952 lr 0.00012102 grad_norm 0.346042 rank 0
2025-01-11 08:24:05,165 DEBUG TRAIN Batch 176/800 loss 0.029219 acc 0.979218 lr 0.00012100 grad_norm 0.350256 rank 1
2025-01-11 08:24:05,166 DEBUG TRAIN Batch 176/800 loss 0.026586 acc 0.982857 lr 0.00012100 grad_norm 0.350256 rank 2
2025-01-11 08:24:05,166 DEBUG TRAIN Batch 176/800 loss 0.025668 acc 0.980583 lr 0.00012100 grad_norm 0.350256 rank 0
2025-01-11 08:24:30,361 DEBUG TRAIN Batch 176/900 loss 0.030378 acc 0.979188 lr 0.00012098 grad_norm 0.394110 rank 1
2025-01-11 08:24:30,361 DEBUG TRAIN Batch 176/900 loss 0.024029 acc 0.983607 lr 0.00012098 grad_norm 0.394110 rank 0
2025-01-11 08:24:30,361 DEBUG TRAIN Batch 176/900 loss 0.014288 acc 0.990669 lr 0.00012098 grad_norm 0.394110 rank 2
2025-01-11 08:24:54,579 DEBUG TRAIN Batch 176/1000 loss 0.038637 acc 0.975938 lr 0.00012097 grad_norm 0.356137 rank 0
2025-01-11 08:24:54,579 DEBUG TRAIN Batch 176/1000 loss 0.019017 acc 0.983974 lr 0.00012097 grad_norm 0.356137 rank 1
2025-01-11 08:24:54,579 DEBUG TRAIN Batch 176/1000 loss 0.022556 acc 0.984329 lr 0.00012097 grad_norm 0.356137 rank 2
2025-01-11 08:25:19,576 DEBUG TRAIN Batch 176/1100 loss 0.046548 acc 0.971530 lr 0.00012095 grad_norm 0.339112 rank 2
2025-01-11 08:25:19,577 DEBUG TRAIN Batch 176/1100 loss 0.030091 acc 0.979636 lr 0.00012095 grad_norm 0.339112 rank 0
2025-01-11 08:25:19,577 DEBUG TRAIN Batch 176/1100 loss 0.005496 acc 0.998305 lr 0.00012095 grad_norm 0.339112 rank 1
2025-01-11 08:25:43,510 DEBUG TRAIN Batch 176/1200 loss 0.038277 acc 0.975065 lr 0.00012093 grad_norm 0.363709 rank 0
2025-01-11 08:25:43,510 DEBUG TRAIN Batch 176/1200 loss 0.021014 acc 0.984127 lr 0.00012093 grad_norm 0.363709 rank 2
2025-01-11 08:25:43,512 DEBUG TRAIN Batch 176/1200 loss 0.015587 acc 0.989521 lr 0.00012093 grad_norm 0.363709 rank 1
2025-01-11 08:26:08,372 DEBUG TRAIN Batch 176/1300 loss 0.021781 acc 0.983373 lr 0.00012091 grad_norm 0.364171 rank 0
2025-01-11 08:26:08,372 DEBUG TRAIN Batch 176/1300 loss 0.024617 acc 0.986894 lr 0.00012091 grad_norm 0.364171 rank 1
2025-01-11 08:26:08,372 DEBUG TRAIN Batch 176/1300 loss 0.042340 acc 0.974382 lr 0.00012091 grad_norm 0.364171 rank 2
2025-01-11 08:26:34,000 DEBUG TRAIN Batch 176/1400 loss 0.039809 acc 0.971930 lr 0.00012090 grad_norm 0.377791 rank 2
2025-01-11 08:26:34,000 DEBUG TRAIN Batch 176/1400 loss 0.026149 acc 0.981361 lr 0.00012090 grad_norm 0.377791 rank 1
2025-01-11 08:26:34,000 DEBUG TRAIN Batch 176/1400 loss 0.025722 acc 0.980666 lr 0.00012090 grad_norm 0.377791 rank 0
2025-01-11 08:26:57,742 DEBUG TRAIN Batch 176/1500 loss 0.023996 acc 0.981785 lr 0.00012088 grad_norm 0.382137 rank 0
2025-01-11 08:26:57,742 DEBUG TRAIN Batch 176/1500 loss 0.032538 acc 0.979000 lr 0.00012088 grad_norm 0.382137 rank 1
2025-01-11 08:26:57,742 DEBUG TRAIN Batch 176/1500 loss 0.028604 acc 0.980796 lr 0.00012088 grad_norm 0.382137 rank 2
2025-01-11 08:27:22,249 DEBUG TRAIN Batch 176/1600 loss 0.029466 acc 0.976852 lr 0.00012086 grad_norm 0.363319 rank 2
2025-01-11 08:27:22,249 DEBUG TRAIN Batch 176/1600 loss 0.032837 acc 0.982226 lr 0.00012086 grad_norm 0.363319 rank 0
2025-01-11 08:27:22,249 DEBUG TRAIN Batch 176/1600 loss 0.028033 acc 0.979130 lr 0.00012086 grad_norm 0.363319 rank 1
2025-01-11 08:27:45,745 DEBUG TRAIN Batch 176/1700 loss 0.016604 acc 0.989767 lr 0.00012084 grad_norm 0.353555 rank 0
2025-01-11 08:27:45,745 DEBUG TRAIN Batch 176/1700 loss 0.034811 acc 0.975948 lr 0.00012084 grad_norm 0.353555 rank 2
2025-01-11 08:27:45,745 DEBUG TRAIN Batch 176/1700 loss 0.033067 acc 0.977359 lr 0.00012084 grad_norm 0.353555 rank 1
2025-01-11 08:28:09,692 DEBUG TRAIN Batch 176/1800 loss 0.018959 acc 0.989247 lr 0.00012082 grad_norm 0.348837 rank 1
2025-01-11 08:28:09,692 DEBUG TRAIN Batch 176/1800 loss 0.031892 acc 0.979550 lr 0.00012082 grad_norm 0.348837 rank 0
2025-01-11 08:28:09,692 DEBUG TRAIN Batch 176/1800 loss 0.030423 acc 0.982063 lr 0.00012082 grad_norm 0.348837 rank 2
2025-01-11 08:28:33,310 DEBUG TRAIN Batch 176/1900 loss 0.022911 acc 0.984688 lr 0.00012081 grad_norm 0.384120 rank 0
2025-01-11 08:28:33,310 DEBUG TRAIN Batch 176/1900 loss 0.033845 acc 0.973817 lr 0.00012081 grad_norm 0.384120 rank 2
2025-01-11 08:28:33,310 DEBUG TRAIN Batch 176/1900 loss 0.019005 acc 0.988485 lr 0.00012081 grad_norm 0.384120 rank 1
2025-01-11 08:28:57,035 DEBUG TRAIN Batch 176/2000 loss 0.020241 acc 0.985112 lr 0.00012079 grad_norm 0.369959 rank 0
2025-01-11 08:28:57,035 DEBUG TRAIN Batch 176/2000 loss 0.035282 acc 0.978629 lr 0.00012079 grad_norm 0.369959 rank 1
2025-01-11 08:28:57,035 DEBUG TRAIN Batch 176/2000 loss 0.026732 acc 0.981876 lr 0.00012079 grad_norm 0.369959 rank 2
2025-01-11 08:29:20,723 DEBUG TRAIN Batch 176/2100 loss 0.033814 acc 0.977633 lr 0.00012077 grad_norm 0.369652 rank 0
2025-01-11 08:29:20,724 DEBUG TRAIN Batch 176/2100 loss 0.022510 acc 0.989484 lr 0.00012077 grad_norm 0.369652 rank 2
2025-01-11 08:29:20,724 DEBUG TRAIN Batch 176/2100 loss 0.025379 acc 0.984503 lr 0.00012077 grad_norm 0.369652 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 08:30:31,637 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 08:30:31,679 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 08:30:32,042 INFO Epoch 176 Step 171422 on_batch_end True CV rank 2
2025-01-11 08:30:32,042 INFO Epoch 176 Step 171422 on_batch_end True CV rank 0
2025-01-11 08:30:32,043 INFO Epoch 176 Step 171422 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 08:30:41,053 DEBUG CV Batch 176/100 loss 0.000804 acc 1.000000  rank 0
2025-01-11 08:30:41,291 DEBUG CV Batch 176/100 loss 0.000804 acc 1.000000  rank 2
2025-01-11 08:30:41,572 INFO Epoch 176 Step 171422 CV info lr 0.00012076378754635568 0 rank loss_2.7327319357628816 acc_0.7806589726293296
2025-01-11 08:30:41,665 DEBUG CV Batch 176/100 loss 0.000804 acc 1.000000  rank 1
2025-01-11 08:30:41,836 INFO Epoch 176 Step 171422 CV info lr 0.00012076378754635568 2 rank loss_2.7327319357628816 acc_0.7806589726293296
2025-01-11 08:30:42,205 INFO Epoch 176 Step 171422 CV info lr 0.00012076378754635568 1 rank loss_2.7327319357628816 acc_0.7806589726293296
2025-01-11 08:30:42,861 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_176_whole.pt
2025-01-11 08:30:42,873 INFO Added key: store_based_barrier_key:179 to store for rank: 0
2025-01-11 08:30:42,883 INFO Added key: store_based_barrier_key:179 to store for rank: 2
2025-01-11 08:30:42,883 INFO Added key: store_based_barrier_key:179 to store for rank: 1
2025-01-11 08:30:42,883 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:179 with 3 nodes.
2025-01-11 08:30:42,883 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:179 with 3 nodes.
2025-01-11 08:30:42,888 INFO Epoch 177 TRAIN info lr 0.00012076378754635568 rank 2
2025-01-11 08:30:42,888 INFO Epoch 177 TRAIN info lr 0.00012076378754635568 rank 1
2025-01-11 08:30:42,888 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 08:30:42,888 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 08:30:42,893 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:179 with 3 nodes.
2025-01-11 08:30:42,896 INFO Epoch 177 TRAIN info lr 0.00012076378754635568 rank 0
2025-01-11 08:30:42,897 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 08:31:16,619 DEBUG TRAIN Batch 177/100 loss 0.030973 acc 0.975345 lr 0.00012075 grad_norm 0.362598 rank 2
2025-01-11 08:31:16,619 DEBUG TRAIN Batch 177/100 loss 0.028995 acc 0.981835 lr 0.00012075 grad_norm 0.362598 rank 0
2025-01-11 08:31:16,619 DEBUG TRAIN Batch 177/100 loss 0.021799 acc 0.986373 lr 0.00012075 grad_norm 0.362598 rank 1
2025-01-11 08:31:40,500 DEBUG TRAIN Batch 177/200 loss 0.022189 acc 0.987966 lr 0.00012073 grad_norm 0.354960 rank 2
2025-01-11 08:31:40,500 DEBUG TRAIN Batch 177/200 loss 0.029968 acc 0.980464 lr 0.00012073 grad_norm 0.354960 rank 0
2025-01-11 08:31:40,501 DEBUG TRAIN Batch 177/200 loss 0.014124 acc 0.991217 lr 0.00012073 grad_norm 0.354960 rank 1
2025-01-11 08:32:04,318 DEBUG TRAIN Batch 177/300 loss 0.026093 acc 0.982692 lr 0.00012071 grad_norm 0.355593 rank 2
2025-01-11 08:32:04,318 DEBUG TRAIN Batch 177/300 loss 0.033540 acc 0.977143 lr 0.00012071 grad_norm 0.355593 rank 1
2025-01-11 08:32:04,318 DEBUG TRAIN Batch 177/300 loss 0.026879 acc 0.983547 lr 0.00012071 grad_norm 0.355593 rank 0
2025-01-11 08:32:28,407 DEBUG TRAIN Batch 177/400 loss 0.025964 acc 0.982517 lr 0.00012069 grad_norm 0.380690 rank 0
2025-01-11 08:32:28,407 DEBUG TRAIN Batch 177/400 loss 0.034433 acc 0.976264 lr 0.00012069 grad_norm 0.380690 rank 1
2025-01-11 08:32:28,407 DEBUG TRAIN Batch 177/400 loss 0.023526 acc 0.981375 lr 0.00012069 grad_norm 0.380690 rank 2
2025-01-11 08:32:52,494 DEBUG TRAIN Batch 177/500 loss 0.031373 acc 0.978887 lr 0.00012068 grad_norm 0.349000 rank 0
2025-01-11 08:32:52,494 DEBUG TRAIN Batch 177/500 loss 0.024818 acc 0.978220 lr 0.00012068 grad_norm 0.349000 rank 1
2025-01-11 08:32:52,494 DEBUG TRAIN Batch 177/500 loss 0.026346 acc 0.981779 lr 0.00012068 grad_norm 0.349000 rank 2
2025-01-11 08:33:16,292 DEBUG TRAIN Batch 177/600 loss 0.034034 acc 0.983070 lr 0.00012066 grad_norm 0.383903 rank 0
2025-01-11 08:33:16,292 DEBUG TRAIN Batch 177/600 loss 0.033355 acc 0.974427 lr 0.00012066 grad_norm 0.383903 rank 1
2025-01-11 08:33:16,292 DEBUG TRAIN Batch 177/600 loss 0.018922 acc 0.987952 lr 0.00012066 grad_norm 0.383903 rank 2
2025-01-11 08:33:41,017 DEBUG TRAIN Batch 177/700 loss 0.027160 acc 0.980090 lr 0.00012064 grad_norm 0.365399 rank 0
2025-01-11 08:33:41,017 DEBUG TRAIN Batch 177/700 loss 0.027199 acc 0.980063 lr 0.00012064 grad_norm 0.365399 rank 1
2025-01-11 08:33:41,017 DEBUG TRAIN Batch 177/700 loss 0.028896 acc 0.985577 lr 0.00012064 grad_norm 0.365399 rank 2
2025-01-11 08:34:05,895 DEBUG TRAIN Batch 177/800 loss 0.011439 acc 0.989766 lr 0.00012062 grad_norm 0.373518 rank 2
2025-01-11 08:34:05,895 DEBUG TRAIN Batch 177/800 loss 0.021065 acc 0.989919 lr 0.00012062 grad_norm 0.373518 rank 1
2025-01-11 08:34:05,895 DEBUG TRAIN Batch 177/800 loss 0.033395 acc 0.975904 lr 0.00012062 grad_norm 0.373518 rank 0
2025-01-11 08:34:30,321 DEBUG TRAIN Batch 177/900 loss 0.028899 acc 0.979432 lr 0.00012061 grad_norm 0.362106 rank 0
2025-01-11 08:34:30,321 DEBUG TRAIN Batch 177/900 loss 0.025267 acc 0.987437 lr 0.00012061 grad_norm 0.362106 rank 1
2025-01-11 08:34:30,321 DEBUG TRAIN Batch 177/900 loss 0.027124 acc 0.981030 lr 0.00012061 grad_norm 0.362106 rank 2
2025-01-11 08:34:54,737 DEBUG TRAIN Batch 177/1000 loss 0.021936 acc 0.987052 lr 0.00012059 grad_norm 0.358364 rank 1
2025-01-11 08:34:54,737 DEBUG TRAIN Batch 177/1000 loss 0.023754 acc 0.979691 lr 0.00012059 grad_norm 0.358364 rank 0
2025-01-11 08:34:54,737 DEBUG TRAIN Batch 177/1000 loss 0.035582 acc 0.975000 lr 0.00012059 grad_norm 0.358364 rank 2
2025-01-11 08:35:18,777 DEBUG TRAIN Batch 177/1100 loss 0.023385 acc 0.980328 lr 0.00012057 grad_norm 0.357133 rank 1
2025-01-11 08:35:18,778 DEBUG TRAIN Batch 177/1100 loss 0.018035 acc 0.987026 lr 0.00012057 grad_norm 0.357133 rank 0
2025-01-11 08:35:18,778 DEBUG TRAIN Batch 177/1100 loss 0.024546 acc 0.983034 lr 0.00012057 grad_norm 0.357133 rank 2
2025-01-11 08:35:42,895 DEBUG TRAIN Batch 177/1200 loss 0.026430 acc 0.984260 lr 0.00012055 grad_norm 0.325506 rank 0
2025-01-11 08:35:42,895 DEBUG TRAIN Batch 177/1200 loss 0.027817 acc 0.977297 lr 0.00012055 grad_norm 0.325506 rank 2
2025-01-11 08:35:42,895 DEBUG TRAIN Batch 177/1200 loss 0.020321 acc 0.983479 lr 0.00012055 grad_norm 0.325506 rank 1
2025-01-11 08:36:07,105 DEBUG TRAIN Batch 177/1300 loss 0.029919 acc 0.980063 lr 0.00012054 grad_norm 0.360431 rank 0
2025-01-11 08:36:07,105 DEBUG TRAIN Batch 177/1300 loss 0.025470 acc 0.982092 lr 0.00012054 grad_norm 0.360431 rank 1
2025-01-11 08:36:07,105 DEBUG TRAIN Batch 177/1300 loss 0.029719 acc 0.976723 lr 0.00012054 grad_norm 0.360431 rank 2
2025-01-11 08:36:30,984 DEBUG TRAIN Batch 177/1400 loss 0.017763 acc 0.993344 lr 0.00012052 grad_norm 0.361167 rank 1
2025-01-11 08:36:30,984 DEBUG TRAIN Batch 177/1400 loss 0.023589 acc 0.984829 lr 0.00012052 grad_norm 0.361167 rank 0
2025-01-11 08:36:30,984 DEBUG TRAIN Batch 177/1400 loss 0.026809 acc 0.978682 lr 0.00012052 grad_norm 0.361167 rank 2
2025-01-11 08:36:54,449 DEBUG TRAIN Batch 177/1500 loss 0.021253 acc 0.991220 lr 0.00012050 grad_norm 0.343698 rank 2
2025-01-11 08:36:54,449 DEBUG TRAIN Batch 177/1500 loss 0.017095 acc 0.988048 lr 0.00012050 grad_norm 0.343698 rank 0
2025-01-11 08:36:54,449 DEBUG TRAIN Batch 177/1500 loss 0.032174 acc 0.978746 lr 0.00012050 grad_norm 0.343698 rank 1
2025-01-11 08:37:18,209 DEBUG TRAIN Batch 177/1600 loss 0.020912 acc 0.984552 lr 0.00012048 grad_norm 0.353178 rank 0
2025-01-11 08:37:18,209 DEBUG TRAIN Batch 177/1600 loss 0.012185 acc 0.991605 lr 0.00012048 grad_norm 0.353178 rank 2
2025-01-11 08:37:18,209 DEBUG TRAIN Batch 177/1600 loss 0.023650 acc 0.984655 lr 0.00012048 grad_norm 0.353178 rank 1
2025-01-11 08:37:42,856 DEBUG TRAIN Batch 177/1700 loss 0.009172 acc 0.994983 lr 0.00012047 grad_norm 0.380191 rank 0
2025-01-11 08:37:42,856 DEBUG TRAIN Batch 177/1700 loss 0.046485 acc 0.961772 lr 0.00012047 grad_norm 0.380191 rank 1
2025-01-11 08:37:42,856 DEBUG TRAIN Batch 177/1700 loss 0.023329 acc 0.980140 lr 0.00012047 grad_norm 0.380191 rank 2
2025-01-11 08:38:06,513 DEBUG TRAIN Batch 177/1800 loss 0.025181 acc 0.983631 lr 0.00012045 grad_norm 0.369081 rank 0
2025-01-11 08:38:06,513 DEBUG TRAIN Batch 177/1800 loss 0.041609 acc 0.970667 lr 0.00012045 grad_norm 0.369081 rank 1
2025-01-11 08:38:06,513 DEBUG TRAIN Batch 177/1800 loss 0.040055 acc 0.976723 lr 0.00012045 grad_norm 0.369081 rank 2
2025-01-11 08:38:30,692 DEBUG TRAIN Batch 177/1900 loss 0.030868 acc 0.979846 lr 0.00012043 grad_norm 0.350700 rank 2
2025-01-11 08:38:30,692 DEBUG TRAIN Batch 177/1900 loss 0.020314 acc 0.985056 lr 0.00012043 grad_norm 0.350700 rank 0
2025-01-11 08:38:30,692 DEBUG TRAIN Batch 177/1900 loss 0.033226 acc 0.973786 lr 0.00012043 grad_norm 0.350700 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 08:39:44,596 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 08:39:44,599 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 08:39:45,020 INFO Epoch 177 Step 172399 on_batch_end True CV rank 2
2025-01-11 08:39:45,020 INFO Epoch 177 Step 172399 on_batch_end True CV rank 0
2025-01-11 08:39:45,020 INFO Epoch 177 Step 172399 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 08:39:53,953 DEBUG CV Batch 177/100 loss 0.004973 acc 0.997770  rank 0
2025-01-11 08:39:54,362 DEBUG CV Batch 177/100 loss 0.004973 acc 0.997770  rank 2
2025-01-11 08:39:54,471 INFO Epoch 177 Step 172399 CV info lr 0.0001204211119644431 0 rank loss_2.7254161789007187 acc_0.7812357794558793
2025-01-11 08:39:54,682 DEBUG CV Batch 177/100 loss 0.004973 acc 0.997770  rank 1
2025-01-11 08:39:54,903 INFO Epoch 177 Step 172399 CV info lr 0.0001204211119644431 2 rank loss_2.7254161789007187 acc_0.7812357794558793
2025-01-11 08:39:55,218 INFO Epoch 177 Step 172399 CV info lr 0.0001204211119644431 1 rank loss_2.7254161789007187 acc_0.7812357794558793
2025-01-11 08:39:55,745 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_177_whole.pt
2025-01-11 08:39:55,767 INFO Added key: store_based_barrier_key:180 to store for rank: 0
2025-01-11 08:39:55,767 INFO Added key: store_based_barrier_key:180 to store for rank: 1
2025-01-11 08:39:55,767 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:180 with 3 nodes.
2025-01-11 08:39:55,768 INFO Added key: store_based_barrier_key:180 to store for rank: 2
2025-01-11 08:39:55,768 INFO Epoch 178 TRAIN info lr 0.0001204211119644431 rank 1
2025-01-11 08:39:55,768 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 08:39:55,768 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:180 with 3 nodes.
2025-01-11 08:39:55,772 INFO Epoch 178 TRAIN info lr 0.0001204211119644431 rank 2
2025-01-11 08:39:55,773 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 08:39:55,777 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:180 with 3 nodes.
2025-01-11 08:39:55,780 INFO Epoch 178 TRAIN info lr 0.0001204211119644431 rank 0
2025-01-11 08:39:55,780 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 08:40:28,451 DEBUG TRAIN Batch 178/100 loss 0.023113 acc 0.984581 lr 0.00012040 grad_norm 0.360064 rank 0
2025-01-11 08:40:28,451 DEBUG TRAIN Batch 178/100 loss 0.040561 acc 0.972279 lr 0.00012040 grad_norm 0.360064 rank 1
2025-01-11 08:40:28,451 DEBUG TRAIN Batch 178/100 loss 0.023512 acc 0.984710 lr 0.00012040 grad_norm 0.360064 rank 2
2025-01-11 08:40:52,379 DEBUG TRAIN Batch 178/200 loss 0.016345 acc 0.988506 lr 0.00012039 grad_norm 0.337215 rank 1
2025-01-11 08:40:52,380 DEBUG TRAIN Batch 178/200 loss 0.025364 acc 0.984813 lr 0.00012039 grad_norm 0.337215 rank 0
2025-01-11 08:40:52,380 DEBUG TRAIN Batch 178/200 loss 0.026403 acc 0.985915 lr 0.00012039 grad_norm 0.337215 rank 2
2025-01-11 08:41:16,348 DEBUG TRAIN Batch 178/300 loss 0.017275 acc 0.988836 lr 0.00012037 grad_norm 0.368555 rank 0
2025-01-11 08:41:16,348 DEBUG TRAIN Batch 178/300 loss 0.030448 acc 0.981000 lr 0.00012037 grad_norm 0.368555 rank 1
2025-01-11 08:41:16,348 DEBUG TRAIN Batch 178/300 loss 0.023823 acc 0.982648 lr 0.00012037 grad_norm 0.368555 rank 2
2025-01-11 08:41:40,508 DEBUG TRAIN Batch 178/400 loss 0.024287 acc 0.981207 lr 0.00012035 grad_norm 0.351970 rank 0
2025-01-11 08:41:40,508 DEBUG TRAIN Batch 178/400 loss 0.019748 acc 0.987978 lr 0.00012035 grad_norm 0.351970 rank 1
2025-01-11 08:41:40,509 DEBUG TRAIN Batch 178/400 loss 0.027853 acc 0.981964 lr 0.00012035 grad_norm 0.351970 rank 2
2025-01-11 08:42:04,317 DEBUG TRAIN Batch 178/500 loss 0.025911 acc 0.983543 lr 0.00012033 grad_norm 0.351652 rank 0
2025-01-11 08:42:04,317 DEBUG TRAIN Batch 178/500 loss 0.028045 acc 0.984531 lr 0.00012033 grad_norm 0.351652 rank 1
2025-01-11 08:42:04,318 DEBUG TRAIN Batch 178/500 loss 0.030917 acc 0.976697 lr 0.00012033 grad_norm 0.351652 rank 2
2025-01-11 08:42:28,609 DEBUG TRAIN Batch 178/600 loss 0.023530 acc 0.983505 lr 0.00012032 grad_norm 0.384269 rank 0
2025-01-11 08:42:28,609 DEBUG TRAIN Batch 178/600 loss 0.043306 acc 0.969965 lr 0.00012032 grad_norm 0.384269 rank 1
2025-01-11 08:42:28,609 DEBUG TRAIN Batch 178/600 loss 0.027701 acc 0.974277 lr 0.00012032 grad_norm 0.384269 rank 2
2025-01-11 08:42:52,872 DEBUG TRAIN Batch 178/700 loss 0.017967 acc 0.989160 lr 0.00012030 grad_norm 0.334493 rank 0
2025-01-11 08:42:52,872 DEBUG TRAIN Batch 178/700 loss 0.023930 acc 0.985222 lr 0.00012030 grad_norm 0.334493 rank 1
2025-01-11 08:42:52,872 DEBUG TRAIN Batch 178/700 loss 0.028750 acc 0.980806 lr 0.00012030 grad_norm 0.334493 rank 2
2025-01-11 08:43:17,003 DEBUG TRAIN Batch 178/800 loss 0.022648 acc 0.985089 lr 0.00012028 grad_norm 0.321953 rank 1
2025-01-11 08:43:17,004 DEBUG TRAIN Batch 178/800 loss 0.024056 acc 0.985437 lr 0.00012028 grad_norm 0.321953 rank 0
2025-01-11 08:43:17,004 DEBUG TRAIN Batch 178/800 loss 0.026146 acc 0.983855 lr 0.00012028 grad_norm 0.321953 rank 2
2025-01-11 08:43:41,059 DEBUG TRAIN Batch 178/900 loss 0.033389 acc 0.983871 lr 0.00012026 grad_norm 0.345214 rank 1
2025-01-11 08:43:41,059 DEBUG TRAIN Batch 178/900 loss 0.009623 acc 0.991667 lr 0.00012026 grad_norm 0.345214 rank 2
2025-01-11 08:43:41,059 DEBUG TRAIN Batch 178/900 loss 0.029628 acc 0.976661 lr 0.00012026 grad_norm 0.345214 rank 0
2025-01-11 08:44:05,805 DEBUG TRAIN Batch 178/1000 loss 0.033529 acc 0.983395 lr 0.00012025 grad_norm 0.372047 rank 1
2025-01-11 08:44:05,805 DEBUG TRAIN Batch 178/1000 loss 0.025065 acc 0.981768 lr 0.00012025 grad_norm 0.372047 rank 0
2025-01-11 08:44:05,806 DEBUG TRAIN Batch 178/1000 loss 0.039240 acc 0.973297 lr 0.00012025 grad_norm 0.372047 rank 2
2025-01-11 08:44:30,005 DEBUG TRAIN Batch 178/1100 loss 0.025372 acc 0.982422 lr 0.00012023 grad_norm 0.352044 rank 0
2025-01-11 08:44:30,006 DEBUG TRAIN Batch 178/1100 loss 0.018696 acc 0.987571 lr 0.00012023 grad_norm 0.352044 rank 1
2025-01-11 08:44:30,006 DEBUG TRAIN Batch 178/1100 loss 0.038989 acc 0.969896 lr 0.00012023 grad_norm 0.352044 rank 2
2025-01-11 08:44:54,008 DEBUG TRAIN Batch 178/1200 loss 0.026590 acc 0.980337 lr 0.00012021 grad_norm 0.346751 rank 0
2025-01-11 08:44:54,009 DEBUG TRAIN Batch 178/1200 loss 0.028270 acc 0.981855 lr 0.00012021 grad_norm 0.346751 rank 1
2025-01-11 08:44:54,009 DEBUG TRAIN Batch 178/1200 loss 0.018674 acc 0.983897 lr 0.00012021 grad_norm 0.346751 rank 2
2025-01-11 08:45:18,173 DEBUG TRAIN Batch 178/1300 loss 0.034748 acc 0.979293 lr 0.00012019 grad_norm 0.347751 rank 0
2025-01-11 08:45:18,174 DEBUG TRAIN Batch 178/1300 loss 0.015338 acc 0.990361 lr 0.00012019 grad_norm 0.347751 rank 1
2025-01-11 08:45:18,174 DEBUG TRAIN Batch 178/1300 loss 0.034290 acc 0.978887 lr 0.00012019 grad_norm 0.347751 rank 2
2025-01-11 08:45:42,228 DEBUG TRAIN Batch 178/1400 loss 0.030631 acc 0.975962 lr 0.00012018 grad_norm 0.380570 rank 1
2025-01-11 08:45:42,228 DEBUG TRAIN Batch 178/1400 loss 0.025605 acc 0.979429 lr 0.00012018 grad_norm 0.380570 rank 0
2025-01-11 08:45:42,228 DEBUG TRAIN Batch 178/1400 loss 0.031659 acc 0.976293 lr 0.00012018 grad_norm 0.380570 rank 2
2025-01-11 08:46:07,858 DEBUG TRAIN Batch 178/1500 loss 0.040730 acc 0.977093 lr 0.00012016 grad_norm 0.345303 rank 0
2025-01-11 08:46:07,859 DEBUG TRAIN Batch 178/1500 loss 0.032272 acc 0.980392 lr 0.00012016 grad_norm 0.345303 rank 2
2025-01-11 08:46:07,859 DEBUG TRAIN Batch 178/1500 loss 0.013562 acc 0.991814 lr 0.00012016 grad_norm 0.345303 rank 1
2025-01-11 08:46:31,149 DEBUG TRAIN Batch 178/1600 loss 0.032219 acc 0.977022 lr 0.00012014 grad_norm 0.362902 rank 1
2025-01-11 08:46:31,149 DEBUG TRAIN Batch 178/1600 loss 0.034642 acc 0.971082 lr 0.00012014 grad_norm 0.362902 rank 2
2025-01-11 08:46:31,277 DEBUG TRAIN Batch 178/1600 loss 0.021928 acc 0.983114 lr 0.00012014 grad_norm 0.362902 rank 0
2025-01-11 08:46:55,558 DEBUG TRAIN Batch 178/1700 loss 0.020430 acc 0.983607 lr 0.00012013 grad_norm 0.378719 rank 1
2025-01-11 08:46:55,558 DEBUG TRAIN Batch 178/1700 loss 0.039035 acc 0.974116 lr 0.00012013 grad_norm 0.378719 rank 0
2025-01-11 08:46:55,558 DEBUG TRAIN Batch 178/1700 loss 0.020055 acc 0.980583 lr 0.00012013 grad_norm 0.378719 rank 2
2025-01-11 08:47:20,285 DEBUG TRAIN Batch 178/1800 loss 0.030886 acc 0.978485 lr 0.00012011 grad_norm 0.369093 rank 0
2025-01-11 08:47:20,285 DEBUG TRAIN Batch 178/1800 loss 0.030734 acc 0.974383 lr 0.00012011 grad_norm 0.369093 rank 1
2025-01-11 08:47:20,285 DEBUG TRAIN Batch 178/1800 loss 0.032488 acc 0.978464 lr 0.00012011 grad_norm 0.369093 rank 2
2025-01-11 08:47:43,982 DEBUG TRAIN Batch 178/1900 loss 0.030657 acc 0.980787 lr 0.00012009 grad_norm 0.351191 rank 0
2025-01-11 08:47:43,982 DEBUG TRAIN Batch 178/1900 loss 0.027551 acc 0.980251 lr 0.00012009 grad_norm 0.351191 rank 1
2025-01-11 08:47:43,983 DEBUG TRAIN Batch 178/1900 loss 0.027569 acc 0.981354 lr 0.00012009 grad_norm 0.351191 rank 2
2025-01-11 08:48:08,493 DEBUG TRAIN Batch 178/2000 loss 0.032923 acc 0.972921 lr 0.00012007 grad_norm 0.338551 rank 0
2025-01-11 08:48:08,493 DEBUG TRAIN Batch 178/2000 loss 0.033000 acc 0.978238 lr 0.00012007 grad_norm 0.338551 rank 1
2025-01-11 08:48:08,493 DEBUG TRAIN Batch 178/2000 loss 0.021538 acc 0.980216 lr 0.00012007 grad_norm 0.338551 rank 2
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 08:49:29,255 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 08:49:29,258 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 08:49:29,667 INFO Epoch 178 Step 173443 on_batch_end True CV rank 0
2025-01-11 08:49:29,667 INFO Epoch 178 Step 173443 on_batch_end True CV rank 1
2025-01-11 08:49:29,667 INFO Epoch 178 Step 173443 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 08:49:38,936 DEBUG CV Batch 178/100 loss 0.003268 acc 0.998885  rank 0
2025-01-11 08:49:39,153 DEBUG CV Batch 178/100 loss 0.003268 acc 0.998885  rank 2
2025-01-11 08:49:39,391 DEBUG CV Batch 178/100 loss 0.003268 acc 0.998885  rank 1
2025-01-11 08:49:39,408 INFO Epoch 178 Step 173443 CV info lr 0.00012005814142803962 0 rank loss_2.723317080527506 acc_0.7810862329706811
2025-01-11 08:49:39,692 INFO Epoch 178 Step 173443 CV info lr 0.00012005814142803962 2 rank loss_2.723317080527506 acc_0.7810862329706811
2025-01-11 08:49:39,927 INFO Epoch 178 Step 173443 CV info lr 0.00012005814142803962 1 rank loss_2.723317080527506 acc_0.7810862329706811
2025-01-11 08:49:40,681 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_178_whole.pt
2025-01-11 08:49:40,692 INFO Added key: store_based_barrier_key:181 to store for rank: 0
2025-01-11 08:49:40,702 INFO Added key: store_based_barrier_key:181 to store for rank: 2
2025-01-11 08:49:40,703 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:181 with 3 nodes.
2025-01-11 08:49:40,703 INFO Added key: store_based_barrier_key:181 to store for rank: 1
2025-01-11 08:49:40,703 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:181 with 3 nodes.
2025-01-11 08:49:40,706 INFO Epoch 179 TRAIN info lr 0.00012005814142803962 rank 1
2025-01-11 08:49:40,706 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 08:49:40,709 INFO Epoch 179 TRAIN info lr 0.00012005814142803962 rank 2
2025-01-11 08:49:40,709 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 08:49:40,713 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:181 with 3 nodes.
2025-01-11 08:49:40,714 INFO Epoch 179 TRAIN info lr 0.00012005814142803962 rank 0
2025-01-11 08:49:40,714 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 08:50:11,585 DEBUG TRAIN Batch 179/100 loss 0.033308 acc 0.980932 lr 0.00012004 grad_norm 0.363769 rank 2
2025-01-11 08:50:11,585 DEBUG TRAIN Batch 179/100 loss 0.027751 acc 0.984740 lr 0.00012004 grad_norm 0.363769 rank 1
2025-01-11 08:50:11,586 DEBUG TRAIN Batch 179/100 loss 0.023929 acc 0.984211 lr 0.00012004 grad_norm 0.363769 rank 0
2025-01-11 08:50:35,473 DEBUG TRAIN Batch 179/200 loss 0.017862 acc 0.987113 lr 0.00012002 grad_norm 0.385071 rank 2
2025-01-11 08:50:35,474 DEBUG TRAIN Batch 179/200 loss 0.021672 acc 0.982500 lr 0.00012002 grad_norm 0.385071 rank 0
2025-01-11 08:50:35,474 DEBUG TRAIN Batch 179/200 loss 0.026871 acc 0.984267 lr 0.00012002 grad_norm 0.385071 rank 1
2025-01-11 08:50:58,787 DEBUG TRAIN Batch 179/300 loss 0.028906 acc 0.974310 lr 0.00012001 grad_norm 0.354379 rank 2
2025-01-11 08:50:58,788 DEBUG TRAIN Batch 179/300 loss 0.022155 acc 0.984503 lr 0.00012001 grad_norm 0.354379 rank 1
2025-01-11 08:50:58,788 DEBUG TRAIN Batch 179/300 loss 0.026543 acc 0.980564 lr 0.00012001 grad_norm 0.354379 rank 0
2025-01-11 08:51:22,318 DEBUG TRAIN Batch 179/400 loss 0.028624 acc 0.978439 lr 0.00011999 grad_norm 0.344479 rank 2
2025-01-11 08:51:22,319 DEBUG TRAIN Batch 179/400 loss 0.022161 acc 0.986301 lr 0.00011999 grad_norm 0.344479 rank 1
2025-01-11 08:51:22,319 DEBUG TRAIN Batch 179/400 loss 0.025553 acc 0.983051 lr 0.00011999 grad_norm 0.344479 rank 0
2025-01-11 08:51:46,134 DEBUG TRAIN Batch 179/500 loss 0.033908 acc 0.980861 lr 0.00011997 grad_norm 0.325524 rank 1
2025-01-11 08:51:46,134 DEBUG TRAIN Batch 179/500 loss 0.022058 acc 0.986147 lr 0.00011997 grad_norm 0.325524 rank 2
2025-01-11 08:51:46,135 DEBUG TRAIN Batch 179/500 loss 0.036394 acc 0.975871 lr 0.00011997 grad_norm 0.325524 rank 0
2025-01-11 08:52:09,543 DEBUG TRAIN Batch 179/600 loss 0.023869 acc 0.983621 lr 0.00011995 grad_norm 0.334051 rank 2
2025-01-11 08:52:09,543 DEBUG TRAIN Batch 179/600 loss 0.034645 acc 0.977431 lr 0.00011995 grad_norm 0.334051 rank 0
2025-01-11 08:52:09,543 DEBUG TRAIN Batch 179/600 loss 0.023831 acc 0.982974 lr 0.00011995 grad_norm 0.334051 rank 1
2025-01-11 08:52:34,446 DEBUG TRAIN Batch 179/700 loss 0.026405 acc 0.986381 lr 0.00011994 grad_norm 0.342668 rank 1
2025-01-11 08:52:34,446 DEBUG TRAIN Batch 179/700 loss 0.029360 acc 0.981250 lr 0.00011994 grad_norm 0.342668 rank 0
2025-01-11 08:52:34,522 DEBUG TRAIN Batch 179/700 loss 0.027794 acc 0.975871 lr 0.00011994 grad_norm 0.342668 rank 2
2025-01-11 08:52:57,778 DEBUG TRAIN Batch 179/800 loss 0.031396 acc 0.977978 lr 0.00011992 grad_norm 0.350776 rank 2
2025-01-11 08:52:57,778 DEBUG TRAIN Batch 179/800 loss 0.024506 acc 0.977517 lr 0.00011992 grad_norm 0.350776 rank 0
2025-01-11 08:52:57,778 DEBUG TRAIN Batch 179/800 loss 0.017042 acc 0.987903 lr 0.00011992 grad_norm 0.350776 rank 1
2025-01-11 08:53:21,854 DEBUG TRAIN Batch 179/900 loss 0.018618 acc 0.986486 lr 0.00011990 grad_norm 0.349371 rank 2
2025-01-11 08:53:21,854 DEBUG TRAIN Batch 179/900 loss 0.032250 acc 0.979788 lr 0.00011990 grad_norm 0.349371 rank 0
2025-01-11 08:53:21,854 DEBUG TRAIN Batch 179/900 loss 0.013846 acc 0.991525 lr 0.00011990 grad_norm 0.349371 rank 1
2025-01-11 08:53:45,913 DEBUG TRAIN Batch 179/1000 loss 0.025767 acc 0.979633 lr 0.00011989 grad_norm 0.351339 rank 0
2025-01-11 08:53:45,913 DEBUG TRAIN Batch 179/1000 loss 0.027675 acc 0.981718 lr 0.00011989 grad_norm 0.351339 rank 1
2025-01-11 08:53:45,913 DEBUG TRAIN Batch 179/1000 loss 0.023007 acc 0.985213 lr 0.00011989 grad_norm 0.351339 rank 2
2025-01-11 08:54:09,536 DEBUG TRAIN Batch 179/1100 loss 0.026550 acc 0.981267 lr 0.00011987 grad_norm 0.363995 rank 0
2025-01-11 08:54:09,536 DEBUG TRAIN Batch 179/1100 loss 0.029570 acc 0.982318 lr 0.00011987 grad_norm 0.363995 rank 2
2025-01-11 08:54:09,539 DEBUG TRAIN Batch 179/1100 loss 0.022230 acc 0.983264 lr 0.00011987 grad_norm 0.363995 rank 1
2025-01-11 08:54:33,313 DEBUG TRAIN Batch 179/1200 loss 0.028128 acc 0.979265 lr 0.00011985 grad_norm 0.364850 rank 1
2025-01-11 08:54:33,314 DEBUG TRAIN Batch 179/1200 loss 0.017797 acc 0.985468 lr 0.00011985 grad_norm 0.364850 rank 2
2025-01-11 08:54:33,314 DEBUG TRAIN Batch 179/1200 loss 0.040326 acc 0.968074 lr 0.00011985 grad_norm 0.364850 rank 0
2025-01-11 08:54:57,195 DEBUG TRAIN Batch 179/1300 loss 0.022883 acc 0.981132 lr 0.00011983 grad_norm 0.347426 rank 1
2025-01-11 08:54:57,195 DEBUG TRAIN Batch 179/1300 loss 0.030123 acc 0.978910 lr 0.00011983 grad_norm 0.347426 rank 0
2025-01-11 08:54:57,195 DEBUG TRAIN Batch 179/1300 loss 0.029760 acc 0.977756 lr 0.00011983 grad_norm 0.347426 rank 2
2025-01-11 08:55:22,102 DEBUG TRAIN Batch 179/1400 loss 0.044332 acc 0.973223 lr 0.00011982 grad_norm 0.367877 rank 1
2025-01-11 08:55:22,102 DEBUG TRAIN Batch 179/1400 loss 0.014407 acc 0.991896 lr 0.00011982 grad_norm 0.367877 rank 2
2025-01-11 08:55:22,103 DEBUG TRAIN Batch 179/1400 loss 0.029303 acc 0.984283 lr 0.00011982 grad_norm 0.367877 rank 0
2025-01-11 08:55:45,894 DEBUG TRAIN Batch 179/1500 loss 0.026590 acc 0.983127 lr 0.00011980 grad_norm 0.356035 rank 1
2025-01-11 08:55:45,894 DEBUG TRAIN Batch 179/1500 loss 0.028537 acc 0.982441 lr 0.00011980 grad_norm 0.356035 rank 0
2025-01-11 08:55:45,894 DEBUG TRAIN Batch 179/1500 loss 0.015628 acc 0.988489 lr 0.00011980 grad_norm 0.356035 rank 2
2025-01-11 08:56:10,470 DEBUG TRAIN Batch 179/1600 loss 0.025003 acc 0.982609 lr 0.00011978 grad_norm 0.361413 rank 2
2025-01-11 08:56:10,470 DEBUG TRAIN Batch 179/1600 loss 0.040139 acc 0.969175 lr 0.00011978 grad_norm 0.361413 rank 1
2025-01-11 08:56:10,470 DEBUG TRAIN Batch 179/1600 loss 0.016330 acc 0.988462 lr 0.00011978 grad_norm 0.361413 rank 0
2025-01-11 08:56:35,476 DEBUG TRAIN Batch 179/1700 loss 0.034949 acc 0.978363 lr 0.00011977 grad_norm 0.356514 rank 0
2025-01-11 08:56:35,476 DEBUG TRAIN Batch 179/1700 loss 0.024490 acc 0.984405 lr 0.00011977 grad_norm 0.356514 rank 1
2025-01-11 08:56:35,476 DEBUG TRAIN Batch 179/1700 loss 0.022711 acc 0.981025 lr 0.00011977 grad_norm 0.356514 rank 2
2025-01-11 08:56:59,661 DEBUG TRAIN Batch 179/1800 loss 0.030130 acc 0.977639 lr 0.00011975 grad_norm 0.346970 rank 1
2025-01-11 08:56:59,662 DEBUG TRAIN Batch 179/1800 loss 0.019540 acc 0.988263 lr 0.00011975 grad_norm 0.346970 rank 2
2025-01-11 08:56:59,662 DEBUG TRAIN Batch 179/1800 loss 0.023368 acc 0.986584 lr 0.00011975 grad_norm 0.346970 rank 0
2025-01-11 08:57:24,738 DEBUG TRAIN Batch 179/1900 loss 0.028780 acc 0.980822 lr 0.00011973 grad_norm 0.392017 rank 2
2025-01-11 08:57:24,738 DEBUG TRAIN Batch 179/1900 loss 0.035613 acc 0.974650 lr 0.00011973 grad_norm 0.392017 rank 1
2025-01-11 08:57:24,738 DEBUG TRAIN Batch 179/1900 loss 0.027924 acc 0.974719 lr 0.00011973 grad_norm 0.392017 rank 0
2025-01-11 08:57:50,013 DEBUG TRAIN Batch 179/2000 loss 0.022090 acc 0.986655 lr 0.00011971 grad_norm 0.353933 rank 0
2025-01-11 08:57:50,012 DEBUG TRAIN Batch 179/2000 loss 0.029919 acc 0.983202 lr 0.00011971 grad_norm 0.353933 rank 1
2025-01-11 08:57:50,013 DEBUG TRAIN Batch 179/2000 loss 0.011431 acc 0.990476 lr 0.00011971 grad_norm 0.353933 rank 2
2025-01-11 08:58:13,961 DEBUG TRAIN Batch 179/2100 loss 0.017631 acc 0.991338 lr 0.00011970 grad_norm 0.345728 rank 1
2025-01-11 08:58:13,961 DEBUG TRAIN Batch 179/2100 loss 0.022875 acc 0.981855 lr 0.00011970 grad_norm 0.345728 rank 0
2025-01-11 08:58:13,961 DEBUG TRAIN Batch 179/2100 loss 0.017284 acc 0.987535 lr 0.00011970 grad_norm 0.345728 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 08:59:29,557 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 08:59:29,571 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 08:59:29,925 INFO Epoch 179 Step 174524 on_batch_end True CV rank 2
2025-01-11 08:59:29,925 INFO Epoch 179 Step 174524 on_batch_end True CV rank 0
2025-01-11 08:59:29,925 INFO Epoch 179 Step 174524 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 08:59:38,941 DEBUG CV Batch 179/100 loss 0.002412 acc 0.998885  rank 0
2025-01-11 08:59:39,146 DEBUG CV Batch 179/100 loss 0.002412 acc 0.998885  rank 2
2025-01-11 08:59:39,423 INFO Epoch 179 Step 174524 CV info lr 0.00011968574438196375 0 rank loss_2.7305130308871557 acc_0.7809240292561682
2025-01-11 08:59:39,670 INFO Epoch 179 Step 174524 CV info lr 0.00011968574438196375 2 rank loss_2.7305130308871557 acc_0.7809240292561682
2025-01-11 08:59:39,789 DEBUG CV Batch 179/100 loss 0.002412 acc 0.998885  rank 1
2025-01-11 08:59:40,308 INFO Epoch 179 Step 174524 CV info lr 0.00011968574438196375 1 rank loss_2.7305130308871557 acc_0.7809240292561682
2025-01-11 08:59:40,719 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_179_whole.pt
2025-01-11 08:59:40,741 INFO Added key: store_based_barrier_key:182 to store for rank: 0
2025-01-11 08:59:40,751 INFO Added key: store_based_barrier_key:182 to store for rank: 2
2025-01-11 08:59:40,751 INFO Added key: store_based_barrier_key:182 to store for rank: 1
2025-01-11 08:59:40,752 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:182 with 3 nodes.
2025-01-11 08:59:40,758 INFO Epoch 180 TRAIN info lr 0.00011968574438196375 rank 1
2025-01-11 08:59:40,758 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 08:59:40,761 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:182 with 3 nodes.
2025-01-11 08:59:40,761 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:182 with 3 nodes.
2025-01-11 08:59:40,763 INFO Epoch 180 TRAIN info lr 0.00011968574438196375 rank 0
2025-01-11 08:59:40,763 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 08:59:40,768 INFO Epoch 180 TRAIN info lr 0.00011968574438196375 rank 2
2025-01-11 08:59:40,768 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 09:00:14,733 DEBUG TRAIN Batch 180/100 loss 0.024541 acc 0.983673 lr 0.00011967 grad_norm 0.344574 rank 0
2025-01-11 09:00:14,733 DEBUG TRAIN Batch 180/100 loss 0.037367 acc 0.978241 lr 0.00011967 grad_norm 0.344574 rank 2
2025-01-11 09:00:14,734 DEBUG TRAIN Batch 180/100 loss 0.024113 acc 0.983268 lr 0.00011967 grad_norm 0.344574 rank 1
2025-01-11 09:00:38,795 DEBUG TRAIN Batch 180/200 loss 0.033974 acc 0.976000 lr 0.00011965 grad_norm 0.367316 rank 0
2025-01-11 09:00:38,796 DEBUG TRAIN Batch 180/200 loss 0.026711 acc 0.984663 lr 0.00011965 grad_norm 0.367316 rank 2
2025-01-11 09:00:38,796 DEBUG TRAIN Batch 180/200 loss 0.028254 acc 0.978887 lr 0.00011965 grad_norm 0.367316 rank 1
2025-01-11 09:01:03,782 DEBUG TRAIN Batch 180/300 loss 0.029429 acc 0.980658 lr 0.00011963 grad_norm 0.345556 rank 2
2025-01-11 09:01:03,783 DEBUG TRAIN Batch 180/300 loss 0.041011 acc 0.974048 lr 0.00011963 grad_norm 0.345556 rank 1
2025-01-11 09:01:03,783 DEBUG TRAIN Batch 180/300 loss 0.021309 acc 0.986084 lr 0.00011963 grad_norm 0.345556 rank 0
2025-01-11 09:01:27,643 DEBUG TRAIN Batch 180/400 loss 0.021774 acc 0.987027 lr 0.00011962 grad_norm 0.377630 rank 0
2025-01-11 09:01:27,643 DEBUG TRAIN Batch 180/400 loss 0.029869 acc 0.974863 lr 0.00011962 grad_norm 0.377630 rank 2
2025-01-11 09:01:27,643 DEBUG TRAIN Batch 180/400 loss 0.042324 acc 0.975634 lr 0.00011962 grad_norm 0.377630 rank 1
2025-01-11 09:01:51,906 DEBUG TRAIN Batch 180/500 loss 0.030067 acc 0.980651 lr 0.00011960 grad_norm 0.337420 rank 1
2025-01-11 09:01:51,906 DEBUG TRAIN Batch 180/500 loss 0.022722 acc 0.984615 lr 0.00011960 grad_norm 0.337420 rank 2
2025-01-11 09:01:51,907 DEBUG TRAIN Batch 180/500 loss 0.025784 acc 0.981061 lr 0.00011960 grad_norm 0.337420 rank 0
2025-01-11 09:02:16,281 DEBUG TRAIN Batch 180/600 loss 0.031141 acc 0.986830 lr 0.00011958 grad_norm 0.333671 rank 2
2025-01-11 09:02:16,281 DEBUG TRAIN Batch 180/600 loss 0.031192 acc 0.974609 lr 0.00011958 grad_norm 0.333671 rank 0
2025-01-11 09:02:16,282 DEBUG TRAIN Batch 180/600 loss 0.038738 acc 0.974160 lr 0.00011958 grad_norm 0.333671 rank 1
2025-01-11 09:02:40,457 DEBUG TRAIN Batch 180/700 loss 0.031852 acc 0.978182 lr 0.00011957 grad_norm 0.354842 rank 2
2025-01-11 09:02:40,457 DEBUG TRAIN Batch 180/700 loss 0.021271 acc 0.986388 lr 0.00011957 grad_norm 0.354842 rank 1
2025-01-11 09:02:40,457 DEBUG TRAIN Batch 180/700 loss 0.025288 acc 0.980736 lr 0.00011957 grad_norm 0.354842 rank 0
2025-01-11 09:03:04,351 DEBUG TRAIN Batch 180/800 loss 0.021939 acc 0.985294 lr 0.00011955 grad_norm 0.310922 rank 0
2025-01-11 09:03:04,352 DEBUG TRAIN Batch 180/800 loss 0.021618 acc 0.986326 lr 0.00011955 grad_norm 0.310922 rank 2
2025-01-11 09:03:04,352 DEBUG TRAIN Batch 180/800 loss 0.029465 acc 0.980216 lr 0.00011955 grad_norm 0.310922 rank 1
2025-01-11 09:03:28,071 DEBUG TRAIN Batch 180/900 loss 0.025522 acc 0.983871 lr 0.00011953 grad_norm 0.359357 rank 1
2025-01-11 09:03:28,071 DEBUG TRAIN Batch 180/900 loss 0.025123 acc 0.979167 lr 0.00011953 grad_norm 0.359357 rank 0
2025-01-11 09:03:28,071 DEBUG TRAIN Batch 180/900 loss 0.025606 acc 0.985901 lr 0.00011953 grad_norm 0.359357 rank 2
2025-01-11 09:03:52,003 DEBUG TRAIN Batch 180/1000 loss 0.034915 acc 0.981150 lr 0.00011951 grad_norm 0.339229 rank 2
2025-01-11 09:03:52,004 DEBUG TRAIN Batch 180/1000 loss 0.016300 acc 0.990123 lr 0.00011951 grad_norm 0.339229 rank 0
2025-01-11 09:03:52,004 DEBUG TRAIN Batch 180/1000 loss 0.032495 acc 0.980969 lr 0.00011951 grad_norm 0.339229 rank 1
2025-01-11 09:04:16,234 DEBUG TRAIN Batch 180/1100 loss 0.034703 acc 0.975191 lr 0.00011950 grad_norm 0.382671 rank 0
2025-01-11 09:04:16,235 DEBUG TRAIN Batch 180/1100 loss 0.024202 acc 0.986444 lr 0.00011950 grad_norm 0.382671 rank 2
2025-01-11 09:04:16,235 DEBUG TRAIN Batch 180/1100 loss 0.032008 acc 0.981546 lr 0.00011950 grad_norm 0.382671 rank 1
2025-01-11 09:04:40,757 DEBUG TRAIN Batch 180/1200 loss 0.030145 acc 0.980076 lr 0.00011948 grad_norm 0.367139 rank 1
2025-01-11 09:04:40,758 DEBUG TRAIN Batch 180/1200 loss 0.009564 acc 0.993517 lr 0.00011948 grad_norm 0.367139 rank 0
2025-01-11 09:04:40,758 DEBUG TRAIN Batch 180/1200 loss 0.035377 acc 0.971560 lr 0.00011948 grad_norm 0.367139 rank 2
2025-01-11 09:05:04,805 DEBUG TRAIN Batch 180/1300 loss 0.015387 acc 0.988439 lr 0.00011946 grad_norm 0.345417 rank 0
2025-01-11 09:05:04,805 DEBUG TRAIN Batch 180/1300 loss 0.034837 acc 0.976923 lr 0.00011946 grad_norm 0.345417 rank 1
2025-01-11 09:05:04,805 DEBUG TRAIN Batch 180/1300 loss 0.024262 acc 0.984504 lr 0.00011946 grad_norm 0.345417 rank 2
2025-01-11 09:05:29,637 DEBUG TRAIN Batch 180/1400 loss 0.029631 acc 0.982011 lr 0.00011945 grad_norm 0.370764 rank 2
2025-01-11 09:05:29,637 DEBUG TRAIN Batch 180/1400 loss 0.031558 acc 0.981098 lr 0.00011945 grad_norm 0.370764 rank 1
2025-01-11 09:05:29,637 DEBUG TRAIN Batch 180/1400 loss 0.017878 acc 0.989937 lr 0.00011945 grad_norm 0.370764 rank 0
2025-01-11 09:05:55,016 DEBUG TRAIN Batch 180/1500 loss 0.021720 acc 0.987500 lr 0.00011943 grad_norm 0.373318 rank 1
2025-01-11 09:05:55,016 DEBUG TRAIN Batch 180/1500 loss 0.019923 acc 0.984906 lr 0.00011943 grad_norm 0.373318 rank 0
2025-01-11 09:05:55,017 DEBUG TRAIN Batch 180/1500 loss 0.031700 acc 0.977012 lr 0.00011943 grad_norm 0.373318 rank 2
2025-01-11 09:06:19,461 DEBUG TRAIN Batch 180/1600 loss 0.020052 acc 0.985680 lr 0.00011941 grad_norm 0.357331 rank 0
2025-01-11 09:06:19,461 DEBUG TRAIN Batch 180/1600 loss 0.034906 acc 0.979112 lr 0.00011941 grad_norm 0.357331 rank 1
2025-01-11 09:06:19,461 DEBUG TRAIN Batch 180/1600 loss 0.028355 acc 0.981047 lr 0.00011941 grad_norm 0.357331 rank 2
2025-01-11 09:06:43,571 DEBUG TRAIN Batch 180/1700 loss 0.020824 acc 0.987415 lr 0.00011940 grad_norm 0.370299 rank 1
2025-01-11 09:06:43,572 DEBUG TRAIN Batch 180/1700 loss 0.029449 acc 0.980663 lr 0.00011940 grad_norm 0.370299 rank 0
2025-01-11 09:06:43,572 DEBUG TRAIN Batch 180/1700 loss 0.033527 acc 0.967775 lr 0.00011940 grad_norm 0.370299 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 09:08:01,207 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 09:08:01,209 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 09:08:01,737 INFO Epoch 180 Step 175410 on_batch_end True CV rank 2
2025-01-11 09:08:01,737 INFO Epoch 180 Step 175410 on_batch_end True CV rank 0
2025-01-11 09:08:01,737 INFO Epoch 180 Step 175410 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 09:08:10,826 DEBUG CV Batch 180/100 loss 0.002763 acc 0.998885  rank 0
2025-01-11 09:08:11,168 DEBUG CV Batch 180/100 loss 0.002763 acc 0.998885  rank 2
2025-01-11 09:08:11,347 INFO Epoch 180 Step 175410 CV info lr 0.00011938309398181124 0 rank loss_2.734572001032479 acc_0.7806333772707403
2025-01-11 09:08:11,489 DEBUG CV Batch 180/100 loss 0.002763 acc 0.998885  rank 1
2025-01-11 09:08:11,706 INFO Epoch 180 Step 175410 CV info lr 0.00011938309398181124 2 rank loss_2.734572001032479 acc_0.7806333772707403
2025-01-11 09:08:12,035 INFO Epoch 180 Step 175410 CV info lr 0.00011938309398181124 1 rank loss_2.734572001032479 acc_0.7806333772707403
2025-01-11 09:08:12,659 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_180_whole.pt
2025-01-11 09:08:12,681 INFO Added key: store_based_barrier_key:183 to store for rank: 0
2025-01-11 09:08:12,692 INFO Added key: store_based_barrier_key:183 to store for rank: 2
2025-01-11 09:08:12,692 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:183 with 3 nodes.
2025-01-11 09:08:12,692 INFO Added key: store_based_barrier_key:183 to store for rank: 1
2025-01-11 09:08:12,692 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:183 with 3 nodes.
2025-01-11 09:08:12,695 INFO Epoch 181 TRAIN info lr 0.00011938309398181124 rank 2
2025-01-11 09:08:12,696 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 09:08:12,699 INFO Epoch 181 TRAIN info lr 0.00011938309398181124 rank 1
2025-01-11 09:08:12,699 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 09:08:12,702 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:183 with 3 nodes.
2025-01-11 09:08:12,706 INFO Epoch 181 TRAIN info lr 0.00011938309398181124 rank 0
2025-01-11 09:08:12,706 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 09:08:48,388 DEBUG TRAIN Batch 181/100 loss 0.036064 acc 0.977064 lr 0.00011937 grad_norm 0.342317 rank 1
2025-01-11 09:08:48,388 DEBUG TRAIN Batch 181/100 loss 0.020675 acc 0.992405 lr 0.00011937 grad_norm 0.342317 rank 0
2025-01-11 09:08:48,388 DEBUG TRAIN Batch 181/100 loss 0.024796 acc 0.983903 lr 0.00011937 grad_norm 0.342317 rank 2
2025-01-11 09:09:12,673 DEBUG TRAIN Batch 181/200 loss 0.017973 acc 0.988304 lr 0.00011935 grad_norm 0.324068 rank 0
2025-01-11 09:09:12,674 DEBUG TRAIN Batch 181/200 loss 0.021664 acc 0.986842 lr 0.00011935 grad_norm 0.324068 rank 1
2025-01-11 09:09:12,674 DEBUG TRAIN Batch 181/200 loss 0.019169 acc 0.987165 lr 0.00011935 grad_norm 0.324068 rank 2
2025-01-11 09:09:37,475 DEBUG TRAIN Batch 181/300 loss 0.011070 acc 0.990099 lr 0.00011933 grad_norm 0.326951 rank 0
2025-01-11 09:09:37,475 DEBUG TRAIN Batch 181/300 loss 0.023476 acc 0.980932 lr 0.00011933 grad_norm 0.326951 rank 1
2025-01-11 09:09:37,475 DEBUG TRAIN Batch 181/300 loss 0.028436 acc 0.980392 lr 0.00011933 grad_norm 0.326951 rank 2
2025-01-11 09:10:01,857 DEBUG TRAIN Batch 181/400 loss 0.028415 acc 0.977927 lr 0.00011932 grad_norm 0.373640 rank 1
2025-01-11 09:10:01,857 DEBUG TRAIN Batch 181/400 loss 0.021184 acc 0.989676 lr 0.00011932 grad_norm 0.373640 rank 0
2025-01-11 09:10:01,858 DEBUG TRAIN Batch 181/400 loss 0.017244 acc 0.986919 lr 0.00011932 grad_norm 0.373640 rank 2
2025-01-11 09:10:26,150 DEBUG TRAIN Batch 181/500 loss 0.029708 acc 0.971136 lr 0.00011930 grad_norm 0.343405 rank 1
2025-01-11 09:10:26,151 DEBUG TRAIN Batch 181/500 loss 0.024607 acc 0.978399 lr 0.00011930 grad_norm 0.343405 rank 0
2025-01-11 09:10:26,151 DEBUG TRAIN Batch 181/500 loss 0.019956 acc 0.988397 lr 0.00011930 grad_norm 0.343405 rank 2
2025-01-11 09:10:50,748 DEBUG TRAIN Batch 181/600 loss 0.019457 acc 0.988278 lr 0.00011928 grad_norm 0.341237 rank 0
2025-01-11 09:10:50,748 DEBUG TRAIN Batch 181/600 loss 0.019959 acc 0.984069 lr 0.00011928 grad_norm 0.341237 rank 2
2025-01-11 09:10:50,748 DEBUG TRAIN Batch 181/600 loss 0.026714 acc 0.983810 lr 0.00011928 grad_norm 0.341237 rank 1
2025-01-11 09:11:14,081 DEBUG TRAIN Batch 181/700 loss 0.030270 acc 0.981910 lr 0.00011926 grad_norm 0.338369 rank 2
2025-01-11 09:11:14,081 DEBUG TRAIN Batch 181/700 loss 0.016119 acc 0.986577 lr 0.00011926 grad_norm 0.338369 rank 0
2025-01-11 09:11:14,082 DEBUG TRAIN Batch 181/700 loss 0.025101 acc 0.984259 lr 0.00011926 grad_norm 0.338369 rank 1
2025-01-11 09:11:38,853 DEBUG TRAIN Batch 181/800 loss 0.016114 acc 0.988060 lr 0.00011925 grad_norm 0.388627 rank 2
2025-01-11 09:11:38,853 DEBUG TRAIN Batch 181/800 loss 0.029079 acc 0.982906 lr 0.00011925 grad_norm 0.388627 rank 0
2025-01-11 09:11:38,853 DEBUG TRAIN Batch 181/800 loss 0.037529 acc 0.978938 lr 0.00011925 grad_norm 0.388627 rank 1
2025-01-11 09:12:02,858 DEBUG TRAIN Batch 181/900 loss 0.036675 acc 0.967963 lr 0.00011923 grad_norm 0.397609 rank 1
2025-01-11 09:12:02,858 DEBUG TRAIN Batch 181/900 loss 0.031853 acc 0.978374 lr 0.00011923 grad_norm 0.397609 rank 2
2025-01-11 09:12:02,858 DEBUG TRAIN Batch 181/900 loss 0.025487 acc 0.977341 lr 0.00011923 grad_norm 0.397609 rank 0
2025-01-11 09:12:27,327 DEBUG TRAIN Batch 181/1000 loss 0.037861 acc 0.976895 lr 0.00011921 grad_norm 0.360129 rank 1
2025-01-11 09:12:27,328 DEBUG TRAIN Batch 181/1000 loss 0.033297 acc 0.976937 lr 0.00011921 grad_norm 0.360129 rank 2
2025-01-11 09:12:27,328 DEBUG TRAIN Batch 181/1000 loss 0.009945 acc 0.990814 lr 0.00011921 grad_norm 0.360129 rank 0
2025-01-11 09:12:52,540 DEBUG TRAIN Batch 181/1100 loss 0.029366 acc 0.981030 lr 0.00011920 grad_norm 0.356631 rank 1
2025-01-11 09:12:52,540 DEBUG TRAIN Batch 181/1100 loss 0.034405 acc 0.974584 lr 0.00011920 grad_norm 0.356631 rank 2
2025-01-11 09:12:52,540 DEBUG TRAIN Batch 181/1100 loss 0.026623 acc 0.982086 lr 0.00011920 grad_norm 0.356631 rank 0
2025-01-11 09:13:16,372 DEBUG TRAIN Batch 181/1200 loss 0.028482 acc 0.980600 lr 0.00011918 grad_norm 0.355215 rank 0
2025-01-11 09:13:16,372 DEBUG TRAIN Batch 181/1200 loss 0.018557 acc 0.989413 lr 0.00011918 grad_norm 0.355215 rank 1
2025-01-11 09:13:16,372 DEBUG TRAIN Batch 181/1200 loss 0.025746 acc 0.984392 lr 0.00011918 grad_norm 0.355215 rank 2
2025-01-11 09:13:40,840 DEBUG TRAIN Batch 181/1300 loss 0.033767 acc 0.979243 lr 0.00011916 grad_norm 0.393053 rank 0
2025-01-11 09:13:40,840 DEBUG TRAIN Batch 181/1300 loss 0.024691 acc 0.986125 lr 0.00011916 grad_norm 0.393053 rank 2
2025-01-11 09:13:40,840 DEBUG TRAIN Batch 181/1300 loss 0.024090 acc 0.980410 lr 0.00011916 grad_norm 0.393053 rank 1
2025-01-11 09:14:04,412 DEBUG TRAIN Batch 181/1400 loss 0.037078 acc 0.975309 lr 0.00011915 grad_norm 0.373884 rank 1
2025-01-11 09:14:04,412 DEBUG TRAIN Batch 181/1400 loss 0.025362 acc 0.983539 lr 0.00011915 grad_norm 0.373884 rank 2
2025-01-11 09:14:04,412 DEBUG TRAIN Batch 181/1400 loss 0.037431 acc 0.975881 lr 0.00011915 grad_norm 0.373884 rank 0
2025-01-11 09:14:28,340 DEBUG TRAIN Batch 181/1500 loss 0.020875 acc 0.985915 lr 0.00011913 grad_norm 0.339166 rank 0
2025-01-11 09:14:28,340 DEBUG TRAIN Batch 181/1500 loss 0.028381 acc 0.981300 lr 0.00011913 grad_norm 0.339166 rank 1
2025-01-11 09:14:28,340 DEBUG TRAIN Batch 181/1500 loss 0.021804 acc 0.981730 lr 0.00011913 grad_norm 0.339166 rank 2
2025-01-11 09:14:52,367 DEBUG TRAIN Batch 181/1600 loss 0.029035 acc 0.981744 lr 0.00011911 grad_norm 0.352989 rank 1
2025-01-11 09:14:52,367 DEBUG TRAIN Batch 181/1600 loss 0.028382 acc 0.981430 lr 0.00011911 grad_norm 0.352989 rank 0
2025-01-11 09:14:52,368 DEBUG TRAIN Batch 181/1600 loss 0.020978 acc 0.987918 lr 0.00011911 grad_norm 0.352989 rank 2
2025-01-11 09:15:16,162 DEBUG TRAIN Batch 181/1700 loss 0.018851 acc 0.991218 lr 0.00011909 grad_norm 0.391698 rank 1
2025-01-11 09:15:16,163 DEBUG TRAIN Batch 181/1700 loss 0.037676 acc 0.974232 lr 0.00011909 grad_norm 0.391698 rank 0
2025-01-11 09:15:16,163 DEBUG TRAIN Batch 181/1700 loss 0.037793 acc 0.975000 lr 0.00011909 grad_norm 0.391698 rank 2
2025-01-11 09:15:40,454 DEBUG TRAIN Batch 181/1800 loss 0.019713 acc 0.987724 lr 0.00011908 grad_norm 0.350599 rank 0
2025-01-11 09:15:40,454 DEBUG TRAIN Batch 181/1800 loss 0.027314 acc 0.982796 lr 0.00011908 grad_norm 0.350599 rank 1
2025-01-11 09:15:40,454 DEBUG TRAIN Batch 181/1800 loss 0.025861 acc 0.982383 lr 0.00011908 grad_norm 0.350599 rank 2
2025-01-11 09:16:05,020 DEBUG TRAIN Batch 181/1900 loss 0.028582 acc 0.976562 lr 0.00011906 grad_norm 0.408458 rank 2
2025-01-11 09:16:05,020 DEBUG TRAIN Batch 181/1900 loss 0.028012 acc 0.977591 lr 0.00011906 grad_norm 0.408458 rank 1
2025-01-11 09:16:05,020 DEBUG TRAIN Batch 181/1900 loss 0.030658 acc 0.978417 lr 0.00011906 grad_norm 0.408458 rank 0
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 09:17:10,910 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 09:17:10,910 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 09:17:11,363 INFO Epoch 181 Step 176371 on_batch_end True CV rank 2
2025-01-11 09:17:11,363 INFO Epoch 181 Step 176371 on_batch_end True CV rank 0
2025-01-11 09:17:11,364 INFO Epoch 181 Step 176371 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 09:17:20,511 DEBUG CV Batch 181/100 loss 0.008987 acc 0.996656  rank 0
2025-01-11 09:17:20,782 DEBUG CV Batch 181/100 loss 0.008987 acc 0.996656  rank 2
2025-01-11 09:17:21,046 INFO Epoch 181 Step 176371 CV info lr 0.00011905740591464549 0 rank loss_2.7426481081773155 acc_0.7804529923096037
2025-01-11 09:17:21,141 DEBUG CV Batch 181/100 loss 0.008987 acc 0.996656  rank 1
2025-01-11 09:17:21,319 INFO Epoch 181 Step 176371 CV info lr 0.00011905740591464549 2 rank loss_2.7426481081773155 acc_0.7804529923096037
2025-01-11 09:17:21,683 INFO Epoch 181 Step 176371 CV info lr 0.00011905740591464549 1 rank loss_2.7426481081773155 acc_0.7804529923096037
2025-01-11 09:17:22,344 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_181_whole.pt
2025-01-11 09:17:22,366 INFO Added key: store_based_barrier_key:184 to store for rank: 0
2025-01-11 09:17:22,366 INFO Added key: store_based_barrier_key:184 to store for rank: 1
2025-01-11 09:17:22,366 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:184 with 3 nodes.
2025-01-11 09:17:22,366 INFO Added key: store_based_barrier_key:184 to store for rank: 2
2025-01-11 09:17:22,366 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:184 with 3 nodes.
2025-01-11 09:17:22,371 INFO Epoch 182 TRAIN info lr 0.00011905740591464549 rank 1
2025-01-11 09:17:22,371 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 09:17:22,371 INFO Epoch 182 TRAIN info lr 0.00011905740591464549 rank 2
2025-01-11 09:17:22,371 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 09:17:22,376 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:184 with 3 nodes.
2025-01-11 09:17:22,376 INFO Epoch 182 TRAIN info lr 0.00011905740591464549 rank 0
2025-01-11 09:17:22,376 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 09:17:58,614 DEBUG TRAIN Batch 182/100 loss 0.033826 acc 0.978910 lr 0.00011904 grad_norm 0.339222 rank 0
2025-01-11 09:17:58,615 DEBUG TRAIN Batch 182/100 loss 0.032929 acc 0.974684 lr 0.00011904 grad_norm 0.339222 rank 2
2025-01-11 09:17:58,615 DEBUG TRAIN Batch 182/100 loss 0.017159 acc 0.988248 lr 0.00011904 grad_norm 0.339222 rank 1
2025-01-11 09:18:22,506 DEBUG TRAIN Batch 182/200 loss 0.028585 acc 0.980198 lr 0.00011902 grad_norm 0.340984 rank 1
2025-01-11 09:18:22,506 DEBUG TRAIN Batch 182/200 loss 0.031014 acc 0.978322 lr 0.00011902 grad_norm 0.340984 rank 2
2025-01-11 09:18:22,507 DEBUG TRAIN Batch 182/200 loss 0.020834 acc 0.987723 lr 0.00011902 grad_norm 0.340984 rank 0
2025-01-11 09:18:47,350 DEBUG TRAIN Batch 182/300 loss 0.029084 acc 0.979724 lr 0.00011901 grad_norm 0.351090 rank 1
2025-01-11 09:18:47,350 DEBUG TRAIN Batch 182/300 loss 0.028079 acc 0.977778 lr 0.00011901 grad_norm 0.351090 rank 2
2025-01-11 09:18:47,351 DEBUG TRAIN Batch 182/300 loss 0.027060 acc 0.980668 lr 0.00011901 grad_norm 0.351090 rank 0
2025-01-11 09:19:11,437 DEBUG TRAIN Batch 182/400 loss 0.020129 acc 0.987692 lr 0.00011899 grad_norm 0.338546 rank 1
2025-01-11 09:19:11,437 DEBUG TRAIN Batch 182/400 loss 0.020403 acc 0.982228 lr 0.00011899 grad_norm 0.338546 rank 2
2025-01-11 09:19:11,437 DEBUG TRAIN Batch 182/400 loss 0.032812 acc 0.981896 lr 0.00011899 grad_norm 0.338546 rank 0
2025-01-11 09:19:36,393 DEBUG TRAIN Batch 182/500 loss 0.023711 acc 0.983539 lr 0.00011897 grad_norm 0.318645 rank 1
2025-01-11 09:19:36,394 DEBUG TRAIN Batch 182/500 loss 0.008987 acc 0.996599 lr 0.00011897 grad_norm 0.318645 rank 0
2025-01-11 09:19:36,394 DEBUG TRAIN Batch 182/500 loss 0.025729 acc 0.981333 lr 0.00011897 grad_norm 0.318645 rank 2
2025-01-11 09:20:01,806 DEBUG TRAIN Batch 182/600 loss 0.030765 acc 0.982456 lr 0.00011896 grad_norm 0.360651 rank 0
2025-01-11 09:20:01,806 DEBUG TRAIN Batch 182/600 loss 0.021628 acc 0.983740 lr 0.00011896 grad_norm 0.360651 rank 1
2025-01-11 09:20:01,807 DEBUG TRAIN Batch 182/600 loss 0.043908 acc 0.969342 lr 0.00011896 grad_norm 0.360651 rank 2
2025-01-11 09:20:26,042 DEBUG TRAIN Batch 182/700 loss 0.027453 acc 0.981982 lr 0.00011894 grad_norm 0.358374 rank 0
2025-01-11 09:20:26,043 DEBUG TRAIN Batch 182/700 loss 0.028146 acc 0.979015 lr 0.00011894 grad_norm 0.358374 rank 1
2025-01-11 09:20:26,043 DEBUG TRAIN Batch 182/700 loss 0.034593 acc 0.976021 lr 0.00011894 grad_norm 0.358374 rank 2
2025-01-11 09:20:51,827 DEBUG TRAIN Batch 182/800 loss 0.023786 acc 0.982054 lr 0.00011892 grad_norm 0.322380 rank 1
2025-01-11 09:20:51,827 DEBUG TRAIN Batch 182/800 loss 0.030184 acc 0.981481 lr 0.00011892 grad_norm 0.322380 rank 2
2025-01-11 09:20:51,827 DEBUG TRAIN Batch 182/800 loss 0.023743 acc 0.987319 lr 0.00011892 grad_norm 0.322380 rank 0
2025-01-11 09:21:15,423 DEBUG TRAIN Batch 182/900 loss 0.023491 acc 0.981681 lr 0.00011891 grad_norm 0.345280 rank 1
2025-01-11 09:21:15,424 DEBUG TRAIN Batch 182/900 loss 0.029568 acc 0.983410 lr 0.00011891 grad_norm 0.345280 rank 0
2025-01-11 09:21:15,424 DEBUG TRAIN Batch 182/900 loss 0.018639 acc 0.985207 lr 0.00011891 grad_norm 0.345280 rank 2
2025-01-11 09:21:39,695 DEBUG TRAIN Batch 182/1000 loss 0.016722 acc 0.990950 lr 0.00011889 grad_norm 0.362142 rank 1
2025-01-11 09:21:39,695 DEBUG TRAIN Batch 182/1000 loss 0.032985 acc 0.976636 lr 0.00011889 grad_norm 0.362142 rank 2
2025-01-11 09:21:39,696 DEBUG TRAIN Batch 182/1000 loss 0.031758 acc 0.978102 lr 0.00011889 grad_norm 0.362142 rank 0
2025-01-11 09:22:05,743 DEBUG TRAIN Batch 182/1100 loss 0.023867 acc 0.989062 lr 0.00011887 grad_norm 0.370281 rank 1
2025-01-11 09:22:05,743 DEBUG TRAIN Batch 182/1100 loss 0.019974 acc 0.987952 lr 0.00011887 grad_norm 0.370281 rank 0
2025-01-11 09:22:05,744 DEBUG TRAIN Batch 182/1100 loss 0.032172 acc 0.977444 lr 0.00011887 grad_norm 0.370281 rank 2
2025-01-11 09:22:30,157 DEBUG TRAIN Batch 182/1200 loss 0.032991 acc 0.976546 lr 0.00011886 grad_norm 0.376721 rank 0
2025-01-11 09:22:30,157 DEBUG TRAIN Batch 182/1200 loss 0.031559 acc 0.980825 lr 0.00011886 grad_norm 0.376721 rank 1
2025-01-11 09:22:30,157 DEBUG TRAIN Batch 182/1200 loss 0.031219 acc 0.979317 lr 0.00011886 grad_norm 0.376721 rank 2
2025-01-11 09:22:53,656 DEBUG TRAIN Batch 182/1300 loss 0.021437 acc 0.979900 lr 0.00011884 grad_norm 0.361218 rank 2
2025-01-11 09:22:53,656 DEBUG TRAIN Batch 182/1300 loss 0.029615 acc 0.978641 lr 0.00011884 grad_norm 0.361218 rank 0
2025-01-11 09:22:53,656 DEBUG TRAIN Batch 182/1300 loss 0.028362 acc 0.979835 lr 0.00011884 grad_norm 0.361218 rank 1
2025-01-11 09:23:17,445 DEBUG TRAIN Batch 182/1400 loss 0.017602 acc 0.985089 lr 0.00011882 grad_norm 0.348286 rank 0
2025-01-11 09:23:17,445 DEBUG TRAIN Batch 182/1400 loss 0.017453 acc 0.987952 lr 0.00011882 grad_norm 0.348286 rank 1
2025-01-11 09:23:17,445 DEBUG TRAIN Batch 182/1400 loss 0.032163 acc 0.982857 lr 0.00011882 grad_norm 0.348286 rank 2
2025-01-11 09:23:41,007 DEBUG TRAIN Batch 182/1500 loss 0.032961 acc 0.976818 lr 0.00011881 grad_norm 0.391767 rank 0
2025-01-11 09:23:41,007 DEBUG TRAIN Batch 182/1500 loss 0.037413 acc 0.970874 lr 0.00011881 grad_norm 0.391767 rank 1
2025-01-11 09:23:41,007 DEBUG TRAIN Batch 182/1500 loss 0.019199 acc 0.987629 lr 0.00011881 grad_norm 0.391767 rank 2
2025-01-11 09:24:04,844 DEBUG TRAIN Batch 182/1600 loss 0.028278 acc 0.985968 lr 0.00011879 grad_norm 0.335145 rank 2
2025-01-11 09:24:04,845 DEBUG TRAIN Batch 182/1600 loss 0.023207 acc 0.983929 lr 0.00011879 grad_norm 0.335145 rank 1
2025-01-11 09:24:04,845 DEBUG TRAIN Batch 182/1600 loss 0.022384 acc 0.983168 lr 0.00011879 grad_norm 0.335145 rank 0
2025-01-11 09:24:28,352 DEBUG TRAIN Batch 182/1700 loss 0.028976 acc 0.979628 lr 0.00011877 grad_norm 0.374249 rank 1
2025-01-11 09:24:28,352 DEBUG TRAIN Batch 182/1700 loss 0.031104 acc 0.978082 lr 0.00011877 grad_norm 0.374249 rank 0
2025-01-11 09:24:28,353 DEBUG TRAIN Batch 182/1700 loss 0.031777 acc 0.980681 lr 0.00011877 grad_norm 0.374249 rank 2
2025-01-11 09:24:52,286 DEBUG TRAIN Batch 182/1800 loss 0.025977 acc 0.979943 lr 0.00011875 grad_norm 0.334826 rank 2
2025-01-11 09:24:52,286 DEBUG TRAIN Batch 182/1800 loss 0.016340 acc 0.991705 lr 0.00011875 grad_norm 0.334826 rank 0
2025-01-11 09:24:52,287 DEBUG TRAIN Batch 182/1800 loss 0.030529 acc 0.980427 lr 0.00011875 grad_norm 0.334826 rank 1
2025-01-11 09:25:16,087 DEBUG TRAIN Batch 182/1900 loss 0.020021 acc 0.986742 lr 0.00011874 grad_norm 0.355164 rank 0
2025-01-11 09:25:16,091 DEBUG TRAIN Batch 182/1900 loss 0.029504 acc 0.977495 lr 0.00011874 grad_norm 0.355164 rank 1
2025-01-11 09:25:16,091 DEBUG TRAIN Batch 182/1900 loss 0.041299 acc 0.972533 lr 0.00011874 grad_norm 0.355164 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 09:26:25,851 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 09:26:25,852 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 09:26:26,331 INFO Epoch 182 Step 177341 on_batch_end True CV rank 0
2025-01-11 09:26:26,331 INFO Epoch 182 Step 177341 on_batch_end True CV rank 2
2025-01-11 09:26:26,331 INFO Epoch 182 Step 177341 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 09:26:35,524 DEBUG CV Batch 182/100 loss 0.002737 acc 0.998885  rank 0
2025-01-11 09:26:35,772 DEBUG CV Batch 182/100 loss 0.002737 acc 0.998885  rank 2
2025-01-11 09:26:36,053 INFO Epoch 182 Step 177341 CV info lr 0.00011873135600296693 0 rank loss_2.751180563502235 acc_0.7803158838497964
2025-01-11 09:26:36,171 DEBUG CV Batch 182/100 loss 0.002737 acc 0.998885  rank 1
2025-01-11 09:26:36,319 INFO Epoch 182 Step 177341 CV info lr 0.00011873135600296693 2 rank loss_2.751180563502235 acc_0.7803158838497964
2025-01-11 09:26:36,715 INFO Epoch 182 Step 177341 CV info lr 0.00011873135600296693 1 rank loss_2.751180563502235 acc_0.7803158838497964
2025-01-11 09:26:37,321 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_182_whole.pt
2025-01-11 09:26:37,343 INFO Added key: store_based_barrier_key:185 to store for rank: 0
2025-01-11 09:26:37,343 INFO Added key: store_based_barrier_key:185 to store for rank: 1
2025-01-11 09:26:37,343 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:185 with 3 nodes.
2025-01-11 09:26:37,343 INFO Added key: store_based_barrier_key:185 to store for rank: 2
2025-01-11 09:26:37,344 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:185 with 3 nodes.
2025-01-11 09:26:37,345 INFO Epoch 183 TRAIN info lr 0.00011873135600296693 rank 2
2025-01-11 09:26:37,345 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 09:26:37,346 INFO Epoch 183 TRAIN info lr 0.00011873135600296693 rank 1
2025-01-11 09:26:37,346 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 09:26:37,353 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:185 with 3 nodes.
2025-01-11 09:26:37,355 INFO Epoch 183 TRAIN info lr 0.00011873135600296693 rank 0
2025-01-11 09:26:37,355 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 09:27:08,393 DEBUG TRAIN Batch 183/100 loss 0.039282 acc 0.970010 lr 0.00011871 grad_norm 0.347600 rank 0
2025-01-11 09:27:08,394 DEBUG TRAIN Batch 183/100 loss 0.017292 acc 0.988613 lr 0.00011871 grad_norm 0.347600 rank 2
2025-01-11 09:27:08,394 DEBUG TRAIN Batch 183/100 loss 0.018448 acc 0.985340 lr 0.00011871 grad_norm 0.347600 rank 1
2025-01-11 09:27:32,206 DEBUG TRAIN Batch 183/200 loss 0.036694 acc 0.975031 lr 0.00011870 grad_norm 0.383494 rank 0
2025-01-11 09:27:32,207 DEBUG TRAIN Batch 183/200 loss 0.015394 acc 0.992492 lr 0.00011870 grad_norm 0.383494 rank 1
2025-01-11 09:27:32,207 DEBUG TRAIN Batch 183/200 loss 0.028617 acc 0.984689 lr 0.00011870 grad_norm 0.383494 rank 2
2025-01-11 09:27:55,711 DEBUG TRAIN Batch 183/300 loss 0.021292 acc 0.987138 lr 0.00011868 grad_norm 0.342885 rank 1
2025-01-11 09:27:55,711 DEBUG TRAIN Batch 183/300 loss 0.026082 acc 0.984475 lr 0.00011868 grad_norm 0.342885 rank 0
2025-01-11 09:27:55,711 DEBUG TRAIN Batch 183/300 loss 0.021498 acc 0.984432 lr 0.00011868 grad_norm 0.342885 rank 2
2025-01-11 09:28:19,316 DEBUG TRAIN Batch 183/400 loss 0.018144 acc 0.988095 lr 0.00011866 grad_norm 0.358568 rank 0
2025-01-11 09:28:19,316 DEBUG TRAIN Batch 183/400 loss 0.019945 acc 0.993384 lr 0.00011866 grad_norm 0.358568 rank 1
2025-01-11 09:28:19,316 DEBUG TRAIN Batch 183/400 loss 0.041045 acc 0.975025 lr 0.00011866 grad_norm 0.358568 rank 2
2025-01-11 09:28:43,239 DEBUG TRAIN Batch 183/500 loss 0.022890 acc 0.983917 lr 0.00011865 grad_norm 0.330998 rank 0
2025-01-11 09:28:43,239 DEBUG TRAIN Batch 183/500 loss 0.020015 acc 0.986694 lr 0.00011865 grad_norm 0.330998 rank 2
2025-01-11 09:28:43,239 DEBUG TRAIN Batch 183/500 loss 0.026961 acc 0.984169 lr 0.00011865 grad_norm 0.330998 rank 1
2025-01-11 09:29:06,692 DEBUG TRAIN Batch 183/600 loss 0.025603 acc 0.986513 lr 0.00011863 grad_norm 0.332661 rank 0
2025-01-11 09:29:06,692 DEBUG TRAIN Batch 183/600 loss 0.023068 acc 0.984421 lr 0.00011863 grad_norm 0.332661 rank 1
2025-01-11 09:29:06,692 DEBUG TRAIN Batch 183/600 loss 0.019822 acc 0.986051 lr 0.00011863 grad_norm 0.332661 rank 2
2025-01-11 09:29:30,963 DEBUG TRAIN Batch 183/700 loss 0.029058 acc 0.978625 lr 0.00011861 grad_norm 0.363446 rank 2
2025-01-11 09:29:30,963 DEBUG TRAIN Batch 183/700 loss 0.019830 acc 0.987342 lr 0.00011861 grad_norm 0.363446 rank 0
2025-01-11 09:29:30,964 DEBUG TRAIN Batch 183/700 loss 0.027933 acc 0.981013 lr 0.00011861 grad_norm 0.363446 rank 1
2025-01-11 09:29:55,218 DEBUG TRAIN Batch 183/800 loss 0.022716 acc 0.982869 lr 0.00011860 grad_norm 0.361604 rank 1
2025-01-11 09:29:55,218 DEBUG TRAIN Batch 183/800 loss 0.031349 acc 0.977024 lr 0.00011860 grad_norm 0.361604 rank 2
2025-01-11 09:29:55,218 DEBUG TRAIN Batch 183/800 loss 0.018508 acc 0.990405 lr 0.00011860 grad_norm 0.361604 rank 0
2025-01-11 09:30:19,015 DEBUG TRAIN Batch 183/900 loss 0.022806 acc 0.987578 lr 0.00011858 grad_norm 0.353026 rank 0
2025-01-11 09:30:19,015 DEBUG TRAIN Batch 183/900 loss 0.023809 acc 0.980080 lr 0.00011858 grad_norm 0.353026 rank 1
2025-01-11 09:30:19,015 DEBUG TRAIN Batch 183/900 loss 0.040360 acc 0.973251 lr 0.00011858 grad_norm 0.353026 rank 2
2025-01-11 09:30:43,112 DEBUG TRAIN Batch 183/1000 loss 0.026162 acc 0.980276 lr 0.00011856 grad_norm 0.380695 rank 0
2025-01-11 09:30:43,113 DEBUG TRAIN Batch 183/1000 loss 0.034717 acc 0.976253 lr 0.00011856 grad_norm 0.380695 rank 1
2025-01-11 09:30:43,113 DEBUG TRAIN Batch 183/1000 loss 0.030943 acc 0.972923 lr 0.00011856 grad_norm 0.380695 rank 2
2025-01-11 09:31:07,169 DEBUG TRAIN Batch 183/1100 loss 0.016168 acc 0.988235 lr 0.00011855 grad_norm 0.345249 rank 0
2025-01-11 09:31:07,169 DEBUG TRAIN Batch 183/1100 loss 0.046932 acc 0.970306 lr 0.00011855 grad_norm 0.345249 rank 1
2025-01-11 09:31:07,169 DEBUG TRAIN Batch 183/1100 loss 0.032932 acc 0.984095 lr 0.00011855 grad_norm 0.345249 rank 2
2025-01-11 09:31:30,902 DEBUG TRAIN Batch 183/1200 loss 0.016354 acc 0.988615 lr 0.00011853 grad_norm 0.331728 rank 0
2025-01-11 09:31:30,902 DEBUG TRAIN Batch 183/1200 loss 0.027544 acc 0.980501 lr 0.00011853 grad_norm 0.331728 rank 1
2025-01-11 09:31:30,902 DEBUG TRAIN Batch 183/1200 loss 0.023477 acc 0.981132 lr 0.00011853 grad_norm 0.331728 rank 2
2025-01-11 09:31:55,162 DEBUG TRAIN Batch 183/1300 loss 0.022089 acc 0.983287 lr 0.00011851 grad_norm 0.362786 rank 0
2025-01-11 09:31:55,162 DEBUG TRAIN Batch 183/1300 loss 0.025367 acc 0.982163 lr 0.00011851 grad_norm 0.362786 rank 1
2025-01-11 09:31:55,162 DEBUG TRAIN Batch 183/1300 loss 0.025337 acc 0.980583 lr 0.00011851 grad_norm 0.362786 rank 2
2025-01-11 09:32:18,957 DEBUG TRAIN Batch 183/1400 loss 0.026722 acc 0.980786 lr 0.00011850 grad_norm 0.378584 rank 1
2025-01-11 09:32:18,957 DEBUG TRAIN Batch 183/1400 loss 0.025637 acc 0.983784 lr 0.00011850 grad_norm 0.378584 rank 0
2025-01-11 09:32:18,958 DEBUG TRAIN Batch 183/1400 loss 0.036108 acc 0.976077 lr 0.00011850 grad_norm 0.378584 rank 2
2025-01-11 09:32:43,226 DEBUG TRAIN Batch 183/1500 loss 0.026661 acc 0.984029 lr 0.00011848 grad_norm 0.364714 rank 0
2025-01-11 09:32:43,226 DEBUG TRAIN Batch 183/1500 loss 0.030166 acc 0.978545 lr 0.00011848 grad_norm 0.364714 rank 1
2025-01-11 09:32:43,227 DEBUG TRAIN Batch 183/1500 loss 0.024739 acc 0.986607 lr 0.00011848 grad_norm 0.364714 rank 2
2025-01-11 09:33:07,874 DEBUG TRAIN Batch 183/1600 loss 0.026305 acc 0.986261 lr 0.00011846 grad_norm 0.355978 rank 0
2025-01-11 09:33:07,875 DEBUG TRAIN Batch 183/1600 loss 0.032847 acc 0.975477 lr 0.00011846 grad_norm 0.355978 rank 1
2025-01-11 09:33:07,876 DEBUG TRAIN Batch 183/1600 loss 0.025415 acc 0.984629 lr 0.00011846 grad_norm 0.355978 rank 2
2025-01-11 09:33:33,020 DEBUG TRAIN Batch 183/1700 loss 0.022813 acc 0.985902 lr 0.00011845 grad_norm 0.354922 rank 1
2025-01-11 09:33:33,020 DEBUG TRAIN Batch 183/1700 loss 0.026139 acc 0.985088 lr 0.00011845 grad_norm 0.354922 rank 2
2025-01-11 09:33:33,020 DEBUG TRAIN Batch 183/1700 loss 0.019657 acc 0.985380 lr 0.00011845 grad_norm 0.354922 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 09:34:33,151 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 09:34:33,156 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 09:34:33,579 INFO Epoch 183 Step 178191 on_batch_end True CV rank 1
2025-01-11 09:34:33,579 INFO Epoch 183 Step 178191 on_batch_end True CV rank 0
2025-01-11 09:34:33,579 INFO Epoch 183 Step 178191 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 09:34:42,545 DEBUG CV Batch 183/100 loss 0.000473 acc 1.000000  rank 0
2025-01-11 09:34:42,919 DEBUG CV Batch 183/100 loss 0.000473 acc 1.000000  rank 2
2025-01-11 09:34:43,062 INFO Epoch 183 Step 178191 CV info lr 0.00011844783356445924 0 rank loss_2.7357820756211972 acc_0.7811894627255306
2025-01-11 09:34:43,104 DEBUG CV Batch 183/100 loss 0.000473 acc 1.000000  rank 1
2025-01-11 09:34:43,447 INFO Epoch 183 Step 178191 CV info lr 0.00011844783356445924 2 rank loss_2.7357820756211972 acc_0.7811894627255306
2025-01-11 09:34:43,636 INFO Epoch 183 Step 178191 CV info lr 0.00011844783356445924 1 rank loss_2.7357820756211972 acc_0.7811894627255306
2025-01-11 09:34:44,354 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_183_whole.pt
2025-01-11 09:34:44,376 INFO Added key: store_based_barrier_key:186 to store for rank: 0
2025-01-11 09:34:44,376 INFO Added key: store_based_barrier_key:186 to store for rank: 1
2025-01-11 09:34:44,376 INFO Added key: store_based_barrier_key:186 to store for rank: 2
2025-01-11 09:34:44,377 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:186 with 3 nodes.
2025-01-11 09:34:44,380 INFO Epoch 184 TRAIN info lr 0.00011844783356445924 rank 2
2025-01-11 09:34:44,380 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 09:34:44,386 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:186 with 3 nodes.
2025-01-11 09:34:44,386 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:186 with 3 nodes.
2025-01-11 09:34:44,389 INFO Epoch 184 TRAIN info lr 0.00011844783356445924 rank 1
2025-01-11 09:34:44,390 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 09:34:44,390 INFO Epoch 184 TRAIN info lr 0.00011844783356445924 rank 0
2025-01-11 09:34:44,390 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 09:35:17,961 DEBUG TRAIN Batch 184/100 loss 0.034481 acc 0.976809 lr 0.00011843 grad_norm 0.356940 rank 2
2025-01-11 09:35:17,962 DEBUG TRAIN Batch 184/100 loss 0.028769 acc 0.982774 lr 0.00011843 grad_norm 0.356940 rank 0
2025-01-11 09:35:17,962 DEBUG TRAIN Batch 184/100 loss 0.020490 acc 0.985641 lr 0.00011843 grad_norm 0.356940 rank 1
2025-01-11 09:35:41,573 DEBUG TRAIN Batch 184/200 loss 0.024351 acc 0.982709 lr 0.00011841 grad_norm 0.369637 rank 2
2025-01-11 09:35:41,573 DEBUG TRAIN Batch 184/200 loss 0.020847 acc 0.984037 lr 0.00011841 grad_norm 0.369637 rank 0
2025-01-11 09:35:41,574 DEBUG TRAIN Batch 184/200 loss 0.028740 acc 0.979904 lr 0.00011841 grad_norm 0.369637 rank 1
2025-01-11 09:36:05,682 DEBUG TRAIN Batch 184/300 loss 0.030547 acc 0.980663 lr 0.00011840 grad_norm 0.363937 rank 0
2025-01-11 09:36:05,682 DEBUG TRAIN Batch 184/300 loss 0.041807 acc 0.966302 lr 0.00011840 grad_norm 0.363937 rank 1
2025-01-11 09:36:05,682 DEBUG TRAIN Batch 184/300 loss 0.020708 acc 0.988384 lr 0.00011840 grad_norm 0.363937 rank 2
2025-01-11 09:36:29,904 DEBUG TRAIN Batch 184/400 loss 0.013303 acc 0.990338 lr 0.00011838 grad_norm 0.322477 rank 0
2025-01-11 09:36:29,904 DEBUG TRAIN Batch 184/400 loss 0.025217 acc 0.981043 lr 0.00011838 grad_norm 0.322477 rank 1
2025-01-11 09:36:29,905 DEBUG TRAIN Batch 184/400 loss 0.024693 acc 0.982609 lr 0.00011838 grad_norm 0.322477 rank 2
2025-01-11 09:36:53,889 DEBUG TRAIN Batch 184/500 loss 0.026035 acc 0.982175 lr 0.00011836 grad_norm 0.357593 rank 0
2025-01-11 09:36:53,890 DEBUG TRAIN Batch 184/500 loss 0.029024 acc 0.980952 lr 0.00011836 grad_norm 0.357593 rank 1
2025-01-11 09:36:53,890 DEBUG TRAIN Batch 184/500 loss 0.031652 acc 0.977699 lr 0.00011836 grad_norm 0.357593 rank 2
2025-01-11 09:37:17,820 DEBUG TRAIN Batch 184/600 loss 0.021492 acc 0.985344 lr 0.00011835 grad_norm 0.335158 rank 1
2025-01-11 09:37:17,820 DEBUG TRAIN Batch 184/600 loss 0.025853 acc 0.982270 lr 0.00011835 grad_norm 0.335158 rank 0
2025-01-11 09:37:17,821 DEBUG TRAIN Batch 184/600 loss 0.030894 acc 0.981771 lr 0.00011835 grad_norm 0.335158 rank 2
2025-01-11 09:37:41,995 DEBUG TRAIN Batch 184/700 loss 0.017195 acc 0.988166 lr 0.00011833 grad_norm 0.360033 rank 0
2025-01-11 09:37:41,996 DEBUG TRAIN Batch 184/700 loss 0.031416 acc 0.975962 lr 0.00011833 grad_norm 0.360033 rank 1
2025-01-11 09:37:41,996 DEBUG TRAIN Batch 184/700 loss 0.030763 acc 0.977205 lr 0.00011833 grad_norm 0.360033 rank 2
2025-01-11 09:38:06,187 DEBUG TRAIN Batch 184/800 loss 0.018905 acc 0.991237 lr 0.00011832 grad_norm 0.392771 rank 0
2025-01-11 09:38:06,187 DEBUG TRAIN Batch 184/800 loss 0.046308 acc 0.969244 lr 0.00011832 grad_norm 0.392771 rank 1
2025-01-11 09:38:06,187 DEBUG TRAIN Batch 184/800 loss 0.031453 acc 0.974586 lr 0.00011832 grad_norm 0.392771 rank 2
2025-01-11 09:38:30,194 DEBUG TRAIN Batch 184/900 loss 0.020554 acc 0.985660 lr 0.00011830 grad_norm 0.357826 rank 0
2025-01-11 09:38:30,194 DEBUG TRAIN Batch 184/900 loss 0.038659 acc 0.972321 lr 0.00011830 grad_norm 0.357826 rank 2
2025-01-11 09:38:30,194 DEBUG TRAIN Batch 184/900 loss 0.030222 acc 0.981308 lr 0.00011830 grad_norm 0.357826 rank 1
2025-01-11 09:38:54,052 DEBUG TRAIN Batch 184/1000 loss 0.027014 acc 0.978763 lr 0.00011828 grad_norm 0.369827 rank 0
2025-01-11 09:38:54,052 DEBUG TRAIN Batch 184/1000 loss 0.036536 acc 0.979364 lr 0.00011828 grad_norm 0.369827 rank 1
2025-01-11 09:38:54,052 DEBUG TRAIN Batch 184/1000 loss 0.027389 acc 0.978065 lr 0.00011828 grad_norm 0.369827 rank 2
2025-01-11 09:39:18,457 DEBUG TRAIN Batch 184/1100 loss 0.022802 acc 0.987356 lr 0.00011827 grad_norm 0.341193 rank 1
2025-01-11 09:39:18,457 DEBUG TRAIN Batch 184/1100 loss 0.023074 acc 0.985591 lr 0.00011827 grad_norm 0.341193 rank 2
2025-01-11 09:39:18,458 DEBUG TRAIN Batch 184/1100 loss 0.020936 acc 0.986458 lr 0.00011827 grad_norm 0.341193 rank 0
2025-01-11 09:39:42,599 DEBUG TRAIN Batch 184/1200 loss 0.038914 acc 0.978062 lr 0.00011825 grad_norm 0.352457 rank 0
2025-01-11 09:39:42,600 DEBUG TRAIN Batch 184/1200 loss 0.018954 acc 0.984375 lr 0.00011825 grad_norm 0.352457 rank 1
2025-01-11 09:39:42,600 DEBUG TRAIN Batch 184/1200 loss 0.013564 acc 0.994872 lr 0.00011825 grad_norm 0.352457 rank 2
2025-01-11 09:40:06,572 DEBUG TRAIN Batch 184/1300 loss 0.035884 acc 0.975936 lr 0.00011823 grad_norm 0.348169 rank 0
2025-01-11 09:40:06,572 DEBUG TRAIN Batch 184/1300 loss 0.028248 acc 0.978686 lr 0.00011823 grad_norm 0.348169 rank 1
2025-01-11 09:40:06,573 DEBUG TRAIN Batch 184/1300 loss 0.029702 acc 0.984820 lr 0.00011823 grad_norm 0.348169 rank 2
2025-01-11 09:40:30,458 DEBUG TRAIN Batch 184/1400 loss 0.021962 acc 0.990369 lr 0.00011822 grad_norm 0.355169 rank 0
2025-01-11 09:40:30,458 DEBUG TRAIN Batch 184/1400 loss 0.022643 acc 0.985560 lr 0.00011822 grad_norm 0.355169 rank 1
2025-01-11 09:40:30,458 DEBUG TRAIN Batch 184/1400 loss 0.033981 acc 0.977165 lr 0.00011822 grad_norm 0.355169 rank 2
2025-01-11 09:40:54,767 DEBUG TRAIN Batch 184/1500 loss 0.028811 acc 0.978448 lr 0.00011820 grad_norm 0.362437 rank 0
2025-01-11 09:40:54,767 DEBUG TRAIN Batch 184/1500 loss 0.032049 acc 0.979452 lr 0.00011820 grad_norm 0.362437 rank 1
2025-01-11 09:40:54,768 DEBUG TRAIN Batch 184/1500 loss 0.024010 acc 0.979789 lr 0.00011820 grad_norm 0.362437 rank 2
2025-01-11 09:41:18,644 DEBUG TRAIN Batch 184/1600 loss 0.014254 acc 0.991001 lr 0.00011818 grad_norm 0.358517 rank 0
2025-01-11 09:41:18,644 DEBUG TRAIN Batch 184/1600 loss 0.032627 acc 0.976555 lr 0.00011818 grad_norm 0.358517 rank 2
2025-01-11 09:41:18,644 DEBUG TRAIN Batch 184/1600 loss 0.029666 acc 0.976723 lr 0.00011818 grad_norm 0.358517 rank 1
2025-01-11 09:41:42,187 DEBUG TRAIN Batch 184/1700 loss 0.034180 acc 0.982222 lr 0.00011817 grad_norm 0.343576 rank 1
2025-01-11 09:41:42,187 DEBUG TRAIN Batch 184/1700 loss 0.035934 acc 0.977539 lr 0.00011817 grad_norm 0.343576 rank 0
2025-01-11 09:41:42,188 DEBUG TRAIN Batch 184/1700 loss 0.021443 acc 0.987867 lr 0.00011817 grad_norm 0.343576 rank 2
2025-01-11 09:42:06,259 DEBUG TRAIN Batch 184/1800 loss 0.026720 acc 0.982301 lr 0.00011815 grad_norm 0.337404 rank 0
2025-01-11 09:42:06,260 DEBUG TRAIN Batch 184/1800 loss 0.028842 acc 0.979532 lr 0.00011815 grad_norm 0.337404 rank 1
2025-01-11 09:42:06,260 DEBUG TRAIN Batch 184/1800 loss 0.028156 acc 0.981250 lr 0.00011815 grad_norm 0.337404 rank 2
2025-01-11 09:42:30,556 DEBUG TRAIN Batch 184/1900 loss 0.040500 acc 0.976744 lr 0.00011813 grad_norm 0.344205 rank 1
2025-01-11 09:42:30,557 DEBUG TRAIN Batch 184/1900 loss 0.018663 acc 0.986207 lr 0.00011813 grad_norm 0.344205 rank 2
2025-01-11 09:42:30,557 DEBUG TRAIN Batch 184/1900 loss 0.021289 acc 0.985570 lr 0.00011813 grad_norm 0.344205 rank 0
2025-01-11 09:42:54,924 DEBUG TRAIN Batch 184/2000 loss 0.021497 acc 0.985673 lr 0.00011812 grad_norm 0.390577 rank 2
2025-01-11 09:42:54,924 DEBUG TRAIN Batch 184/2000 loss 0.027705 acc 0.978238 lr 0.00011812 grad_norm 0.390577 rank 0
2025-01-11 09:42:54,925 DEBUG TRAIN Batch 184/2000 loss 0.032722 acc 0.972924 lr 0.00011812 grad_norm 0.390577 rank 1
2025-01-11 09:43:20,685 DEBUG TRAIN Batch 184/2100 loss 0.025575 acc 0.984767 lr 0.00011810 grad_norm 0.378008 rank 2
2025-01-11 09:43:20,685 DEBUG TRAIN Batch 184/2100 loss 0.023138 acc 0.984496 lr 0.00011810 grad_norm 0.378008 rank 0
2025-01-11 09:43:20,685 DEBUG TRAIN Batch 184/2100 loss 0.039031 acc 0.974671 lr 0.00011810 grad_norm 0.378008 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 09:44:29,251 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 09:44:29,253 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 09:44:29,734 INFO Epoch 184 Step 179259 on_batch_end True CV rank 1
2025-01-11 09:44:29,734 INFO Epoch 184 Step 179259 on_batch_end True CV rank 2
2025-01-11 09:44:29,734 INFO Epoch 184 Step 179259 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 09:44:38,819 DEBUG CV Batch 184/100 loss 0.003792 acc 0.998885  rank 0
2025-01-11 09:44:39,321 DEBUG CV Batch 184/100 loss 0.003792 acc 0.998885  rank 2
2025-01-11 09:44:39,346 INFO Epoch 184 Step 179259 CV info lr 0.00011809445864224881 0 rank loss_2.740652378318485 acc_0.7806168477001943
2025-01-11 09:44:39,464 DEBUG CV Batch 184/100 loss 0.003792 acc 0.998885  rank 1
2025-01-11 09:44:39,881 INFO Epoch 184 Step 179259 CV info lr 0.00011809445864224881 2 rank loss_2.740652378318485 acc_0.7806168477001943
2025-01-11 09:44:39,996 INFO Epoch 184 Step 179259 CV info lr 0.00011809445864224881 1 rank loss_2.740652378318485 acc_0.7806168477001943
2025-01-11 09:44:40,622 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_184_whole.pt
2025-01-11 09:44:40,634 INFO Added key: store_based_barrier_key:187 to store for rank: 0
2025-01-11 09:44:40,645 INFO Added key: store_based_barrier_key:187 to store for rank: 2
2025-01-11 09:44:40,645 INFO Added key: store_based_barrier_key:187 to store for rank: 1
2025-01-11 09:44:40,645 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:187 with 3 nodes.
2025-01-11 09:44:40,645 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:187 with 3 nodes.
2025-01-11 09:44:40,650 INFO Epoch 185 TRAIN info lr 0.00011809445864224881 rank 2
2025-01-11 09:44:40,650 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 09:44:40,651 INFO Epoch 185 TRAIN info lr 0.00011809445864224881 rank 1
2025-01-11 09:44:40,651 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 09:44:40,654 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:187 with 3 nodes.
2025-01-11 09:44:40,659 INFO Epoch 185 TRAIN info lr 0.00011809445864224881 rank 0
2025-01-11 09:44:40,659 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 09:45:11,937 DEBUG TRAIN Batch 185/100 loss 0.019922 acc 0.986345 lr 0.00011808 grad_norm 0.360637 rank 2
2025-01-11 09:45:11,938 DEBUG TRAIN Batch 185/100 loss 0.031351 acc 0.983201 lr 0.00011808 grad_norm 0.360637 rank 0
2025-01-11 09:45:11,938 DEBUG TRAIN Batch 185/100 loss 0.032092 acc 0.977528 lr 0.00011808 grad_norm 0.360637 rank 1
2025-01-11 09:45:35,787 DEBUG TRAIN Batch 185/200 loss 0.022163 acc 0.980818 lr 0.00011806 grad_norm 0.333726 rank 1
2025-01-11 09:45:35,788 DEBUG TRAIN Batch 185/200 loss 0.027525 acc 0.982226 lr 0.00011806 grad_norm 0.333726 rank 0
2025-01-11 09:45:35,788 DEBUG TRAIN Batch 185/200 loss 0.020326 acc 0.985547 lr 0.00011806 grad_norm 0.333726 rank 2
2025-01-11 09:45:59,367 DEBUG TRAIN Batch 185/300 loss 0.028349 acc 0.981151 lr 0.00011805 grad_norm 0.331614 rank 1
2025-01-11 09:45:59,368 DEBUG TRAIN Batch 185/300 loss 0.019571 acc 0.988889 lr 0.00011805 grad_norm 0.331614 rank 0
2025-01-11 09:45:59,368 DEBUG TRAIN Batch 185/300 loss 0.035195 acc 0.973991 lr 0.00011805 grad_norm 0.331614 rank 2
2025-01-11 09:46:22,925 DEBUG TRAIN Batch 185/400 loss 0.040630 acc 0.980000 lr 0.00011803 grad_norm 0.399597 rank 0
2025-01-11 09:46:22,926 DEBUG TRAIN Batch 185/400 loss 0.018111 acc 0.988235 lr 0.00011803 grad_norm 0.399597 rank 2
2025-01-11 09:46:22,951 DEBUG TRAIN Batch 185/400 loss 0.033950 acc 0.974918 lr 0.00011803 grad_norm 0.399597 rank 1
2025-01-11 09:46:46,826 DEBUG TRAIN Batch 185/500 loss 0.022987 acc 0.985043 lr 0.00011801 grad_norm 0.353765 rank 0
2025-01-11 09:46:46,827 DEBUG TRAIN Batch 185/500 loss 0.025901 acc 0.980909 lr 0.00011801 grad_norm 0.353765 rank 1
2025-01-11 09:46:46,827 DEBUG TRAIN Batch 185/500 loss 0.032518 acc 0.979351 lr 0.00011801 grad_norm 0.353765 rank 2
2025-01-11 09:47:10,427 DEBUG TRAIN Batch 185/600 loss 0.025165 acc 0.983701 lr 0.00011800 grad_norm 0.326902 rank 1
2025-01-11 09:47:10,428 DEBUG TRAIN Batch 185/600 loss 0.020490 acc 0.986667 lr 0.00011800 grad_norm 0.326902 rank 2
2025-01-11 09:47:10,428 DEBUG TRAIN Batch 185/600 loss 0.027739 acc 0.979148 lr 0.00011800 grad_norm 0.326902 rank 0
2025-01-11 09:47:34,391 DEBUG TRAIN Batch 185/700 loss 0.036448 acc 0.972777 lr 0.00011798 grad_norm 0.373062 rank 0
2025-01-11 09:47:34,391 DEBUG TRAIN Batch 185/700 loss 0.030219 acc 0.978383 lr 0.00011798 grad_norm 0.373062 rank 1
2025-01-11 09:47:34,392 DEBUG TRAIN Batch 185/700 loss 0.031874 acc 0.980018 lr 0.00011798 grad_norm 0.373062 rank 2
2025-01-11 09:47:58,118 DEBUG TRAIN Batch 185/800 loss 0.009611 acc 0.990415 lr 0.00011796 grad_norm 0.305921 rank 0
2025-01-11 09:47:58,118 DEBUG TRAIN Batch 185/800 loss 0.017208 acc 0.987830 lr 0.00011796 grad_norm 0.305921 rank 1
2025-01-11 09:47:58,119 DEBUG TRAIN Batch 185/800 loss 0.017501 acc 0.987584 lr 0.00011796 grad_norm 0.305921 rank 2
2025-01-11 09:48:22,040 DEBUG TRAIN Batch 185/900 loss 0.022162 acc 0.986805 lr 0.00011795 grad_norm 0.360226 rank 1
2025-01-11 09:48:22,040 DEBUG TRAIN Batch 185/900 loss 0.034429 acc 0.977948 lr 0.00011795 grad_norm 0.360226 rank 0
2025-01-11 09:48:22,041 DEBUG TRAIN Batch 185/900 loss 0.032921 acc 0.976339 lr 0.00011795 grad_norm 0.360226 rank 2
2025-01-11 09:48:45,679 DEBUG TRAIN Batch 185/1000 loss 0.028199 acc 0.982821 lr 0.00011793 grad_norm 0.356558 rank 0
2025-01-11 09:48:45,679 DEBUG TRAIN Batch 185/1000 loss 0.025191 acc 0.986359 lr 0.00011793 grad_norm 0.356558 rank 1
2025-01-11 09:48:45,679 DEBUG TRAIN Batch 185/1000 loss 0.030899 acc 0.980583 lr 0.00011793 grad_norm 0.356558 rank 2
2025-01-11 09:49:09,217 DEBUG TRAIN Batch 185/1100 loss 0.016191 acc 0.988708 lr 0.00011791 grad_norm 0.337281 rank 1
2025-01-11 09:49:09,217 DEBUG TRAIN Batch 185/1100 loss 0.023004 acc 0.986046 lr 0.00011791 grad_norm 0.337281 rank 0
2025-01-11 09:49:09,218 DEBUG TRAIN Batch 185/1100 loss 0.023500 acc 0.985061 lr 0.00011791 grad_norm 0.337281 rank 2
2025-01-11 09:49:32,503 DEBUG TRAIN Batch 185/1200 loss 0.030745 acc 0.977113 lr 0.00011790 grad_norm 0.332027 rank 0
2025-01-11 09:49:32,504 DEBUG TRAIN Batch 185/1200 loss 0.022581 acc 0.983962 lr 0.00011790 grad_norm 0.332027 rank 2
2025-01-11 09:49:32,504 DEBUG TRAIN Batch 185/1200 loss 0.032828 acc 0.983152 lr 0.00011790 grad_norm 0.332027 rank 1
2025-01-11 09:49:55,855 DEBUG TRAIN Batch 185/1300 loss 0.020665 acc 0.988775 lr 0.00011788 grad_norm 0.350575 rank 0
2025-01-11 09:49:55,855 DEBUG TRAIN Batch 185/1300 loss 0.024493 acc 0.983838 lr 0.00011788 grad_norm 0.350575 rank 1
2025-01-11 09:49:55,855 DEBUG TRAIN Batch 185/1300 loss 0.029208 acc 0.978887 lr 0.00011788 grad_norm 0.350575 rank 2
2025-01-11 09:50:20,269 DEBUG TRAIN Batch 185/1400 loss 0.033088 acc 0.973522 lr 0.00011786 grad_norm 0.363837 rank 1
2025-01-11 09:50:20,269 DEBUG TRAIN Batch 185/1400 loss 0.030367 acc 0.976825 lr 0.00011786 grad_norm 0.363837 rank 0
2025-01-11 09:50:20,270 DEBUG TRAIN Batch 185/1400 loss 0.027028 acc 0.980114 lr 0.00011786 grad_norm 0.363837 rank 2
2025-01-11 09:50:43,517 DEBUG TRAIN Batch 185/1500 loss 0.048478 acc 0.971145 lr 0.00011785 grad_norm 0.370783 rank 0
2025-01-11 09:50:43,517 DEBUG TRAIN Batch 185/1500 loss 0.029423 acc 0.981660 lr 0.00011785 grad_norm 0.370783 rank 2
2025-01-11 09:50:43,517 DEBUG TRAIN Batch 185/1500 loss 0.019438 acc 0.982796 lr 0.00011785 grad_norm 0.370783 rank 1
2025-01-11 09:51:07,387 DEBUG TRAIN Batch 185/1600 loss 0.032666 acc 0.975229 lr 0.00011783 grad_norm 0.375416 rank 0
2025-01-11 09:51:07,387 DEBUG TRAIN Batch 185/1600 loss 0.034298 acc 0.978302 lr 0.00011783 grad_norm 0.375416 rank 1
2025-01-11 09:51:07,387 DEBUG TRAIN Batch 185/1600 loss 0.028613 acc 0.974775 lr 0.00011783 grad_norm 0.375416 rank 2
2025-01-11 09:51:31,644 DEBUG TRAIN Batch 185/1700 loss 0.030611 acc 0.981300 lr 0.00011782 grad_norm 0.332004 rank 0
2025-01-11 09:51:31,644 DEBUG TRAIN Batch 185/1700 loss 0.016965 acc 0.988584 lr 0.00011782 grad_norm 0.332004 rank 1
2025-01-11 09:51:31,644 DEBUG TRAIN Batch 185/1700 loss 0.020775 acc 0.989784 lr 0.00011782 grad_norm 0.332004 rank 2
2025-01-11 09:51:56,362 DEBUG TRAIN Batch 185/1800 loss 0.022501 acc 0.988012 lr 0.00011780 grad_norm 0.326072 rank 1
2025-01-11 09:51:56,362 DEBUG TRAIN Batch 185/1800 loss 0.014588 acc 0.992163 lr 0.00011780 grad_norm 0.326072 rank 2
2025-01-11 09:51:56,362 DEBUG TRAIN Batch 185/1800 loss 0.019956 acc 0.988613 lr 0.00011780 grad_norm 0.326072 rank 0
2025-01-11 09:52:21,260 DEBUG TRAIN Batch 185/1900 loss 0.052167 acc 0.965090 lr 0.00011778 grad_norm 0.408164 rank 2
2025-01-11 09:52:21,260 DEBUG TRAIN Batch 185/1900 loss 0.029581 acc 0.977314 lr 0.00011778 grad_norm 0.408164 rank 1
2025-01-11 09:52:21,261 DEBUG TRAIN Batch 185/1900 loss 0.014659 acc 0.993143 lr 0.00011778 grad_norm 0.408164 rank 0
2025-01-11 09:52:46,516 DEBUG TRAIN Batch 185/2000 loss 0.016932 acc 0.988683 lr 0.00011777 grad_norm 0.342030 rank 2
2025-01-11 09:52:46,516 DEBUG TRAIN Batch 185/2000 loss 0.024495 acc 0.986066 lr 0.00011777 grad_norm 0.342030 rank 0
2025-01-11 09:52:46,517 DEBUG TRAIN Batch 185/2000 loss 0.022663 acc 0.986861 lr 0.00011777 grad_norm 0.342030 rank 1
2025-01-11 09:53:11,715 DEBUG TRAIN Batch 185/2100 loss 0.026187 acc 0.982238 lr 0.00011775 grad_norm 0.335878 rank 1
2025-01-11 09:53:11,715 DEBUG TRAIN Batch 185/2100 loss 0.040883 acc 0.967626 lr 0.00011775 grad_norm 0.335878 rank 0
2025-01-11 09:53:11,715 DEBUG TRAIN Batch 185/2100 loss 0.011948 acc 0.991279 lr 0.00011775 grad_norm 0.335878 rank 2
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 09:54:32,504 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 09:54:32,509 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 09:54:32,788 INFO Epoch 185 Step 180349 on_batch_end True CV rank 1
2025-01-11 09:54:32,788 INFO Epoch 185 Step 180349 on_batch_end True CV rank 0
2025-01-11 09:54:32,788 INFO Epoch 185 Step 180349 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 09:54:41,802 DEBUG CV Batch 185/100 loss 0.002221 acc 0.998885  rank 0
2025-01-11 09:54:42,120 DEBUG CV Batch 185/100 loss 0.002221 acc 0.998885  rank 2
2025-01-11 09:54:42,341 INFO Epoch 185 Step 180349 CV info lr 0.00011773704594505489 0 rank loss_2.7671551169365367 acc_0.7803320492568769
2025-01-11 09:54:42,429 DEBUG CV Batch 185/100 loss 0.002221 acc 0.998885  rank 1
2025-01-11 09:54:42,647 INFO Epoch 185 Step 180349 CV info lr 0.00011773704594505489 2 rank loss_2.7671551169365367 acc_0.7803320492568769
2025-01-11 09:54:42,972 INFO Epoch 185 Step 180349 CV info lr 0.00011773704594505489 1 rank loss_2.7671551169365367 acc_0.7803320492568769
2025-01-11 09:54:43,623 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_185_whole.pt
2025-01-11 09:54:43,635 INFO Added key: store_based_barrier_key:188 to store for rank: 0
2025-01-11 09:54:43,645 INFO Added key: store_based_barrier_key:188 to store for rank: 2
2025-01-11 09:54:43,645 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:188 with 3 nodes.
2025-01-11 09:54:43,645 INFO Added key: store_based_barrier_key:188 to store for rank: 1
2025-01-11 09:54:43,645 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:188 with 3 nodes.
2025-01-11 09:54:43,654 INFO Epoch 186 TRAIN info lr 0.00011773704594505489 rank 2
2025-01-11 09:54:43,654 INFO Epoch 186 TRAIN info lr 0.00011773704594505489 rank 1
2025-01-11 09:54:43,654 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 09:54:43,654 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 09:54:43,655 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:188 with 3 nodes.
2025-01-11 09:54:43,661 INFO Epoch 186 TRAIN info lr 0.00011773704594505489 rank 0
2025-01-11 09:54:43,661 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 09:55:17,764 DEBUG TRAIN Batch 186/100 loss 0.014386 acc 0.991018 lr 0.00011772 grad_norm 0.340280 rank 1
2025-01-11 09:55:17,764 DEBUG TRAIN Batch 186/100 loss 0.034328 acc 0.978392 lr 0.00011772 grad_norm 0.340280 rank 2
2025-01-11 09:55:17,765 DEBUG TRAIN Batch 186/100 loss 0.020319 acc 0.981779 lr 0.00011772 grad_norm 0.340280 rank 0
2025-01-11 09:55:41,888 DEBUG TRAIN Batch 186/200 loss 0.029517 acc 0.982193 lr 0.00011770 grad_norm 0.334602 rank 0
2025-01-11 09:55:41,888 DEBUG TRAIN Batch 186/200 loss 0.012583 acc 0.991716 lr 0.00011770 grad_norm 0.334602 rank 1
2025-01-11 09:55:41,888 DEBUG TRAIN Batch 186/200 loss 0.018796 acc 0.987358 lr 0.00011770 grad_norm 0.334602 rank 2
2025-01-11 09:56:06,184 DEBUG TRAIN Batch 186/300 loss 0.025385 acc 0.977230 lr 0.00011769 grad_norm 0.360708 rank 1
2025-01-11 09:56:06,184 DEBUG TRAIN Batch 186/300 loss 0.023259 acc 0.983271 lr 0.00011769 grad_norm 0.360708 rank 0
2025-01-11 09:56:06,184 DEBUG TRAIN Batch 186/300 loss 0.033209 acc 0.976585 lr 0.00011769 grad_norm 0.360708 rank 2
2025-01-11 09:56:30,279 DEBUG TRAIN Batch 186/400 loss 0.013786 acc 0.989736 lr 0.00011767 grad_norm 0.358409 rank 1
2025-01-11 09:56:30,279 DEBUG TRAIN Batch 186/400 loss 0.022449 acc 0.987374 lr 0.00011767 grad_norm 0.358409 rank 0
2025-01-11 09:56:30,279 DEBUG TRAIN Batch 186/400 loss 0.028558 acc 0.980473 lr 0.00011767 grad_norm 0.358409 rank 2
2025-01-11 09:56:54,826 DEBUG TRAIN Batch 186/500 loss 0.014314 acc 0.988235 lr 0.00011766 grad_norm 0.359747 rank 1
2025-01-11 09:56:54,826 DEBUG TRAIN Batch 186/500 loss 0.021093 acc 0.985050 lr 0.00011766 grad_norm 0.359747 rank 0
2025-01-11 09:56:54,826 DEBUG TRAIN Batch 186/500 loss 0.032972 acc 0.979592 lr 0.00011766 grad_norm 0.359747 rank 2
2025-01-11 09:57:18,893 DEBUG TRAIN Batch 186/600 loss 0.009080 acc 0.992701 lr 0.00011764 grad_norm 0.355135 rank 1
2025-01-11 09:57:18,894 DEBUG TRAIN Batch 186/600 loss 0.033732 acc 0.977733 lr 0.00011764 grad_norm 0.355135 rank 2
2025-01-11 09:57:18,894 DEBUG TRAIN Batch 186/600 loss 0.027813 acc 0.978218 lr 0.00011764 grad_norm 0.355135 rank 0
2025-01-11 09:57:43,133 DEBUG TRAIN Batch 186/700 loss 0.023448 acc 0.981244 lr 0.00011762 grad_norm 0.353268 rank 1
2025-01-11 09:57:43,133 DEBUG TRAIN Batch 186/700 loss 0.019500 acc 0.987590 lr 0.00011762 grad_norm 0.353268 rank 0
2025-01-11 09:57:43,134 DEBUG TRAIN Batch 186/700 loss 0.039838 acc 0.973090 lr 0.00011762 grad_norm 0.353268 rank 2
2025-01-11 09:58:07,325 DEBUG TRAIN Batch 186/800 loss 0.017223 acc 0.991304 lr 0.00011761 grad_norm 0.353062 rank 1
2025-01-11 09:58:07,325 DEBUG TRAIN Batch 186/800 loss 0.016206 acc 0.991228 lr 0.00011761 grad_norm 0.353062 rank 0
2025-01-11 09:58:07,325 DEBUG TRAIN Batch 186/800 loss 0.021911 acc 0.987288 lr 0.00011761 grad_norm 0.353062 rank 2
2025-01-11 09:58:31,557 DEBUG TRAIN Batch 186/900 loss 0.027336 acc 0.982391 lr 0.00011759 grad_norm 0.351106 rank 1
2025-01-11 09:58:31,558 DEBUG TRAIN Batch 186/900 loss 0.030658 acc 0.972004 lr 0.00011759 grad_norm 0.351106 rank 2
2025-01-11 09:58:31,558 DEBUG TRAIN Batch 186/900 loss 0.012390 acc 0.987198 lr 0.00011759 grad_norm 0.351106 rank 0
2025-01-11 09:58:55,745 DEBUG TRAIN Batch 186/1000 loss 0.026306 acc 0.979381 lr 0.00011757 grad_norm 0.333630 rank 1
2025-01-11 09:58:55,745 DEBUG TRAIN Batch 186/1000 loss 0.020302 acc 0.991351 lr 0.00011757 grad_norm 0.333630 rank 2
2025-01-11 09:58:55,746 DEBUG TRAIN Batch 186/1000 loss 0.029735 acc 0.974181 lr 0.00011757 grad_norm 0.333630 rank 0
2025-01-11 09:59:19,546 DEBUG TRAIN Batch 186/1100 loss 0.026924 acc 0.985089 lr 0.00011756 grad_norm 0.345852 rank 1
2025-01-11 09:59:19,546 DEBUG TRAIN Batch 186/1100 loss 0.024728 acc 0.982537 lr 0.00011756 grad_norm 0.345852 rank 0
2025-01-11 09:59:19,547 DEBUG TRAIN Batch 186/1100 loss 0.026177 acc 0.983511 lr 0.00011756 grad_norm 0.345852 rank 2
2025-01-11 09:59:43,479 DEBUG TRAIN Batch 186/1200 loss 0.020162 acc 0.986922 lr 0.00011754 grad_norm 0.349598 rank 1
2025-01-11 09:59:43,480 DEBUG TRAIN Batch 186/1200 loss 0.017777 acc 0.987988 lr 0.00011754 grad_norm 0.349598 rank 0
2025-01-11 09:59:43,480 DEBUG TRAIN Batch 186/1200 loss 0.027472 acc 0.979279 lr 0.00011754 grad_norm 0.349598 rank 2
2025-01-11 10:00:07,647 DEBUG TRAIN Batch 186/1300 loss 0.027782 acc 0.979072 lr 0.00011753 grad_norm 0.333407 rank 1
2025-01-11 10:00:07,647 DEBUG TRAIN Batch 186/1300 loss 0.022619 acc 0.990486 lr 0.00011753 grad_norm 0.333407 rank 0
2025-01-11 10:00:07,647 DEBUG TRAIN Batch 186/1300 loss 0.030121 acc 0.979611 lr 0.00011753 grad_norm 0.333407 rank 2
2025-01-11 10:00:31,733 DEBUG TRAIN Batch 186/1400 loss 0.021344 acc 0.984615 lr 0.00011751 grad_norm 0.422102 rank 1
2025-01-11 10:00:31,734 DEBUG TRAIN Batch 186/1400 loss 0.048719 acc 0.969262 lr 0.00011751 grad_norm 0.422102 rank 2
2025-01-11 10:00:31,734 DEBUG TRAIN Batch 186/1400 loss 0.024017 acc 0.985148 lr 0.00011751 grad_norm 0.422102 rank 0
2025-01-11 10:00:55,927 DEBUG TRAIN Batch 186/1500 loss 0.019337 acc 0.988764 lr 0.00011749 grad_norm 0.348694 rank 2
2025-01-11 10:00:55,927 DEBUG TRAIN Batch 186/1500 loss 0.024974 acc 0.981818 lr 0.00011749 grad_norm 0.348694 rank 0
2025-01-11 10:00:55,927 DEBUG TRAIN Batch 186/1500 loss 0.025790 acc 0.986789 lr 0.00011749 grad_norm 0.348694 rank 1
2025-01-11 10:01:20,029 DEBUG TRAIN Batch 186/1600 loss 0.037789 acc 0.971869 lr 0.00011748 grad_norm 0.357391 rank 2
2025-01-11 10:01:20,030 DEBUG TRAIN Batch 186/1600 loss 0.036241 acc 0.975845 lr 0.00011748 grad_norm 0.357391 rank 0
2025-01-11 10:01:20,030 DEBUG TRAIN Batch 186/1600 loss 0.030545 acc 0.982654 lr 0.00011748 grad_norm 0.357391 rank 1
2025-01-11 10:01:43,236 DEBUG TRAIN Batch 186/1700 loss 0.033195 acc 0.979265 lr 0.00011746 grad_norm 0.321917 rank 2
2025-01-11 10:01:43,237 DEBUG TRAIN Batch 186/1700 loss 0.030810 acc 0.980995 lr 0.00011746 grad_norm 0.321917 rank 0
2025-01-11 10:01:43,237 DEBUG TRAIN Batch 186/1700 loss 0.021888 acc 0.987536 lr 0.00011746 grad_norm 0.321917 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 10:02:49,352 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 10:02:49,358 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 10:02:49,806 INFO Epoch 186 Step 181212 on_batch_end True CV rank 1
2025-01-11 10:02:49,806 INFO Epoch 186 Step 181212 on_batch_end True CV rank 0
2025-01-11 10:02:49,807 INFO Epoch 186 Step 181212 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 10:02:58,801 DEBUG CV Batch 186/100 loss 0.002214 acc 0.998885  rank 0
2025-01-11 10:02:59,093 DEBUG CV Batch 186/100 loss 0.002214 acc 0.998885  rank 2
2025-01-11 10:02:59,244 DEBUG CV Batch 186/100 loss 0.002214 acc 0.998885  rank 1
2025-01-11 10:02:59,335 INFO Epoch 186 Step 181212 CV info lr 0.0001174563572147734 0 rank loss_2.7516242202664056 acc_0.7818280838822064
2025-01-11 10:02:59,634 INFO Epoch 186 Step 181212 CV info lr 0.0001174563572147734 2 rank loss_2.7516242202664056 acc_0.7818280838822064
2025-01-11 10:02:59,781 INFO Epoch 186 Step 181212 CV info lr 0.0001174563572147734 1 rank loss_2.7516242202664056 acc_0.7818280838822064
2025-01-11 10:03:00,625 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_186_whole.pt
2025-01-11 10:03:00,647 INFO Added key: store_based_barrier_key:189 to store for rank: 0
2025-01-11 10:03:00,657 INFO Added key: store_based_barrier_key:189 to store for rank: 2
2025-01-11 10:03:00,657 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:189 with 3 nodes.
2025-01-11 10:03:00,657 INFO Added key: store_based_barrier_key:189 to store for rank: 1
2025-01-11 10:03:00,657 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:189 with 3 nodes.
2025-01-11 10:03:00,658 INFO Epoch 187 TRAIN info lr 0.0001174563572147734 rank 1
2025-01-11 10:03:00,658 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 10:03:00,664 INFO Epoch 187 TRAIN info lr 0.0001174563572147734 rank 2
2025-01-11 10:03:00,665 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 10:03:00,667 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:189 with 3 nodes.
2025-01-11 10:03:00,670 INFO Epoch 187 TRAIN info lr 0.0001174563572147734 rank 0
2025-01-11 10:03:00,670 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 10:03:31,255 DEBUG TRAIN Batch 187/100 loss 0.020225 acc 0.989680 lr 0.00011744 grad_norm 0.300424 rank 0
2025-01-11 10:03:31,255 DEBUG TRAIN Batch 187/100 loss 0.017704 acc 0.985417 lr 0.00011744 grad_norm 0.300424 rank 1
2025-01-11 10:03:31,255 DEBUG TRAIN Batch 187/100 loss 0.013835 acc 0.993617 lr 0.00011744 grad_norm 0.300424 rank 2
2025-01-11 10:03:54,804 DEBUG TRAIN Batch 187/200 loss 0.015488 acc 0.988106 lr 0.00011742 grad_norm 0.366805 rank 0
2025-01-11 10:03:54,804 DEBUG TRAIN Batch 187/200 loss 0.026825 acc 0.983636 lr 0.00011742 grad_norm 0.366805 rank 2
2025-01-11 10:03:54,804 DEBUG TRAIN Batch 187/200 loss 0.031121 acc 0.976998 lr 0.00011742 grad_norm 0.366805 rank 1
2025-01-11 10:04:18,308 DEBUG TRAIN Batch 187/300 loss 0.018899 acc 0.989331 lr 0.00011741 grad_norm 0.320828 rank 0
2025-01-11 10:04:18,308 DEBUG TRAIN Batch 187/300 loss 0.016247 acc 0.988593 lr 0.00011741 grad_norm 0.320828 rank 2
2025-01-11 10:04:18,308 DEBUG TRAIN Batch 187/300 loss 0.025077 acc 0.981939 lr 0.00011741 grad_norm 0.320828 rank 1
2025-01-11 10:04:41,586 DEBUG TRAIN Batch 187/400 loss 0.022225 acc 0.982906 lr 0.00011739 grad_norm 0.358373 rank 1
2025-01-11 10:04:41,587 DEBUG TRAIN Batch 187/400 loss 0.023125 acc 0.985491 lr 0.00011739 grad_norm 0.358373 rank 2
2025-01-11 10:04:41,587 DEBUG TRAIN Batch 187/400 loss 0.024761 acc 0.981964 lr 0.00011739 grad_norm 0.358373 rank 0
2025-01-11 10:05:05,619 DEBUG TRAIN Batch 187/500 loss 0.021970 acc 0.990809 lr 0.00011738 grad_norm 0.356507 rank 2
2025-01-11 10:05:05,620 DEBUG TRAIN Batch 187/500 loss 0.026414 acc 0.979554 lr 0.00011738 grad_norm 0.356507 rank 1
2025-01-11 10:05:05,620 DEBUG TRAIN Batch 187/500 loss 0.034313 acc 0.978196 lr 0.00011738 grad_norm 0.356507 rank 0
2025-01-11 10:05:29,298 DEBUG TRAIN Batch 187/600 loss 0.020074 acc 0.984749 lr 0.00011736 grad_norm 0.322489 rank 0
2025-01-11 10:05:29,299 DEBUG TRAIN Batch 187/600 loss 0.020032 acc 0.984962 lr 0.00011736 grad_norm 0.322489 rank 2
2025-01-11 10:05:29,299 DEBUG TRAIN Batch 187/600 loss 0.015199 acc 0.985160 lr 0.00011736 grad_norm 0.322489 rank 1
2025-01-11 10:05:54,342 DEBUG TRAIN Batch 187/700 loss 0.025069 acc 0.982507 lr 0.00011734 grad_norm 0.316539 rank 0
2025-01-11 10:05:54,342 DEBUG TRAIN Batch 187/700 loss 0.021907 acc 0.986529 lr 0.00011734 grad_norm 0.316539 rank 2
2025-01-11 10:05:54,342 DEBUG TRAIN Batch 187/700 loss 0.011524 acc 0.989744 lr 0.00011734 grad_norm 0.316539 rank 1
2025-01-11 10:06:18,077 DEBUG TRAIN Batch 187/800 loss 0.030066 acc 0.980685 lr 0.00011733 grad_norm 0.339807 rank 2
2025-01-11 10:06:18,077 DEBUG TRAIN Batch 187/800 loss 0.026339 acc 0.983350 lr 0.00011733 grad_norm 0.339807 rank 0
2025-01-11 10:06:18,077 DEBUG TRAIN Batch 187/800 loss 0.019917 acc 0.984733 lr 0.00011733 grad_norm 0.339807 rank 1
2025-01-11 10:06:42,258 DEBUG TRAIN Batch 187/900 loss 0.016181 acc 0.985155 lr 0.00011731 grad_norm 0.378964 rank 1
2025-01-11 10:06:42,258 DEBUG TRAIN Batch 187/900 loss 0.028453 acc 0.983432 lr 0.00011731 grad_norm 0.378964 rank 0
2025-01-11 10:06:42,258 DEBUG TRAIN Batch 187/900 loss 0.037573 acc 0.976481 lr 0.00011731 grad_norm 0.378964 rank 2
2025-01-11 10:07:07,434 DEBUG TRAIN Batch 187/1000 loss 0.020222 acc 0.983221 lr 0.00011729 grad_norm 0.342414 rank 1
2025-01-11 10:07:07,434 DEBUG TRAIN Batch 187/1000 loss 0.022004 acc 0.981689 lr 0.00011729 grad_norm 0.342414 rank 0
2025-01-11 10:07:07,434 DEBUG TRAIN Batch 187/1000 loss 0.024169 acc 0.983749 lr 0.00011729 grad_norm 0.342414 rank 2
2025-01-11 10:07:32,096 DEBUG TRAIN Batch 187/1100 loss 0.033866 acc 0.970699 lr 0.00011728 grad_norm 0.362493 rank 1
2025-01-11 10:07:32,096 DEBUG TRAIN Batch 187/1100 loss 0.031682 acc 0.979167 lr 0.00011728 grad_norm 0.362493 rank 0
2025-01-11 10:07:32,096 DEBUG TRAIN Batch 187/1100 loss 0.025496 acc 0.984171 lr 0.00011728 grad_norm 0.362493 rank 2
2025-01-11 10:07:55,881 DEBUG TRAIN Batch 187/1200 loss 0.025093 acc 0.979630 lr 0.00011726 grad_norm 0.344747 rank 0
2025-01-11 10:07:55,881 DEBUG TRAIN Batch 187/1200 loss 0.031087 acc 0.975402 lr 0.00011726 grad_norm 0.344747 rank 2
2025-01-11 10:07:55,881 DEBUG TRAIN Batch 187/1200 loss 0.021706 acc 0.984194 lr 0.00011726 grad_norm 0.344747 rank 1
2025-01-11 10:08:21,028 DEBUG TRAIN Batch 187/1300 loss 0.017285 acc 0.985143 lr 0.00011725 grad_norm 0.344854 rank 2
2025-01-11 10:08:21,028 DEBUG TRAIN Batch 187/1300 loss 0.014442 acc 0.988136 lr 0.00011725 grad_norm 0.344854 rank 1
2025-01-11 10:08:21,028 DEBUG TRAIN Batch 187/1300 loss 0.024164 acc 0.977143 lr 0.00011725 grad_norm 0.344854 rank 0
2025-01-11 10:08:45,432 DEBUG TRAIN Batch 187/1400 loss 0.012592 acc 0.991018 lr 0.00011723 grad_norm 0.352588 rank 1
2025-01-11 10:08:45,432 DEBUG TRAIN Batch 187/1400 loss 0.029674 acc 0.982867 lr 0.00011723 grad_norm 0.352588 rank 2
2025-01-11 10:08:45,433 DEBUG TRAIN Batch 187/1400 loss 0.022977 acc 0.983626 lr 0.00011723 grad_norm 0.352588 rank 0
2025-01-11 10:09:10,623 DEBUG TRAIN Batch 187/1500 loss 0.033885 acc 0.974779 lr 0.00011721 grad_norm 0.330492 rank 1
2025-01-11 10:09:10,624 DEBUG TRAIN Batch 187/1500 loss 0.024861 acc 0.981584 lr 0.00011721 grad_norm 0.330492 rank 0
2025-01-11 10:09:10,624 DEBUG TRAIN Batch 187/1500 loss 0.026022 acc 0.981888 lr 0.00011721 grad_norm 0.330492 rank 2
2025-01-11 10:09:35,691 DEBUG TRAIN Batch 187/1600 loss 0.030309 acc 0.978166 lr 0.00011720 grad_norm 0.370359 rank 0
2025-01-11 10:09:35,691 DEBUG TRAIN Batch 187/1600 loss 0.035880 acc 0.968512 lr 0.00011720 grad_norm 0.370359 rank 2
2025-01-11 10:09:35,692 DEBUG TRAIN Batch 187/1600 loss 0.034999 acc 0.978199 lr 0.00011720 grad_norm 0.370359 rank 1
2025-01-11 10:09:59,895 DEBUG TRAIN Batch 187/1700 loss 0.026746 acc 0.983209 lr 0.00011718 grad_norm 0.368609 rank 1
2025-01-11 10:09:59,895 DEBUG TRAIN Batch 187/1700 loss 0.019225 acc 0.986254 lr 0.00011718 grad_norm 0.368609 rank 0
2025-01-11 10:09:59,896 DEBUG TRAIN Batch 187/1700 loss 0.038336 acc 0.978281 lr 0.00011718 grad_norm 0.368609 rank 2
2025-01-11 10:10:24,782 DEBUG TRAIN Batch 187/1800 loss 0.035728 acc 0.980108 lr 0.00011717 grad_norm 0.375682 rank 1
2025-01-11 10:10:24,782 DEBUG TRAIN Batch 187/1800 loss 0.033033 acc 0.973002 lr 0.00011717 grad_norm 0.375682 rank 0
2025-01-11 10:10:24,782 DEBUG TRAIN Batch 187/1800 loss 0.032684 acc 0.981317 lr 0.00011717 grad_norm 0.375682 rank 2
2025-01-11 10:10:49,424 DEBUG TRAIN Batch 187/1900 loss 0.033155 acc 0.980374 lr 0.00011715 grad_norm 0.340936 rank 0
2025-01-11 10:10:49,424 DEBUG TRAIN Batch 187/1900 loss 0.024724 acc 0.978908 lr 0.00011715 grad_norm 0.340936 rank 2
2025-01-11 10:10:49,424 DEBUG TRAIN Batch 187/1900 loss 0.029566 acc 0.981634 lr 0.00011715 grad_norm 0.340936 rank 1
2025-01-11 10:11:13,669 DEBUG TRAIN Batch 187/2000 loss 0.027473 acc 0.980752 lr 0.00011713 grad_norm 0.358617 rank 2
2025-01-11 10:11:13,669 DEBUG TRAIN Batch 187/2000 loss 0.025860 acc 0.981801 lr 0.00011713 grad_norm 0.358617 rank 0
2025-01-11 10:11:13,670 DEBUG TRAIN Batch 187/2000 loss 0.037376 acc 0.975741 lr 0.00011713 grad_norm 0.358617 rank 1
2025-01-11 10:11:37,930 DEBUG TRAIN Batch 187/2100 loss 0.028236 acc 0.979392 lr 0.00011712 grad_norm 0.370510 rank 1
2025-01-11 10:11:37,930 DEBUG TRAIN Batch 187/2100 loss 0.019438 acc 0.988320 lr 0.00011712 grad_norm 0.370510 rank 2
2025-01-11 10:11:37,930 DEBUG TRAIN Batch 187/2100 loss 0.030194 acc 0.978033 lr 0.00011712 grad_norm 0.370510 rank 0
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 10:12:49,939 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 10:12:49,940 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 10:12:50,336 INFO Epoch 187 Step 182286 on_batch_end True CV rank 0
2025-01-11 10:12:50,336 INFO Epoch 187 Step 182286 on_batch_end True CV rank 1
2025-01-11 10:12:50,336 INFO Epoch 187 Step 182286 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 10:12:59,302 DEBUG CV Batch 187/100 loss 0.001277 acc 1.000000  rank 0
2025-01-11 10:12:59,554 DEBUG CV Batch 187/100 loss 0.001277 acc 1.000000  rank 2
2025-01-11 10:12:59,810 INFO Epoch 187 Step 182286 CV info lr 0.00011710982898931194 0 rank loss_2.7680529741895348 acc_0.7809438791714216
2025-01-11 10:12:59,904 DEBUG CV Batch 187/100 loss 0.001277 acc 1.000000  rank 1
2025-01-11 10:13:00,097 INFO Epoch 187 Step 182286 CV info lr 0.00011710982898931194 2 rank loss_2.7680529741895348 acc_0.7809438791714216
2025-01-11 10:13:00,448 INFO Epoch 187 Step 182286 CV info lr 0.00011710982898931194 1 rank loss_2.7680529741895348 acc_0.7809438791714216
2025-01-11 10:13:01,094 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_187_whole.pt
2025-01-11 10:13:01,105 INFO Added key: store_based_barrier_key:190 to store for rank: 0
2025-01-11 10:13:01,115 INFO Added key: store_based_barrier_key:190 to store for rank: 2
2025-01-11 10:13:01,116 INFO Added key: store_based_barrier_key:190 to store for rank: 1
2025-01-11 10:13:01,116 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:190 with 3 nodes.
2025-01-11 10:13:01,117 INFO Epoch 188 TRAIN info lr 0.00011710982898931194 rank 1
2025-01-11 10:13:01,117 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 10:13:01,125 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:190 with 3 nodes.
2025-01-11 10:13:01,126 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:190 with 3 nodes.
2025-01-11 10:13:01,133 INFO Epoch 188 TRAIN info lr 0.00011710982898931194 rank 0
2025-01-11 10:13:01,133 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 10:13:01,134 INFO Epoch 188 TRAIN info lr 0.00011710982898931194 rank 2
2025-01-11 10:13:01,134 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 10:13:31,003 DEBUG TRAIN Batch 188/100 loss 0.023301 acc 0.983398 lr 0.00011709 grad_norm 0.321223 rank 1
2025-01-11 10:13:31,004 DEBUG TRAIN Batch 188/100 loss 0.025806 acc 0.989095 lr 0.00011709 grad_norm 0.321223 rank 2
2025-01-11 10:13:31,004 DEBUG TRAIN Batch 188/100 loss 0.014077 acc 0.988810 lr 0.00011709 grad_norm 0.321223 rank 0
2025-01-11 10:13:54,673 DEBUG TRAIN Batch 188/200 loss 0.027641 acc 0.981836 lr 0.00011708 grad_norm 0.328645 rank 1
2025-01-11 10:13:54,673 DEBUG TRAIN Batch 188/200 loss 0.025783 acc 0.984660 lr 0.00011708 grad_norm 0.328645 rank 0
2025-01-11 10:13:54,673 DEBUG TRAIN Batch 188/200 loss 0.025121 acc 0.983957 lr 0.00011708 grad_norm 0.328645 rank 2
2025-01-11 10:14:17,802 DEBUG TRAIN Batch 188/300 loss 0.034831 acc 0.978011 lr 0.00011706 grad_norm 0.375933 rank 0
2025-01-11 10:14:17,802 DEBUG TRAIN Batch 188/300 loss 0.036867 acc 0.976268 lr 0.00011706 grad_norm 0.375933 rank 1
2025-01-11 10:14:17,803 DEBUG TRAIN Batch 188/300 loss 0.031060 acc 0.978346 lr 0.00011706 grad_norm 0.375933 rank 2
2025-01-11 10:14:41,198 DEBUG TRAIN Batch 188/400 loss 0.040113 acc 0.970951 lr 0.00011705 grad_norm 0.317889 rank 0
2025-01-11 10:14:41,198 DEBUG TRAIN Batch 188/400 loss 0.023408 acc 0.984862 lr 0.00011705 grad_norm 0.317889 rank 1
2025-01-11 10:14:41,198 DEBUG TRAIN Batch 188/400 loss 0.023831 acc 0.980749 lr 0.00011705 grad_norm 0.317889 rank 2
2025-01-11 10:15:04,512 DEBUG TRAIN Batch 188/500 loss 0.015731 acc 0.988626 lr 0.00011703 grad_norm 0.373901 rank 1
2025-01-11 10:15:04,513 DEBUG TRAIN Batch 188/500 loss 0.032234 acc 0.976096 lr 0.00011703 grad_norm 0.373901 rank 0
2025-01-11 10:15:04,513 DEBUG TRAIN Batch 188/500 loss 0.038215 acc 0.971354 lr 0.00011703 grad_norm 0.373901 rank 2
2025-01-11 10:15:28,157 DEBUG TRAIN Batch 188/600 loss 0.027401 acc 0.977251 lr 0.00011701 grad_norm 0.346207 rank 0
2025-01-11 10:15:28,157 DEBUG TRAIN Batch 188/600 loss 0.024683 acc 0.980132 lr 0.00011701 grad_norm 0.346207 rank 1
2025-01-11 10:15:28,158 DEBUG TRAIN Batch 188/600 loss 0.023430 acc 0.985806 lr 0.00011701 grad_norm 0.346207 rank 2
2025-01-11 10:15:52,259 DEBUG TRAIN Batch 188/700 loss 0.031660 acc 0.974747 lr 0.00011700 grad_norm 0.362458 rank 1
2025-01-11 10:15:52,259 DEBUG TRAIN Batch 188/700 loss 0.033603 acc 0.973978 lr 0.00011700 grad_norm 0.362458 rank 0
2025-01-11 10:15:52,259 DEBUG TRAIN Batch 188/700 loss 0.033473 acc 0.977436 lr 0.00011700 grad_norm 0.362458 rank 2
2025-01-11 10:16:15,887 DEBUG TRAIN Batch 188/800 loss 0.026508 acc 0.979700 lr 0.00011698 grad_norm 0.362624 rank 1
2025-01-11 10:16:15,887 DEBUG TRAIN Batch 188/800 loss 0.024062 acc 0.983462 lr 0.00011698 grad_norm 0.362624 rank 0
2025-01-11 10:16:15,888 DEBUG TRAIN Batch 188/800 loss 0.032490 acc 0.979148 lr 0.00011698 grad_norm 0.362624 rank 2
2025-01-11 10:16:39,838 DEBUG TRAIN Batch 188/900 loss 0.013978 acc 0.989035 lr 0.00011697 grad_norm 0.355827 rank 1
2025-01-11 10:16:39,839 DEBUG TRAIN Batch 188/900 loss 0.028117 acc 0.983081 lr 0.00011697 grad_norm 0.355827 rank 0
2025-01-11 10:16:39,839 DEBUG TRAIN Batch 188/900 loss 0.020035 acc 0.986152 lr 0.00011697 grad_norm 0.355827 rank 2
2025-01-11 10:17:03,826 DEBUG TRAIN Batch 188/1000 loss 0.028764 acc 0.984698 lr 0.00011695 grad_norm 0.365015 rank 1
2025-01-11 10:17:03,826 DEBUG TRAIN Batch 188/1000 loss 0.027484 acc 0.978109 lr 0.00011695 grad_norm 0.365015 rank 0
2025-01-11 10:17:03,826 DEBUG TRAIN Batch 188/1000 loss 0.028402 acc 0.978495 lr 0.00011695 grad_norm 0.365015 rank 2
2025-01-11 10:17:27,633 DEBUG TRAIN Batch 188/1100 loss 0.027192 acc 0.975775 lr 0.00011693 grad_norm 0.358962 rank 1
2025-01-11 10:17:27,633 DEBUG TRAIN Batch 188/1100 loss 0.024307 acc 0.977431 lr 0.00011693 grad_norm 0.358962 rank 0
2025-01-11 10:17:27,633 DEBUG TRAIN Batch 188/1100 loss 0.025437 acc 0.983225 lr 0.00011693 grad_norm 0.358962 rank 2
2025-01-11 10:17:51,373 DEBUG TRAIN Batch 188/1200 loss 0.022183 acc 0.983696 lr 0.00011692 grad_norm 0.338860 rank 0
2025-01-11 10:17:51,373 DEBUG TRAIN Batch 188/1200 loss 0.027716 acc 0.980488 lr 0.00011692 grad_norm 0.338860 rank 2
2025-01-11 10:17:51,373 DEBUG TRAIN Batch 188/1200 loss 0.027493 acc 0.979371 lr 0.00011692 grad_norm 0.338860 rank 1
2025-01-11 10:18:15,148 DEBUG TRAIN Batch 188/1300 loss 0.030320 acc 0.977451 lr 0.00011690 grad_norm 0.364278 rank 1
2025-01-11 10:18:15,149 DEBUG TRAIN Batch 188/1300 loss 0.024300 acc 0.987678 lr 0.00011690 grad_norm 0.364278 rank 0
2025-01-11 10:18:15,149 DEBUG TRAIN Batch 188/1300 loss 0.029358 acc 0.983923 lr 0.00011690 grad_norm 0.364278 rank 2
2025-01-11 10:18:39,375 DEBUG TRAIN Batch 188/1400 loss 0.028270 acc 0.982042 lr 0.00011689 grad_norm 0.334865 rank 1
2025-01-11 10:18:39,375 DEBUG TRAIN Batch 188/1400 loss 0.019537 acc 0.986014 lr 0.00011689 grad_norm 0.334865 rank 0
2025-01-11 10:18:39,376 DEBUG TRAIN Batch 188/1400 loss 0.038927 acc 0.975352 lr 0.00011689 grad_norm 0.334865 rank 2
2025-01-11 10:19:02,726 DEBUG TRAIN Batch 188/1500 loss 0.019606 acc 0.987152 lr 0.00011687 grad_norm 0.327718 rank 1
2025-01-11 10:19:02,727 DEBUG TRAIN Batch 188/1500 loss 0.021668 acc 0.985870 lr 0.00011687 grad_norm 0.327718 rank 0
2025-01-11 10:19:02,727 DEBUG TRAIN Batch 188/1500 loss 0.024764 acc 0.984805 lr 0.00011687 grad_norm 0.327718 rank 2
2025-01-11 10:19:27,555 DEBUG TRAIN Batch 188/1600 loss 0.014393 acc 0.991694 lr 0.00011685 grad_norm 0.345526 rank 0
2025-01-11 10:19:27,555 DEBUG TRAIN Batch 188/1600 loss 0.017181 acc 0.990888 lr 0.00011685 grad_norm 0.345526 rank 1
2025-01-11 10:19:27,556 DEBUG TRAIN Batch 188/1600 loss 0.029415 acc 0.982391 lr 0.00011685 grad_norm 0.345526 rank 2
2025-01-11 10:19:52,376 DEBUG TRAIN Batch 188/1700 loss 0.031867 acc 0.977695 lr 0.00011684 grad_norm 0.377900 rank 1
2025-01-11 10:19:52,376 DEBUG TRAIN Batch 188/1700 loss 0.018731 acc 0.987666 lr 0.00011684 grad_norm 0.377900 rank 0
2025-01-11 10:19:52,377 DEBUG TRAIN Batch 188/1700 loss 0.047858 acc 0.975543 lr 0.00011684 grad_norm 0.377900 rank 2
2025-01-11 10:20:17,129 DEBUG TRAIN Batch 188/1800 loss 0.034937 acc 0.980340 lr 0.00011682 grad_norm 0.371097 rank 0
2025-01-11 10:20:17,129 DEBUG TRAIN Batch 188/1800 loss 0.017930 acc 0.986070 lr 0.00011682 grad_norm 0.371097 rank 1
2025-01-11 10:20:17,129 DEBUG TRAIN Batch 188/1800 loss 0.029054 acc 0.978802 lr 0.00011682 grad_norm 0.371097 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 10:21:33,176 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 10:21:33,176 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 10:21:33,648 INFO Epoch 188 Step 183218 on_batch_end True CV rank 2
2025-01-11 10:21:33,648 INFO Epoch 188 Step 183218 on_batch_end True CV rank 0
2025-01-11 10:21:33,648 INFO Epoch 188 Step 183218 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 10:21:42,836 DEBUG CV Batch 188/100 loss 0.000262 acc 1.000000  rank 0
2025-01-11 10:21:43,070 DEBUG CV Batch 188/100 loss 0.000262 acc 1.000000  rank 2
2025-01-11 10:21:43,308 DEBUG CV Batch 188/100 loss 0.000262 acc 1.000000  rank 1
2025-01-11 10:21:43,325 INFO Epoch 188 Step 183218 CV info lr 0.00011681158995930851 0 rank loss_2.7553705537281705 acc_0.780562164490683
2025-01-11 10:21:43,616 INFO Epoch 188 Step 183218 CV info lr 0.00011681158995930851 2 rank loss_2.7553705537281705 acc_0.780562164490683
2025-01-11 10:21:43,849 INFO Epoch 188 Step 183218 CV info lr 0.00011681158995930851 1 rank loss_2.7553705537281705 acc_0.780562164490683
2025-01-11 10:21:44,617 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_188_whole.pt
2025-01-11 10:21:44,639 INFO Added key: store_based_barrier_key:191 to store for rank: 0
2025-01-11 10:21:44,649 INFO Added key: store_based_barrier_key:191 to store for rank: 2
2025-01-11 10:21:44,649 INFO Added key: store_based_barrier_key:191 to store for rank: 1
2025-01-11 10:21:44,650 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:191 with 3 nodes.
2025-01-11 10:21:44,659 INFO Epoch 189 TRAIN info lr 0.00011681158995930851 rank 1
2025-01-11 10:21:44,659 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 10:21:44,659 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:191 with 3 nodes.
2025-01-11 10:21:44,660 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:191 with 3 nodes.
2025-01-11 10:21:44,660 INFO Epoch 189 TRAIN info lr 0.00011681158995930851 rank 2
2025-01-11 10:21:44,660 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 10:21:44,667 INFO Epoch 189 TRAIN info lr 0.00011681158995930851 rank 0
2025-01-11 10:21:44,667 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 10:22:20,636 DEBUG TRAIN Batch 189/100 loss 0.015743 acc 0.986961 lr 0.00011680 grad_norm 0.333168 rank 0
2025-01-11 10:22:20,636 DEBUG TRAIN Batch 189/100 loss 0.017071 acc 0.991358 lr 0.00011680 grad_norm 0.333168 rank 2
2025-01-11 10:22:20,637 DEBUG TRAIN Batch 189/100 loss 0.025661 acc 0.986499 lr 0.00011680 grad_norm 0.333168 rank 1
2025-01-11 10:22:45,120 DEBUG TRAIN Batch 189/200 loss 0.017006 acc 0.987059 lr 0.00011678 grad_norm 0.360732 rank 0
2025-01-11 10:22:45,120 DEBUG TRAIN Batch 189/200 loss 0.027461 acc 0.979612 lr 0.00011678 grad_norm 0.360732 rank 2
2025-01-11 10:22:45,120 DEBUG TRAIN Batch 189/200 loss 0.029880 acc 0.977422 lr 0.00011678 grad_norm 0.360732 rank 1
2025-01-11 10:23:09,763 DEBUG TRAIN Batch 189/300 loss 0.029126 acc 0.977758 lr 0.00011676 grad_norm 0.354099 rank 1
2025-01-11 10:23:09,762 DEBUG TRAIN Batch 189/300 loss 0.029880 acc 0.982971 lr 0.00011676 grad_norm 0.354099 rank 0
2025-01-11 10:23:09,763 DEBUG TRAIN Batch 189/300 loss 0.013386 acc 0.990196 lr 0.00011676 grad_norm 0.354099 rank 2
2025-01-11 10:23:33,813 DEBUG TRAIN Batch 189/400 loss 0.019333 acc 0.988858 lr 0.00011675 grad_norm 0.337045 rank 0
2025-01-11 10:23:33,813 DEBUG TRAIN Batch 189/400 loss 0.026138 acc 0.984012 lr 0.00011675 grad_norm 0.337045 rank 2
2025-01-11 10:23:33,814 DEBUG TRAIN Batch 189/400 loss 0.027968 acc 0.985309 lr 0.00011675 grad_norm 0.337045 rank 1
2025-01-11 10:23:58,285 DEBUG TRAIN Batch 189/500 loss 0.032915 acc 0.979798 lr 0.00011673 grad_norm 0.375204 rank 2
2025-01-11 10:23:58,285 DEBUG TRAIN Batch 189/500 loss 0.022601 acc 0.981300 lr 0.00011673 grad_norm 0.375204 rank 1
2025-01-11 10:23:58,285 DEBUG TRAIN Batch 189/500 loss 0.035007 acc 0.980000 lr 0.00011673 grad_norm 0.375204 rank 0
2025-01-11 10:24:23,068 DEBUG TRAIN Batch 189/600 loss 0.015510 acc 0.986430 lr 0.00011672 grad_norm 0.351952 rank 2
2025-01-11 10:24:23,069 DEBUG TRAIN Batch 189/600 loss 0.018155 acc 0.988006 lr 0.00011672 grad_norm 0.351952 rank 1
2025-01-11 10:24:23,069 DEBUG TRAIN Batch 189/600 loss 0.015526 acc 0.986683 lr 0.00011672 grad_norm 0.351952 rank 0
2025-01-11 10:24:47,539 DEBUG TRAIN Batch 189/700 loss 0.032894 acc 0.983529 lr 0.00011670 grad_norm 0.368283 rank 2
2025-01-11 10:24:47,539 DEBUG TRAIN Batch 189/700 loss 0.027766 acc 0.981625 lr 0.00011670 grad_norm 0.368283 rank 0
2025-01-11 10:24:47,539 DEBUG TRAIN Batch 189/700 loss 0.027383 acc 0.981627 lr 0.00011670 grad_norm 0.368283 rank 1
2025-01-11 10:25:12,173 DEBUG TRAIN Batch 189/800 loss 0.023754 acc 0.984517 lr 0.00011668 grad_norm 0.372997 rank 2
2025-01-11 10:25:12,173 DEBUG TRAIN Batch 189/800 loss 0.020277 acc 0.988304 lr 0.00011668 grad_norm 0.372997 rank 0
2025-01-11 10:25:12,173 DEBUG TRAIN Batch 189/800 loss 0.022546 acc 0.986386 lr 0.00011668 grad_norm 0.372997 rank 1
2025-01-11 10:25:36,381 DEBUG TRAIN Batch 189/900 loss 0.023047 acc 0.984146 lr 0.00011667 grad_norm 0.347283 rank 1
2025-01-11 10:25:36,382 DEBUG TRAIN Batch 189/900 loss 0.032582 acc 0.978467 lr 0.00011667 grad_norm 0.347283 rank 0
2025-01-11 10:25:36,385 DEBUG TRAIN Batch 189/900 loss 0.013275 acc 0.990741 lr 0.00011667 grad_norm 0.347283 rank 2
2025-01-11 10:26:00,955 DEBUG TRAIN Batch 189/1000 loss 0.015758 acc 0.989204 lr 0.00011665 grad_norm 0.297025 rank 2
2025-01-11 10:26:00,955 DEBUG TRAIN Batch 189/1000 loss 0.026855 acc 0.982160 lr 0.00011665 grad_norm 0.297025 rank 0
2025-01-11 10:26:00,956 DEBUG TRAIN Batch 189/1000 loss 0.016654 acc 0.986314 lr 0.00011665 grad_norm 0.297025 rank 1
2025-01-11 10:26:25,970 DEBUG TRAIN Batch 189/1100 loss 0.037453 acc 0.975207 lr 0.00011664 grad_norm 0.356447 rank 2
2025-01-11 10:26:25,970 DEBUG TRAIN Batch 189/1100 loss 0.034178 acc 0.978984 lr 0.00011664 grad_norm 0.356447 rank 0
2025-01-11 10:26:25,970 DEBUG TRAIN Batch 189/1100 loss 0.015531 acc 0.987629 lr 0.00011664 grad_norm 0.356447 rank 1
2025-01-11 10:26:50,006 DEBUG TRAIN Batch 189/1200 loss 0.029727 acc 0.979381 lr 0.00011662 grad_norm 0.366791 rank 0
2025-01-11 10:26:50,006 DEBUG TRAIN Batch 189/1200 loss 0.030144 acc 0.977688 lr 0.00011662 grad_norm 0.366791 rank 1
2025-01-11 10:26:50,006 DEBUG TRAIN Batch 189/1200 loss 0.029624 acc 0.980146 lr 0.00011662 grad_norm 0.366791 rank 2
2025-01-11 10:27:13,737 DEBUG TRAIN Batch 189/1300 loss 0.029797 acc 0.980052 lr 0.00011660 grad_norm 0.351884 rank 2
2025-01-11 10:27:13,737 DEBUG TRAIN Batch 189/1300 loss 0.017731 acc 0.986755 lr 0.00011660 grad_norm 0.351884 rank 1
2025-01-11 10:27:13,738 DEBUG TRAIN Batch 189/1300 loss 0.025373 acc 0.981383 lr 0.00011660 grad_norm 0.351884 rank 0
2025-01-11 10:27:37,295 DEBUG TRAIN Batch 189/1400 loss 0.027187 acc 0.982676 lr 0.00011659 grad_norm 0.326259 rank 0
2025-01-11 10:27:37,295 DEBUG TRAIN Batch 189/1400 loss 0.022291 acc 0.985889 lr 0.00011659 grad_norm 0.326259 rank 2
2025-01-11 10:27:37,295 DEBUG TRAIN Batch 189/1400 loss 0.018818 acc 0.985104 lr 0.00011659 grad_norm 0.326259 rank 1
2025-01-11 10:28:00,894 DEBUG TRAIN Batch 189/1500 loss 0.023997 acc 0.985104 lr 0.00011657 grad_norm 0.364846 rank 2
2025-01-11 10:28:00,894 DEBUG TRAIN Batch 189/1500 loss 0.026981 acc 0.979853 lr 0.00011657 grad_norm 0.364846 rank 1
2025-01-11 10:28:00,894 DEBUG TRAIN Batch 189/1500 loss 0.021499 acc 0.983945 lr 0.00011657 grad_norm 0.364846 rank 0
2025-01-11 10:28:24,861 DEBUG TRAIN Batch 189/1600 loss 0.024021 acc 0.983392 lr 0.00011656 grad_norm 0.366810 rank 1
2025-01-11 10:28:24,861 DEBUG TRAIN Batch 189/1600 loss 0.033203 acc 0.983156 lr 0.00011656 grad_norm 0.366810 rank 0
2025-01-11 10:28:24,861 DEBUG TRAIN Batch 189/1600 loss 0.022645 acc 0.981076 lr 0.00011656 grad_norm 0.366810 rank 2
2025-01-11 10:28:48,189 DEBUG TRAIN Batch 189/1700 loss 0.024868 acc 0.979981 lr 0.00011654 grad_norm 0.360712 rank 1
2025-01-11 10:28:48,189 DEBUG TRAIN Batch 189/1700 loss 0.034871 acc 0.976303 lr 0.00011654 grad_norm 0.360712 rank 0
2025-01-11 10:28:48,189 DEBUG TRAIN Batch 189/1700 loss 0.031440 acc 0.976281 lr 0.00011654 grad_norm 0.360712 rank 2
2025-01-11 10:29:12,474 DEBUG TRAIN Batch 189/1800 loss 0.027200 acc 0.982075 lr 0.00011653 grad_norm 0.341363 rank 1
2025-01-11 10:29:12,474 DEBUG TRAIN Batch 189/1800 loss 0.025102 acc 0.983562 lr 0.00011653 grad_norm 0.341363 rank 0
2025-01-11 10:29:12,475 DEBUG TRAIN Batch 189/1800 loss 0.020490 acc 0.987952 lr 0.00011653 grad_norm 0.341363 rank 2
2025-01-11 10:29:35,861 DEBUG TRAIN Batch 189/1900 loss 0.031760 acc 0.974039 lr 0.00011651 grad_norm 0.363022 rank 1
2025-01-11 10:29:35,861 DEBUG TRAIN Batch 189/1900 loss 0.037291 acc 0.977297 lr 0.00011651 grad_norm 0.363022 rank 2
2025-01-11 10:29:35,861 DEBUG TRAIN Batch 189/1900 loss 0.026786 acc 0.980505 lr 0.00011651 grad_norm 0.363022 rank 0
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 10:30:41,168 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 10:30:41,170 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 10:30:41,595 INFO Epoch 189 Step 184179 on_batch_end True CV rank 1
2025-01-11 10:30:41,595 INFO Epoch 189 Step 184179 on_batch_end True CV rank 2
2025-01-11 10:30:41,595 INFO Epoch 189 Step 184179 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 10:30:50,940 DEBUG CV Batch 189/100 loss 0.000526 acc 1.000000  rank 0
2025-01-11 10:30:51,057 DEBUG CV Batch 189/100 loss 0.000526 acc 1.000000  rank 2
2025-01-11 10:30:51,254 DEBUG CV Batch 189/100 loss 0.000526 acc 1.000000  rank 1
2025-01-11 10:30:51,414 INFO Epoch 189 Step 184179 CV info lr 0.00011650644455163552 0 rank loss_2.7646595197041743 acc_0.7811999941865603
2025-01-11 10:30:51,570 INFO Epoch 189 Step 184179 CV info lr 0.00011650644455163552 2 rank loss_2.7646595197041743 acc_0.7811999941865603
2025-01-11 10:30:51,795 INFO Epoch 189 Step 184179 CV info lr 0.00011650644455163552 1 rank loss_2.7646595197041743 acc_0.7811999941865603
2025-01-11 10:30:52,697 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_189_whole.pt
2025-01-11 10:30:52,719 INFO Added key: store_based_barrier_key:192 to store for rank: 0
2025-01-11 10:30:52,729 INFO Added key: store_based_barrier_key:192 to store for rank: 2
2025-01-11 10:30:52,729 INFO Added key: store_based_barrier_key:192 to store for rank: 1
2025-01-11 10:30:52,730 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:192 with 3 nodes.
2025-01-11 10:30:52,739 INFO Epoch 190 TRAIN info lr 0.00011650644455163552 rank 1
2025-01-11 10:30:52,739 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 10:30:52,739 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:192 with 3 nodes.
2025-01-11 10:30:52,740 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:192 with 3 nodes.
2025-01-11 10:30:52,742 INFO Epoch 190 TRAIN info lr 0.00011650644455163552 rank 0
2025-01-11 10:30:52,742 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 10:30:52,742 INFO Epoch 190 TRAIN info lr 0.00011650644455163552 rank 2
2025-01-11 10:30:52,742 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 10:31:26,478 DEBUG TRAIN Batch 190/100 loss 0.032232 acc 0.979331 lr 0.00011649 grad_norm 0.344254 rank 2
2025-01-11 10:31:26,479 DEBUG TRAIN Batch 190/100 loss 0.033973 acc 0.978887 lr 0.00011649 grad_norm 0.344254 rank 0
2025-01-11 10:31:26,479 DEBUG TRAIN Batch 190/100 loss 0.029058 acc 0.982624 lr 0.00011649 grad_norm 0.344254 rank 1
2025-01-11 10:31:50,564 DEBUG TRAIN Batch 190/200 loss 0.016054 acc 0.988651 lr 0.00011647 grad_norm 0.336973 rank 1
2025-01-11 10:31:50,564 DEBUG TRAIN Batch 190/200 loss 0.039695 acc 0.972591 lr 0.00011647 grad_norm 0.336973 rank 2
2025-01-11 10:31:50,565 DEBUG TRAIN Batch 190/200 loss 0.029296 acc 0.983827 lr 0.00011647 grad_norm 0.336973 rank 0
2025-01-11 10:32:15,041 DEBUG TRAIN Batch 190/300 loss 0.023029 acc 0.980932 lr 0.00011646 grad_norm 0.323946 rank 0
2025-01-11 10:32:15,041 DEBUG TRAIN Batch 190/300 loss 0.028501 acc 0.981928 lr 0.00011646 grad_norm 0.323946 rank 2
2025-01-11 10:32:15,041 DEBUG TRAIN Batch 190/300 loss 0.028519 acc 0.976809 lr 0.00011646 grad_norm 0.323946 rank 1
2025-01-11 10:32:39,282 DEBUG TRAIN Batch 190/400 loss 0.021626 acc 0.984303 lr 0.00011644 grad_norm 0.360137 rank 0
2025-01-11 10:32:39,282 DEBUG TRAIN Batch 190/400 loss 0.031668 acc 0.979284 lr 0.00011644 grad_norm 0.360137 rank 1
2025-01-11 10:32:39,282 DEBUG TRAIN Batch 190/400 loss 0.042033 acc 0.980877 lr 0.00011644 grad_norm 0.360137 rank 2
2025-01-11 10:33:03,003 DEBUG TRAIN Batch 190/500 loss 0.019859 acc 0.986287 lr 0.00011643 grad_norm 0.353638 rank 1
2025-01-11 10:33:03,003 DEBUG TRAIN Batch 190/500 loss 0.020113 acc 0.989910 lr 0.00011643 grad_norm 0.353638 rank 0
2025-01-11 10:33:03,003 DEBUG TRAIN Batch 190/500 loss 0.020890 acc 0.986486 lr 0.00011643 grad_norm 0.353638 rank 2
2025-01-11 10:33:27,059 DEBUG TRAIN Batch 190/600 loss 0.020515 acc 0.986141 lr 0.00011641 grad_norm 0.329894 rank 1
2025-01-11 10:33:27,059 DEBUG TRAIN Batch 190/600 loss 0.027020 acc 0.980620 lr 0.00011641 grad_norm 0.329894 rank 0
2025-01-11 10:33:27,059 DEBUG TRAIN Batch 190/600 loss 0.022127 acc 0.987302 lr 0.00011641 grad_norm 0.329894 rank 2
2025-01-11 10:33:52,286 DEBUG TRAIN Batch 190/700 loss 0.013802 acc 0.993220 lr 0.00011640 grad_norm 0.350766 rank 1
2025-01-11 10:33:52,286 DEBUG TRAIN Batch 190/700 loss 0.020368 acc 0.987528 lr 0.00011640 grad_norm 0.350766 rank 0
2025-01-11 10:33:52,286 DEBUG TRAIN Batch 190/700 loss 0.017595 acc 0.988875 lr 0.00011640 grad_norm 0.350766 rank 2
2025-01-11 10:34:16,855 DEBUG TRAIN Batch 190/800 loss 0.015954 acc 0.987934 lr 0.00011638 grad_norm 0.603089 rank 1
2025-01-11 10:34:16,856 DEBUG TRAIN Batch 190/800 loss 0.033712 acc 0.977211 lr 0.00011638 grad_norm 0.603089 rank 0
2025-01-11 10:34:16,856 DEBUG TRAIN Batch 190/800 loss 0.030855 acc 0.980282 lr 0.00011638 grad_norm 0.603089 rank 2
2025-01-11 10:34:40,924 DEBUG TRAIN Batch 190/900 loss 0.020486 acc 0.984000 lr 0.00011636 grad_norm 0.340491 rank 1
2025-01-11 10:34:40,925 DEBUG TRAIN Batch 190/900 loss 0.019207 acc 0.988855 lr 0.00011636 grad_norm 0.340491 rank 0
2025-01-11 10:34:40,925 DEBUG TRAIN Batch 190/900 loss 0.020004 acc 0.987867 lr 0.00011636 grad_norm 0.340491 rank 2
2025-01-11 10:35:05,916 DEBUG TRAIN Batch 190/1000 loss 0.028384 acc 0.976513 lr 0.00011635 grad_norm 0.357418 rank 1
2025-01-11 10:35:05,916 DEBUG TRAIN Batch 190/1000 loss 0.025763 acc 0.984093 lr 0.00011635 grad_norm 0.357418 rank 0
2025-01-11 10:35:05,916 DEBUG TRAIN Batch 190/1000 loss 0.025224 acc 0.977507 lr 0.00011635 grad_norm 0.357418 rank 2
2025-01-11 10:35:30,000 DEBUG TRAIN Batch 190/1100 loss 0.015170 acc 0.990279 lr 0.00011633 grad_norm 0.333340 rank 1
2025-01-11 10:35:30,001 DEBUG TRAIN Batch 190/1100 loss 0.022331 acc 0.984348 lr 0.00011633 grad_norm 0.333340 rank 2
2025-01-11 10:35:30,002 DEBUG TRAIN Batch 190/1100 loss 0.017644 acc 0.988858 lr 0.00011633 grad_norm 0.333340 rank 0
2025-01-11 10:35:54,252 DEBUG TRAIN Batch 190/1200 loss 0.017580 acc 0.990485 lr 0.00011632 grad_norm 0.321093 rank 0
2025-01-11 10:35:54,252 DEBUG TRAIN Batch 190/1200 loss 0.017026 acc 0.987524 lr 0.00011632 grad_norm 0.321093 rank 1
2025-01-11 10:35:54,252 DEBUG TRAIN Batch 190/1200 loss 0.027401 acc 0.984805 lr 0.00011632 grad_norm 0.321093 rank 2
2025-01-11 10:36:19,021 DEBUG TRAIN Batch 190/1300 loss 0.018726 acc 0.985484 lr 0.00011630 grad_norm 0.335607 rank 1
2025-01-11 10:36:19,021 DEBUG TRAIN Batch 190/1300 loss 0.030894 acc 0.979913 lr 0.00011630 grad_norm 0.335607 rank 2
2025-01-11 10:36:19,022 DEBUG TRAIN Batch 190/1300 loss 0.012908 acc 0.992443 lr 0.00011630 grad_norm 0.335607 rank 0
2025-01-11 10:36:42,977 DEBUG TRAIN Batch 190/1400 loss 0.026001 acc 0.982906 lr 0.00011629 grad_norm 0.396748 rank 1
2025-01-11 10:36:42,977 DEBUG TRAIN Batch 190/1400 loss 0.019874 acc 0.984694 lr 0.00011629 grad_norm 0.396748 rank 0
2025-01-11 10:36:42,977 DEBUG TRAIN Batch 190/1400 loss 0.041168 acc 0.975936 lr 0.00011629 grad_norm 0.396748 rank 2
2025-01-11 10:37:08,003 DEBUG TRAIN Batch 190/1500 loss 0.019794 acc 0.986270 lr 0.00011627 grad_norm 0.354486 rank 1
2025-01-11 10:37:08,003 DEBUG TRAIN Batch 190/1500 loss 0.024964 acc 0.983333 lr 0.00011627 grad_norm 0.354486 rank 0
2025-01-11 10:37:08,004 DEBUG TRAIN Batch 190/1500 loss 0.027897 acc 0.977436 lr 0.00011627 grad_norm 0.354486 rank 2
2025-01-11 10:37:32,695 DEBUG TRAIN Batch 190/1600 loss 0.022630 acc 0.990302 lr 0.00011625 grad_norm 0.358459 rank 1
2025-01-11 10:37:32,695 DEBUG TRAIN Batch 190/1600 loss 0.030998 acc 0.978484 lr 0.00011625 grad_norm 0.358459 rank 0
2025-01-11 10:37:32,695 DEBUG TRAIN Batch 190/1600 loss 0.024931 acc 0.979798 lr 0.00011625 grad_norm 0.358459 rank 2
2025-01-11 10:37:56,555 DEBUG TRAIN Batch 190/1700 loss 0.037477 acc 0.973660 lr 0.00011624 grad_norm 0.375901 rank 0
2025-01-11 10:37:56,556 DEBUG TRAIN Batch 190/1700 loss 0.023238 acc 0.985604 lr 0.00011624 grad_norm 0.375901 rank 1
2025-01-11 10:37:56,556 DEBUG TRAIN Batch 190/1700 loss 0.028208 acc 0.983986 lr 0.00011624 grad_norm 0.375901 rank 2
2025-01-11 10:38:20,689 DEBUG TRAIN Batch 190/1800 loss 0.016764 acc 0.989305 lr 0.00011622 grad_norm 0.332578 rank 2
2025-01-11 10:38:20,689 DEBUG TRAIN Batch 190/1800 loss 0.027543 acc 0.979270 lr 0.00011622 grad_norm 0.332578 rank 1
2025-01-11 10:38:20,690 DEBUG TRAIN Batch 190/1800 loss 0.021158 acc 0.986042 lr 0.00011622 grad_norm 0.332578 rank 0
2025-01-11 10:38:45,158 DEBUG TRAIN Batch 190/1900 loss 0.024098 acc 0.981870 lr 0.00011621 grad_norm 0.362759 rank 2
2025-01-11 10:38:45,158 DEBUG TRAIN Batch 190/1900 loss 0.031909 acc 0.981111 lr 0.00011621 grad_norm 0.362759 rank 0
2025-01-11 10:38:45,158 DEBUG TRAIN Batch 190/1900 loss 0.025466 acc 0.984930 lr 0.00011621 grad_norm 0.362759 rank 1
2025-01-11 10:39:08,939 DEBUG TRAIN Batch 190/2000 loss 0.016361 acc 0.990074 lr 0.00011619 grad_norm 0.362497 rank 2
2025-01-11 10:39:08,939 DEBUG TRAIN Batch 190/2000 loss 0.031898 acc 0.981048 lr 0.00011619 grad_norm 0.362497 rank 0
2025-01-11 10:39:08,939 DEBUG TRAIN Batch 190/2000 loss 0.039727 acc 0.975184 lr 0.00011619 grad_norm 0.362497 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 10:40:18,519 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 10:40:18,521 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 10:40:18,829 INFO Epoch 190 Step 185199 on_batch_end True CV rank 2
2025-01-11 10:40:18,829 INFO Epoch 190 Step 185199 on_batch_end True CV rank 0
2025-01-11 10:40:18,829 INFO Epoch 190 Step 185199 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 10:40:27,820 DEBUG CV Batch 190/100 loss 0.000496 acc 1.000000  rank 0
2025-01-11 10:40:27,984 DEBUG CV Batch 190/100 loss 0.000496 acc 1.000000  rank 2
2025-01-11 10:40:28,349 INFO Epoch 190 Step 185199 CV info lr 0.00011618516676032297 0 rank loss_2.780881213471746 acc_0.7815261172098026
2025-01-11 10:40:28,465 DEBUG CV Batch 190/100 loss 0.000496 acc 1.000000  rank 1
2025-01-11 10:40:28,521 INFO Epoch 190 Step 185199 CV info lr 0.00011618516676032297 2 rank loss_2.780881213471746 acc_0.7815261172098026
2025-01-11 10:40:29,012 INFO Epoch 190 Step 185199 CV info lr 0.00011618516676032297 1 rank loss_2.780881213471746 acc_0.7815261172098026
2025-01-11 10:40:29,622 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_190_whole.pt
2025-01-11 10:40:29,634 INFO Added key: store_based_barrier_key:193 to store for rank: 0
2025-01-11 10:40:29,644 INFO Added key: store_based_barrier_key:193 to store for rank: 2
2025-01-11 10:40:29,644 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:193 with 3 nodes.
2025-01-11 10:40:29,644 INFO Added key: store_based_barrier_key:193 to store for rank: 1
2025-01-11 10:40:29,644 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:193 with 3 nodes.
2025-01-11 10:40:29,646 INFO Epoch 191 TRAIN info lr 0.00011618516676032297 rank 1
2025-01-11 10:40:29,646 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 10:40:29,648 INFO Epoch 191 TRAIN info lr 0.00011618516676032297 rank 2
2025-01-11 10:40:29,648 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 10:40:29,654 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:193 with 3 nodes.
2025-01-11 10:40:29,658 INFO Epoch 191 TRAIN info lr 0.00011618516676032297 rank 0
2025-01-11 10:40:29,658 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 10:41:03,490 DEBUG TRAIN Batch 191/100 loss 0.025359 acc 0.981787 lr 0.00011617 grad_norm 0.346918 rank 2
2025-01-11 10:41:03,490 DEBUG TRAIN Batch 191/100 loss 0.020238 acc 0.991054 lr 0.00011617 grad_norm 0.346918 rank 1
2025-01-11 10:41:03,491 DEBUG TRAIN Batch 191/100 loss 0.030303 acc 0.980188 lr 0.00011617 grad_norm 0.346918 rank 0
2025-01-11 10:41:27,434 DEBUG TRAIN Batch 191/200 loss 0.030982 acc 0.982211 lr 0.00011615 grad_norm 0.368722 rank 2
2025-01-11 10:41:27,434 DEBUG TRAIN Batch 191/200 loss 0.022413 acc 0.986920 lr 0.00011615 grad_norm 0.368722 rank 1
2025-01-11 10:41:27,435 DEBUG TRAIN Batch 191/200 loss 0.015064 acc 0.989924 lr 0.00011615 grad_norm 0.368722 rank 0
2025-01-11 10:41:51,797 DEBUG TRAIN Batch 191/300 loss 0.020028 acc 0.988395 lr 0.00011614 grad_norm 0.339172 rank 2
2025-01-11 10:41:51,797 DEBUG TRAIN Batch 191/300 loss 0.025554 acc 0.981079 lr 0.00011614 grad_norm 0.339172 rank 0
2025-01-11 10:41:51,797 DEBUG TRAIN Batch 191/300 loss 0.028316 acc 0.977941 lr 0.00011614 grad_norm 0.339172 rank 1
2025-01-11 10:42:15,713 DEBUG TRAIN Batch 191/400 loss 0.026864 acc 0.977359 lr 0.00011612 grad_norm 0.333463 rank 2
2025-01-11 10:42:15,713 DEBUG TRAIN Batch 191/400 loss 0.023380 acc 0.982049 lr 0.00011612 grad_norm 0.333463 rank 0
2025-01-11 10:42:15,714 DEBUG TRAIN Batch 191/400 loss 0.010876 acc 0.994269 lr 0.00011612 grad_norm 0.333463 rank 1
2025-01-11 10:42:39,913 DEBUG TRAIN Batch 191/500 loss 0.027055 acc 0.980198 lr 0.00011611 grad_norm 0.327425 rank 0
2025-01-11 10:42:39,914 DEBUG TRAIN Batch 191/500 loss 0.021316 acc 0.985263 lr 0.00011611 grad_norm 0.327425 rank 1
2025-01-11 10:42:39,913 DEBUG TRAIN Batch 191/500 loss 0.019840 acc 0.986789 lr 0.00011611 grad_norm 0.327425 rank 2
2025-01-11 10:43:03,672 DEBUG TRAIN Batch 191/600 loss 0.019674 acc 0.987041 lr 0.00011609 grad_norm 0.354279 rank 2
2025-01-11 10:43:03,672 DEBUG TRAIN Batch 191/600 loss 0.013620 acc 0.986618 lr 0.00011609 grad_norm 0.354279 rank 1
2025-01-11 10:43:03,674 DEBUG TRAIN Batch 191/600 loss 0.020313 acc 0.985126 lr 0.00011609 grad_norm 0.354279 rank 0
2025-01-11 10:43:27,942 DEBUG TRAIN Batch 191/700 loss 0.026416 acc 0.981873 lr 0.00011608 grad_norm 0.351584 rank 2
2025-01-11 10:43:27,942 DEBUG TRAIN Batch 191/700 loss 0.029007 acc 0.979270 lr 0.00011608 grad_norm 0.351584 rank 1
2025-01-11 10:43:27,942 DEBUG TRAIN Batch 191/700 loss 0.024319 acc 0.988235 lr 0.00011608 grad_norm 0.351584 rank 0
2025-01-11 10:43:52,298 DEBUG TRAIN Batch 191/800 loss 0.015933 acc 0.988713 lr 0.00011606 grad_norm 0.334422 rank 0
2025-01-11 10:43:52,298 DEBUG TRAIN Batch 191/800 loss 0.026672 acc 0.983456 lr 0.00011606 grad_norm 0.334422 rank 2
2025-01-11 10:43:52,299 DEBUG TRAIN Batch 191/800 loss 0.013231 acc 0.992625 lr 0.00011606 grad_norm 0.334422 rank 1
2025-01-11 10:44:16,117 DEBUG TRAIN Batch 191/900 loss 0.026696 acc 0.981634 lr 0.00011604 grad_norm 0.352682 rank 1
2025-01-11 10:44:16,118 DEBUG TRAIN Batch 191/900 loss 0.015548 acc 0.987382 lr 0.00011604 grad_norm 0.352682 rank 2
2025-01-11 10:44:16,118 DEBUG TRAIN Batch 191/900 loss 0.039316 acc 0.973661 lr 0.00011604 grad_norm 0.352682 rank 0
2025-01-11 10:44:40,185 DEBUG TRAIN Batch 191/1000 loss 0.034114 acc 0.980245 lr 0.00011603 grad_norm 0.329656 rank 0
2025-01-11 10:44:40,185 DEBUG TRAIN Batch 191/1000 loss 0.034094 acc 0.977396 lr 0.00011603 grad_norm 0.329656 rank 2
2025-01-11 10:44:40,186 DEBUG TRAIN Batch 191/1000 loss 0.015476 acc 0.988683 lr 0.00011603 grad_norm 0.329656 rank 1
2025-01-11 10:45:05,064 DEBUG TRAIN Batch 191/1100 loss 0.020727 acc 0.986622 lr 0.00011601 grad_norm 0.385969 rank 1
2025-01-11 10:45:05,065 DEBUG TRAIN Batch 191/1100 loss 0.036773 acc 0.977583 lr 0.00011601 grad_norm 0.385969 rank 0
2025-01-11 10:45:05,065 DEBUG TRAIN Batch 191/1100 loss 0.024440 acc 0.985280 lr 0.00011601 grad_norm 0.385969 rank 2
2025-01-11 10:45:28,657 DEBUG TRAIN Batch 191/1200 loss 0.023531 acc 0.981105 lr 0.00011600 grad_norm 0.366868 rank 1
2025-01-11 10:45:28,657 DEBUG TRAIN Batch 191/1200 loss 0.022376 acc 0.986829 lr 0.00011600 grad_norm 0.366868 rank 0
2025-01-11 10:45:28,658 DEBUG TRAIN Batch 191/1200 loss 0.018526 acc 0.984741 lr 0.00011600 grad_norm 0.366868 rank 2
2025-01-11 10:45:53,062 DEBUG TRAIN Batch 191/1300 loss 0.015390 acc 0.991443 lr 0.00011598 grad_norm 0.344687 rank 1
2025-01-11 10:45:53,063 DEBUG TRAIN Batch 191/1300 loss 0.038657 acc 0.976703 lr 0.00011598 grad_norm 0.344687 rank 0
2025-01-11 10:45:53,063 DEBUG TRAIN Batch 191/1300 loss 0.023684 acc 0.984925 lr 0.00011598 grad_norm 0.344687 rank 2
2025-01-11 10:46:18,128 DEBUG TRAIN Batch 191/1400 loss 0.025844 acc 0.982363 lr 0.00011597 grad_norm 0.332326 rank 1
2025-01-11 10:46:18,128 DEBUG TRAIN Batch 191/1400 loss 0.017832 acc 0.985045 lr 0.00011597 grad_norm 0.332326 rank 2
2025-01-11 10:46:18,128 DEBUG TRAIN Batch 191/1400 loss 0.021565 acc 0.985216 lr 0.00011597 grad_norm 0.332326 rank 0
2025-01-11 10:46:42,184 DEBUG TRAIN Batch 191/1500 loss 0.022982 acc 0.987751 lr 0.00011595 grad_norm 0.358238 rank 1
2025-01-11 10:46:42,184 DEBUG TRAIN Batch 191/1500 loss 0.026952 acc 0.980617 lr 0.00011595 grad_norm 0.358238 rank 0
2025-01-11 10:46:42,184 DEBUG TRAIN Batch 191/1500 loss 0.023075 acc 0.984799 lr 0.00011595 grad_norm 0.358238 rank 2
2025-01-11 10:47:07,417 DEBUG TRAIN Batch 191/1600 loss 0.025443 acc 0.981897 lr 0.00011594 grad_norm 0.334667 rank 1
2025-01-11 10:47:07,417 DEBUG TRAIN Batch 191/1600 loss 0.020065 acc 0.987069 lr 0.00011594 grad_norm 0.334667 rank 0
2025-01-11 10:47:07,417 DEBUG TRAIN Batch 191/1600 loss 0.029174 acc 0.980224 lr 0.00011594 grad_norm 0.334667 rank 2
2025-01-11 10:47:31,007 DEBUG TRAIN Batch 191/1700 loss 0.023001 acc 0.983716 lr 0.00011592 grad_norm 0.347162 rank 0
2025-01-11 10:47:31,007 DEBUG TRAIN Batch 191/1700 loss 0.023353 acc 0.983810 lr 0.00011592 grad_norm 0.347162 rank 2
2025-01-11 10:47:31,007 DEBUG TRAIN Batch 191/1700 loss 0.018877 acc 0.982866 lr 0.00011592 grad_norm 0.347162 rank 1
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 10:48:53,247 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59975ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 10:48:53,273 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 10:48:53,694 INFO Epoch 191 Step 186095 on_batch_end True CV rank 1
2025-01-11 10:48:53,694 INFO Epoch 191 Step 186095 on_batch_end True CV rank 0
2025-01-11 10:48:53,695 INFO Epoch 191 Step 186095 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 10:49:02,615 DEBUG CV Batch 191/100 loss 0.000417 acc 1.000000  rank 0
2025-01-11 10:49:02,968 DEBUG CV Batch 191/100 loss 0.000417 acc 1.000000  rank 2
2025-01-11 10:49:03,129 INFO Epoch 191 Step 186095 CV info lr 0.00011590512829065036 0 rank loss_2.7676686113542623 acc_0.7807998625855697
2025-01-11 10:49:03,512 INFO Epoch 191 Step 186095 CV info lr 0.00011590512829065036 2 rank loss_2.7676686113542623 acc_0.7807998625855697
2025-01-11 10:49:03,543 DEBUG CV Batch 191/100 loss 0.000417 acc 1.000000  rank 1
2025-01-11 10:49:04,080 INFO Epoch 191 Step 186095 CV info lr 0.00011590512829065036 1 rank loss_2.7676686113542623 acc_0.7807998625855697
2025-01-11 10:49:04,420 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_191_whole.pt
2025-01-11 10:49:04,441 INFO Added key: store_based_barrier_key:194 to store for rank: 0
2025-01-11 10:49:04,452 INFO Added key: store_based_barrier_key:194 to store for rank: 2
2025-01-11 10:49:04,452 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:194 with 3 nodes.
2025-01-11 10:49:04,452 INFO Added key: store_based_barrier_key:194 to store for rank: 1
2025-01-11 10:49:04,452 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:194 with 3 nodes.
2025-01-11 10:49:04,458 INFO Epoch 192 TRAIN info lr 0.00011590512829065036 rank 1
2025-01-11 10:49:04,458 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 10:49:04,462 INFO Epoch 192 TRAIN info lr 0.00011590512829065036 rank 2
2025-01-11 10:49:04,462 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 10:49:04,462 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:194 with 3 nodes.
2025-01-11 10:49:04,465 INFO Epoch 192 TRAIN info lr 0.00011590512829065036 rank 0
2025-01-11 10:49:04,465 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 10:49:35,563 DEBUG TRAIN Batch 192/100 loss 0.027586 acc 0.983991 lr 0.00011589 grad_norm 0.364795 rank 1
2025-01-11 10:49:35,563 DEBUG TRAIN Batch 192/100 loss 0.028594 acc 0.983264 lr 0.00011589 grad_norm 0.364795 rank 2
2025-01-11 10:49:35,563 DEBUG TRAIN Batch 192/100 loss 0.030414 acc 0.981614 lr 0.00011589 grad_norm 0.364795 rank 0
2025-01-11 10:49:59,304 DEBUG TRAIN Batch 192/200 loss 0.031094 acc 0.980786 lr 0.00011587 grad_norm 0.347481 rank 0
2025-01-11 10:49:59,304 DEBUG TRAIN Batch 192/200 loss 0.024048 acc 0.982633 lr 0.00011587 grad_norm 0.347481 rank 1
2025-01-11 10:49:59,305 DEBUG TRAIN Batch 192/200 loss 0.030011 acc 0.977570 lr 0.00011587 grad_norm 0.347481 rank 2
2025-01-11 10:50:22,805 DEBUG TRAIN Batch 192/300 loss 0.021531 acc 0.985045 lr 0.00011586 grad_norm 0.360126 rank 0
2025-01-11 10:50:22,805 DEBUG TRAIN Batch 192/300 loss 0.039263 acc 0.975495 lr 0.00011586 grad_norm 0.360126 rank 1
2025-01-11 10:50:22,806 DEBUG TRAIN Batch 192/300 loss 0.021163 acc 0.985646 lr 0.00011586 grad_norm 0.360126 rank 2
2025-01-11 10:50:46,489 DEBUG TRAIN Batch 192/400 loss 0.015923 acc 0.990033 lr 0.00011584 grad_norm 0.363231 rank 0
2025-01-11 10:50:46,490 DEBUG TRAIN Batch 192/400 loss 0.025205 acc 0.980208 lr 0.00011584 grad_norm 0.363231 rank 1
2025-01-11 10:50:46,490 DEBUG TRAIN Batch 192/400 loss 0.030357 acc 0.977549 lr 0.00011584 grad_norm 0.363231 rank 2
2025-01-11 10:51:10,338 DEBUG TRAIN Batch 192/500 loss 0.024765 acc 0.982014 lr 0.00011583 grad_norm 0.344220 rank 0
2025-01-11 10:51:10,339 DEBUG TRAIN Batch 192/500 loss 0.042513 acc 0.975309 lr 0.00011583 grad_norm 0.344220 rank 1
2025-01-11 10:51:10,339 DEBUG TRAIN Batch 192/500 loss 0.018285 acc 0.986655 lr 0.00011583 grad_norm 0.344220 rank 2
2025-01-11 10:51:33,597 DEBUG TRAIN Batch 192/600 loss 0.030724 acc 0.979370 lr 0.00011581 grad_norm 0.355209 rank 1
2025-01-11 10:51:33,597 DEBUG TRAIN Batch 192/600 loss 0.026826 acc 0.986111 lr 0.00011581 grad_norm 0.355209 rank 2
2025-01-11 10:51:33,597 DEBUG TRAIN Batch 192/600 loss 0.024148 acc 0.980119 lr 0.00011581 grad_norm 0.355209 rank 0
2025-01-11 10:51:57,687 DEBUG TRAIN Batch 192/700 loss 0.029644 acc 0.982932 lr 0.00011580 grad_norm 0.356321 rank 0
2025-01-11 10:51:57,687 DEBUG TRAIN Batch 192/700 loss 0.022848 acc 0.983856 lr 0.00011580 grad_norm 0.356321 rank 2
2025-01-11 10:51:57,687 DEBUG TRAIN Batch 192/700 loss 0.027904 acc 0.979846 lr 0.00011580 grad_norm 0.356321 rank 1
2025-01-11 10:52:22,035 DEBUG TRAIN Batch 192/800 loss 0.016631 acc 0.988532 lr 0.00011578 grad_norm 0.366177 rank 0
2025-01-11 10:52:22,035 DEBUG TRAIN Batch 192/800 loss 0.040120 acc 0.976000 lr 0.00011578 grad_norm 0.366177 rank 1
2025-01-11 10:52:22,035 DEBUG TRAIN Batch 192/800 loss 0.040351 acc 0.977738 lr 0.00011578 grad_norm 0.366177 rank 2
2025-01-11 10:52:46,010 DEBUG TRAIN Batch 192/900 loss 0.019473 acc 0.985479 lr 0.00011577 grad_norm 0.360460 rank 1
2025-01-11 10:52:46,010 DEBUG TRAIN Batch 192/900 loss 0.023440 acc 0.981132 lr 0.00011577 grad_norm 0.360460 rank 0
2025-01-11 10:52:46,011 DEBUG TRAIN Batch 192/900 loss 0.031251 acc 0.982342 lr 0.00011577 grad_norm 0.360460 rank 2
2025-01-11 10:53:09,914 DEBUG TRAIN Batch 192/1000 loss 0.021914 acc 0.984405 lr 0.00011575 grad_norm 0.351233 rank 0
2025-01-11 10:53:09,914 DEBUG TRAIN Batch 192/1000 loss 0.024556 acc 0.983690 lr 0.00011575 grad_norm 0.351233 rank 1
2025-01-11 10:53:09,914 DEBUG TRAIN Batch 192/1000 loss 0.021456 acc 0.986829 lr 0.00011575 grad_norm 0.351233 rank 2
2025-01-11 10:53:34,441 DEBUG TRAIN Batch 192/1100 loss 0.019225 acc 0.985535 lr 0.00011573 grad_norm 0.324755 rank 1
2025-01-11 10:53:34,442 DEBUG TRAIN Batch 192/1100 loss 0.024176 acc 0.985673 lr 0.00011573 grad_norm 0.324755 rank 0
2025-01-11 10:53:34,442 DEBUG TRAIN Batch 192/1100 loss 0.018340 acc 0.988675 lr 0.00011573 grad_norm 0.324755 rank 2
2025-01-11 10:53:58,722 DEBUG TRAIN Batch 192/1200 loss 0.030748 acc 0.978910 lr 0.00011572 grad_norm 0.317773 rank 1
2025-01-11 10:53:58,722 DEBUG TRAIN Batch 192/1200 loss 0.027320 acc 0.981443 lr 0.00011572 grad_norm 0.317773 rank 2
2025-01-11 10:53:58,722 DEBUG TRAIN Batch 192/1200 loss 0.020667 acc 0.985388 lr 0.00011572 grad_norm 0.317773 rank 0
2025-01-11 10:54:23,550 DEBUG TRAIN Batch 192/1300 loss 0.020674 acc 0.986667 lr 0.00011570 grad_norm 0.355393 rank 0
2025-01-11 10:54:23,550 DEBUG TRAIN Batch 192/1300 loss 0.033993 acc 0.975992 lr 0.00011570 grad_norm 0.355393 rank 2
2025-01-11 10:54:23,550 DEBUG TRAIN Batch 192/1300 loss 0.009999 acc 0.995333 lr 0.00011570 grad_norm 0.355393 rank 1
2025-01-11 10:54:47,124 DEBUG TRAIN Batch 192/1400 loss 0.028003 acc 0.979730 lr 0.00011569 grad_norm 0.361841 rank 0
2025-01-11 10:54:47,124 DEBUG TRAIN Batch 192/1400 loss 0.019974 acc 0.987718 lr 0.00011569 grad_norm 0.361841 rank 1
2025-01-11 10:54:47,124 DEBUG TRAIN Batch 192/1400 loss 0.031196 acc 0.978300 lr 0.00011569 grad_norm 0.361841 rank 2
2025-01-11 10:55:11,263 DEBUG TRAIN Batch 192/1500 loss 0.024929 acc 0.982821 lr 0.00011567 grad_norm 0.348684 rank 0
2025-01-11 10:55:11,263 DEBUG TRAIN Batch 192/1500 loss 0.028736 acc 0.979945 lr 0.00011567 grad_norm 0.348684 rank 1
2025-01-11 10:55:11,264 DEBUG TRAIN Batch 192/1500 loss 0.022536 acc 0.983940 lr 0.00011567 grad_norm 0.348684 rank 2
2025-01-11 10:55:36,617 DEBUG TRAIN Batch 192/1600 loss 0.021054 acc 0.984095 lr 0.00011566 grad_norm 0.319329 rank 1
2025-01-11 10:55:36,617 DEBUG TRAIN Batch 192/1600 loss 0.020554 acc 0.989989 lr 0.00011566 grad_norm 0.319329 rank 0
2025-01-11 10:55:36,617 DEBUG TRAIN Batch 192/1600 loss 0.026083 acc 0.979446 lr 0.00011566 grad_norm 0.319329 rank 2
2025-01-11 10:56:00,920 DEBUG TRAIN Batch 192/1700 loss 0.016188 acc 0.986181 lr 0.00011564 grad_norm 0.348348 rank 1
2025-01-11 10:56:00,920 DEBUG TRAIN Batch 192/1700 loss 0.025523 acc 0.983527 lr 0.00011564 grad_norm 0.348348 rank 0
2025-01-11 10:56:00,920 DEBUG TRAIN Batch 192/1700 loss 0.039868 acc 0.978355 lr 0.00011564 grad_norm 0.348348 rank 2
2025-01-11 10:56:25,910 DEBUG TRAIN Batch 192/1800 loss 0.036764 acc 0.974790 lr 0.00011563 grad_norm 0.375569 rank 1
2025-01-11 10:56:25,910 DEBUG TRAIN Batch 192/1800 loss 0.025405 acc 0.984097 lr 0.00011563 grad_norm 0.375569 rank 0
2025-01-11 10:56:25,910 DEBUG TRAIN Batch 192/1800 loss 0.028336 acc 0.981000 lr 0.00011563 grad_norm 0.375569 rank 2
2025-01-11 10:56:50,171 DEBUG TRAIN Batch 192/1900 loss 0.025449 acc 0.983264 lr 0.00011561 grad_norm 0.360180 rank 1
2025-01-11 10:56:50,171 DEBUG TRAIN Batch 192/1900 loss 0.034027 acc 0.975970 lr 0.00011561 grad_norm 0.360180 rank 0
2025-01-11 10:56:50,171 DEBUG TRAIN Batch 192/1900 loss 0.026996 acc 0.979808 lr 0.00011561 grad_norm 0.360180 rank 2
2025-01-11 10:57:14,779 DEBUG TRAIN Batch 192/2000 loss 0.027279 acc 0.978395 lr 0.00011559 grad_norm 0.369069 rank 0
2025-01-11 10:57:14,780 DEBUG TRAIN Batch 192/2000 loss 0.028883 acc 0.982597 lr 0.00011559 grad_norm 0.369069 rank 1
2025-01-11 10:57:14,780 DEBUG TRAIN Batch 192/2000 loss 0.010581 acc 0.995896 lr 0.00011559 grad_norm 0.369069 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 10:58:19,676 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 59965ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 10:58:19,706 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 10:58:20,142 INFO Epoch 192 Step 187104 on_batch_end True CV rank 1
2025-01-11 10:58:20,142 INFO Epoch 192 Step 187104 on_batch_end True CV rank 0
2025-01-11 10:58:20,142 INFO Epoch 192 Step 187104 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 10:58:29,110 DEBUG CV Batch 192/100 loss 0.002135 acc 0.998885  rank 0
2025-01-11 10:58:29,614 INFO Epoch 192 Step 187104 CV info lr 0.00011559218370256745 0 rank loss_2.768985032223435 acc_0.780185939319301
2025-01-11 10:58:29,662 DEBUG CV Batch 192/100 loss 0.002135 acc 0.998885  rank 2
2025-01-11 10:58:29,859 DEBUG CV Batch 192/100 loss 0.002135 acc 0.998885  rank 1
2025-01-11 10:58:30,206 INFO Epoch 192 Step 187104 CV info lr 0.00011559218370256745 2 rank loss_2.768985032223435 acc_0.780185939319301
2025-01-11 10:58:30,403 INFO Epoch 192 Step 187104 CV info lr 0.00011559218370256745 1 rank loss_2.768985032223435 acc_0.780185939319301
2025-01-11 10:58:30,890 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_192_whole.pt
2025-01-11 10:58:30,902 INFO Added key: store_based_barrier_key:195 to store for rank: 0
2025-01-11 10:58:30,912 INFO Added key: store_based_barrier_key:195 to store for rank: 2
2025-01-11 10:58:30,912 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:195 with 3 nodes.
2025-01-11 10:58:30,912 INFO Added key: store_based_barrier_key:195 to store for rank: 1
2025-01-11 10:58:30,913 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:195 with 3 nodes.
2025-01-11 10:58:30,915 INFO Epoch 193 TRAIN info lr 0.00011559218370256745 rank 1
2025-01-11 10:58:30,915 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 10:58:30,916 INFO Epoch 193 TRAIN info lr 0.00011559218370256745 rank 2
2025-01-11 10:58:30,916 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 10:58:30,922 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:195 with 3 nodes.
2025-01-11 10:58:30,926 INFO Epoch 193 TRAIN info lr 0.00011559218370256745 rank 0
2025-01-11 10:58:30,926 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 10:59:06,323 DEBUG TRAIN Batch 193/100 loss 0.021014 acc 0.987562 lr 0.00011558 grad_norm 0.347922 rank 0
2025-01-11 10:59:06,323 DEBUG TRAIN Batch 193/100 loss 0.018618 acc 0.986529 lr 0.00011558 grad_norm 0.347922 rank 2
2025-01-11 10:59:06,323 DEBUG TRAIN Batch 193/100 loss 0.034900 acc 0.980533 lr 0.00011558 grad_norm 0.347922 rank 1
2025-01-11 10:59:30,434 DEBUG TRAIN Batch 193/200 loss 0.019409 acc 0.982692 lr 0.00011556 grad_norm 0.366032 rank 0
2025-01-11 10:59:30,435 DEBUG TRAIN Batch 193/200 loss 0.029490 acc 0.977128 lr 0.00011556 grad_norm 0.366032 rank 1
2025-01-11 10:59:30,435 DEBUG TRAIN Batch 193/200 loss 0.030943 acc 0.978456 lr 0.00011556 grad_norm 0.366032 rank 2
2025-01-11 10:59:54,652 DEBUG TRAIN Batch 193/300 loss 0.016198 acc 0.985859 lr 0.00011555 grad_norm 0.340431 rank 1
2025-01-11 10:59:54,652 DEBUG TRAIN Batch 193/300 loss 0.025045 acc 0.982906 lr 0.00011555 grad_norm 0.340431 rank 2
2025-01-11 10:59:54,652 DEBUG TRAIN Batch 193/300 loss 0.018599 acc 0.988562 lr 0.00011555 grad_norm 0.340431 rank 0
2025-01-11 11:00:18,253 DEBUG TRAIN Batch 193/400 loss 0.033358 acc 0.978852 lr 0.00011553 grad_norm 0.330361 rank 2
2025-01-11 11:00:18,254 DEBUG TRAIN Batch 193/400 loss 0.019749 acc 0.982628 lr 0.00011553 grad_norm 0.330361 rank 1
2025-01-11 11:00:18,254 DEBUG TRAIN Batch 193/400 loss 0.009788 acc 0.995640 lr 0.00011553 grad_norm 0.330361 rank 0
2025-01-11 11:00:42,757 DEBUG TRAIN Batch 193/500 loss 0.019734 acc 0.987488 lr 0.00011552 grad_norm 0.335758 rank 1
2025-01-11 11:00:42,757 DEBUG TRAIN Batch 193/500 loss 0.028518 acc 0.982609 lr 0.00011552 grad_norm 0.335758 rank 0
2025-01-11 11:00:42,758 DEBUG TRAIN Batch 193/500 loss 0.022570 acc 0.985889 lr 0.00011552 grad_norm 0.335758 rank 2
2025-01-11 11:01:07,520 DEBUG TRAIN Batch 193/600 loss 0.021045 acc 0.987455 lr 0.00011550 grad_norm 0.346897 rank 0
2025-01-11 11:01:07,520 DEBUG TRAIN Batch 193/600 loss 0.023597 acc 0.982193 lr 0.00011550 grad_norm 0.346897 rank 1
2025-01-11 11:01:07,521 DEBUG TRAIN Batch 193/600 loss 0.018617 acc 0.987985 lr 0.00011550 grad_norm 0.346897 rank 2
2025-01-11 11:01:32,013 DEBUG TRAIN Batch 193/700 loss 0.045470 acc 0.974672 lr 0.00011548 grad_norm 0.354990 rank 2
2025-01-11 11:01:32,013 DEBUG TRAIN Batch 193/700 loss 0.018829 acc 0.985870 lr 0.00011548 grad_norm 0.354990 rank 1
2025-01-11 11:01:32,014 DEBUG TRAIN Batch 193/700 loss 0.016923 acc 0.986301 lr 0.00011548 grad_norm 0.354990 rank 0
2025-01-11 11:01:56,994 DEBUG TRAIN Batch 193/800 loss 0.025598 acc 0.985915 lr 0.00011547 grad_norm 0.338256 rank 2
2025-01-11 11:01:56,995 DEBUG TRAIN Batch 193/800 loss 0.019318 acc 0.987448 lr 0.00011547 grad_norm 0.338256 rank 1
2025-01-11 11:01:56,995 DEBUG TRAIN Batch 193/800 loss 0.026956 acc 0.980444 lr 0.00011547 grad_norm 0.338256 rank 0
2025-01-11 11:02:21,254 DEBUG TRAIN Batch 193/900 loss 0.031108 acc 0.975741 lr 0.00011545 grad_norm 0.332952 rank 1
2025-01-11 11:02:21,255 DEBUG TRAIN Batch 193/900 loss 0.015476 acc 0.994845 lr 0.00011545 grad_norm 0.332952 rank 2
2025-01-11 11:02:21,255 DEBUG TRAIN Batch 193/900 loss 0.011395 acc 0.993865 lr 0.00011545 grad_norm 0.332952 rank 0
2025-01-11 11:02:45,410 DEBUG TRAIN Batch 193/1000 loss 0.015742 acc 0.990421 lr 0.00011544 grad_norm 0.336199 rank 1
2025-01-11 11:02:45,410 DEBUG TRAIN Batch 193/1000 loss 0.018894 acc 0.986523 lr 0.00011544 grad_norm 0.336199 rank 0
2025-01-11 11:02:45,410 DEBUG TRAIN Batch 193/1000 loss 0.029782 acc 0.974955 lr 0.00011544 grad_norm 0.336199 rank 2
2025-01-11 11:03:10,985 DEBUG TRAIN Batch 193/1100 loss 0.019644 acc 0.984110 lr 0.00011542 grad_norm 0.331038 rank 1
2025-01-11 11:03:10,985 DEBUG TRAIN Batch 193/1100 loss 0.030389 acc 0.979612 lr 0.00011542 grad_norm 0.331038 rank 0
2025-01-11 11:03:10,985 DEBUG TRAIN Batch 193/1100 loss 0.019801 acc 0.984000 lr 0.00011542 grad_norm 0.331038 rank 2
2025-01-11 11:03:35,330 DEBUG TRAIN Batch 193/1200 loss 0.024413 acc 0.983536 lr 0.00011541 grad_norm 0.354547 rank 1
2025-01-11 11:03:35,330 DEBUG TRAIN Batch 193/1200 loss 0.021702 acc 0.986359 lr 0.00011541 grad_norm 0.354547 rank 0
2025-01-11 11:03:35,331 DEBUG TRAIN Batch 193/1200 loss 0.020557 acc 0.988041 lr 0.00011541 grad_norm 0.354547 rank 2
2025-01-11 11:03:58,928 DEBUG TRAIN Batch 193/1300 loss 0.029970 acc 0.984487 lr 0.00011539 grad_norm 0.355385 rank 0
2025-01-11 11:03:58,928 DEBUG TRAIN Batch 193/1300 loss 0.019732 acc 0.984091 lr 0.00011539 grad_norm 0.355385 rank 1
2025-01-11 11:03:58,929 DEBUG TRAIN Batch 193/1300 loss 0.033962 acc 0.971179 lr 0.00011539 grad_norm 0.355385 rank 2
2025-01-11 11:04:23,097 DEBUG TRAIN Batch 193/1400 loss 0.026526 acc 0.984127 lr 0.00011538 grad_norm 0.355525 rank 1
2025-01-11 11:04:23,097 DEBUG TRAIN Batch 193/1400 loss 0.027407 acc 0.980971 lr 0.00011538 grad_norm 0.355525 rank 2
2025-01-11 11:04:23,098 DEBUG TRAIN Batch 193/1400 loss 0.026456 acc 0.985599 lr 0.00011538 grad_norm 0.355525 rank 0
2025-01-11 11:04:47,236 DEBUG TRAIN Batch 193/1500 loss 0.024231 acc 0.983051 lr 0.00011536 grad_norm 0.355188 rank 2
2025-01-11 11:04:47,236 DEBUG TRAIN Batch 193/1500 loss 0.028436 acc 0.979980 lr 0.00011536 grad_norm 0.355188 rank 1
2025-01-11 11:04:47,236 DEBUG TRAIN Batch 193/1500 loss 0.038736 acc 0.969479 lr 0.00011536 grad_norm 0.355188 rank 0
2025-01-11 11:05:10,872 DEBUG TRAIN Batch 193/1600 loss 0.024295 acc 0.983740 lr 0.00011535 grad_norm 0.364357 rank 2
2025-01-11 11:05:10,872 DEBUG TRAIN Batch 193/1600 loss 0.038483 acc 0.975694 lr 0.00011535 grad_norm 0.364357 rank 1
2025-01-11 11:05:10,872 DEBUG TRAIN Batch 193/1600 loss 0.032108 acc 0.977755 lr 0.00011535 grad_norm 0.364357 rank 0
2025-01-11 11:05:34,663 DEBUG TRAIN Batch 193/1700 loss 0.028570 acc 0.985311 lr 0.00011533 grad_norm 0.356375 rank 1
2025-01-11 11:05:34,663 DEBUG TRAIN Batch 193/1700 loss 0.027324 acc 0.980496 lr 0.00011533 grad_norm 0.356375 rank 0
2025-01-11 11:05:34,664 DEBUG TRAIN Batch 193/1700 loss 0.021560 acc 0.987585 lr 0.00011533 grad_norm 0.356375 rank 2
2025-01-11 11:05:58,961 DEBUG TRAIN Batch 193/1800 loss 0.020871 acc 0.985022 lr 0.00011532 grad_norm 0.328521 rank 2
2025-01-11 11:05:58,961 DEBUG TRAIN Batch 193/1800 loss 0.027052 acc 0.980806 lr 0.00011532 grad_norm 0.328521 rank 0
2025-01-11 11:05:58,961 DEBUG TRAIN Batch 193/1800 loss 0.019640 acc 0.985556 lr 0.00011532 grad_norm 0.328521 rank 1
2025-01-11 11:06:22,442 DEBUG TRAIN Batch 193/1900 loss 0.033267 acc 0.972810 lr 0.00011530 grad_norm 0.369926 rank 2
2025-01-11 11:06:22,442 DEBUG TRAIN Batch 193/1900 loss 0.025607 acc 0.975248 lr 0.00011530 grad_norm 0.369926 rank 1
2025-01-11 11:06:22,442 DEBUG TRAIN Batch 193/1900 loss 0.024211 acc 0.985768 lr 0.00011530 grad_norm 0.369926 rank 0
2025-01-11 11:06:46,183 DEBUG TRAIN Batch 193/2000 loss 0.029110 acc 0.979667 lr 0.00011528 grad_norm 0.348532 rank 2
2025-01-11 11:06:46,183 DEBUG TRAIN Batch 193/2000 loss 0.019628 acc 0.984375 lr 0.00011528 grad_norm 0.348532 rank 0
2025-01-11 11:06:46,183 DEBUG TRAIN Batch 193/2000 loss 0.031760 acc 0.982966 lr 0.00011528 grad_norm 0.348532 rank 1
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 11:07:47,129 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 11:07:47,130 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 11:07:47,562 INFO Epoch 193 Step 188106 on_batch_end True CV rank 1
2025-01-11 11:07:47,562 INFO Epoch 193 Step 188106 on_batch_end True CV rank 2
2025-01-11 11:07:47,562 INFO Epoch 193 Step 188106 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 11:07:56,709 DEBUG CV Batch 193/100 loss 0.001465 acc 1.000000  rank 0
2025-01-11 11:07:56,738 DEBUG CV Batch 193/100 loss 0.001465 acc 1.000000  rank 2
2025-01-11 11:07:57,041 DEBUG CV Batch 193/100 loss 0.001465 acc 1.000000  rank 1
2025-01-11 11:07:57,199 INFO Epoch 193 Step 188106 CV info lr 0.00011528390533356399 0 rank loss_2.785806252667195 acc_0.7801601417493402
2025-01-11 11:07:57,259 INFO Epoch 193 Step 188106 CV info lr 0.00011528390533356399 2 rank loss_2.785806252667195 acc_0.7801601417493402
2025-01-11 11:07:57,535 INFO Epoch 193 Step 188106 CV info lr 0.00011528390533356399 1 rank loss_2.785806252667195 acc_0.7801601417493402
2025-01-11 11:07:58,472 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_193_whole.pt
2025-01-11 11:07:58,494 INFO Added key: store_based_barrier_key:196 to store for rank: 0
2025-01-11 11:07:58,504 INFO Added key: store_based_barrier_key:196 to store for rank: 2
2025-01-11 11:07:58,505 INFO Added key: store_based_barrier_key:196 to store for rank: 1
2025-01-11 11:07:58,506 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:196 with 3 nodes.
2025-01-11 11:07:58,514 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:196 with 3 nodes.
2025-01-11 11:07:58,514 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:196 with 3 nodes.
2025-01-11 11:07:58,516 INFO Epoch 194 TRAIN info lr 0.00011528390533356399 rank 1
2025-01-11 11:07:58,516 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 11:07:58,519 INFO Epoch 194 TRAIN info lr 0.00011528390533356399 rank 2
2025-01-11 11:07:58,519 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 11:07:58,520 INFO Epoch 194 TRAIN info lr 0.00011528390533356399 rank 0
2025-01-11 11:07:58,520 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 11:08:33,883 DEBUG TRAIN Batch 194/100 loss 0.013323 acc 0.993719 lr 0.00011527 grad_norm 0.313337 rank 0
2025-01-11 11:08:33,883 DEBUG TRAIN Batch 194/100 loss 0.025076 acc 0.983083 lr 0.00011527 grad_norm 0.313337 rank 2
2025-01-11 11:08:33,884 DEBUG TRAIN Batch 194/100 loss 0.028727 acc 0.978147 lr 0.00011527 grad_norm 0.313337 rank 1
2025-01-11 11:08:57,964 DEBUG TRAIN Batch 194/200 loss 0.036227 acc 0.979631 lr 0.00011525 grad_norm 0.355138 rank 0
2025-01-11 11:08:57,964 DEBUG TRAIN Batch 194/200 loss 0.023043 acc 0.981445 lr 0.00011525 grad_norm 0.355138 rank 1
2025-01-11 11:08:57,964 DEBUG TRAIN Batch 194/200 loss 0.032119 acc 0.979167 lr 0.00011525 grad_norm 0.355138 rank 2
2025-01-11 11:09:22,044 DEBUG TRAIN Batch 194/300 loss 0.013004 acc 0.991896 lr 0.00011524 grad_norm 0.307069 rank 0
2025-01-11 11:09:22,044 DEBUG TRAIN Batch 194/300 loss 0.019173 acc 0.988785 lr 0.00011524 grad_norm 0.307069 rank 1
2025-01-11 11:09:22,044 DEBUG TRAIN Batch 194/300 loss 0.020368 acc 0.988433 lr 0.00011524 grad_norm 0.307069 rank 2
2025-01-11 11:09:45,566 DEBUG TRAIN Batch 194/400 loss 0.027177 acc 0.984463 lr 0.00011522 grad_norm 0.341419 rank 0
2025-01-11 11:09:45,566 DEBUG TRAIN Batch 194/400 loss 0.014929 acc 0.987654 lr 0.00011522 grad_norm 0.341419 rank 1
2025-01-11 11:09:45,567 DEBUG TRAIN Batch 194/400 loss 0.024885 acc 0.984877 lr 0.00011522 grad_norm 0.341419 rank 2
2025-01-11 11:10:09,958 DEBUG TRAIN Batch 194/500 loss 0.016357 acc 0.987730 lr 0.00011521 grad_norm 0.339729 rank 1
2025-01-11 11:10:09,958 DEBUG TRAIN Batch 194/500 loss 0.015242 acc 0.987760 lr 0.00011521 grad_norm 0.339729 rank 0
2025-01-11 11:10:09,959 DEBUG TRAIN Batch 194/500 loss 0.019661 acc 0.986916 lr 0.00011521 grad_norm 0.339729 rank 2
2025-01-11 11:10:35,203 DEBUG TRAIN Batch 194/600 loss 0.021144 acc 0.982309 lr 0.00011519 grad_norm 0.334848 rank 0
2025-01-11 11:10:35,203 DEBUG TRAIN Batch 194/600 loss 0.033945 acc 0.977148 lr 0.00011519 grad_norm 0.334848 rank 1
2025-01-11 11:10:35,203 DEBUG TRAIN Batch 194/600 loss 0.029256 acc 0.980282 lr 0.00011519 grad_norm 0.334848 rank 2
2025-01-11 11:10:59,085 DEBUG TRAIN Batch 194/700 loss 0.025464 acc 0.980334 lr 0.00011518 grad_norm 0.358978 rank 1
2025-01-11 11:10:59,085 DEBUG TRAIN Batch 194/700 loss 0.020134 acc 0.985377 lr 0.00011518 grad_norm 0.358978 rank 0
2025-01-11 11:10:59,085 DEBUG TRAIN Batch 194/700 loss 0.026837 acc 0.982776 lr 0.00011518 grad_norm 0.358978 rank 2
2025-01-11 11:11:24,306 DEBUG TRAIN Batch 194/800 loss 0.035087 acc 0.981216 lr 0.00011516 grad_norm 0.363671 rank 0
2025-01-11 11:11:24,306 DEBUG TRAIN Batch 194/800 loss 0.029652 acc 0.976767 lr 0.00011516 grad_norm 0.363671 rank 1
2025-01-11 11:11:24,306 DEBUG TRAIN Batch 194/800 loss 0.016712 acc 0.992823 lr 0.00011516 grad_norm 0.363671 rank 2
2025-01-11 11:11:48,253 DEBUG TRAIN Batch 194/900 loss 0.038844 acc 0.977127 lr 0.00011515 grad_norm 0.357586 rank 2
2025-01-11 11:11:48,253 DEBUG TRAIN Batch 194/900 loss 0.019214 acc 0.983657 lr 0.00011515 grad_norm 0.357586 rank 1
2025-01-11 11:11:48,254 DEBUG TRAIN Batch 194/900 loss 0.015697 acc 0.989028 lr 0.00011515 grad_norm 0.357586 rank 0
2025-01-11 11:12:12,422 DEBUG TRAIN Batch 194/1000 loss 0.011719 acc 0.993007 lr 0.00011513 grad_norm 0.326990 rank 0
2025-01-11 11:12:12,422 DEBUG TRAIN Batch 194/1000 loss 0.021900 acc 0.980507 lr 0.00011513 grad_norm 0.326990 rank 1
2025-01-11 11:12:12,422 DEBUG TRAIN Batch 194/1000 loss 0.021782 acc 0.981839 lr 0.00011513 grad_norm 0.326990 rank 2
2025-01-11 11:12:37,690 DEBUG TRAIN Batch 194/1100 loss 0.024612 acc 0.984970 lr 0.00011512 grad_norm 0.361034 rank 1
2025-01-11 11:12:37,691 DEBUG TRAIN Batch 194/1100 loss 0.026972 acc 0.982025 lr 0.00011512 grad_norm 0.361034 rank 2
2025-01-11 11:12:37,691 DEBUG TRAIN Batch 194/1100 loss 0.023967 acc 0.981481 lr 0.00011512 grad_norm 0.361034 rank 0
2025-01-11 11:13:01,857 DEBUG TRAIN Batch 194/1200 loss 0.026136 acc 0.982997 lr 0.00011510 grad_norm 0.338360 rank 1
2025-01-11 11:13:01,858 DEBUG TRAIN Batch 194/1200 loss 0.021342 acc 0.984520 lr 0.00011510 grad_norm 0.338360 rank 0
2025-01-11 11:13:01,858 DEBUG TRAIN Batch 194/1200 loss 0.022085 acc 0.980392 lr 0.00011510 grad_norm 0.338360 rank 2
2025-01-11 11:13:25,855 DEBUG TRAIN Batch 194/1300 loss 0.025172 acc 0.984043 lr 0.00011509 grad_norm 0.340228 rank 1
2025-01-11 11:13:25,855 DEBUG TRAIN Batch 194/1300 loss 0.030041 acc 0.978761 lr 0.00011509 grad_norm 0.340228 rank 0
2025-01-11 11:13:25,856 DEBUG TRAIN Batch 194/1300 loss 0.028267 acc 0.979298 lr 0.00011509 grad_norm 0.340228 rank 2
2025-01-11 11:13:50,171 DEBUG TRAIN Batch 194/1400 loss 0.031106 acc 0.980104 lr 0.00011507 grad_norm 0.318956 rank 1
2025-01-11 11:13:50,171 DEBUG TRAIN Batch 194/1400 loss 0.023838 acc 0.984526 lr 0.00011507 grad_norm 0.318956 rank 0
2025-01-11 11:13:50,171 DEBUG TRAIN Batch 194/1400 loss 0.020516 acc 0.987215 lr 0.00011507 grad_norm 0.318956 rank 2
2025-01-11 11:14:13,289 DEBUG TRAIN Batch 194/1500 loss 0.017907 acc 0.988802 lr 0.00011505 grad_norm 0.335386 rank 1
2025-01-11 11:14:13,289 DEBUG TRAIN Batch 194/1500 loss 0.032506 acc 0.981033 lr 0.00011505 grad_norm 0.335386 rank 0
2025-01-11 11:14:13,289 DEBUG TRAIN Batch 194/1500 loss 0.017304 acc 0.987391 lr 0.00011505 grad_norm 0.335386 rank 2
2025-01-11 11:14:37,178 DEBUG TRAIN Batch 194/1600 loss 0.028481 acc 0.981884 lr 0.00011504 grad_norm 0.347291 rank 0
2025-01-11 11:14:37,178 DEBUG TRAIN Batch 194/1600 loss 0.037016 acc 0.972342 lr 0.00011504 grad_norm 0.347291 rank 1
2025-01-11 11:14:37,178 DEBUG TRAIN Batch 194/1600 loss 0.015639 acc 0.990676 lr 0.00011504 grad_norm 0.347291 rank 2
2025-01-11 11:15:00,512 DEBUG TRAIN Batch 194/1700 loss 0.027661 acc 0.977821 lr 0.00011502 grad_norm 0.334758 rank 0
2025-01-11 11:15:00,512 DEBUG TRAIN Batch 194/1700 loss 0.034443 acc 0.974855 lr 0.00011502 grad_norm 0.334758 rank 1
2025-01-11 11:15:00,512 DEBUG TRAIN Batch 194/1700 loss 0.027952 acc 0.982472 lr 0.00011502 grad_norm 0.334758 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 11:16:13,060 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 11:16:13,061 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 11:16:13,527 INFO Epoch 194 Step 188982 on_batch_end True CV rank 0
2025-01-11 11:16:13,527 INFO Epoch 194 Step 188982 on_batch_end True CV rank 2
2025-01-11 11:16:13,528 INFO Epoch 194 Step 188982 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 11:16:22,554 DEBUG CV Batch 194/100 loss 0.001654 acc 0.998885  rank 0
2025-01-11 11:16:22,942 DEBUG CV Batch 194/100 loss 0.001654 acc 0.998885  rank 2
2025-01-11 11:16:23,087 INFO Epoch 194 Step 188982 CV info lr 0.00011501640365907216 0 rank loss_2.7958183840614526 acc_0.7808066135958621
2025-01-11 11:16:23,218 DEBUG CV Batch 194/100 loss 0.001654 acc 0.998885  rank 1
2025-01-11 11:16:23,487 INFO Epoch 194 Step 188982 CV info lr 0.00011501640365907216 2 rank loss_2.7958183840614526 acc_0.7808066135958621
2025-01-11 11:16:23,760 INFO Epoch 194 Step 188982 CV info lr 0.00011501640365907216 1 rank loss_2.7958183840614526 acc_0.7808066135958621
2025-01-11 11:16:24,357 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_194_whole.pt
2025-01-11 11:16:24,369 INFO Added key: store_based_barrier_key:197 to store for rank: 0
2025-01-11 11:16:24,379 INFO Added key: store_based_barrier_key:197 to store for rank: 2
2025-01-11 11:16:24,379 INFO Added key: store_based_barrier_key:197 to store for rank: 1
2025-01-11 11:16:24,379 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:197 with 3 nodes.
2025-01-11 11:16:24,386 INFO Epoch 195 TRAIN info lr 0.00011501640365907216 rank 1
2025-01-11 11:16:24,386 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 11:16:24,389 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:197 with 3 nodes.
2025-01-11 11:16:24,389 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:197 with 3 nodes.
2025-01-11 11:16:24,392 INFO Epoch 195 TRAIN info lr 0.00011501640365907216 rank 0
2025-01-11 11:16:24,392 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 11:16:24,394 INFO Epoch 195 TRAIN info lr 0.00011501640365907216 rank 2
2025-01-11 11:16:24,394 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 11:16:54,913 DEBUG TRAIN Batch 195/100 loss 0.028346 acc 0.981557 lr 0.00011500 grad_norm 0.367681 rank 0
2025-01-11 11:16:54,913 DEBUG TRAIN Batch 195/100 loss 0.026153 acc 0.978970 lr 0.00011500 grad_norm 0.367681 rank 1
2025-01-11 11:16:54,913 DEBUG TRAIN Batch 195/100 loss 0.031820 acc 0.979646 lr 0.00011500 grad_norm 0.367681 rank 2
2025-01-11 11:17:18,686 DEBUG TRAIN Batch 195/200 loss 0.014039 acc 0.988806 lr 0.00011499 grad_norm 0.306075 rank 0
2025-01-11 11:17:18,687 DEBUG TRAIN Batch 195/200 loss 0.017617 acc 0.988462 lr 0.00011499 grad_norm 0.306075 rank 1
2025-01-11 11:17:18,687 DEBUG TRAIN Batch 195/200 loss 0.014410 acc 0.992357 lr 0.00011499 grad_norm 0.306075 rank 2
2025-01-11 11:17:42,067 DEBUG TRAIN Batch 195/300 loss 0.021597 acc 0.988462 lr 0.00011497 grad_norm 0.332061 rank 1
2025-01-11 11:17:42,067 DEBUG TRAIN Batch 195/300 loss 0.018925 acc 0.989544 lr 0.00011497 grad_norm 0.332061 rank 0
2025-01-11 11:17:42,068 DEBUG TRAIN Batch 195/300 loss 0.026237 acc 0.980057 lr 0.00011497 grad_norm 0.332061 rank 2
2025-01-11 11:18:05,761 DEBUG TRAIN Batch 195/400 loss 0.023392 acc 0.987842 lr 0.00011496 grad_norm 0.373714 rank 0
2025-01-11 11:18:05,762 DEBUG TRAIN Batch 195/400 loss 0.032106 acc 0.975713 lr 0.00011496 grad_norm 0.373714 rank 1
2025-01-11 11:18:05,762 DEBUG TRAIN Batch 195/400 loss 0.039679 acc 0.973440 lr 0.00011496 grad_norm 0.373714 rank 2
2025-01-11 11:18:29,789 DEBUG TRAIN Batch 195/500 loss 0.024022 acc 0.982790 lr 0.00011494 grad_norm 0.338182 rank 1
2025-01-11 11:18:29,790 DEBUG TRAIN Batch 195/500 loss 0.022028 acc 0.986258 lr 0.00011494 grad_norm 0.338182 rank 2
2025-01-11 11:18:29,790 DEBUG TRAIN Batch 195/500 loss 0.024420 acc 0.984143 lr 0.00011494 grad_norm 0.338182 rank 0
2025-01-11 11:18:53,820 DEBUG TRAIN Batch 195/600 loss 0.016924 acc 0.992460 lr 0.00011493 grad_norm 0.339394 rank 2
2025-01-11 11:18:53,820 DEBUG TRAIN Batch 195/600 loss 0.023985 acc 0.982358 lr 0.00011493 grad_norm 0.339394 rank 1
2025-01-11 11:18:53,820 DEBUG TRAIN Batch 195/600 loss 0.024503 acc 0.979034 lr 0.00011493 grad_norm 0.339394 rank 0
2025-01-11 11:19:18,225 DEBUG TRAIN Batch 195/700 loss 0.018284 acc 0.984234 lr 0.00011491 grad_norm 0.322299 rank 0
2025-01-11 11:19:18,225 DEBUG TRAIN Batch 195/700 loss 0.020265 acc 0.987705 lr 0.00011491 grad_norm 0.322299 rank 2
2025-01-11 11:19:18,226 DEBUG TRAIN Batch 195/700 loss 0.026807 acc 0.982143 lr 0.00011491 grad_norm 0.322299 rank 1
2025-01-11 11:19:42,267 DEBUG TRAIN Batch 195/800 loss 0.020442 acc 0.987368 lr 0.00011489 grad_norm 0.343405 rank 1
2025-01-11 11:19:42,268 DEBUG TRAIN Batch 195/800 loss 0.027200 acc 0.979771 lr 0.00011489 grad_norm 0.343405 rank 0
2025-01-11 11:19:42,268 DEBUG TRAIN Batch 195/800 loss 0.029832 acc 0.981081 lr 0.00011489 grad_norm 0.343405 rank 2
2025-01-11 11:20:06,484 DEBUG TRAIN Batch 195/900 loss 0.022855 acc 0.987305 lr 0.00011488 grad_norm 0.323042 rank 0
2025-01-11 11:20:06,484 DEBUG TRAIN Batch 195/900 loss 0.025806 acc 0.986430 lr 0.00011488 grad_norm 0.323042 rank 2
2025-01-11 11:20:06,484 DEBUG TRAIN Batch 195/900 loss 0.032291 acc 0.983364 lr 0.00011488 grad_norm 0.323042 rank 1
2025-01-11 11:20:31,587 DEBUG TRAIN Batch 195/1000 loss 0.026706 acc 0.981943 lr 0.00011486 grad_norm 0.343787 rank 2
2025-01-11 11:20:31,587 DEBUG TRAIN Batch 195/1000 loss 0.027606 acc 0.981250 lr 0.00011486 grad_norm 0.343787 rank 0
2025-01-11 11:20:31,588 DEBUG TRAIN Batch 195/1000 loss 0.031180 acc 0.981095 lr 0.00011486 grad_norm 0.343787 rank 1
2025-01-11 11:20:55,716 DEBUG TRAIN Batch 195/1100 loss 0.019434 acc 0.987828 lr 0.00011485 grad_norm 0.351063 rank 1
2025-01-11 11:20:55,715 DEBUG TRAIN Batch 195/1100 loss 0.025477 acc 0.986811 lr 0.00011485 grad_norm 0.351063 rank 2
2025-01-11 11:20:55,716 DEBUG TRAIN Batch 195/1100 loss 0.029679 acc 0.981464 lr 0.00011485 grad_norm 0.351063 rank 0
2025-01-11 11:21:19,995 DEBUG TRAIN Batch 195/1200 loss 0.021613 acc 0.983146 lr 0.00011483 grad_norm 0.340158 rank 2
2025-01-11 11:21:19,996 DEBUG TRAIN Batch 195/1200 loss 0.042252 acc 0.975345 lr 0.00011483 grad_norm 0.340158 rank 0
2025-01-11 11:21:19,996 DEBUG TRAIN Batch 195/1200 loss 0.024033 acc 0.985088 lr 0.00011483 grad_norm 0.340158 rank 1
2025-01-11 11:21:43,694 DEBUG TRAIN Batch 195/1300 loss 0.014565 acc 0.989413 lr 0.00011482 grad_norm 0.328346 rank 0
2025-01-11 11:21:43,694 DEBUG TRAIN Batch 195/1300 loss 0.019085 acc 0.986058 lr 0.00011482 grad_norm 0.328346 rank 2
2025-01-11 11:21:43,695 DEBUG TRAIN Batch 195/1300 loss 0.023732 acc 0.985075 lr 0.00011482 grad_norm 0.328346 rank 1
2025-01-11 11:22:08,086 DEBUG TRAIN Batch 195/1400 loss 0.024974 acc 0.983218 lr 0.00011480 grad_norm 0.370362 rank 2
2025-01-11 11:22:08,087 DEBUG TRAIN Batch 195/1400 loss 0.035717 acc 0.977133 lr 0.00011480 grad_norm 0.370362 rank 1
2025-01-11 11:22:08,087 DEBUG TRAIN Batch 195/1400 loss 0.023429 acc 0.981176 lr 0.00011480 grad_norm 0.370362 rank 0
2025-01-11 11:22:32,922 DEBUG TRAIN Batch 195/1500 loss 0.023177 acc 0.986166 lr 0.00011479 grad_norm 0.328173 rank 2
2025-01-11 11:22:32,923 DEBUG TRAIN Batch 195/1500 loss 0.024188 acc 0.984541 lr 0.00011479 grad_norm 0.328173 rank 1
2025-01-11 11:22:32,923 DEBUG TRAIN Batch 195/1500 loss 0.025630 acc 0.985267 lr 0.00011479 grad_norm 0.328173 rank 0
2025-01-11 11:22:56,949 DEBUG TRAIN Batch 195/1600 loss 0.023583 acc 0.986680 lr 0.00011477 grad_norm 0.332719 rank 1
2025-01-11 11:22:56,949 DEBUG TRAIN Batch 195/1600 loss 0.021902 acc 0.988798 lr 0.00011477 grad_norm 0.332719 rank 2
2025-01-11 11:22:56,949 DEBUG TRAIN Batch 195/1600 loss 0.013327 acc 0.993600 lr 0.00011477 grad_norm 0.332719 rank 0
2025-01-11 11:23:21,468 DEBUG TRAIN Batch 195/1700 loss 0.025317 acc 0.982059 lr 0.00011476 grad_norm 0.377364 rank 1
2025-01-11 11:23:21,469 DEBUG TRAIN Batch 195/1700 loss 0.029021 acc 0.982759 lr 0.00011476 grad_norm 0.377364 rank 2
2025-01-11 11:23:21,469 DEBUG TRAIN Batch 195/1700 loss 0.018014 acc 0.986111 lr 0.00011476 grad_norm 0.377364 rank 0
2025-01-11 11:23:46,719 DEBUG TRAIN Batch 195/1800 loss 0.020360 acc 0.982541 lr 0.00011474 grad_norm 0.314851 rank 1
2025-01-11 11:23:46,720 DEBUG TRAIN Batch 195/1800 loss 0.009148 acc 0.992063 lr 0.00011474 grad_norm 0.314851 rank 0
2025-01-11 11:23:46,720 DEBUG TRAIN Batch 195/1800 loss 0.022964 acc 0.985310 lr 0.00011474 grad_norm 0.314851 rank 2
2025-01-11 11:24:11,117 DEBUG TRAIN Batch 195/1900 loss 0.030225 acc 0.983246 lr 0.00011473 grad_norm 0.363155 rank 1
2025-01-11 11:24:11,117 DEBUG TRAIN Batch 195/1900 loss 0.015191 acc 0.989754 lr 0.00011473 grad_norm 0.363155 rank 0
2025-01-11 11:24:11,117 DEBUG TRAIN Batch 195/1900 loss 0.026858 acc 0.982932 lr 0.00011473 grad_norm 0.363155 rank 2
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 11:25:22,337 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 11:25:22,339 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 11:25:22,816 INFO Epoch 195 Step 189955 on_batch_end True CV rank 2
2025-01-11 11:25:22,816 INFO Epoch 195 Step 189955 on_batch_end True CV rank 0
2025-01-11 11:25:22,816 INFO Epoch 195 Step 189955 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 11:25:31,892 DEBUG CV Batch 195/100 loss 0.001279 acc 1.000000  rank 0
2025-01-11 11:25:32,006 DEBUG CV Batch 195/100 loss 0.001279 acc 1.000000  rank 2
2025-01-11 11:25:32,374 INFO Epoch 195 Step 189955 CV info lr 0.00011472145317502135 0 rank loss_2.794903846521361 acc_0.7807940146640727
2025-01-11 11:25:32,530 DEBUG CV Batch 195/100 loss 0.001279 acc 1.000000  rank 1
2025-01-11 11:25:32,547 INFO Epoch 195 Step 189955 CV info lr 0.00011472145317502135 2 rank loss_2.794903846521361 acc_0.7807940146640727
2025-01-11 11:25:33,077 INFO Epoch 195 Step 189955 CV info lr 0.00011472145317502135 1 rank loss_2.794903846521361 acc_0.7807940146640727
2025-01-11 11:25:33,661 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_195_whole.pt
2025-01-11 11:25:33,683 INFO Added key: store_based_barrier_key:198 to store for rank: 0
2025-01-11 11:25:33,683 INFO Added key: store_based_barrier_key:198 to store for rank: 1
2025-01-11 11:25:33,683 INFO Added key: store_based_barrier_key:198 to store for rank: 2
2025-01-11 11:25:33,683 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:198 with 3 nodes.
2025-01-11 11:25:33,683 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:198 with 3 nodes.
2025-01-11 11:25:33,687 INFO Epoch 196 TRAIN info lr 0.00011472145317502135 rank 2
2025-01-11 11:25:33,687 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 11:25:33,693 INFO Epoch 196 TRAIN info lr 0.00011472145317502135 rank 1
2025-01-11 11:25:33,693 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 11:25:33,693 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:198 with 3 nodes.
2025-01-11 11:25:33,695 INFO Epoch 196 TRAIN info lr 0.00011472145317502135 rank 0
2025-01-11 11:25:33,695 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 11:26:04,740 DEBUG TRAIN Batch 196/100 loss 0.021129 acc 0.985022 lr 0.00011471 grad_norm 0.342688 rank 0
2025-01-11 11:26:04,740 DEBUG TRAIN Batch 196/100 loss 0.019707 acc 0.986667 lr 0.00011471 grad_norm 0.342688 rank 1
2025-01-11 11:26:04,740 DEBUG TRAIN Batch 196/100 loss 0.035816 acc 0.976764 lr 0.00011471 grad_norm 0.342688 rank 2
2025-01-11 11:26:28,480 DEBUG TRAIN Batch 196/200 loss 0.017317 acc 0.987437 lr 0.00011469 grad_norm 0.315666 rank 2
2025-01-11 11:26:28,480 DEBUG TRAIN Batch 196/200 loss 0.021787 acc 0.987248 lr 0.00011469 grad_norm 0.315666 rank 1
2025-01-11 11:26:28,480 DEBUG TRAIN Batch 196/200 loss 0.022330 acc 0.983130 lr 0.00011469 grad_norm 0.315666 rank 0
2025-01-11 11:26:53,108 DEBUG TRAIN Batch 196/300 loss 0.026193 acc 0.983051 lr 0.00011468 grad_norm 0.323395 rank 0
2025-01-11 11:26:53,108 DEBUG TRAIN Batch 196/300 loss 0.020710 acc 0.987353 lr 0.00011468 grad_norm 0.323395 rank 1
2025-01-11 11:26:53,108 DEBUG TRAIN Batch 196/300 loss 0.023126 acc 0.983130 lr 0.00011468 grad_norm 0.323395 rank 2
2025-01-11 11:27:16,757 DEBUG TRAIN Batch 196/400 loss 0.016211 acc 0.989967 lr 0.00011466 grad_norm 0.358683 rank 1
2025-01-11 11:27:16,757 DEBUG TRAIN Batch 196/400 loss 0.022784 acc 0.985577 lr 0.00011466 grad_norm 0.358683 rank 2
2025-01-11 11:27:16,757 DEBUG TRAIN Batch 196/400 loss 0.031153 acc 0.977906 lr 0.00011466 grad_norm 0.358683 rank 0
2025-01-11 11:27:41,220 DEBUG TRAIN Batch 196/500 loss 0.017334 acc 0.991014 lr 0.00011465 grad_norm 0.321424 rank 0
2025-01-11 11:27:41,220 DEBUG TRAIN Batch 196/500 loss 0.023550 acc 0.977839 lr 0.00011465 grad_norm 0.321424 rank 1
2025-01-11 11:27:41,220 DEBUG TRAIN Batch 196/500 loss 0.016674 acc 0.990792 lr 0.00011465 grad_norm 0.321424 rank 2
2025-01-11 11:28:05,639 DEBUG TRAIN Batch 196/600 loss 0.019076 acc 0.985755 lr 0.00011463 grad_norm 0.343228 rank 1
2025-01-11 11:28:05,639 DEBUG TRAIN Batch 196/600 loss 0.027215 acc 0.984481 lr 0.00011463 grad_norm 0.343228 rank 0
2025-01-11 11:28:05,640 DEBUG TRAIN Batch 196/600 loss 0.025579 acc 0.981735 lr 0.00011463 grad_norm 0.343228 rank 2
2025-01-11 11:28:29,804 DEBUG TRAIN Batch 196/700 loss 0.017157 acc 0.989433 lr 0.00011462 grad_norm 0.349494 rank 1
2025-01-11 11:28:29,804 DEBUG TRAIN Batch 196/700 loss 0.020158 acc 0.985885 lr 0.00011462 grad_norm 0.349494 rank 0
2025-01-11 11:28:29,804 DEBUG TRAIN Batch 196/700 loss 0.024430 acc 0.981250 lr 0.00011462 grad_norm 0.349494 rank 2
2025-01-11 11:28:53,623 DEBUG TRAIN Batch 196/800 loss 0.020598 acc 0.985185 lr 0.00011460 grad_norm 0.347292 rank 0
2025-01-11 11:28:53,623 DEBUG TRAIN Batch 196/800 loss 0.025467 acc 0.984488 lr 0.00011460 grad_norm 0.347292 rank 1
2025-01-11 11:28:53,623 DEBUG TRAIN Batch 196/800 loss 0.015373 acc 0.989154 lr 0.00011460 grad_norm 0.347292 rank 2
2025-01-11 11:29:17,264 DEBUG TRAIN Batch 196/900 loss 0.018822 acc 0.986139 lr 0.00011459 grad_norm 0.355316 rank 1
2025-01-11 11:29:17,264 DEBUG TRAIN Batch 196/900 loss 0.021791 acc 0.986258 lr 0.00011459 grad_norm 0.355316 rank 0
2025-01-11 11:29:17,264 DEBUG TRAIN Batch 196/900 loss 0.035277 acc 0.975455 lr 0.00011459 grad_norm 0.355316 rank 2
2025-01-11 11:29:41,249 DEBUG TRAIN Batch 196/1000 loss 0.022312 acc 0.980952 lr 0.00011457 grad_norm 0.352816 rank 2
2025-01-11 11:29:41,250 DEBUG TRAIN Batch 196/1000 loss 0.024632 acc 0.981798 lr 0.00011457 grad_norm 0.352816 rank 0
2025-01-11 11:29:41,250 DEBUG TRAIN Batch 196/1000 loss 0.029528 acc 0.980410 lr 0.00011457 grad_norm 0.352816 rank 1
2025-01-11 11:30:05,804 DEBUG TRAIN Batch 196/1100 loss 0.022340 acc 0.982407 lr 0.00011456 grad_norm 0.363947 rank 0
2025-01-11 11:30:05,805 DEBUG TRAIN Batch 196/1100 loss 0.025149 acc 0.983977 lr 0.00011456 grad_norm 0.363947 rank 2
2025-01-11 11:30:05,805 DEBUG TRAIN Batch 196/1100 loss 0.025384 acc 0.980410 lr 0.00011456 grad_norm 0.363947 rank 1
2025-01-11 11:30:30,078 DEBUG TRAIN Batch 196/1200 loss 0.024449 acc 0.981614 lr 0.00011454 grad_norm 0.349611 rank 1
2025-01-11 11:30:30,078 DEBUG TRAIN Batch 196/1200 loss 0.025665 acc 0.979816 lr 0.00011454 grad_norm 0.349611 rank 0
2025-01-11 11:30:30,078 DEBUG TRAIN Batch 196/1200 loss 0.035507 acc 0.977778 lr 0.00011454 grad_norm 0.349611 rank 2
2025-01-11 11:30:53,996 DEBUG TRAIN Batch 196/1300 loss 0.015101 acc 0.987603 lr 0.00011453 grad_norm 0.338695 rank 0
2025-01-11 11:30:53,996 DEBUG TRAIN Batch 196/1300 loss 0.028529 acc 0.977396 lr 0.00011453 grad_norm 0.338695 rank 1
2025-01-11 11:30:53,996 DEBUG TRAIN Batch 196/1300 loss 0.030168 acc 0.979401 lr 0.00011453 grad_norm 0.338695 rank 2
2025-01-11 11:31:17,721 DEBUG TRAIN Batch 196/1400 loss 0.011669 acc 0.992553 lr 0.00011451 grad_norm 0.307328 rank 0
2025-01-11 11:31:17,722 DEBUG TRAIN Batch 196/1400 loss 0.029162 acc 0.983685 lr 0.00011451 grad_norm 0.307328 rank 1
2025-01-11 11:31:17,722 DEBUG TRAIN Batch 196/1400 loss 0.023066 acc 0.982811 lr 0.00011451 grad_norm 0.307328 rank 2
2025-01-11 11:31:42,458 DEBUG TRAIN Batch 196/1500 loss 0.024553 acc 0.983051 lr 0.00011450 grad_norm 0.376667 rank 0
2025-01-11 11:31:42,458 DEBUG TRAIN Batch 196/1500 loss 0.024978 acc 0.985809 lr 0.00011450 grad_norm 0.376667 rank 1
2025-01-11 11:31:42,458 DEBUG TRAIN Batch 196/1500 loss 0.028940 acc 0.975352 lr 0.00011450 grad_norm 0.376667 rank 2
2025-01-11 11:32:05,964 DEBUG TRAIN Batch 196/1600 loss 0.029189 acc 0.980926 lr 0.00011448 grad_norm 0.344361 rank 1
2025-01-11 11:32:05,964 DEBUG TRAIN Batch 196/1600 loss 0.019568 acc 0.991045 lr 0.00011448 grad_norm 0.344361 rank 0
2025-01-11 11:32:05,964 DEBUG TRAIN Batch 196/1600 loss 0.014321 acc 0.992400 lr 0.00011448 grad_norm 0.344361 rank 2
2025-01-11 11:32:29,808 DEBUG TRAIN Batch 196/1700 loss 0.020040 acc 0.987603 lr 0.00011447 grad_norm 0.325650 rank 1
2025-01-11 11:32:29,809 DEBUG TRAIN Batch 196/1700 loss 0.015287 acc 0.990968 lr 0.00011447 grad_norm 0.325650 rank 0
2025-01-11 11:32:29,809 DEBUG TRAIN Batch 196/1700 loss 0.027577 acc 0.981553 lr 0.00011447 grad_norm 0.325650 rank 2
2025-01-11 11:32:55,062 DEBUG TRAIN Batch 196/1800 loss 0.033546 acc 0.973404 lr 0.00011445 grad_norm 0.348484 rank 1
2025-01-11 11:32:55,063 DEBUG TRAIN Batch 196/1800 loss 0.018528 acc 0.990521 lr 0.00011445 grad_norm 0.348484 rank 0
2025-01-11 11:32:55,063 DEBUG TRAIN Batch 196/1800 loss 0.021677 acc 0.983111 lr 0.00011445 grad_norm 0.348484 rank 2
2025-01-11 11:33:18,246 DEBUG TRAIN Batch 196/1900 loss 0.030540 acc 0.976364 lr 0.00011444 grad_norm 0.367680 rank 1
2025-01-11 11:33:18,247 DEBUG TRAIN Batch 196/1900 loss 0.017390 acc 0.986063 lr 0.00011444 grad_norm 0.367680 rank 0
2025-01-11 11:33:18,247 DEBUG TRAIN Batch 196/1900 loss 0.024281 acc 0.983577 lr 0.00011444 grad_norm 0.367680 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 11:34:23,661 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 11:34:23,662 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 11:34:24,100 INFO Epoch 196 Step 190916 on_batch_end True CV rank 0
2025-01-11 11:34:24,100 INFO Epoch 196 Step 190916 on_batch_end True CV rank 2
2025-01-11 11:34:24,100 INFO Epoch 196 Step 190916 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 11:34:33,266 DEBUG CV Batch 196/100 loss 0.003464 acc 0.998885  rank 0
2025-01-11 11:34:33,331 DEBUG CV Batch 196/100 loss 0.003464 acc 0.998885  rank 2
2025-01-11 11:34:33,743 DEBUG CV Batch 196/100 loss 0.003464 acc 0.998885  rank 1
2025-01-11 11:34:33,795 INFO Epoch 196 Step 190916 CV info lr 0.00011443235639226554 0 rank loss_2.799867033032793 acc_0.7804399632048189
2025-01-11 11:34:33,870 INFO Epoch 196 Step 190916 CV info lr 0.00011443235639226554 2 rank loss_2.799867033032793 acc_0.7804399632048189
2025-01-11 11:34:34,285 INFO Epoch 196 Step 190916 CV info lr 0.00011443235639226554 1 rank loss_2.799867033032793 acc_0.7804399632048189
2025-01-11 11:34:35,055 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_196_whole.pt
2025-01-11 11:34:35,066 INFO Added key: store_based_barrier_key:199 to store for rank: 0
2025-01-11 11:34:35,076 INFO Added key: store_based_barrier_key:199 to store for rank: 2
2025-01-11 11:34:35,076 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:199 with 3 nodes.
2025-01-11 11:34:35,076 INFO Added key: store_based_barrier_key:199 to store for rank: 1
2025-01-11 11:34:35,077 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:199 with 3 nodes.
2025-01-11 11:34:35,077 INFO Epoch 197 TRAIN info lr 0.00011443235639226554 rank 2
2025-01-11 11:34:35,077 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 11:34:35,079 INFO Epoch 197 TRAIN info lr 0.00011443235639226554 rank 1
2025-01-11 11:34:35,079 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 11:34:35,087 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:199 with 3 nodes.
2025-01-11 11:34:35,089 INFO Epoch 197 TRAIN info lr 0.00011443235639226554 rank 0
2025-01-11 11:34:35,089 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 11:35:11,292 DEBUG TRAIN Batch 197/100 loss 0.012619 acc 0.991195 lr 0.00011442 grad_norm 0.319287 rank 1
2025-01-11 11:35:11,293 DEBUG TRAIN Batch 197/100 loss 0.024770 acc 0.981876 lr 0.00011442 grad_norm 0.319287 rank 0
2025-01-11 11:35:11,293 DEBUG TRAIN Batch 197/100 loss 0.017711 acc 0.987654 lr 0.00011442 grad_norm 0.319287 rank 2
2025-01-11 11:35:35,554 DEBUG TRAIN Batch 197/200 loss 0.019164 acc 0.984314 lr 0.00011440 grad_norm 0.346040 rank 1
2025-01-11 11:35:35,554 DEBUG TRAIN Batch 197/200 loss 0.024826 acc 0.984279 lr 0.00011440 grad_norm 0.346040 rank 0
2025-01-11 11:35:35,554 DEBUG TRAIN Batch 197/200 loss 0.015041 acc 0.991755 lr 0.00011440 grad_norm 0.346040 rank 2
2025-01-11 11:36:00,943 DEBUG TRAIN Batch 197/300 loss 0.010128 acc 0.993496 lr 0.00011439 grad_norm 0.333910 rank 1
2025-01-11 11:36:00,944 DEBUG TRAIN Batch 197/300 loss 0.026137 acc 0.980057 lr 0.00011439 grad_norm 0.333910 rank 0
2025-01-11 11:36:00,944 DEBUG TRAIN Batch 197/300 loss 0.033957 acc 0.974790 lr 0.00011439 grad_norm 0.333910 rank 2
2025-01-11 11:36:26,091 DEBUG TRAIN Batch 197/400 loss 0.013337 acc 0.991329 lr 0.00011437 grad_norm 0.333843 rank 1
2025-01-11 11:36:26,091 DEBUG TRAIN Batch 197/400 loss 0.018860 acc 0.985294 lr 0.00011437 grad_norm 0.333843 rank 2
2025-01-11 11:36:26,091 DEBUG TRAIN Batch 197/400 loss 0.021358 acc 0.987565 lr 0.00011437 grad_norm 0.333843 rank 0
2025-01-11 11:36:50,390 DEBUG TRAIN Batch 197/500 loss 0.019087 acc 0.987908 lr 0.00011436 grad_norm 0.326590 rank 1
2025-01-11 11:36:50,391 DEBUG TRAIN Batch 197/500 loss 0.034855 acc 0.981463 lr 0.00011436 grad_norm 0.326590 rank 0
2025-01-11 11:36:50,391 DEBUG TRAIN Batch 197/500 loss 0.021795 acc 0.984955 lr 0.00011436 grad_norm 0.326590 rank 2
2025-01-11 11:37:15,572 DEBUG TRAIN Batch 197/600 loss 0.012401 acc 0.993258 lr 0.00011434 grad_norm 0.328285 rank 1
2025-01-11 11:37:15,572 DEBUG TRAIN Batch 197/600 loss 0.018250 acc 0.983254 lr 0.00011434 grad_norm 0.328285 rank 2
2025-01-11 11:37:15,573 DEBUG TRAIN Batch 197/600 loss 0.028641 acc 0.978550 lr 0.00011434 grad_norm 0.328285 rank 0
2025-01-11 11:37:40,398 DEBUG TRAIN Batch 197/700 loss 0.022912 acc 0.984783 lr 0.00011433 grad_norm 0.398596 rank 1
2025-01-11 11:37:40,398 DEBUG TRAIN Batch 197/700 loss 0.039936 acc 0.975962 lr 0.00011433 grad_norm 0.398596 rank 2
2025-01-11 11:37:40,399 DEBUG TRAIN Batch 197/700 loss 0.030910 acc 0.973529 lr 0.00011433 grad_norm 0.398596 rank 0
2025-01-11 11:38:06,036 DEBUG TRAIN Batch 197/800 loss 0.028680 acc 0.982734 lr 0.00011431 grad_norm 0.335464 rank 2
2025-01-11 11:38:06,036 DEBUG TRAIN Batch 197/800 loss 0.012816 acc 0.991364 lr 0.00011431 grad_norm 0.335464 rank 1
2025-01-11 11:38:06,036 DEBUG TRAIN Batch 197/800 loss 0.024362 acc 0.983377 lr 0.00011431 grad_norm 0.335464 rank 0
2025-01-11 11:38:29,471 DEBUG TRAIN Batch 197/900 loss 0.027971 acc 0.979965 lr 0.00011430 grad_norm 0.345565 rank 2
2025-01-11 11:38:29,471 DEBUG TRAIN Batch 197/900 loss 0.021507 acc 0.986343 lr 0.00011430 grad_norm 0.345565 rank 1
2025-01-11 11:38:29,472 DEBUG TRAIN Batch 197/900 loss 0.025985 acc 0.984026 lr 0.00011430 grad_norm 0.345565 rank 0
2025-01-11 11:38:54,041 DEBUG TRAIN Batch 197/1000 loss 0.028697 acc 0.980732 lr 0.00011428 grad_norm 0.336364 rank 2
2025-01-11 11:38:54,042 DEBUG TRAIN Batch 197/1000 loss 0.014076 acc 0.988048 lr 0.00011428 grad_norm 0.336364 rank 1
2025-01-11 11:38:54,043 DEBUG TRAIN Batch 197/1000 loss 0.027287 acc 0.975828 lr 0.00011428 grad_norm 0.336364 rank 0
2025-01-11 11:39:19,287 DEBUG TRAIN Batch 197/1100 loss 0.029945 acc 0.980583 lr 0.00011427 grad_norm 0.365931 rank 1
2025-01-11 11:39:19,287 DEBUG TRAIN Batch 197/1100 loss 0.029724 acc 0.980198 lr 0.00011427 grad_norm 0.365931 rank 0
2025-01-11 11:39:19,287 DEBUG TRAIN Batch 197/1100 loss 0.028020 acc 0.976583 lr 0.00011427 grad_norm 0.365931 rank 2
2025-01-11 11:39:42,847 DEBUG TRAIN Batch 197/1200 loss 0.020233 acc 0.988530 lr 0.00011425 grad_norm 0.347543 rank 1
2025-01-11 11:39:42,847 DEBUG TRAIN Batch 197/1200 loss 0.021994 acc 0.987472 lr 0.00011425 grad_norm 0.347543 rank 2
2025-01-11 11:39:42,848 DEBUG TRAIN Batch 197/1200 loss 0.021733 acc 0.981203 lr 0.00011425 grad_norm 0.347543 rank 0
2025-01-11 11:40:06,642 DEBUG TRAIN Batch 197/1300 loss 0.033138 acc 0.980180 lr 0.00011424 grad_norm 0.364382 rank 1
2025-01-11 11:40:06,642 DEBUG TRAIN Batch 197/1300 loss 0.019762 acc 0.985033 lr 0.00011424 grad_norm 0.364382 rank 2
2025-01-11 11:40:06,642 DEBUG TRAIN Batch 197/1300 loss 0.029119 acc 0.980827 lr 0.00011424 grad_norm 0.364382 rank 0
2025-01-11 11:40:30,537 DEBUG TRAIN Batch 197/1400 loss 0.026707 acc 0.980856 lr 0.00011422 grad_norm 0.343140 rank 2
2025-01-11 11:40:30,537 DEBUG TRAIN Batch 197/1400 loss 0.029325 acc 0.978821 lr 0.00011422 grad_norm 0.343140 rank 0
2025-01-11 11:40:30,538 DEBUG TRAIN Batch 197/1400 loss 0.027238 acc 0.982317 lr 0.00011422 grad_norm 0.343140 rank 1
2025-01-11 11:40:54,220 DEBUG TRAIN Batch 197/1500 loss 0.037521 acc 0.973592 lr 0.00011421 grad_norm 0.370605 rank 0
2025-01-11 11:40:54,220 DEBUG TRAIN Batch 197/1500 loss 0.023956 acc 0.983068 lr 0.00011421 grad_norm 0.370605 rank 1
2025-01-11 11:40:54,220 DEBUG TRAIN Batch 197/1500 loss 0.034545 acc 0.979960 lr 0.00011421 grad_norm 0.370605 rank 2
2025-01-11 11:41:18,690 DEBUG TRAIN Batch 197/1600 loss 0.023347 acc 0.985902 lr 0.00011419 grad_norm 0.346280 rank 0
2025-01-11 11:41:18,690 DEBUG TRAIN Batch 197/1600 loss 0.034813 acc 0.974038 lr 0.00011419 grad_norm 0.346280 rank 1
2025-01-11 11:41:18,690 DEBUG TRAIN Batch 197/1600 loss 0.020602 acc 0.981802 lr 0.00011419 grad_norm 0.346280 rank 2
2025-01-11 11:41:42,588 DEBUG TRAIN Batch 197/1700 loss 0.026527 acc 0.983218 lr 0.00011418 grad_norm 0.365587 rank 0
2025-01-11 11:41:42,588 DEBUG TRAIN Batch 197/1700 loss 0.031627 acc 0.975973 lr 0.00011418 grad_norm 0.365587 rank 1
2025-01-11 11:41:42,588 DEBUG TRAIN Batch 197/1700 loss 0.021382 acc 0.983498 lr 0.00011418 grad_norm 0.365587 rank 2
2025-01-11 11:42:06,736 DEBUG TRAIN Batch 197/1800 loss 0.026221 acc 0.980583 lr 0.00011416 grad_norm 0.348521 rank 1
2025-01-11 11:42:06,736 DEBUG TRAIN Batch 197/1800 loss 0.026260 acc 0.984718 lr 0.00011416 grad_norm 0.348521 rank 2
2025-01-11 11:42:06,737 DEBUG TRAIN Batch 197/1800 loss 0.016043 acc 0.988806 lr 0.00011416 grad_norm 0.348521 rank 0
2025-01-11 11:42:31,319 DEBUG TRAIN Batch 197/1900 loss 0.025723 acc 0.979249 lr 0.00011415 grad_norm 0.365618 rank 0
2025-01-11 11:42:31,319 DEBUG TRAIN Batch 197/1900 loss 0.020816 acc 0.984032 lr 0.00011415 grad_norm 0.365618 rank 2
2025-01-11 11:42:31,319 DEBUG TRAIN Batch 197/1900 loss 0.024115 acc 0.981589 lr 0.00011415 grad_norm 0.365618 rank 1
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 11:43:34,260 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 11:43:34,262 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 11:43:34,676 INFO Epoch 197 Step 191872 on_batch_end True CV rank 2
2025-01-11 11:43:34,676 INFO Epoch 197 Step 191872 on_batch_end True CV rank 0
2025-01-11 11:43:34,676 INFO Epoch 197 Step 191872 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 11:43:43,924 DEBUG CV Batch 197/100 loss 0.000667 acc 1.000000  rank 2
2025-01-11 11:43:44,139 DEBUG CV Batch 197/100 loss 0.000667 acc 1.000000  rank 0
2025-01-11 11:43:44,416 INFO Epoch 197 Step 191872 CV info lr 0.00011414692146434142 2 rank loss_2.810059680690086 acc_0.7807244183985811
2025-01-11 11:43:44,665 INFO Epoch 197 Step 191872 CV info lr 0.00011414692146434142 0 rank loss_2.810059680690086 acc_0.7807244183985811
2025-01-11 11:43:44,696 DEBUG CV Batch 197/100 loss 0.000667 acc 1.000000  rank 1
2025-01-11 11:43:45,254 INFO Epoch 197 Step 191872 CV info lr 0.00011414692146434142 1 rank loss_2.810059680690086 acc_0.7807244183985811
2025-01-11 11:43:46,020 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_197_whole.pt
2025-01-11 11:43:46,032 INFO Added key: store_based_barrier_key:200 to store for rank: 0
2025-01-11 11:43:46,042 INFO Added key: store_based_barrier_key:200 to store for rank: 2
2025-01-11 11:43:46,042 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:200 with 3 nodes.
2025-01-11 11:43:46,042 INFO Added key: store_based_barrier_key:200 to store for rank: 1
2025-01-11 11:43:46,043 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:200 with 3 nodes.
2025-01-11 11:43:46,044 INFO Epoch 198 TRAIN info lr 0.00011414692146434142 rank 2
2025-01-11 11:43:46,044 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 11:43:46,048 INFO Epoch 198 TRAIN info lr 0.00011414692146434142 rank 1
2025-01-11 11:43:46,048 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 11:43:46,053 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:200 with 3 nodes.
2025-01-11 11:43:46,058 INFO Epoch 198 TRAIN info lr 0.00011414692146434142 rank 0
2025-01-11 11:43:46,058 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 11:44:20,398 DEBUG TRAIN Batch 198/100 loss 0.023092 acc 0.989691 lr 0.00011413 grad_norm 0.352912 rank 1
2025-01-11 11:44:20,398 DEBUG TRAIN Batch 198/100 loss 0.023721 acc 0.980479 lr 0.00011413 grad_norm 0.352912 rank 2
2025-01-11 11:44:20,400 DEBUG TRAIN Batch 198/100 loss 0.022281 acc 0.983838 lr 0.00011413 grad_norm 0.352912 rank 0
2025-01-11 11:44:44,687 DEBUG TRAIN Batch 198/200 loss 0.032865 acc 0.974820 lr 0.00011412 grad_norm 0.379465 rank 1
2025-01-11 11:44:44,688 DEBUG TRAIN Batch 198/200 loss 0.033332 acc 0.977012 lr 0.00011412 grad_norm 0.379465 rank 2
2025-01-11 11:44:44,688 DEBUG TRAIN Batch 198/200 loss 0.022786 acc 0.983529 lr 0.00011412 grad_norm 0.379465 rank 0
2025-01-11 11:45:10,223 DEBUG TRAIN Batch 198/300 loss 0.024208 acc 0.981366 lr 0.00011410 grad_norm 0.348237 rank 2
2025-01-11 11:45:10,223 DEBUG TRAIN Batch 198/300 loss 0.034663 acc 0.982160 lr 0.00011410 grad_norm 0.348237 rank 1
2025-01-11 11:45:10,224 DEBUG TRAIN Batch 198/300 loss 0.018351 acc 0.989603 lr 0.00011410 grad_norm 0.348237 rank 0
2025-01-11 11:45:35,003 DEBUG TRAIN Batch 198/400 loss 0.021807 acc 0.986156 lr 0.00011409 grad_norm 0.349739 rank 1
2025-01-11 11:45:35,003 DEBUG TRAIN Batch 198/400 loss 0.013469 acc 0.988439 lr 0.00011409 grad_norm 0.349739 rank 0
2025-01-11 11:45:35,003 DEBUG TRAIN Batch 198/400 loss 0.014159 acc 0.989095 lr 0.00011409 grad_norm 0.349739 rank 2
2025-01-11 11:45:59,311 DEBUG TRAIN Batch 198/500 loss 0.020255 acc 0.987097 lr 0.00011407 grad_norm 0.360255 rank 0
2025-01-11 11:45:59,311 DEBUG TRAIN Batch 198/500 loss 0.028550 acc 0.976437 lr 0.00011407 grad_norm 0.360255 rank 1
2025-01-11 11:45:59,311 DEBUG TRAIN Batch 198/500 loss 0.023495 acc 0.983886 lr 0.00011407 grad_norm 0.360255 rank 2
2025-01-11 11:46:23,822 DEBUG TRAIN Batch 198/600 loss 0.024225 acc 0.979110 lr 0.00011406 grad_norm 0.315423 rank 2
2025-01-11 11:46:23,822 DEBUG TRAIN Batch 198/600 loss 0.012757 acc 0.991347 lr 0.00011406 grad_norm 0.315423 rank 0
2025-01-11 11:46:23,823 DEBUG TRAIN Batch 198/600 loss 0.017219 acc 0.988107 lr 0.00011406 grad_norm 0.315423 rank 1
2025-01-11 11:46:48,337 DEBUG TRAIN Batch 198/700 loss 0.022248 acc 0.984671 lr 0.00011404 grad_norm 0.339046 rank 1
2025-01-11 11:46:48,338 DEBUG TRAIN Batch 198/700 loss 0.013007 acc 0.992681 lr 0.00011404 grad_norm 0.339046 rank 2
2025-01-11 11:46:48,338 DEBUG TRAIN Batch 198/700 loss 0.031358 acc 0.981837 lr 0.00011404 grad_norm 0.339046 rank 0
2025-01-11 11:47:13,155 DEBUG TRAIN Batch 198/800 loss 0.019817 acc 0.987730 lr 0.00011403 grad_norm 0.311044 rank 1
2025-01-11 11:47:13,155 DEBUG TRAIN Batch 198/800 loss 0.012713 acc 0.992647 lr 0.00011403 grad_norm 0.311044 rank 0
2025-01-11 11:47:13,155 DEBUG TRAIN Batch 198/800 loss 0.022220 acc 0.986854 lr 0.00011403 grad_norm 0.311044 rank 2
2025-01-11 11:47:36,610 DEBUG TRAIN Batch 198/900 loss 0.037471 acc 0.978424 lr 0.00011401 grad_norm 0.351699 rank 1
2025-01-11 11:47:36,610 DEBUG TRAIN Batch 198/900 loss 0.031598 acc 0.986761 lr 0.00011401 grad_norm 0.351699 rank 0
2025-01-11 11:47:36,610 DEBUG TRAIN Batch 198/900 loss 0.022964 acc 0.984466 lr 0.00011401 grad_norm 0.351699 rank 2
2025-01-11 11:48:00,311 DEBUG TRAIN Batch 198/1000 loss 0.022665 acc 0.985520 lr 0.00011400 grad_norm 0.346666 rank 0
2025-01-11 11:48:00,311 DEBUG TRAIN Batch 198/1000 loss 0.027788 acc 0.981546 lr 0.00011400 grad_norm 0.346666 rank 1
2025-01-11 11:48:00,311 DEBUG TRAIN Batch 198/1000 loss 0.018288 acc 0.982927 lr 0.00011400 grad_norm 0.346666 rank 2
2025-01-11 11:48:23,829 DEBUG TRAIN Batch 198/1100 loss 0.033548 acc 0.974449 lr 0.00011398 grad_norm 0.360260 rank 0
2025-01-11 11:48:23,829 DEBUG TRAIN Batch 198/1100 loss 0.029968 acc 0.979003 lr 0.00011398 grad_norm 0.360260 rank 1
2025-01-11 11:48:23,829 DEBUG TRAIN Batch 198/1100 loss 0.023697 acc 0.982394 lr 0.00011398 grad_norm 0.360260 rank 2
2025-01-11 11:48:47,739 DEBUG TRAIN Batch 198/1200 loss 0.019352 acc 0.984048 lr 0.00011397 grad_norm 0.333973 rank 1
2025-01-11 11:48:47,740 DEBUG TRAIN Batch 198/1200 loss 0.024466 acc 0.985929 lr 0.00011397 grad_norm 0.333973 rank 2
2025-01-11 11:48:47,740 DEBUG TRAIN Batch 198/1200 loss 0.015082 acc 0.988675 lr 0.00011397 grad_norm 0.333973 rank 0
2025-01-11 11:49:11,328 DEBUG TRAIN Batch 198/1300 loss 0.028144 acc 0.981443 lr 0.00011395 grad_norm 0.337357 rank 1
2025-01-11 11:49:11,328 DEBUG TRAIN Batch 198/1300 loss 0.017553 acc 0.986641 lr 0.00011395 grad_norm 0.337357 rank 0
2025-01-11 11:49:11,328 DEBUG TRAIN Batch 198/1300 loss 0.024686 acc 0.981818 lr 0.00011395 grad_norm 0.337357 rank 2
2025-01-11 11:49:35,006 DEBUG TRAIN Batch 198/1400 loss 0.033609 acc 0.980527 lr 0.00011394 grad_norm 0.362357 rank 1
2025-01-11 11:49:35,007 DEBUG TRAIN Batch 198/1400 loss 0.030218 acc 0.973963 lr 0.00011394 grad_norm 0.362357 rank 2
2025-01-11 11:49:35,007 DEBUG TRAIN Batch 198/1400 loss 0.023382 acc 0.980857 lr 0.00011394 grad_norm 0.362357 rank 0
2025-01-11 11:49:58,682 DEBUG TRAIN Batch 198/1500 loss 0.027584 acc 0.979187 lr 0.00011392 grad_norm 0.326504 rank 0
2025-01-11 11:49:58,682 DEBUG TRAIN Batch 198/1500 loss 0.014455 acc 0.989523 lr 0.00011392 grad_norm 0.326504 rank 2
2025-01-11 11:49:58,683 DEBUG TRAIN Batch 198/1500 loss 0.020045 acc 0.984710 lr 0.00011392 grad_norm 0.326504 rank 1
2025-01-11 11:50:23,662 DEBUG TRAIN Batch 198/1600 loss 0.026443 acc 0.981579 lr 0.00011391 grad_norm 0.359852 rank 2
2025-01-11 11:50:23,662 DEBUG TRAIN Batch 198/1600 loss 0.014180 acc 0.989973 lr 0.00011391 grad_norm 0.359852 rank 0
2025-01-11 11:50:23,663 DEBUG TRAIN Batch 198/1600 loss 0.024741 acc 0.982997 lr 0.00011391 grad_norm 0.359852 rank 1
2025-01-11 11:50:47,299 DEBUG TRAIN Batch 198/1700 loss 0.024535 acc 0.986692 lr 0.00011389 grad_norm 0.344469 rank 1
2025-01-11 11:50:47,300 DEBUG TRAIN Batch 198/1700 loss 0.028070 acc 0.977312 lr 0.00011389 grad_norm 0.344469 rank 0
2025-01-11 11:50:47,300 DEBUG TRAIN Batch 198/1700 loss 0.011919 acc 0.989345 lr 0.00011389 grad_norm 0.344469 rank 2
2025-01-11 11:51:11,560 DEBUG TRAIN Batch 198/1800 loss 0.012362 acc 0.991751 lr 0.00011388 grad_norm 0.349091 rank 1
2025-01-11 11:51:11,560 DEBUG TRAIN Batch 198/1800 loss 0.023071 acc 0.987603 lr 0.00011388 grad_norm 0.349091 rank 0
2025-01-11 11:51:11,561 DEBUG TRAIN Batch 198/1800 loss 0.021540 acc 0.982620 lr 0.00011388 grad_norm 0.349091 rank 2
2025-01-11 11:51:36,757 DEBUG TRAIN Batch 198/1900 loss 0.037877 acc 0.975449 lr 0.00011387 grad_norm 0.331615 rank 1
2025-01-11 11:51:36,758 DEBUG TRAIN Batch 198/1900 loss 0.020060 acc 0.984511 lr 0.00011387 grad_norm 0.331615 rank 0
2025-01-11 11:51:36,758 DEBUG TRAIN Batch 198/1900 loss 0.015016 acc 0.989712 lr 0.00011387 grad_norm 0.331615 rank 2
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 11:53:00,542 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 11:53:00,604 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 11:53:01,062 INFO Epoch 198 Step 192870 on_batch_end True CV rank 2
2025-01-11 11:53:01,063 INFO Epoch 198 Step 192870 on_batch_end True CV rank 0
2025-01-11 11:53:01,063 INFO Epoch 198 Step 192870 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 11:53:10,254 DEBUG CV Batch 198/100 loss 0.001579 acc 1.000000  rank 2
2025-01-11 11:53:10,364 DEBUG CV Batch 198/100 loss 0.001579 acc 1.000000  rank 0
2025-01-11 11:53:10,663 DEBUG CV Batch 198/100 loss 0.001579 acc 1.000000  rank 1
2025-01-11 11:53:10,758 INFO Epoch 198 Step 192870 CV info lr 0.00011385121353345966 2 rank loss_2.795469669890544 acc_0.7812115225875587
2025-01-11 11:53:10,891 INFO Epoch 198 Step 192870 CV info lr 0.00011385121353345966 0 rank loss_2.795469669890544 acc_0.7812115225875587
2025-01-11 11:53:11,197 INFO Epoch 198 Step 192870 CV info lr 0.00011385121353345966 1 rank loss_2.795469669890544 acc_0.7812115225875587
2025-01-11 11:53:12,180 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_198_whole.pt
2025-01-11 11:53:12,191 INFO Added key: store_based_barrier_key:201 to store for rank: 0
2025-01-11 11:53:12,202 INFO Added key: store_based_barrier_key:201 to store for rank: 2
2025-01-11 11:53:12,202 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:201 with 3 nodes.
2025-01-11 11:53:12,202 INFO Added key: store_based_barrier_key:201 to store for rank: 1
2025-01-11 11:53:12,202 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:201 with 3 nodes.
2025-01-11 11:53:12,205 INFO Epoch 199 TRAIN info lr 0.00011385121353345966 rank 2
2025-01-11 11:53:12,205 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 11:53:12,206 INFO Epoch 199 TRAIN info lr 0.00011385121353345966 rank 1
2025-01-11 11:53:12,206 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 11:53:12,212 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:201 with 3 nodes.
2025-01-11 11:53:12,212 INFO Epoch 199 TRAIN info lr 0.00011385121353345966 rank 0
2025-01-11 11:53:12,212 INFO using accumulate grad, new batch size is 2 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 11:53:43,420 DEBUG TRAIN Batch 199/100 loss 0.017426 acc 0.987654 lr 0.00011384 grad_norm 0.336856 rank 2
2025-01-11 11:53:43,420 DEBUG TRAIN Batch 199/100 loss 0.024179 acc 0.984424 lr 0.00011384 grad_norm 0.336856 rank 0
2025-01-11 11:53:43,420 DEBUG TRAIN Batch 199/100 loss 0.027171 acc 0.982805 lr 0.00011384 grad_norm 0.336856 rank 1
2025-01-11 11:54:07,321 DEBUG TRAIN Batch 199/200 loss 0.026722 acc 0.983247 lr 0.00011382 grad_norm 0.386488 rank 0
2025-01-11 11:54:07,322 DEBUG TRAIN Batch 199/200 loss 0.018426 acc 0.991206 lr 0.00011382 grad_norm 0.386488 rank 1
2025-01-11 11:54:07,322 DEBUG TRAIN Batch 199/200 loss 0.023198 acc 0.983648 lr 0.00011382 grad_norm 0.386488 rank 2
2025-01-11 11:54:31,028 DEBUG TRAIN Batch 199/300 loss 0.025000 acc 0.981221 lr 0.00011381 grad_norm 0.317171 rank 0
2025-01-11 11:54:31,028 DEBUG TRAIN Batch 199/300 loss 0.025558 acc 0.983463 lr 0.00011381 grad_norm 0.317171 rank 2
2025-01-11 11:54:31,028 DEBUG TRAIN Batch 199/300 loss 0.028146 acc 0.980574 lr 0.00011381 grad_norm 0.317171 rank 1
2025-01-11 11:54:54,573 DEBUG TRAIN Batch 199/400 loss 0.031078 acc 0.982811 lr 0.00011379 grad_norm 0.356071 rank 0
2025-01-11 11:54:54,573 DEBUG TRAIN Batch 199/400 loss 0.028890 acc 0.981421 lr 0.00011379 grad_norm 0.356071 rank 2
2025-01-11 11:54:54,573 DEBUG TRAIN Batch 199/400 loss 0.021222 acc 0.983885 lr 0.00011379 grad_norm 0.356071 rank 1
2025-01-11 11:55:18,939 DEBUG TRAIN Batch 199/500 loss 0.021981 acc 0.987296 lr 0.00011378 grad_norm 0.323239 rank 1
2025-01-11 11:55:18,939 DEBUG TRAIN Batch 199/500 loss 0.029465 acc 0.976679 lr 0.00011378 grad_norm 0.323239 rank 0
2025-01-11 11:55:18,939 DEBUG TRAIN Batch 199/500 loss 0.027381 acc 0.983592 lr 0.00011378 grad_norm 0.323239 rank 2
2025-01-11 11:55:42,153 DEBUG TRAIN Batch 199/600 loss 0.025950 acc 0.978346 lr 0.00011376 grad_norm 0.361843 rank 1
2025-01-11 11:55:42,154 DEBUG TRAIN Batch 199/600 loss 0.029069 acc 0.979098 lr 0.00011376 grad_norm 0.361843 rank 2
2025-01-11 11:55:42,154 DEBUG TRAIN Batch 199/600 loss 0.026203 acc 0.978302 lr 0.00011376 grad_norm 0.361843 rank 0
2025-01-11 11:56:06,129 DEBUG TRAIN Batch 199/700 loss 0.016915 acc 0.987452 lr 0.00011375 grad_norm 0.326420 rank 1
2025-01-11 11:56:06,129 DEBUG TRAIN Batch 199/700 loss 0.014849 acc 0.992791 lr 0.00011375 grad_norm 0.326420 rank 2
2025-01-11 11:56:06,129 DEBUG TRAIN Batch 199/700 loss 0.018303 acc 0.981763 lr 0.00011375 grad_norm 0.326420 rank 0
2025-01-11 11:56:30,390 DEBUG TRAIN Batch 199/800 loss 0.024500 acc 0.984028 lr 0.00011373 grad_norm 0.337232 rank 2
2025-01-11 11:56:30,390 DEBUG TRAIN Batch 199/800 loss 0.022026 acc 0.983318 lr 0.00011373 grad_norm 0.337232 rank 0
2025-01-11 11:56:30,390 DEBUG TRAIN Batch 199/800 loss 0.022175 acc 0.984026 lr 0.00011373 grad_norm 0.337232 rank 1
2025-01-11 11:56:54,497 DEBUG TRAIN Batch 199/900 loss 0.019575 acc 0.987091 lr 0.00011372 grad_norm 0.294703 rank 1
2025-01-11 11:56:54,497 DEBUG TRAIN Batch 199/900 loss 0.012785 acc 0.990955 lr 0.00011372 grad_norm 0.294703 rank 2
2025-01-11 11:56:54,497 DEBUG TRAIN Batch 199/900 loss 0.024310 acc 0.984155 lr 0.00011372 grad_norm 0.294703 rank 0
2025-01-11 11:57:18,371 DEBUG TRAIN Batch 199/1000 loss 0.017596 acc 0.986583 lr 0.00011370 grad_norm 0.322484 rank 2
2025-01-11 11:57:18,371 DEBUG TRAIN Batch 199/1000 loss 0.014733 acc 0.991314 lr 0.00011370 grad_norm 0.322484 rank 0
2025-01-11 11:57:18,372 DEBUG TRAIN Batch 199/1000 loss 0.029004 acc 0.977538 lr 0.00011370 grad_norm 0.322484 rank 1
2025-01-11 11:57:43,308 DEBUG TRAIN Batch 199/1100 loss 0.017004 acc 0.986509 lr 0.00011369 grad_norm 0.390504 rank 0
2025-01-11 11:57:43,308 DEBUG TRAIN Batch 199/1100 loss 0.026043 acc 0.979962 lr 0.00011369 grad_norm 0.390504 rank 2
2025-01-11 11:57:43,310 DEBUG TRAIN Batch 199/1100 loss 0.024297 acc 0.979835 lr 0.00011369 grad_norm 0.390504 rank 1
2025-01-11 11:58:06,772 DEBUG TRAIN Batch 199/1200 loss 0.025977 acc 0.979452 lr 0.00011367 grad_norm 0.376466 rank 1
2025-01-11 11:58:06,772 DEBUG TRAIN Batch 199/1200 loss 0.023672 acc 0.981098 lr 0.00011367 grad_norm 0.376466 rank 0
2025-01-11 11:58:06,772 DEBUG TRAIN Batch 199/1200 loss 0.030651 acc 0.983431 lr 0.00011367 grad_norm 0.376466 rank 2
2025-01-11 11:58:30,869 DEBUG TRAIN Batch 199/1300 loss 0.019960 acc 0.985632 lr 0.00011366 grad_norm 0.364583 rank 0
2025-01-11 11:58:30,869 DEBUG TRAIN Batch 199/1300 loss 0.028272 acc 0.983108 lr 0.00011366 grad_norm 0.364583 rank 2
2025-01-11 11:58:30,869 DEBUG TRAIN Batch 199/1300 loss 0.027926 acc 0.983564 lr 0.00011366 grad_norm 0.364583 rank 1
2025-01-11 11:58:54,482 DEBUG TRAIN Batch 199/1400 loss 0.018151 acc 0.990741 lr 0.00011365 grad_norm 0.315786 rank 1
2025-01-11 11:58:54,483 DEBUG TRAIN Batch 199/1400 loss 0.021265 acc 0.986301 lr 0.00011365 grad_norm 0.315786 rank 0
2025-01-11 11:58:54,483 DEBUG TRAIN Batch 199/1400 loss 0.018853 acc 0.990476 lr 0.00011365 grad_norm 0.315786 rank 2
2025-01-11 11:59:18,858 DEBUG TRAIN Batch 199/1500 loss 0.022977 acc 0.985205 lr 0.00011363 grad_norm 0.335140 rank 0
2025-01-11 11:59:18,858 DEBUG TRAIN Batch 199/1500 loss 0.018649 acc 0.987220 lr 0.00011363 grad_norm 0.335140 rank 1
2025-01-11 11:59:18,858 DEBUG TRAIN Batch 199/1500 loss 0.027747 acc 0.979412 lr 0.00011363 grad_norm 0.335140 rank 2
2025-01-11 11:59:42,744 DEBUG TRAIN Batch 199/1600 loss 0.027775 acc 0.980822 lr 0.00011362 grad_norm 0.357736 rank 0
2025-01-11 11:59:42,744 DEBUG TRAIN Batch 199/1600 loss 0.030875 acc 0.982726 lr 0.00011362 grad_norm 0.357736 rank 1
2025-01-11 11:59:42,745 DEBUG TRAIN Batch 199/1600 loss 0.029169 acc 0.975111 lr 0.00011362 grad_norm 0.357736 rank 2
2025-01-11 12:00:06,432 DEBUG TRAIN Batch 199/1700 loss 0.028012 acc 0.976031 lr 0.00011360 grad_norm 0.341715 rank 1
2025-01-11 12:00:06,432 DEBUG TRAIN Batch 199/1700 loss 0.025630 acc 0.978937 lr 0.00011360 grad_norm 0.341715 rank 0
2025-01-11 12:00:06,432 DEBUG TRAIN Batch 199/1700 loss 0.027589 acc 0.982922 lr 0.00011360 grad_norm 0.341715 rank 2
2025-01-11 12:00:30,709 DEBUG TRAIN Batch 199/1800 loss 0.019768 acc 0.986869 lr 0.00011359 grad_norm 0.352858 rank 1
2025-01-11 12:00:30,709 DEBUG TRAIN Batch 199/1800 loss 0.023964 acc 0.986124 lr 0.00011359 grad_norm 0.352858 rank 0
2025-01-11 12:00:30,710 DEBUG TRAIN Batch 199/1800 loss 0.017270 acc 0.987842 lr 0.00011359 grad_norm 0.352858 rank 2
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
2025-01-11 12:01:31,705 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 12:01:31,708 INFO Detected uneven workload distribution: [Rank 0]: Rank 2 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 12:01:32,223 INFO Epoch 199 Step 193772 on_batch_end True CV rank 1
2025-01-11 12:01:32,223 INFO Epoch 199 Step 193772 on_batch_end True CV rank 0
2025-01-11 12:01:32,224 INFO Epoch 199 Step 193772 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 12:01:41,317 DEBUG CV Batch 199/100 loss 0.001201 acc 1.000000  rank 0
2025-01-11 12:01:41,692 DEBUG CV Batch 199/100 loss 0.001201 acc 1.000000  rank 2
2025-01-11 12:01:41,849 INFO Epoch 199 Step 193772 CV info lr 0.00011358591828355483 0 rank loss_2.7990856311047727 acc_0.7810001020368776
2025-01-11 12:01:41,870 DEBUG CV Batch 199/100 loss 0.001201 acc 1.000000  rank 1
2025-01-11 12:01:42,240 INFO Epoch 199 Step 193772 CV info lr 0.00011358591828355483 2 rank loss_2.7990856311047727 acc_0.7810001020368776
2025-01-11 12:01:42,285 DEBUG Attempting to acquire lock 140662361054352 on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:01:42,285 DEBUG Lock 140662361054352 acquired on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:01:42,286 DEBUG Attempting to release lock 140662361054352 on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:01:42,286 DEBUG Lock 140662361054352 released on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:01:42,304 DEBUG Attempting to acquire lock 140662361057280 on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:01:42,305 DEBUG Lock 140662361057280 acquired on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:01:42,305 DEBUG Attempting to release lock 140662361057280 on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:01:42,305 DEBUG Lock 140662361057280 released on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:01:42,405 INFO Epoch 199 Step 193772 CV info lr 0.00011358591828355483 1 rank loss_2.7990856311047727 acc_0.7810001020368776
2025-01-11 12:01:42,432 DEBUG Attempting to acquire lock 140707864894032 on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:01:42,432 DEBUG Lock 140707864894032 acquired on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:01:42,432 DEBUG Attempting to release lock 140707864894032 on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:01:42,432 DEBUG Lock 140707864894032 released on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:01:42,436 DEBUG Attempting to acquire lock 140707864898208 on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:01:42,436 DEBUG Lock 140707864898208 acquired on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:01:42,436 DEBUG Attempting to release lock 140707864898208 on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:01:42,436 DEBUG Lock 140707864898208 released on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:01:43,203 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/llm/torch_ddp/epoch_199_whole.pt
2025-01-11 12:01:43,224 DEBUG Attempting to acquire lock 140066406194320 on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:01:43,224 DEBUG Lock 140066406194320 acquired on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:01:43,224 DEBUG Attempting to release lock 140066406194320 on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:01:43,224 DEBUG Lock 140066406194320 released on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:01:43,228 DEBUG Attempting to acquire lock 140066406196768 on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:01:43,229 DEBUG Lock 140066406196768 acquired on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:01:43,229 DEBUG Attempting to release lock 140066406196768 on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:01:43,229 DEBUG Lock 140066406196768 released on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2025-01-11 12:01:52,316] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-11 12:01:52,341] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-11 12:01:52,341] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m NVIDIA Inference is only supported on Ampere and newer architectures
[93m [WARNING] [0m NVIDIA Inference is only supported on Ampere and newer architectures
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m NVIDIA Inference is only supported on Ampere and newer architectures
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
  deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
  deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
  deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
2025-01-11 12:01:57,876 INFO input frame rate=50
2025-01-11 12:01:57,883 INFO input frame rate=50
2025-01-11 12:01:57,894 INFO input frame rate=50
2025-01-11 12:01:58,540 INFO training on multiple gpus, this gpu 0, rank 0, world_size 3
2025-01-11 12:01:58,540 INFO training on multiple gpus, this gpu 1, rank 1, world_size 3
2025-01-11 12:01:58,540 INFO training on multiple gpus, this gpu 2, rank 2, world_size 3
2025-01-11 12:01:58,543 INFO Added key: store_based_barrier_key:1 to store for rank: 1
2025-01-11 12:01:58,544 INFO Added key: store_based_barrier_key:1 to store for rank: 2
2025-01-11 12:01:58,544 INFO Added key: store_based_barrier_key:1 to store for rank: 0
2025-01-11 12:01:58,544 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
2025-01-11 12:01:58,544 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
2025-01-11 12:01:58,553 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
start step 0 start epoch -1
start step 0 start epoch -1
2025-01-11 12:02:01,000 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/flow/torch_ddp/init.pt
start step 0 start epoch -1
2025-01-11 12:02:01,032 INFO Added key: store_based_barrier_key:2 to store for rank: 0
2025-01-11 12:02:01,043 INFO Added key: store_based_barrier_key:2 to store for rank: 1
2025-01-11 12:02:01,044 INFO Added key: store_based_barrier_key:2 to store for rank: 2
2025-01-11 12:02:01,045 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:2 with 3 nodes.
2025-01-11 12:02:01,045 INFO Epoch 0 TRAIN info lr 4e-07 rank 2
2025-01-11 12:02:01,045 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 12:02:01,053 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 3 nodes.
2025-01-11 12:02:01,053 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 3 nodes.
2025-01-11 12:02:01,053 INFO Epoch 0 TRAIN info lr 4e-07 rank 0
2025-01-11 12:02:01,053 INFO using accumulate grad, new batch size is 2 times larger than before
2025-01-11 12:02:01,053 INFO Epoch 0 TRAIN info lr 4e-07 rank 1
2025-01-11 12:02:01,053 INFO using accumulate grad, new batch size is 2 times larger than before
Traceback (most recent call last):
  File "/data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/cosyvoice/bin/train.py", line 170, in <module>
    main()
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/cosyvoice/bin/train.py", line 165, in main
    executor.train_one_epoc(model, optimizer, scheduler, train_data_loader, cv_data_loader, writer, info_dict, scaler, group_join)
  File "/data/minju/TTS/CosyVoice/cosyvoice/utils/executor.py", line 68, in train_one_epoc
    info_dict = batch_forward(model, batch_dict, scaler, info_dict)
  File "/data/minju/TTS/CosyVoice/cosyvoice/utils/train_utils.py", line 255, in batch_forward
    info_dict['loss_dict'] = model(batch, device)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1113, in _run_ddp_forward
    return module_to_run(*inputs, **kwargs)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/minju/TTS/CosyVoice/cosyvoice/flow/flow.py", line 95, in forward
    loss, _ = self.decoder.compute_loss(
  File "/data/minju/TTS/CosyVoice/cosyvoice/flow/flow_matching.py", line 179, in compute_loss
    pred = self.estimator(y, mask, mu, t.squeeze(), spks, cond)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/minju/TTS/CosyVoice/cosyvoice/flow/decoder.py", line 253, in forward
    attn_mask = add_optional_chunk_mask(x, mask_down.bool(), False, False, 0, self.static_chunk_size, -1)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'ConditionalDecoder' object has no attribute 'static_chunk_size'
2025-01-11 12:02:09,316 DEBUG Attempting to acquire lock 139835590246560 on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:02:09,317 DEBUG Lock 139835590246560 acquired on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:02:09,317 DEBUG Attempting to release lock 139835590246560 on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:02:09,317 DEBUG Lock 139835590246560 released on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:02:09,321 DEBUG Attempting to acquire lock 139835590247616 on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:02:09,322 DEBUG Lock 139835590247616 acquired on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:02:09,322 DEBUG Attempting to release lock 139835590247616 on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:02:09,322 DEBUG Lock 139835590247616 released on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
Traceback (most recent call last):
  File "/data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/cosyvoice/bin/train.py", line 170, in <module>
    main()
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/cosyvoice/bin/train.py", line 165, in main
    executor.train_one_epoc(model, optimizer, scheduler, train_data_loader, cv_data_loader, writer, info_dict, scaler, group_join)
  File "/data/minju/TTS/CosyVoice/cosyvoice/utils/executor.py", line 68, in train_one_epoc
    info_dict = batch_forward(model, batch_dict, scaler, info_dict)
  File "/data/minju/TTS/CosyVoice/cosyvoice/utils/train_utils.py", line 255, in batch_forward
    info_dict['loss_dict'] = model(batch, device)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1113, in _run_ddp_forward
    return module_to_run(*inputs, **kwargs)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/minju/TTS/CosyVoice/cosyvoice/flow/flow.py", line 95, in forward
    loss, _ = self.decoder.compute_loss(
  File "/data/minju/TTS/CosyVoice/cosyvoice/flow/flow_matching.py", line 179, in compute_loss
    pred = self.estimator(y, mask, mu, t.squeeze(), spks, cond)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/minju/TTS/CosyVoice/cosyvoice/flow/decoder.py", line 253, in forward
    attn_mask = add_optional_chunk_mask(x, mask_down.bool(), False, False, 0, self.static_chunk_size, -1)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'ConditionalDecoder' object has no attribute 'static_chunk_size'
2025-01-11 12:02:09,419 DEBUG Attempting to acquire lock 139623135003408 on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:02:09,420 DEBUG Lock 139623135003408 acquired on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:02:09,420 DEBUG Attempting to release lock 139623135003408 on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:02:09,420 DEBUG Lock 139623135003408 released on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:02:09,424 DEBUG Attempting to acquire lock 139623135007392 on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:02:09,424 DEBUG Lock 139623135007392 acquired on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:02:09,424 DEBUG Attempting to release lock 139623135007392 on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:02:09,424 DEBUG Lock 139623135007392 released on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
Traceback (most recent call last):
  File "/data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/cosyvoice/bin/train.py", line 170, in <module>
    main()
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/cosyvoice/bin/train.py", line 165, in main
    executor.train_one_epoc(model, optimizer, scheduler, train_data_loader, cv_data_loader, writer, info_dict, scaler, group_join)
  File "/data/minju/TTS/CosyVoice/cosyvoice/utils/executor.py", line 68, in train_one_epoc
    info_dict = batch_forward(model, batch_dict, scaler, info_dict)
  File "/data/minju/TTS/CosyVoice/cosyvoice/utils/train_utils.py", line 255, in batch_forward
    info_dict['loss_dict'] = model(batch, device)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1113, in _run_ddp_forward
    return module_to_run(*inputs, **kwargs)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/minju/TTS/CosyVoice/cosyvoice/flow/flow.py", line 95, in forward
    loss, _ = self.decoder.compute_loss(
  File "/data/minju/TTS/CosyVoice/cosyvoice/flow/flow_matching.py", line 179, in compute_loss
    pred = self.estimator(y, mask, mu, t.squeeze(), spks, cond)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/minju/TTS/CosyVoice/cosyvoice/flow/decoder.py", line 253, in forward
    attn_mask = add_optional_chunk_mask(x, mask_down.bool(), False, False, 0, self.static_chunk_size, -1)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'ConditionalDecoder' object has no attribute 'static_chunk_size'
2025-01-11 12:02:09,471 DEBUG Attempting to acquire lock 139835929837632 on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:02:09,471 DEBUG Lock 139835929837632 acquired on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:02:09,472 DEBUG Attempting to release lock 139835929837632 on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:02:09,472 DEBUG Lock 139835929837632 released on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
2025-01-11 12:02:09,475 DEBUG Attempting to acquire lock 139835929838784 on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:02:09,475 DEBUG Lock 139835929838784 acquired on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:02:09,476 DEBUG Attempting to release lock 139835929838784 on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
2025-01-11 12:02:09,476 DEBUG Lock 139835929838784 released on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 106819 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 106821 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 1 (pid: 106820) of binary: /data/minju/conda/envs/cosyvoice/bin/python
ERROR:torch.distributed.elastic.multiprocessing.errors.error_handler:no error file defined for parent, to copy child error file (/tmp/torchelastic_81lrr8uf/1986_ynde3a8a/attempt_0/1/error.json)
Traceback (most recent call last):
  File "/data/minju/conda/envs/cosyvoice/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
cosyvoice/bin/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-01-11_12:02:09
  host      : eb1fef6b7453
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 106820)
  error_file: /tmp/torchelastic_81lrr8uf/1986_ynde3a8a/attempt_0/1/error.json
  traceback : Traceback (most recent call last):
    File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
      return f(*args, **kwargs)
    File "/data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/cosyvoice/bin/train.py", line 165, in main
      executor.train_one_epoc(model, optimizer, scheduler, train_data_loader, cv_data_loader, writer, info_dict, scaler, group_join)
    File "/data/minju/TTS/CosyVoice/cosyvoice/utils/executor.py", line 68, in train_one_epoc
      info_dict = batch_forward(model, batch_dict, scaler, info_dict)
    File "/data/minju/TTS/CosyVoice/cosyvoice/utils/train_utils.py", line 255, in batch_forward
      info_dict['loss_dict'] = model(batch, device)
    File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
      return forward_call(*args, **kwargs)
    File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
      output = self._run_ddp_forward(*inputs, **kwargs)
    File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1113, in _run_ddp_forward
      return module_to_run(*inputs, **kwargs)
    File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
      return forward_call(*args, **kwargs)
    File "/data/minju/TTS/CosyVoice/cosyvoice/flow/flow.py", line 95, in forward
      loss, _ = self.decoder.compute_loss(
    File "/data/minju/TTS/CosyVoice/cosyvoice/flow/flow_matching.py", line 179, in compute_loss
      pred = self.estimator(y, mask, mu, t.squeeze(), spks, cond)
    File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
      return forward_call(*args, **kwargs)
    File "/data/minju/TTS/CosyVoice/cosyvoice/flow/decoder.py", line 253, in forward
      attn_mask = add_optional_chunk_mask(x, mask_down.bool(), False, False, 0, self.static_chunk_size, -1)
    File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1614, in __getattr__
      raise AttributeError("'{}' object has no attribute '{}'".format(
  AttributeError: 'ConditionalDecoder' object has no attribute 'static_chunk_size'
  
============================================================
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2025-01-11 12:02:14,347] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-11 12:02:14,363] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-11 12:02:14,413] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m NVIDIA Inference is only supported on Ampere and newer architectures
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m NVIDIA Inference is only supported on Ampere and newer architectures
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m NVIDIA Inference is only supported on Ampere and newer architectures
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
2025-01-11 12:02:18,577 INFO training on multiple gpus, this gpu 1, rank 1, world_size 3
2025-01-11 12:02:18,643 INFO training on multiple gpus, this gpu 2, rank 2, world_size 3
2025-01-11 12:02:18,692 INFO training on multiple gpus, this gpu 0, rank 0, world_size 3
2025-01-11 12:02:19,578 INFO Added key: store_based_barrier_key:1 to store for rank: 1
2025-01-11 12:02:19,645 INFO Added key: store_based_barrier_key:1 to store for rank: 2
2025-01-11 12:02:19,655 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
2025-01-11 12:02:19,655 INFO Added key: store_based_barrier_key:1 to store for rank: 0
2025-01-11 12:02:19,655 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
2025-01-11 12:02:19,656 WARNING checkpoint ../../../pretrained_models/CosyVoice-300M/hifigan.pt do not exsist!
2025-01-11 12:02:19,658 WARNING checkpoint ../../../pretrained_models/CosyVoice-300M/hifigan.pt do not exsist!
2025-01-11 12:02:19,661 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
2025-01-11 12:02:19,663 WARNING checkpoint ../../../pretrained_models/CosyVoice-300M/hifigan.pt do not exsist!
start step 0 start epoch -1
start step 0 start epoch -1
2025-01-11 12:02:21,596 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/hifigan/torch_ddp/init.pt
start step 0 start epoch -1
2025-01-11 12:02:21,639 INFO Added key: store_based_barrier_key:2 to store for rank: 0
2025-01-11 12:02:21,639 INFO Added key: store_based_barrier_key:2 to store for rank: 1
2025-01-11 12:02:21,640 INFO Added key: store_based_barrier_key:2 to store for rank: 2
2025-01-11 12:02:21,640 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:2 with 3 nodes.
2025-01-11 12:02:21,640 INFO Epoch 0 TRAIN info lr 0.0002 rank 2
2025-01-11 12:02:21,640 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:02:21,649 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 3 nodes.
2025-01-11 12:02:21,649 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 3 nodes.
2025-01-11 12:02:21,649 INFO Epoch 0 TRAIN info lr 0.0002 rank 0
2025-01-11 12:02:21,649 INFO Epoch 0 TRAIN info lr 0.0002 rank 1
2025-01-11 12:02:21,649 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:02:21,649 INFO using accumulate grad, new batch size is 1 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1, 9], strides() = [1, 1]
bucket_view.sizes() = [1, 9], strides() = [9, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1, 9], strides() = [1, 1]
bucket_view.sizes() = [1, 9], strides() = [9, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1, 9], strides() = [1, 1]
bucket_view.sizes() = [1, 9], strides() = [9, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 12:04:28,036 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 12:04:28,037 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 12:04:28,229 INFO Epoch 0 Step 9 on_batch_end True CV rank 0
2025-01-11 12:04:28,229 INFO Epoch 0 Step 9 on_batch_end True CV rank 2
2025-01-11 12:04:28,229 INFO Epoch 0 Step 9 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 12:04:30,951 INFO Epoch 0 Step 9 CV info lr 0.0002 0 rank loss_124.56624984741211 loss_gen_3.9726524353027344 loss_fm_18.2686824798584 loss_mel_1.8575928211212158 loss_tpr_0.012846700847148895 loss_f0_0.45169948041439056
2025-01-11 12:04:31,224 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/hifigan/torch_ddp/epoch_0_whole.pt
2025-01-11 12:04:31,572 INFO Epoch 0 Step 9 CV info lr 0.0002 2 rank loss_124.56624984741211 loss_gen_3.9726524353027344 loss_fm_18.2686824798584 loss_mel_1.8575928211212158 loss_tpr_0.012846698984503746 loss_f0_0.45169948041439056
2025-01-11 12:04:31,712 INFO Epoch 0 Step 9 CV info lr 0.0002 1 rank loss_130.77123260498047 loss_gen_3.9826207160949707 loss_fm_18.183212280273438 loss_mel_1.9991514682769775 loss_tpr_0.013545328751206398 loss_f0_0.44682975113391876
2025-01-11 12:04:31,724 INFO Added key: store_based_barrier_key:3 to store for rank: 0
2025-01-11 12:04:31,734 INFO Added key: store_based_barrier_key:3 to store for rank: 2
2025-01-11 12:04:31,734 INFO Added key: store_based_barrier_key:3 to store for rank: 1
2025-01-11 12:04:31,734 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:3 with 3 nodes.
2025-01-11 12:04:31,734 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 3 nodes.
2025-01-11 12:04:31,734 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:3 with 3 nodes.
2025-01-11 12:04:31,741 INFO Epoch 1 TRAIN info lr 0.0002 rank 0
2025-01-11 12:04:31,741 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:04:31,744 INFO Epoch 1 TRAIN info lr 0.0002 rank 2
2025-01-11 12:04:31,744 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:04:31,745 INFO Epoch 1 TRAIN info lr 0.0002 rank 1
2025-01-11 12:04:31,745 INFO using accumulate grad, new batch size is 1 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 12:06:44,273 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 12:06:44,470 INFO Epoch 1 Step 17 on_batch_end True CV rank 1
2025-01-11 12:06:44,470 INFO Epoch 1 Step 17 on_batch_end True CV rank 0
2025-01-11 12:06:44,470 INFO Epoch 1 Step 17 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 12:06:46,354 INFO Epoch 1 Step 17 CV info lr 0.0002 0 rank loss_113.08677673339844 loss_gen_2.9639010429382324 loss_fm_19.477896690368652 loss_mel_1.5713534355163574 loss_tpr_0.07201311364769936 loss_f0_0.384163573384285
2025-01-11 12:06:46,437 INFO Epoch 1 Step 17 CV info lr 0.0002 2 rank loss_113.08677673339844 loss_gen_2.9639010429382324 loss_fm_19.477896690368652 loss_mel_1.5713534355163574 loss_tpr_0.07201311364769936 loss_f0_0.384163573384285
2025-01-11 12:06:46,499 INFO Epoch 1 Step 17 CV info lr 0.0002 1 rank loss_113.08677673339844 loss_gen_2.9639010429382324 loss_fm_19.477896690368652 loss_mel_1.5713534355163574 loss_tpr_0.07201311364769936 loss_f0_0.384163573384285
2025-01-11 12:06:46,639 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/hifigan/torch_ddp/epoch_1_whole.pt
2025-01-11 12:06:46,661 INFO Added key: store_based_barrier_key:4 to store for rank: 0
2025-01-11 12:06:46,661 INFO Added key: store_based_barrier_key:4 to store for rank: 1
2025-01-11 12:06:46,661 INFO Added key: store_based_barrier_key:4 to store for rank: 2
2025-01-11 12:06:46,661 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:4 with 3 nodes.
2025-01-11 12:06:46,671 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:4 with 3 nodes.
2025-01-11 12:06:46,671 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:4 with 3 nodes.
2025-01-11 12:06:46,672 INFO Epoch 2 TRAIN info lr 0.0002 rank 2
2025-01-11 12:06:46,672 INFO Epoch 2 TRAIN info lr 0.0002 rank 0
2025-01-11 12:06:46,672 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:06:46,672 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:06:46,673 INFO Epoch 2 TRAIN info lr 0.0002 rank 1
2025-01-11 12:06:46,673 INFO using accumulate grad, new batch size is 1 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 12:08:57,208 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 12:08:57,373 INFO Epoch 2 Step 25 on_batch_end True CV rank 1
2025-01-11 12:08:57,373 INFO Epoch 2 Step 25 on_batch_end True CV rank 0
2025-01-11 12:08:57,373 INFO Epoch 2 Step 25 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 12:08:59,403 INFO Epoch 2 Step 25 CV info lr 0.0002 0 rank loss_106.47428512573242 loss_gen_3.0936596393585205 loss_fm_20.914298057556152 loss_mel_1.3550164699554443 loss_tpr_0.20925520360469818 loss_f0_0.36703647673130035
2025-01-11 12:08:59,473 INFO Epoch 2 Step 25 CV info lr 0.0002 2 rank loss_106.47428512573242 loss_gen_3.0936596393585205 loss_fm_20.914298057556152 loss_mel_1.3550164699554443 loss_tpr_0.20925520360469818 loss_f0_0.36703647673130035
2025-01-11 12:08:59,526 INFO Epoch 2 Step 25 CV info lr 0.0002 1 rank loss_115.9172134399414 loss_gen_3.1347930431365967 loss_fm_20.765734672546387 loss_mel_1.5699383616447449 loss_tpr_0.21235834807157516 loss_f0_0.39136849343776703
2025-01-11 12:08:59,676 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/hifigan/torch_ddp/epoch_2_whole.pt
2025-01-11 12:08:59,698 INFO Added key: store_based_barrier_key:5 to store for rank: 0
2025-01-11 12:08:59,708 INFO Added key: store_based_barrier_key:5 to store for rank: 2
2025-01-11 12:08:59,709 INFO Added key: store_based_barrier_key:5 to store for rank: 1
2025-01-11 12:08:59,709 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:5 with 3 nodes.
2025-01-11 12:08:59,709 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:5 with 3 nodes.
2025-01-11 12:08:59,713 INFO Epoch 3 TRAIN info lr 0.0002 rank 1
2025-01-11 12:08:59,713 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:08:59,719 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:5 with 3 nodes.
2025-01-11 12:08:59,725 INFO Epoch 3 TRAIN info lr 0.0002 rank 2
2025-01-11 12:08:59,726 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:08:59,726 INFO Epoch 3 TRAIN info lr 0.0002 rank 0
2025-01-11 12:08:59,726 INFO using accumulate grad, new batch size is 1 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 12:11:10,232 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 12:11:10,384 INFO Epoch 3 Step 33 on_batch_end True CV rank 1
2025-01-11 12:11:10,384 INFO Epoch 3 Step 33 on_batch_end True CV rank 2
2025-01-11 12:11:10,384 INFO Epoch 3 Step 33 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 12:11:12,282 INFO Epoch 3 Step 33 CV info lr 0.0002 0 rank loss_116.22952270507812 loss_gen_4.30903959274292 loss_fm_24.122840881347656 loss_mel_1.4019895195960999 loss_tpr_0.2149304673075676 loss_f0_0.3703422099351883
2025-01-11 12:11:12,345 INFO Epoch 3 Step 33 CV info lr 0.0002 2 rank loss_116.22952270507812 loss_gen_4.30903959274292 loss_fm_24.122840881347656 loss_mel_1.4019895195960999 loss_tpr_0.2149304673075676 loss_f0_0.3703422099351883
2025-01-11 12:11:12,385 INFO Epoch 3 Step 33 CV info lr 0.0002 1 rank loss_116.81492614746094 loss_gen_4.343648433685303 loss_fm_22.98819065093994 loss_mel_1.4646406769752502 loss_tpr_0.212339386343956 loss_f0_0.3737327754497528
2025-01-11 12:11:12,558 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/hifigan/torch_ddp/epoch_3_whole.pt
2025-01-11 12:11:12,570 INFO Added key: store_based_barrier_key:6 to store for rank: 0
2025-01-11 12:11:12,580 INFO Added key: store_based_barrier_key:6 to store for rank: 1
2025-01-11 12:11:12,580 INFO Added key: store_based_barrier_key:6 to store for rank: 2
2025-01-11 12:11:12,580 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:6 with 3 nodes.
2025-01-11 12:11:12,590 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:6 with 3 nodes.
2025-01-11 12:11:12,590 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:6 with 3 nodes.
2025-01-11 12:11:12,594 INFO Epoch 4 TRAIN info lr 0.0002 rank 1
2025-01-11 12:11:12,595 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:11:12,597 INFO Epoch 4 TRAIN info lr 0.0002 rank 2
2025-01-11 12:11:12,597 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:11:12,597 INFO Epoch 4 TRAIN info lr 0.0002 rank 0
2025-01-11 12:11:12,597 INFO using accumulate grad, new batch size is 1 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 12:13:24,524 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 12:13:24,718 INFO Epoch 4 Step 41 on_batch_end True CV rank 1
2025-01-11 12:13:24,718 INFO Epoch 4 Step 41 on_batch_end True CV rank 0
2025-01-11 12:13:24,718 INFO Epoch 4 Step 41 on_batch_end True CV rank 2
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 12:13:26,643 INFO Epoch 4 Step 41 CV info lr 0.0002 0 rank loss_98.59811401367188 loss_gen_3.9106262922286987 loss_fm_21.80282974243164 loss_mel_1.12288498878479 loss_tpr_0.20530381053686142 loss_f0_0.34669676423072815
2025-01-11 12:13:26,692 INFO Epoch 4 Step 41 CV info lr 0.0002 2 rank loss_98.59811401367188 loss_gen_3.9106262922286987 loss_fm_21.80282974243164 loss_mel_1.12288498878479 loss_tpr_0.20530381053686142 loss_f0_0.34669676423072815
2025-01-11 12:13:26,747 INFO Epoch 4 Step 41 CV info lr 0.0002 1 rank loss_98.94346618652344 loss_gen_3.926811695098877 loss_fm_22.125091552734375 loss_mel_1.1158068180084229 loss_tpr_0.20436686277389526 loss_f0_0.35079653561115265
2025-01-11 12:13:26,921 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/hifigan/torch_ddp/epoch_4_whole.pt
2025-01-11 12:13:26,942 INFO Added key: store_based_barrier_key:7 to store for rank: 0
2025-01-11 12:13:26,953 INFO Added key: store_based_barrier_key:7 to store for rank: 1
2025-01-11 12:13:26,953 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:7 with 3 nodes.
2025-01-11 12:13:26,953 INFO Added key: store_based_barrier_key:7 to store for rank: 2
2025-01-11 12:13:26,953 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:7 with 3 nodes.
2025-01-11 12:13:26,954 INFO Epoch 5 TRAIN info lr 0.0002 rank 1
2025-01-11 12:13:26,954 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:13:26,963 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:7 with 3 nodes.
2025-01-11 12:13:26,973 INFO Epoch 5 TRAIN info lr 0.0002 rank 2
2025-01-11 12:13:26,973 INFO Epoch 5 TRAIN info lr 0.0002 rank 0
2025-01-11 12:13:26,973 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:13:26,973 INFO using accumulate grad, new batch size is 1 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 12:15:38,159 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 12:15:38,167 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 12:15:38,338 INFO Epoch 5 Step 49 on_batch_end True CV rank 2
2025-01-11 12:15:38,338 INFO Epoch 5 Step 49 on_batch_end True CV rank 0
2025-01-11 12:15:38,338 INFO Epoch 5 Step 49 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 12:15:40,262 INFO Epoch 5 Step 49 CV info lr 0.0002 0 rank loss_95.84794235229492 loss_gen_3.736914873123169 loss_fm_22.735074996948242 loss_mel_1.0250874161720276 loss_tpr_0.1966240406036377 loss_f0_0.31532222032546997
2025-01-11 12:15:40,348 INFO Epoch 5 Step 49 CV info lr 0.0002 2 rank loss_95.84794235229492 loss_gen_3.736914873123169 loss_fm_22.735074996948242 loss_mel_1.0250874161720276 loss_tpr_0.1966240406036377 loss_f0_0.31532222032546997
2025-01-11 12:15:40,364 INFO Epoch 5 Step 49 CV info lr 0.0002 1 rank loss_94.36758041381836 loss_gen_3.8076670169830322 loss_fm_21.874070167541504 loss_mel_1.0285915732383728 loss_tpr_0.19838818907737732 loss_f0_0.32676512002944946
2025-01-11 12:15:40,537 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/hifigan/torch_ddp/epoch_5_whole.pt
2025-01-11 12:15:40,559 INFO Added key: store_based_barrier_key:8 to store for rank: 0
2025-01-11 12:15:40,569 INFO Added key: store_based_barrier_key:8 to store for rank: 2
2025-01-11 12:15:40,570 INFO Added key: store_based_barrier_key:8 to store for rank: 1
2025-01-11 12:15:40,570 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:8 with 3 nodes.
2025-01-11 12:15:40,573 INFO Epoch 6 TRAIN info lr 0.0002 rank 1
2025-01-11 12:15:40,573 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:15:40,580 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:8 with 3 nodes.
2025-01-11 12:15:40,580 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:8 with 3 nodes.
2025-01-11 12:15:40,584 INFO Epoch 6 TRAIN info lr 0.0002 rank 2
2025-01-11 12:15:40,584 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:15:40,587 INFO Epoch 6 TRAIN info lr 0.0002 rank 0
2025-01-11 12:15:40,587 INFO using accumulate grad, new batch size is 1 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 12:17:51,260 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 12:17:51,439 INFO Epoch 6 Step 57 on_batch_end True CV rank 1
2025-01-11 12:17:51,440 INFO Epoch 6 Step 57 on_batch_end True CV rank 2
2025-01-11 12:17:51,440 INFO Epoch 6 Step 57 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 12:17:53,336 INFO Epoch 6 Step 57 CV info lr 0.0002 0 rank loss_87.09151458740234 loss_gen_3.2320144176483154 loss_fm_18.73495101928711 loss_mel_1.0206242799758911 loss_tpr_0.1088719330728054 loss_f0_0.35262492299079895
2025-01-11 12:17:53,379 INFO Epoch 6 Step 57 CV info lr 0.0002 2 rank loss_87.09151458740234 loss_gen_3.2320144176483154 loss_fm_18.73495101928711 loss_mel_1.0206242799758911 loss_tpr_0.1088719330728054 loss_f0_0.35262492299079895
2025-01-11 12:17:53,437 INFO Epoch 6 Step 57 CV info lr 0.0002 1 rank loss_79.40440368652344 loss_gen_3.2057085037231445 loss_fm_16.091108798980713 loss_mel_0.9693312346935272 loss_tpr_0.07206723093986511 loss_f0_0.32450544834136963
2025-01-11 12:17:53,660 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/hifigan/torch_ddp/epoch_6_whole.pt
2025-01-11 12:17:53,682 INFO Added key: store_based_barrier_key:9 to store for rank: 0
2025-01-11 12:17:53,692 INFO Added key: store_based_barrier_key:9 to store for rank: 2
2025-01-11 12:17:53,692 INFO Added key: store_based_barrier_key:9 to store for rank: 1
2025-01-11 12:17:53,692 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:9 with 3 nodes.
2025-01-11 12:17:53,693 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:9 with 3 nodes.
2025-01-11 12:17:53,694 INFO Epoch 7 TRAIN info lr 0.0002 rank 1
2025-01-11 12:17:53,694 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:17:53,702 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:9 with 3 nodes.
2025-01-11 12:17:53,709 INFO Epoch 7 TRAIN info lr 0.0002 rank 2
2025-01-11 12:17:53,709 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:17:53,710 INFO Epoch 7 TRAIN info lr 0.0002 rank 0
2025-01-11 12:17:53,710 INFO using accumulate grad, new batch size is 1 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
2025-01-11 12:20:06,749 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 12:20:06,750 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 12:20:06,937 INFO Epoch 7 Step 65 on_batch_end True CV rank 0
2025-01-11 12:20:06,937 INFO Epoch 7 Step 65 on_batch_end True CV rank 2
2025-01-11 12:20:06,937 INFO Epoch 7 Step 65 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 12:20:08,878 INFO Epoch 7 Step 65 CV info lr 0.0002 0 rank loss_81.91658401489258 loss_gen_2.857914924621582 loss_fm_19.075719833374023 loss_mel_0.8996544182300568 loss_tpr_0.0846366360783577 loss_f0_0.33814747631549835
2025-01-11 12:20:08,910 INFO Epoch 7 Step 65 CV info lr 0.0002 2 rank loss_81.91658401489258 loss_gen_2.857914924621582 loss_fm_19.075719833374023 loss_mel_0.8996544182300568 loss_tpr_0.0846366360783577 loss_f0_0.33814747631549835
2025-01-11 12:20:08,944 INFO Epoch 7 Step 65 CV info lr 0.0002 1 rank loss_86.76723861694336 loss_gen_2.9140751361846924 loss_fm_20.663582801818848 loss_mel_0.9356962442398071 loss_tpr_0.09388449788093567 loss_f0_0.3257826268672943
2025-01-11 12:20:09,171 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/hifigan/torch_ddp/epoch_7_whole.pt
2025-01-11 12:20:09,192 INFO Added key: store_based_barrier_key:10 to store for rank: 0
2025-01-11 12:20:09,193 INFO Added key: store_based_barrier_key:10 to store for rank: 2
2025-01-11 12:20:09,193 INFO Added key: store_based_barrier_key:10 to store for rank: 1
2025-01-11 12:20:09,193 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:10 with 3 nodes.
2025-01-11 12:20:09,198 INFO Epoch 8 TRAIN info lr 0.0002 rank 1
2025-01-11 12:20:09,198 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:20:09,203 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:10 with 3 nodes.
2025-01-11 12:20:09,203 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:10 with 3 nodes.
2025-01-11 12:20:09,206 INFO Epoch 8 TRAIN info lr 0.0002 rank 2
2025-01-11 12:20:09,206 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:20:09,213 INFO Epoch 8 TRAIN info lr 0.0002 rank 0
2025-01-11 12:20:09,213 INFO using accumulate grad, new batch size is 1 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 12:22:19,654 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 12:22:19,836 INFO Epoch 8 Step 73 on_batch_end True CV rank 1
2025-01-11 12:22:19,837 INFO Epoch 8 Step 73 on_batch_end True CV rank 2
2025-01-11 12:22:19,837 INFO Epoch 8 Step 73 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 12:22:21,782 INFO Epoch 8 Step 73 CV info lr 0.0002 0 rank loss_87.28543472290039 loss_gen_3.4658682346343994 loss_fm_21.71734046936035 loss_mel_0.8874235153198242 loss_tpr_0.09377926960587502 loss_f0_0.3570486903190613
2025-01-11 12:22:21,842 INFO Epoch 8 Step 73 CV info lr 0.0002 2 rank loss_87.28543472290039 loss_gen_3.4658682346343994 loss_fm_21.71734046936035 loss_mel_0.8874235153198242 loss_tpr_0.09377926960587502 loss_f0_0.3570486903190613
2025-01-11 12:22:21,888 INFO Epoch 8 Step 73 CV info lr 0.0002 1 rank loss_85.62821960449219 loss_gen_3.5915666818618774 loss_fm_20.71579647064209 loss_mel_0.8923672437667847 loss_tpr_0.11483956128358841 loss_f0_0.33369405567646027
2025-01-11 12:22:22,081 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/hifigan/torch_ddp/epoch_8_whole.pt
2025-01-11 12:22:22,092 INFO Added key: store_based_barrier_key:11 to store for rank: 0
2025-01-11 12:22:22,103 INFO Added key: store_based_barrier_key:11 to store for rank: 1
2025-01-11 12:22:22,103 INFO Added key: store_based_barrier_key:11 to store for rank: 2
2025-01-11 12:22:22,103 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:11 with 3 nodes.
2025-01-11 12:22:22,103 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:11 with 3 nodes.
2025-01-11 12:22:22,107 INFO Epoch 9 TRAIN info lr 0.0002 rank 1
2025-01-11 12:22:22,107 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:22:22,113 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:11 with 3 nodes.
2025-01-11 12:22:22,120 INFO Epoch 9 TRAIN info lr 0.0002 rank 2
2025-01-11 12:22:22,120 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:22:22,120 INFO Epoch 9 TRAIN info lr 0.0002 rank 0
2025-01-11 12:22:22,120 INFO using accumulate grad, new batch size is 1 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 12:24:34,041 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 12:24:34,042 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 12:24:34,233 INFO Epoch 9 Step 81 on_batch_end True CV rank 0
2025-01-11 12:24:34,233 INFO Epoch 9 Step 81 on_batch_end True CV rank 2
2025-01-11 12:24:34,233 INFO Epoch 9 Step 81 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 12:24:36,190 INFO Epoch 9 Step 81 CV info lr 0.0002 0 rank loss_87.39591979980469 loss_gen_3.477313280105591 loss_fm_20.442753791809082 loss_mel_0.9463785588741302 loss_tpr_0.09957689791917801 loss_f0_0.34648409485816956
2025-01-11 12:24:36,263 INFO Epoch 9 Step 81 CV info lr 0.0002 1 rank loss_86.32699584960938 loss_gen_3.47388231754303 loss_fm_19.88906764984131 loss_mel_0.9472241401672363 loss_tpr_0.10135903209447861 loss_f0_0.3485306650400162
2025-01-11 12:24:36,281 INFO Epoch 9 Step 81 CV info lr 0.0002 2 rank loss_87.39591979980469 loss_gen_3.477313280105591 loss_fm_20.442753791809082 loss_mel_0.9463785588741302 loss_tpr_0.09957689791917801 loss_f0_0.34648409485816956
2025-01-11 12:24:36,513 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/hifigan/torch_ddp/epoch_9_whole.pt
2025-01-11 12:24:36,525 INFO Added key: store_based_barrier_key:12 to store for rank: 0
2025-01-11 12:24:36,535 INFO Added key: store_based_barrier_key:12 to store for rank: 1
2025-01-11 12:24:36,535 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:12 with 3 nodes.
2025-01-11 12:24:36,535 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:12 with 3 nodes.
2025-01-11 12:24:36,535 INFO Added key: store_based_barrier_key:12 to store for rank: 2
2025-01-11 12:24:36,535 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:12 with 3 nodes.
2025-01-11 12:24:36,538 INFO Epoch 10 TRAIN info lr 0.0002 rank 1
2025-01-11 12:24:36,538 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:24:36,539 INFO Epoch 10 TRAIN info lr 0.0002 rank 0
2025-01-11 12:24:36,539 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:24:36,543 INFO Epoch 10 TRAIN info lr 0.0002 rank 2
2025-01-11 12:24:36,543 INFO using accumulate grad, new batch size is 1 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 12:27:06,128 INFO Detected uneven workload distribution: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:133] Timed out waiting 60000ms for send operation to complete
Break current worker to manually join all workers, world_size 3, current rank 1, current local_rank 1

2025-01-11 12:27:06,311 INFO Epoch 10 Step 89 on_batch_end True CV rank 1
2025-01-11 12:27:06,311 INFO Epoch 10 Step 89 on_batch_end True CV rank 2
2025-01-11 12:27:06,311 INFO Epoch 10 Step 89 on_batch_end True CV rank 0
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 12:27:08,189 INFO Epoch 10 Step 89 CV info lr 0.0002 0 rank loss_85.74173736572266 loss_gen_2.918254852294922 loss_fm_21.263940811157227 loss_mel_0.8859096169471741 loss_tpr_0.10671771690249443 loss_f0_0.3229518234729767
2025-01-11 12:27:08,253 INFO Epoch 10 Step 89 CV info lr 0.0002 2 rank loss_85.74173736572266 loss_gen_2.918254852294922 loss_fm_21.263940811157227 loss_mel_0.8859096169471741 loss_tpr_0.10671771690249443 loss_f0_0.3229518234729767
2025-01-11 12:27:08,304 INFO Epoch 10 Step 89 CV info lr 0.0002 1 rank loss_85.87862396240234 loss_gen_2.9043564796447754 loss_fm_21.49559211730957 loss_mel_0.8794455230236053 loss_tpr_0.1077510342001915 loss_f0_0.30028465390205383
2025-01-11 12:27:08,483 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/hifigan/torch_ddp/epoch_10_whole.pt
2025-01-11 12:27:08,495 INFO Added key: store_based_barrier_key:13 to store for rank: 0
2025-01-11 12:27:08,505 INFO Added key: store_based_barrier_key:13 to store for rank: 1
2025-01-11 12:27:08,505 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:13 with 3 nodes.
2025-01-11 12:27:08,505 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:13 with 3 nodes.
2025-01-11 12:27:08,505 INFO Added key: store_based_barrier_key:13 to store for rank: 2
2025-01-11 12:27:08,505 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:13 with 3 nodes.
2025-01-11 12:27:08,514 INFO Epoch 11 TRAIN info lr 0.0002 rank 1
2025-01-11 12:27:08,514 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:27:08,515 INFO Epoch 11 TRAIN info lr 0.0002 rank 2
2025-01-11 12:27:08,516 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:27:08,516 INFO Epoch 11 TRAIN info lr 0.0002 rank 0
2025-01-11 12:27:08,516 INFO using accumulate grad, new batch size is 1 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 12:29:19,670 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 12:29:19,674 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 12:29:19,856 INFO Epoch 11 Step 97 on_batch_end True CV rank 0
2025-01-11 12:29:19,856 INFO Epoch 11 Step 97 on_batch_end True CV rank 2
2025-01-11 12:29:19,856 INFO Epoch 11 Step 97 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 12:29:21,801 INFO Epoch 11 Step 97 CV info lr 0.0002 0 rank loss_83.69940948486328 loss_gen_3.905231237411499 loss_fm_20.560245513916016 loss_mel_0.8479922115802765 loss_tpr_0.17421606928110123 loss_f0_0.3398202359676361
2025-01-11 12:29:21,856 INFO Epoch 11 Step 97 CV info lr 0.0002 2 rank loss_83.69940948486328 loss_gen_3.905231237411499 loss_fm_20.560245513916016 loss_mel_0.8479922115802765 loss_tpr_0.17421606928110123 loss_f0_0.3398202359676361
2025-01-11 12:29:21,925 INFO Epoch 11 Step 97 CV info lr 0.0002 1 rank loss_89.18115615844727 loss_gen_3.879443883895874 loss_fm_22.62484359741211 loss_mel_0.8782784938812256 loss_tpr_0.19221332669258118 loss_f0_0.33727526664733887
2025-01-11 12:29:22,078 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/hifigan/torch_ddp/epoch_11_whole.pt
2025-01-11 12:29:22,100 INFO Added key: store_based_barrier_key:14 to store for rank: 0
2025-01-11 12:29:22,111 INFO Added key: store_based_barrier_key:14 to store for rank: 1
2025-01-11 12:29:22,111 INFO Added key: store_based_barrier_key:14 to store for rank: 2
2025-01-11 12:29:22,111 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:14 with 3 nodes.
2025-01-11 12:29:22,111 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:14 with 3 nodes.
2025-01-11 12:29:22,114 INFO Epoch 12 TRAIN info lr 0.0002 rank 1
2025-01-11 12:29:22,115 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:29:22,117 INFO Epoch 12 TRAIN info lr 0.0002 rank 2
2025-01-11 12:29:22,118 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:29:22,121 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:14 with 3 nodes.
2025-01-11 12:29:22,127 INFO Epoch 12 TRAIN info lr 0.0002 rank 0
2025-01-11 12:29:22,128 INFO using accumulate grad, new batch size is 1 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
[E ProcessGroupGloo.cpp:138] [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
2025-01-11 12:31:59,137 INFO Detected uneven workload distribution: [Rank 0]: Rank 1 failed to pass monitoredBarrier in 60000 ms
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 0, current local_rank 0

2025-01-11 12:31:59,141 INFO Detected uneven workload distribution: Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 60000ms for recv operation to complete
Break current worker to manually join all workers, world_size 3, current rank 2, current local_rank 2

2025-01-11 12:31:59,333 INFO Epoch 12 Step 105 on_batch_end True CV rank 2
2025-01-11 12:31:59,333 INFO Epoch 12 Step 105 on_batch_end True CV rank 0
2025-01-11 12:31:59,333 INFO Epoch 12 Step 105 on_batch_end True CV rank 1
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
2025-01-11 12:32:01,456 INFO Epoch 12 Step 105 CV info lr 0.0002 0 rank loss_91.52598571777344 loss_gen_3.8622026443481445 loss_fm_24.090601921081543 loss_mel_0.8657037913799286 loss_tpr_0.20411628484725952 loss_f0_0.32179322838783264
2025-01-11 12:32:01,503 INFO Epoch 12 Step 105 CV info lr 0.0002 2 rank loss_91.52598571777344 loss_gen_3.8622026443481445 loss_fm_24.090601921081543 loss_mel_0.8657037913799286 loss_tpr_0.20411628484725952 loss_f0_0.32179322838783264
2025-01-11 12:32:01,551 INFO Epoch 12 Step 105 CV info lr 0.0002 1 rank loss_83.29755020141602 loss_gen_3.8338860273361206 loss_fm_20.876551628112793 loss_mel_0.8268807828426361 loss_tpr_0.17290830612182617 loss_f0_0.32801876962184906
2025-01-11 12:32:01,749 INFO [Rank 0] Checkpoint: save to checkpoint /data/minju/TTS/CosyVoice/examples/libritts/cosyvoice/exp/250110-slx/hifigan/torch_ddp/epoch_12_whole.pt
2025-01-11 12:32:01,771 INFO Added key: store_based_barrier_key:15 to store for rank: 0
2025-01-11 12:32:01,771 INFO Added key: store_based_barrier_key:15 to store for rank: 1
2025-01-11 12:32:01,772 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:15 with 3 nodes.
2025-01-11 12:32:01,771 INFO Added key: store_based_barrier_key:15 to store for rank: 2
2025-01-11 12:32:01,772 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:15 with 3 nodes.
2025-01-11 12:32:01,777 INFO Epoch 13 TRAIN info lr 0.0002 rank 1
2025-01-11 12:32:01,777 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:32:01,779 INFO Epoch 13 TRAIN info lr 0.0002 rank 2
2025-01-11 12:32:01,780 INFO using accumulate grad, new batch size is 1 times larger than before
2025-01-11 12:32:01,781 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:15 with 3 nodes.
2025-01-11 12:32:01,789 INFO Epoch 13 TRAIN info lr 0.0002 rank 0
2025-01-11 12:32:01,790 INFO using accumulate grad, new batch size is 1 times larger than before
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/tokenizer.py:333: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/whisper/assets/multilingual.tiktoken' mode='r' encoding='UTF-8'>
  ranks = {
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: -9) local_rank: 0 (pid: 107306) of binary: /data/minju/conda/envs/cosyvoice/bin/python
Traceback (most recent call last):
  File "/data/minju/conda/envs/cosyvoice/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/minju/conda/envs/cosyvoice/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
cosyvoice/bin/train.py FAILED
-------------------------------------------------------
Failures:
[1]:
  time      : 2025-01-11_12:33:59
  host      : eb1fef6b7453
  rank      : 1 (local_rank: 1)
  exitcode  : -9 (pid: 107307)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 107307
[2]:
  time      : 2025-01-11_12:33:59
  host      : eb1fef6b7453
  rank      : 2 (local_rank: 2)
  exitcode  : -9 (pid: 107308)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 107308
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-01-11_12:33:59
  host      : eb1fef6b7453
  rank      : 0 (local_rank: 0)
  exitcode  : -9 (pid: 107306)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 107306
=======================================================
